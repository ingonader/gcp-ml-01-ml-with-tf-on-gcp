1
00:00:00,000 --> 00:00:02,025
Nehmen wir ein Beispiel.

2
00:00:02,025 --> 00:00:03,525
Wie wäre es mit Immobilien?

3
00:00:03,525 --> 00:00:05,880
Können wir den Preis
einer Immobilie vorhersagen?

4
00:00:05,880 --> 00:00:08,160
Wir müssen zuerst die Features wählen.

5
00:00:08,160 --> 00:00:11,475
Auf diesen Daten basieren die Vorhersagen.

6
00:00:11,475 --> 00:00:14,625
Versuchen wir es mit
einem Modell, dass den Preis

7
00:00:14,625 --> 00:00:18,160
basierend auf der Größe
des Hauses oder der Wohnung vorhersagt.

8
00:00:18,160 --> 00:00:20,310
Als Features wählen wir erstens,

9
00:00:20,310 --> 00:00:22,410
die Wohnfläche, und zweitens,

10
00:00:22,410 --> 00:00:25,225
die Kategorie Haus oder Wohnung.

11
00:00:25,225 --> 00:00:27,435
So wir das implementiert:

12
00:00:27,435 --> 00:00:31,275
Wir verwenden die Feature Column API,
um die Features zu definieren.

13
00:00:31,275 --> 00:00:34,500
Zuerst nehmen wir
eine Nummernspalte für die Wohnfläche,

14
00:00:34,500 --> 00:00:38,125
dann eine Kategoriespalte
für die Immobilienart.

15
00:00:38,125 --> 00:00:42,670
Dieses einfache Modell
hat zwei Kategorien, Haus oder Wohnung.

16
00:00:42,670 --> 00:00:46,049
Jetzt können wir
einen linearen Regressor instanziieren,

17
00:00:46,049 --> 00:00:49,315
einen der vorgefertigten
Estimators für diese Features.

18
00:00:49,315 --> 00:00:52,230
Ein Regressor ist
ein Modell, das eine Zahl ausgibt,

19
00:00:52,230 --> 00:00:56,090
in diesem Fall eine Vorhersage
des Verkaufspreises für eine Immobilie.

20
00:00:56,090 --> 00:00:58,785
Aber wozu brauchen wir die Featurespalten?

21
00:00:58,785 --> 00:01:01,335
Sehen wir uns den Mechanismus dahinter an.

22
00:01:01,335 --> 00:01:05,325
Ein linearer Regressor ist ein Modell,
das mit einem Datenvektor arbeitet.

23
00:01:05,325 --> 00:01:09,540
Es berechnet die gewichtete
Summe aller eingegebenen Datenelemente

24
00:01:09,540 --> 00:01:14,255
und kann darauf trainiert werden,
die Gewichtung an Ihr Problem anzupassen,

25
00:01:14,255 --> 00:01:16,845
hier die Vorhersage des Verkaufspreises.

26
00:01:16,845 --> 00:01:21,825
Wie bekommen wir die Daten
in den einzelnen Eingabevektor,

27
00:01:21,825 --> 00:01:24,225
den der lineare Regressor erwartet?

28
00:01:24,225 --> 00:01:29,160
Die Antwort hängt von
den eingegebenen Daten ab,

29
00:01:29,160 --> 00:01:33,420
daher hilft uns hier
die Feature Columns API.

30
00:01:33,420 --> 00:01:38,720
Sie implementiert Standardmethoden,
um Daten in Vektorelemente einzufügen.

31
00:01:38,720 --> 00:01:42,090
Hier sind die Werte
in einer Nummernspalte nur Zahlen.

32
00:01:42,090 --> 00:01:48,620
Sie können unverändert in ein einzelnes
Element des Eingabevektors kopiert werden.

33
00:01:48,620 --> 00:01:53,475
Die Kategorienspalte
hingegen wird one-hot-codiert.

34
00:01:53,475 --> 00:01:56,045
Wir haben zwei Kategorien.

35
00:01:56,045 --> 00:01:57,975
Daher wird "Haus" zu 1, 0

36
00:01:57,975 --> 00:02:00,650
und "Wohnung" wird zu 0, 1.

37
00:02:00,650 --> 00:02:02,445
Eine dritte Kategorie

38
00:02:02,445 --> 00:02:04,740
würde zu 0, 0, 1 werden und so weiter.

39
00:02:04,740 --> 00:02:10,030
Jetzt weiß der lineare Regressor,
welche Features uns wichtig sind,

40
00:02:10,030 --> 00:02:12,185
kann sie in einen Eingabevektor einfügen

41
00:02:12,185 --> 00:02:15,830
und das tun,
was ein linearer Regressor tut.

42
00:02:15,830 --> 00:02:20,020
Es gibt viele weitere Arten
von Featurespalten zur Auswahl,

43
00:02:20,020 --> 00:02:23,500
Spalten für kontinuierliche
Werte, die in ein Bucket sollen,

44
00:02:23,500 --> 00:02:27,190
Worteinbettungen,
Spaltenkreuzungen und so weiter.

45
00:02:27,190 --> 00:02:31,470
Die angewendeten Transformationen sind in
der TensorFlow-Dokumentation beschrieben,

46
00:02:31,470 --> 00:02:34,360
sodass Sie dort immer nachlesen können.

47
00:02:34,360 --> 00:02:36,350
Für das Modelltraining

48
00:02:36,350 --> 00:02:38,450
müssen wir eine Eingabefunktion schreiben,

49
00:02:38,450 --> 00:02:42,550
die die Features
wie in der Featurespalte benannt ausgibt.

50
00:02:42,550 --> 00:02:46,580
Dies ist ein Training, also brauchen wir
auch die richtigen Antworten, die Labels.

51
00:02:46,580 --> 00:02:51,575
Jetzt können wir die
Trainingsfunktion des Estimators aufrufen,

52
00:02:51,575 --> 00:02:56,470
die das Modell trainiert,
indem sie das Dataset 100 Mal wiederholt.

53
00:02:56,470 --> 00:02:59,305
Wir betrachten später,
wie Batching funktioniert,

54
00:02:59,305 --> 00:03:04,540
aber für die von Ihnen,
die damit schon vertraut sind:

55
00:03:04,540 --> 00:03:08,960
der hier gezeigte Code
trainiert mit einem einzelnen Datenbatch

56
00:03:08,960 --> 00:03:12,370
bei jedem Schritt, und dieses
Batch enthält das gesamte Dataset.

57
00:03:12,370 --> 00:03:16,005
Nach dem Training kann das Modell
für Vorhersagen genutzt werden.

58
00:03:16,005 --> 00:03:19,950
Wir brauchen eine Eingabefunktion,
die Daten für die Vorhersage bietet, hier

59
00:03:19,950 --> 00:03:24,680
ein 140-Quadratmeter-Haus
und eine 170-Quadratmeter-Wohnung.

60
00:03:24,680 --> 00:03:28,660
Die Vorhersagefunktion der Estimator API

61
00:03:28,660 --> 00:03:32,810
gibt einen Python-Generator für
Iterationen der Vorhersagen zurück.

62
00:03:32,810 --> 00:03:37,120
Folgendes wissen wir
schon über die Estimator API:

63
00:03:37,120 --> 00:03:41,435
Die Daten wurden mit
Featurespalten in eine Form gebracht,

64
00:03:41,435 --> 00:03:43,725
die das Modell versteht.

65
00:03:43,725 --> 00:03:48,270
Basierend auf den Featurespalten
wurde ein linearer Regressor instanziiert

66
00:03:48,270 --> 00:03:52,545
und mit dem Aufruf "train"
das Modell für 100 Schritte trainiert.

67
00:03:52,545 --> 00:03:56,960
Trainingsdaten werden über
die Dateneingabefunktion eingespeist

68
00:03:56,960 --> 00:04:00,530
und "predict" aufgerufen, um
Vorhersagen zu erhalten, für die die Daten

69
00:04:00,530 --> 00:04:03,760
wiederum aus einer
Dateneingabefunktion stammen.

70
00:04:03,760 --> 00:04:08,200
Diese besprechen wir
später im Kurs genauer.

71
00:04:08,200 --> 00:04:11,595
Für einen anderen
vorgefertigten Estimator müssen Sie nur

72
00:04:11,595 --> 00:04:15,330
den Klassennamen ändern und
geeignete Konfigurationsparameter angeben.

73
00:04:15,330 --> 00:04:18,329
Wir könnten etwa ein
dichtes neuronales Netzwerk,

74
00:04:18,329 --> 00:04:21,000
einen Regressor und
zwei versteckten Schichten verwenden.

75
00:04:21,000 --> 00:04:23,155
Die erste hat drei Neuronen,

76
00:04:23,155 --> 00:04:24,650
die zweite nur zwei

77
00:04:24,650 --> 00:04:28,930
und am Schluss sagt ein einzelnes
Neuron den Immobilienpreis voraus.

78
00:04:28,930 --> 00:04:32,415
Beachten Sie, dass der Eingabevektor
für beide Modelle derselbe ist.

79
00:04:32,415 --> 00:04:35,190
Wir können dieselben
Featurespalten wiederverwenden.

80
00:04:35,190 --> 00:04:39,840
Hier sind einige Punkte, die Sie in 
dichten neuronalen Netzen anpassen können:

81
00:04:39,840 --> 00:04:41,840
Anzahl und Größe
der versteckten Schichten,

82
00:04:41,840 --> 00:04:44,130
Wahl der Aktivierungsfunktion,

83
00:04:44,130 --> 00:04:50,025
regulierende Parameter, wie "Löschen" oder
ein Optimierer zur Trainingssteigerung.

84
00:04:50,025 --> 00:04:55,175
Am Wichtigsten ist,
dass alle gute Standardwerte bieten.

85
00:04:55,175 --> 00:04:56,910
Für einen DNN-Regressor

86
00:04:56,910 --> 00:05:00,560
sind als Einziges die
versteckte Schichten Pflichtparameter.