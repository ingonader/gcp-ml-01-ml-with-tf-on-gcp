1
00:00:00,000 --> 00:00:05,076
Vamos começar explorando os componentes
da API Estimator e lidando com

2
00:00:05,076 --> 00:00:11,230
outras tarefas comuns de AM, como treino
distribuído, monitoramento e serviço.

3
00:00:11,230 --> 00:00:15,100
Os estimadores fazem parte das APIs
de alto nível do TensorFlow.

4
00:00:15,100 --> 00:00:18,630
O primeiro contato com o
TensorFlow no módulo anterior

5
00:00:18,630 --> 00:00:20,920
foi no nível Core TensorFlow.

6
00:00:20,920 --> 00:00:24,920
Mas você usa o TensorFlow essencialmente
como biblioteca de processamento numérico.

7
00:00:24,920 --> 00:00:29,440
Abaixo desse nível, há uma série de APIs
com as quais você não costuma interagir.

8
00:00:29,440 --> 00:00:32,740
Elas lidam com hardware, CPUs,
GPUs, TPUs ou

9
00:00:32,740 --> 00:00:35,410
plataformas alternativas, como o Android.

10
00:00:35,410 --> 00:00:38,050
Acima do Core TensorFlow, você
encontrará APIs para

11
00:00:38,050 --> 00:00:40,970
todos os tijolos necessários
para criar um modelo.

12
00:00:40,970 --> 00:00:45,160
Diferentes tipos de camadas de redes 
neurais, diferentes funções de perda etc.

13
00:00:45,160 --> 00:00:48,880
E, para finalizar tudo, estimadores.

14
00:00:48,880 --> 00:00:53,344
Um modelo TensorFlow de nível iniciante
envolve duas camadas elétricas neurais

15
00:00:53,344 --> 00:00:54,864
e um loop de treinamento.

16
00:00:54,864 --> 00:00:57,850
Você pode pensar: por que eu
precisaria de ajuda com isso?

17
00:00:57,850 --> 00:00:59,990
Sou um desenvolvedor, 
posso escrever um loop.

18
00:00:59,990 --> 00:01:03,080
Eu concordo com você,
mas agora,

19
00:01:03,080 --> 00:01:08,050
mesmo para modelos minúsculos de
prototipagem, costumo usar estimadores.

20
00:01:08,050 --> 00:01:10,700
Eu gosto do fato de eles
serem intercambiáveis e

21
00:01:10,700 --> 00:01:15,100
possibilitam testar modelos padrão
pré-fabricados em rápida sucessão.

22
00:01:16,560 --> 00:01:20,930
Conforme dados e tempo de treino crescem,
também aumentam as necessidades.

23
00:01:20,930 --> 00:01:24,170
Você precisa de pontos de verificação para
pausar e retomar o treino?

24
00:01:24,170 --> 00:01:25,790
Os estimadores têm isso.

25
00:01:25,790 --> 00:01:27,840
Os dados não se ajustam 
mais à memória?

26
00:01:27,840 --> 00:01:33,090
Estimadores têm uma API que manipula
conjuntos de dados fora da memória.

27
00:01:33,090 --> 00:01:36,180
Você não pode treinar uma grande rede
sem ver como ela está indo.

28
00:01:36,180 --> 00:01:40,210
Estimadores exibem automaticamente
as métricas importantes durante o treino e

29
00:01:40,210 --> 00:01:42,150
você pode visualizá-las no TensorBoard.

30
00:01:42,150 --> 00:01:44,670
Pensou em
treinamento distribuído?

31
00:01:44,670 --> 00:01:49,410
Estimadores vêm com o código de execução
de cluster necessário já incorporado.

32
00:01:49,410 --> 00:01:53,012
E, por fim, você vai querer envolver
o modelo e torná-lo pronto para

33
00:01:53,012 --> 00:01:56,880
o ajuste de hiperparâmetro do ML Engine,
e talvez também colocá-lo em produção

34
00:01:56,880 --> 00:02:00,880
atrás da previsão gerenciada com
escalonamento automático do ML Engine.

35
00:02:00,880 --> 00:02:04,040
A API Estimator também faz isso.

36
00:02:04,040 --> 00:02:08,009
Você ainda quer gravar seu
loop de treinamento com

37
00:02:08,009 --> 00:02:12,240
toda essa funcionalidade de código 
boilerplate repetida toda vez?

38
00:02:12,240 --> 00:02:16,330
Imagino que não. Então vamos dar
uma olhada nesta API.

39
00:02:17,600 --> 00:02:22,388
O estimador de classe base permite
envolver seu próprio modelo, que você

40
00:02:22,388 --> 00:02:25,480
criaria a partir de camadas
usando a API TF Layers.

41
00:02:25,480 --> 00:02:29,520
Mas se você está criando algo
relativamente padrão, não precisa disso.

42
00:02:29,520 --> 00:02:34,140
O TensorFlow possui um conjunto de
estimadores pré-fabricados para teste.

43
00:02:34,140 --> 00:02:39,230
Classificadores de redes neurais lineares
ou densas para rotular dados em categorias

44
00:02:39,230 --> 00:02:43,120
e regressores semelhantes para
prever valores contínuos.

45
00:02:43,120 --> 00:02:48,480
Não esqueça o DNNLinearCombinedClassifier,
também conhecido como

46
00:02:48,480 --> 00:02:53,510
modelo amplo e profundo, de acordo com
o estudo do Google que o popularizou.

47
00:02:53,510 --> 00:02:55,610
Este não é trivial, e
usamos, por exemplo,

48
00:02:55,610 --> 00:02:59,300
para alimentar o mecanismo de
recomendação no Google Play.

49
00:02:59,300 --> 00:03:00,810
Mas é muito flexível e

50
00:03:00,810 --> 00:03:06,096
tem sido descrito como o burro de carga
do aprendizado de máquina empresarial.

51
00:03:06,096 --> 00:03:10,760
Funciona para todos os dados de
estrutura e já está pronto para uso.

52
00:03:10,760 --> 00:03:14,535
Apenas lembre que,
graças à API comum,

53
00:03:14,535 --> 00:03:17,550
os estimadores pré-fabricados
são intercambiáveis.

54
00:03:17,550 --> 00:03:19,370
É fácil testar todos eles.