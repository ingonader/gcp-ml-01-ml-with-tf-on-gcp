Let's start by exploring the components
of the Estimator API, and how to handle other common ML tasks, such as distributed
training, monitoring, and serving. Estimators are a part of
the high level TensorFlow APIs. Your first contact with
TensorFlow in the previous module was at the Core TensorFlow level. But you essentially use TensorFlow
as a numeric processing library. Below this level sits a series of APIs
that you do not typically interact with. They handle the hardware,
CPUs, GPUs, TPUs, or alternative platforms like Android. Above Core TensorFlow,
you will find APIs for all the typical bricks
needed to build a model. Different kinds of neural network layers,
different loss functions, and so on. And finally,
to wrap it all up, Estimators. A beginner level TensorFlow model usually
involves a couple of neural electric layers and a training loop. And you might be thinking,
why would I need help with that? I'm a developer, I can write a loop. And I tend to agree with you, but now for even tiny prototyping models
I tend to use estimators. I like the fact that they
are interchangeable and let me test many standard pre-made
estimator models in quick succession. As data and training time grows,
however, your needs will increase. Do you need checkpoints to pause and
resume your training? Estimators have them. Your data no longer fits in memory? Estimators are designed with a data set
API that handles out of memory data sets. You can not train a large network
without seeing how its doing. Estimators automatically surface key
metrics during training that you can visualize in Tensor board. Are you thinking now about
distributed training? Estimators come with the necessary
cluster execution code already built in. And finally, you will want to wrap
your model to make it ready for ML-Engine's hyper-parameter tuning,
and maybe also push it to production behind ML-Engine's managed
and autoscaled prediction service. The Estimator API has you
covered there as well. Now, tell me, do you still want to
write your training loop yourself with all this boiler plate code
functionality repeat it every time? I thought not, so let us have our
first look at this estimator API. The base class estimator lets you
wrap your own model that you would build from layers using the TF layers API. But if you're building something
fairly standard, no need to go there. TensorFlow has a set of pre-made
estimators that you can try out. Linear or dense neural network classifiers
to classify data into categories, and similar regressors to
predict continuous values. And don't also forget the
DNNLinearCombinedClassifier, also known as the wide and deep model according to the
Google research paper that popularized it. This one is not trivial, we use it for example to power the recommendation
engine in Google Play. But it is very flexible and has times been described as the work
horse of Enterprise Machine Learning. It works for all kinds of structure
data and you can use it out of the box. The one thing to remember is
that thanks to common API, pre-made estimators are interchangeable. It is easy to try and test them all.