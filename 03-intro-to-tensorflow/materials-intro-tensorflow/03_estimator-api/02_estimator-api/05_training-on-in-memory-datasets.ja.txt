Estimator APIの説明で使った定数ではなく
実際のデータを考えましょう データがnumpy配列またはpandasの形で
メモリに収まっている場合 データをモデルにフィードする便利な関数が Estimator APIに備わっています estimator.inputs.numpy_input_fnと
estimator.inputs.pandas_input_fnです 特徴辞書をxとして指定し
features_columnのときと同じ名前を使います labelsはyとして指定します pandasから読み込むとき 特徴の名前は必要ありません APIはfeature_columnの定義で
使われた名前に基づき 正しいカラムを
pandasデータフレームから取り出します これらのinput関数は ニューラルネットワーク モデルを
トレーニングする主な機能を実装します 通常 トレーニングが最もうまくいくのは ステップで入力データのミニバッチを
1度に1つずつ実行する場合です 1つのデータ項目でも
データセット全体でもありません バッチサイズをここで指定できます また トレーニング中にデータセットを
繰り返す回数も指定でき これをエポック数といいます そして トレーニングデータを
徹底的にシャッフルすることが重要です Estimator APIでそれを行うことができます その際 データセットがメモリ内に
複製されるのを防ぐには シャッフルキューのサイズを指定できます デフォルトでは トレーニングデータを
すべて使用するまでトレーニングします またはinput関数のエポック数がnの場合は
n回使用します これをオーバーライドできます つまりtrain関数を呼び出すときに
ステップ数を明示的に指定できます ステップを設定する2つの変数があります まずsteps=1000は 前回のチェックポイントから1,000回の
追加的なステップを実行します 1回のステップは
入力データのバッチ1つ分です 次にmax_steps=1000は
最新のチェックポイントから再開し 前回の実行で達したステップ数を読み取り ステップ数がmax_stepsになるまで続けます これはチェックポイントがすでにあると
何もしない可能性があります これがコード全体です
feature_column、 model、input関数があり pandas、dataframe、トレーニング自体から
データを読み取ります 新しい特徴を追加したいですか？ たとえば 戸建ての寝室（bedroom）の数を feature_columnのリストに追加して pandasデータフレームでも
必ずそれと同じ名前にします