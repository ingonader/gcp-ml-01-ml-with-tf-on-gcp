Exploremos los componentes
de la API de Estimator y veamos cómo realizar
otras tareas comunes de AA como el entrenamiento distribuido,
la supervisión y la entrega. Los estimadores son parte
de las API de alto nivel de TensorFlow. Su primera experiencia
con TensorFlow en el módulo anterior fue en el nivel básico de TensorFlow en el que se usa
como una biblioteca de cálculo numérico. Debajo de este nivel se encuentran las API
con las que no se interactúa normalmente. Administran el hardware, las CPU, GPU, TPU o plataformas alternativas, como Android. Por encima de TensorFlow están las API de todos los componentes
necesarios para construir un modelo diferentes tipos de capas
de redes neuronales funciones de pérdida, etcétera. Por último, para unirlo todo,
tenemos los estimadores. Un modelo de TensorFlow
de nivel básico, por lo general incluye un par de capas de redes 
neuronales y un bucle de entrenamiento. Tal vez piense:
¿Por qué necesitaría ayuda con eso? Soy desarrollador,
puedo escribir un bucle. Y estoy de acuerdo, pero hoy,
incluso en modelos de prototipo pequeños me inclino por los estimadores. Me gustan porque son intercambiables y me permiten probar muchos modelos de estimadores estándares
preparados previamente en sucesión rápida. A medida que los datos
y el tiempo de entrenamiento crecen sus necesidades aumentarán. ¿Necesita controles para pausar
y reanudar el entrenamiento? Los estimadores los tienen. ¿Sus datos ya no caben en la memoria? Los estimadores están diseñados
para trabajar con una API que se ocupa de los conjuntos de datos sin memoria. No puede entrenar
una red grande sin verificar su eficacia. Los estimadores muestran métricas clave
automáticamente durante el entrenamiento que pueden visualizarse en TensorBoard. ¿Qué pasa
con el entrenamiento distribuido? Los estimadores tienen el código
de ejecución de clúster integrado. Por último, hay que unir el modelo a fin de que esté listo para el ajuste
de hiperparámetros de ML Engine y tal vez enviarlo
a producción con el servicio de predicciones administrado
y con escala automática de ML Engine. La API de Estimator
también lo ayuda en eso. ¿Todavía quiere seguir escribiendo
usted mismo sus bucles de entrenamiento con todas las funciones
de código estándar repetidas cada vez? Claro que no. Por eso, veamos
cómo funciona la API de Estimator. La clase base: estimator,
le permite unir su propio modelo que se compila en capas
mediante la API de tf.layers. Pero si compila
un modelo estándar, no la necesitará. TensorFlow tiene estimadores
preparados previamente que puede probar así como clasificadores lineales
o de redes neuronales densas para clasificar datos en categorías y regresores similares
para predecir valores continuos. Y no olvide
el DNNLinearCombinedClassifier también conocido
como el modelo amplio y profundo según el artículo de investigación
de Google que lo popularizó. Este no es trivial.
Es la tecnología que usamos en el motor de recomendaciones
de Google Play, por ejemplo. Pero es muy flexible y se lo describe a menudo
como el caballo de batalla de Enterprise Machine Learning. Funciona con todo tipo
de datos estructurados y viene listo para usarse. Lo que debe recordar es que,
como comparten una API en común los estimadores preparados
previamente son intercambiables. Es fácil probarlos todos.