1
00:00:00,000 --> 00:00:01,915
例を見てみましょう

2
00:00:01,915 --> 00:00:03,725
不動産はどうでしょうか

3
00:00:03,725 --> 00:00:05,880
物件価格を予測できますか？

4
00:00:05,880 --> 00:00:08,520
まず特徴（Feature）をいくつか選びます

5
00:00:08,520 --> 00:00:11,475
これは予測のベースになるデータです

6
00:00:11,475 --> 00:00:15,815
戸建てやアパートのサイズに
基づいて価格を予測する

7
00:00:15,815 --> 00:00:18,160
モデルを構築してみましょう

8
00:00:18,160 --> 00:00:20,050
特徴は次のとおりです

9
00:00:20,050 --> 00:00:22,070
1. 面積（平方フィート）

10
00:00:22,090 --> 00:00:25,225
2. カテゴリ（戸建てまたはアパート）

11
00:00:25,225 --> 00:00:27,435
実装方法を見ていきましょう

12
00:00:27,435 --> 00:00:31,275
feature_column API で
特徴（feature）を定義できます

13
00:00:31,275 --> 00:00:34,500
まず面積（sq footage）の数値列です

14
00:00:34,500 --> 00:00:38,035
次に物件タイプのカテゴリ列です

15
00:00:38,035 --> 00:00:42,670
このシンプルなモデルでは
戸建て（house）とアパート（apt）が可能です

16
00:00:42,670 --> 00:00:46,049
次に LinearRegressorを
インスタンス化できます

17
00:00:46,049 --> 00:00:49,315
これは 上記の特徴のための
作成済みEstimatorです

18
00:00:49,315 --> 00:00:52,230
Regressorは数値を出力するモデルです

19
00:00:52,230 --> 00:00:56,030
ここでは物件の予想販売価格です

20
00:00:56,030 --> 00:00:58,805
なぜ feature_columnが必要なのでしょうか

21
00:00:58,805 --> 00:01:01,335
詳しく見てみましょう

22
00:01:01,335 --> 00:01:05,325
LinearRegressorは
データのベクターを扱うモデルです

23
00:01:05,325 --> 00:01:09,540
入力データ要素の加重合計
（weighted sum）を計算します

24
00:01:09,540 --> 00:01:14,255
そして問題の重みを調整するよう
トレーニングされます

25
00:01:14,255 --> 00:01:16,845
ここでは販売価格の予測です

26
00:01:16,845 --> 00:01:24,225
では LinearRegressor用に どのように
データを1つの入力ベクターにまとめますか？

27
00:01:24,225 --> 00:01:29,160
どんなデータをまとめるかに応じて
さまざまな方法があります

28
00:01:29,160 --> 00:01:33,420
ですから feature_column API が役立ちます

29
00:01:33,420 --> 00:01:38,720
これは データをベクター要素にまとめる
標準的な方法を実装します

30
00:01:38,720 --> 00:01:43,090
このnumeric_columnの値は単なる数値です

31
00:01:43,090 --> 00:01:48,615
これを そのままコピーして
入力ベクターの1つの要素に入れます

32
00:01:48,615 --> 00:01:53,645
一方 categorical_columは
one-hotにエンコードされます

33
00:01:53,645 --> 00:01:55,375
2つのカテゴリがあり

34
00:01:55,375 --> 00:01:57,720
house（戸建て）が1,0で

35
00:01:57,720 --> 00:02:00,625
apt（アパート）は0, 1です

36
00:02:00,625 --> 00:02:05,730
3番目のカテゴリがあれば0, 0, 1
などとエンコードされます

37
00:02:05,760 --> 00:02:10,235
さて LinearRegressorが
これらの特徴を扱えるようになったので

38
00:02:10,235 --> 00:02:12,420
入力ベクターにまとめて

39
00:02:12,420 --> 00:02:16,310
LinearRegressorの機能を適用してみます

40
00:02:16,310 --> 00:02:20,770
他にも多くのfeature_columnタイプから選べます

41
00:02:20,770 --> 00:02:23,590
連続値の列、バケット化用

42
00:02:23,590 --> 00:02:26,970
単語の組み込み、交差列などです

43
00:02:26,970 --> 00:02:31,280
適用される変換は
TensorFlowドキュメントに記載されているので

44
00:02:31,280 --> 00:02:34,190
動作をいつでも確認できます

45
00:02:34,190 --> 00:02:36,450
モデルをトレーニングするには

46
00:02:36,450 --> 00:02:42,680
feature_columnで指定された特徴を返す
input関数を書く必要があります

47
00:02:42,690 --> 00:02:44,425
トレーニング中なので

48
00:02:44,425 --> 00:02:47,215
正解つまり「labels」も必要です

49
00:02:47,215 --> 00:02:51,500
ここで Estimatorの train関数を呼び出し

50
00:02:51,500 --> 00:02:56,655
このデータセットを100回繰り返して
モデルをトレーニングします

51
00:02:56,655 --> 00:02:59,480
バッチ処理の動作については後で見ます

52
00:02:59,480 --> 00:03:04,770
でも バッチ処理の概念を
すでにご存じの方のために言うと

53
00:03:04,770 --> 00:03:09,680
ここに書いたコードはステップごとに
1つのバッチデータでトレーニングし

54
00:03:09,680 --> 00:03:12,825
このバッチにはデータセット全体が含まれます

55
00:03:12,825 --> 00:03:16,230
トレーニングが済んだら
モデルを予測に使えます

56
00:03:16,230 --> 00:03:20,250
予測用のデータを提供する
input関数が必要になります

57
00:03:20,250 --> 00:03:24,970
ここでは1500平方フィートの戸建てと
1800平方フィートのアパートです

58
00:03:24,970 --> 00:03:28,260
Estimator APIのpredict関数は

59
00:03:28,260 --> 00:03:32,730
Pythonジェネレータを返します
これを使って繰り返し予測できます

60
00:03:32,730 --> 00:03:37,065
Estimator APIのここまでの内容を
まとめましょう

61
00:03:37,065 --> 00:03:43,175
モデルにデータを理解させるために
feature_column（特徴列）を使います

62
00:03:43,175 --> 00:03:48,000
feature_columnに基づいて
LinearRegressorをインスタンス化します

63
00:03:48,000 --> 00:03:52,675
trainを呼び出して100回のステップで
モデルをトレーニングします

64
00:03:52,675 --> 00:03:57,090
トレーニング用データが
データ入力関数inputで提供され

65
00:03:57,090 --> 00:04:00,010
予測を得るためにpredictを呼び出して

66
00:04:00,010 --> 00:04:03,760
そのためのデータが
再びinput関数で提供されます

67
00:04:03,760 --> 00:04:08,200
詳細はこのコースで後ほど説明します

68
00:04:08,200 --> 00:04:10,585
別の作成済みEstimatorを使うには

69
00:04:10,585 --> 00:04:15,330
単にクラス名を変更して
適切な構成パラメータを指定するだけです

70
00:04:15,330 --> 00:04:18,399
たとえば
このDense Neural Network Regressorで

71
00:04:18,399 --> 00:04:21,000
2つの隠れ（hidden）レイヤを使えます

72
00:04:21,000 --> 00:04:23,155
1番目には3つのニューロンがあり

73
00:04:23,155 --> 00:04:24,960
2番目には2つだけです

74
00:04:24,960 --> 00:04:28,930
そして物件価格を予測する
1つのニューロンで終わります

75
00:04:28,930 --> 00:04:32,415
なお 両方のモデルで
入力ベクターは同じですから

76
00:04:32,415 --> 00:04:35,190
同じfeature_columnを再利用できます

77
00:04:35,190 --> 00:04:39,620
Dense Neural Network（DNN）で
調整できる項目をいくつか挙げると

78
00:04:39,620 --> 00:04:41,980
隠れレイヤの数とサイズ

79
00:04:41,980 --> 00:04:43,980
活性化関数の選択

80
00:04:43,980 --> 00:04:46,695
ドロップアウトなどの正規化パラメータ

81
00:04:46,695 --> 00:04:50,025
そして トレーニング用の
好みのオプティマイザです

82
00:04:50,025 --> 00:04:55,175
最も重要な点として 適切なデフォルトが
ほぼすべてのものに備わっています

83
00:04:55,175 --> 00:04:56,910
DNNRegressorでは

84
00:04:56,910 --> 00:05:00,560
必須のパラメータは隠れレイヤだけです