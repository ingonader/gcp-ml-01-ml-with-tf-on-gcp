Sprechen wir nun über Checkpoints. Diese werden wichtig,
wenn Sie größere Modelle trainieren. Warum sind sie wichtig? Sie ermöglichen es Ihnen,
das Training fortzusetzen, etwa nach einem Fehler, und Vorhersagen
aus einem Trainingsmodell zu treffen. Sie erhalten Checkpoints kostenlos, geben Sie einfach ein Verzeichnis an. Sehen wir uns nun den Code an. In der vorherigen Lektion
haben wir einen Estimator trainiert, indem wir die Funktion "train" aufgerufen
und Immobilienpreise über einen Aufruf der Funktion "predict" vorhergesagt haben. Natürlich ist das nicht immer sinnvoll, besonders wenn das Training lange dauert. Wir brauchen eine Möglichkeit,
unser Trainingsmodell zu speichern. Dazu dienen Checkpoints.
Diese sind standardmäßig verfügbar, wenn Sie die Estimastor API verwenden. Geben Sie einen Ordner an,
wenn Sie das Modell instanziieren, und die Checkpoints werden
dort regelmäßig gespeichert. Wie stellen Sie einen Estimator
von einem Checkpoint wieder her? Geben Sie bei der
Instanziierung einen Ordner an. Wird dort ein Checkpoint
gefunden, wird er geladen, und der Estimator
ist für Vorhersagen bereit. Das Training wird auch
vom letzten Checkpoint an fortgesetzt. So trainieren Sie weiter,
wenn weitere Trainingsschritte nötig sind. Wenn Sie von Grund auf neu starten
möchten, löschen Sie diesen Ordner. Ohne Checkpoints für den Start beginnt der Estimator
das Training von Grund auf neu. Bitte beachten Sie,
dass ein Neustart vom letzten Checkpoint das Standardverhalten von Estimators ist. Das ist praktisch,
aber Sie müssen daran denken, das Checkpoints-Verzeichnis
zu löschen, um das Training neuzustarten. Vor allem, 
wenn Sie das Modell geändert haben.