Vamos ver nosso terceiro
laboratório de código juntos. Este é sobre treinamento e avaliação. Primeiro, como sempre, vamos localizar
nossos arquivos de laboratório. Então, fazemos login em
cloud.google.com/console usando a conta do laboratório. Depois, você pode abrir o Cloud Shell
usando este pequeno botão e reconectar à instância
do Datalab digitando "datalab connect" e
o nome da instância, "mylab", no meu caso. Está conectando. Quando terminar, use o botão de visualização da Web. Temos que mudar a porta e acessar 8081, porque é essa que o Datalab usa, e estamos
na interface de bloco de notas. Vamos criar um bloco de notas novo
para digitar alguns comandos bash para recuperar nosso código. Depois, clonamos este repositório
e, assim que isso é feito, temos o repositório aqui como
"training data analyst". Os arquivos deste terceiro
laboratório de código ou em "training data analyst", "courses", "machine learning", "deep dive", e, por fim, "TensorFlow". Esse laboratório de código
é o d_traineval. Vamos abrir. Aqui, vamos dar os retoques finais
ao nosso modelo. Então, vamos lá. Não há nada para mudar
na parte de carregamento de dados. Já fizemos isso, usamos
conjuntos de dados para carregar dados CSV de um conjunto
de arquivos CSV em gráficos. E ainda não estamos
alterando nossos recursos. Eles estão bons por enquanto. Isso é novo. A função de entrada de serviço. Precisamos dela para deixar nosso modelo
pronto para implantação. Quando o modelo atender previsões
de uma API REST, ele receberá dados como um feed JSON. Felizmente, a API não nos força a usar um feed JSON que se pareça exatamente
com nossos dados de treinamento em CSV. A função de entrada de serviço existe
para fazer as adaptações necessárias. No entanto, aqui você define
a forma esperada do seu feed JSON, com os nomes esperados, e a forma e o tipo de valores especificados como
marcadores de posição do TensorFlow. Esses marcadores de posição receberão
os valores lidos do feed do JSON. E, neste caso, digamos que não precisaremos de
nenhuma transformação adicional, então apenas dizemos que
nossos recursos são exatamente os mesmos que os marcadores para os recursos
que acabamos de definir. Nosso modelo pode entender
esse dicionário de recursos como ele é. Estamos quase prontos para
chamar, treinar e avaliar. Só precisamos configurar. Escolhemos um modelo,
aqui um LinearRegressor. Definimos uma
especificação de treinamento. É aqui que a função de entrada
de treinamento é conectada. Aqui. Também definimos um exportador, aqui LatestExporter,
o que significa que queremos exportar o modelo pronto para implantação
no final do treinamento. O exportador precisa saber sobre a função de entrada de serviço que
acabamos de definir, aqui mesmo. Depois, definimos nosso EvalSpec. É aqui que entra a função de entrada
de dados eval e, também, como avaliações e exportações só acontecem
depois de um ponto de verificação, também faz sentido analisar
aqui nosso exportador. E agora estamos prontos e configurados. Vamos iniciar o TensorBoard. Aqui mesmo. O TensorBoard foi iniciado,
podemos clicar aqui para abri-lo, e vemos nosso painel vazio por enquanto. Ainda não começamos o treinamento. Então, vamos fazer isso. Vamos executar este treinamento
e avaliar a função. A matriz gerada durante o treinamento
é gravada no diretório de saída usual e o TensorBoard precisa saber
onde encontrá-la. Foi o que especificamos
quando começamos aqui. E agora que começamos o treinamento, vemos nossos registros de treinamento
e devemos ver no TensorBoard, nossas curvas. E aqui estão elas. Aqui está a nossa perda média. Depois de um tempo, vemos nossa perda
média computada no conjunto de dados de treinamento e também em nosso
conjunto de dados de avaliação. Isso é porque estamos treinando
e avaliando ao mesmo tempo. Então, esse modelo ainda está treinando. Vamos esperar até que termine. E conforme o treinamento avança, o TensorBoard pode ser atualizado
automaticamente. Você consegue isso
nessa configuração aqui, "Recarregar os dados a cada 30 segundos", ou pode pressionar o botão "Atualizar"
para atualizar os dados e ver suas curvas de treinamento à medida
que elas evoluem durante o treinamento. E o modelo agora está treinado. E se eu atualizar uma última vez aqui, verei as curvas finais de treinamento. É isso aí. Há muito o que ver
nessas curvas de treinamento, você aprenderá isso mais tarde. Por enquanto, vemos que nosso modelo
não está treinando muito bem. A perda de validação não está melhorando. Mas nós já sabíamos disso. Agora que o código funciona,
os dados são carregados e podemos ver o que acontece
no TensorBoard, estamos prontos para fazer
ciência de dados.