1
00:00:00,000 --> 00:00:03,555
Let's go through our third cold lap together.

2
00:00:03,555 --> 00:00:07,250
This one about train and evaluate.

3
00:00:07,250 --> 00:00:11,400
First, as always, let's locate our lab files.

4
00:00:11,400 --> 00:00:16,030
So we go to clouds.google.com/console log

5
00:00:16,030 --> 00:00:23,670
in using your lab account.

6
00:00:32,150 --> 00:00:38,300
And once you're in, you can open cloud shell using this little portal

7
00:00:38,300 --> 00:00:41,120
and reconnect to your data lab instance by

8
00:00:41,120 --> 00:00:45,090
typing datalab connect and the name of your instance,

9
00:00:46,220 --> 00:00:55,450
mylab in my case.

10
00:01:01,160 --> 00:01:05,070
It's connecting. When it's done,

11
00:01:05,070 --> 00:01:07,560
you use the Web preview button.

12
00:01:07,560 --> 00:01:11,640
We have to change the port and go to 8081,

13
00:01:11,640 --> 00:01:18,045
because that is what datalab uses and we are in our familiar notebook interface.

14
00:01:18,045 --> 00:01:22,170
Let's create a new notebook to type in a couple of bash commands,

15
00:01:22,170 --> 00:01:26,285
so as to retrieve our code.

16
00:01:26,285 --> 00:01:33,900
So, git clone, this repository and as soon as this is done,

17
00:01:33,900 --> 00:01:38,970
we have the repository here as training data analyst.

18
00:01:38,970 --> 00:01:42,150
The files for this thread code lab or

19
00:01:42,150 --> 00:01:52,230
training data analyst courses machine learning,

20
00:01:52,230 --> 00:01:55,530
deep dive, and finally, TensorFlow.

21
00:01:55,530 --> 00:02:02,170
These code lab is the d_traineval. Let's open that.

22
00:02:04,280 --> 00:02:08,510
Here, we will be putting the final touches to our model.

23
00:02:08,510 --> 00:02:13,150
So let's go through it.

24
00:02:13,150 --> 00:02:18,035
There is nothing to change on the data loading front.

25
00:02:18,035 --> 00:02:21,020
We have already done that we used data sets to

26
00:02:21,020 --> 00:02:25,075
load CSV data from a set of charted CSV files.

27
00:02:25,075 --> 00:02:29,795
And, we are still not changing our features.

28
00:02:29,795 --> 00:02:32,570
They are good for now. This is new.

29
00:02:32,570 --> 00:02:34,235
The serving input function.

30
00:02:34,235 --> 00:02:37,975
We need it to make our model ready for deployment.

31
00:02:37,975 --> 00:02:41,610
When the model will be serving predictions from a REST API,

32
00:02:41,610 --> 00:02:45,215
it will be receiving data as a Json feed.

33
00:02:45,215 --> 00:02:48,530
Fortunately, the API does not force us to use

34
00:02:48,530 --> 00:02:52,735
a Json feed that looks exactly like our CSV training data.

35
00:02:52,735 --> 00:02:56,600
The serving input function is here to make the necessary annotations.

36
00:02:56,600 --> 00:03:04,805
Yet, here, you define the expected shape of your Json feed,

37
00:03:04,805 --> 00:03:08,240
with the names to expect and the shape,

38
00:03:08,240 --> 00:03:12,680
and type of values specified as TensorFlow placeholders.

39
00:03:12,680 --> 00:03:17,090
These placeholders will receive the values read from the Json feed.

40
00:03:17,090 --> 00:03:18,905
And in this case,

41
00:03:18,905 --> 00:03:23,255
let's say that's it we will not need any additional transformations,

42
00:03:23,255 --> 00:03:25,820
so we just say that our features are exactly the

43
00:03:25,820 --> 00:03:28,400
same as the feature placeholders we just defined.

44
00:03:28,400 --> 00:03:33,775
Our model can understand this dictionary of features as it is.

45
00:03:33,775 --> 00:03:38,655
We are almost ready to call, train, and evaluate.

46
00:03:38,655 --> 00:03:42,370
We just need a little bit of configuration.

47
00:03:42,500 --> 00:03:47,290
We pick a model, here a LinearRegressor.

48
00:03:47,330 --> 00:03:50,415
We define a training spec.

49
00:03:50,415 --> 00:03:57,090
This is where the train input function is plugged in here.

50
00:03:57,090 --> 00:03:58,719
We also define an exporter,

51
00:03:58,719 --> 00:04:02,390
here the LatestExporter which means that if we want to

52
00:04:02,390 --> 00:04:06,995
export the model ready for deployment at the end of the training.

53
00:04:06,995 --> 00:04:10,625
The exporter needs to know about

54
00:04:10,625 --> 00:04:16,190
the serving input function that we just defined, right here.

55
00:04:16,400 --> 00:04:19,890
Then we define our EvalSpec.

56
00:04:19,890 --> 00:04:23,260
This is where the eval data input function comes in and also,

57
00:04:23,260 --> 00:04:28,090
since both evaluations and exports only happen after a checkpoint,

58
00:04:28,090 --> 00:04:31,925
it makes sense to parse in our exporter here as well.

59
00:04:31,925 --> 00:04:35,460
And now, we are ready and configured.

60
00:04:35,460 --> 00:04:48,010
Let us start TensorBoard, right here.

61
00:04:49,010 --> 00:04:54,400
TensorBoard was started, we can click here to open it,

62
00:04:55,130 --> 00:04:59,635
and we see our dashboard empty for now.

63
00:04:59,635 --> 00:05:01,615
We have not started training yet.

64
00:05:01,615 --> 00:05:08,030
So, let's do that.

65
00:05:08,030 --> 00:05:17,070
Let's actually run this train and evaluate function.

66
00:05:17,070 --> 00:05:21,810
Matrix generated during training are written to our usual output directory,

67
00:05:21,810 --> 00:05:25,920
and TensorBoards needs to know where to find them.

68
00:05:25,920 --> 00:05:30,270
That's what we specified when we started it right here.

69
00:05:30,270 --> 00:05:33,060
And now that we have started the training,

70
00:05:33,060 --> 00:05:39,255
we see our training logs here and we should be saying on the tensor board site,

71
00:05:39,255 --> 00:05:41,580
our curves up here and here they are.

72
00:05:41,580 --> 00:05:44,250
Here is our average loss.

73
00:05:44,250 --> 00:05:50,820
And after a while, we start seeing our average loss computed on our training data set,

74
00:05:50,820 --> 00:05:53,670
and also on our evaluation data set.

75
00:05:53,670 --> 00:05:57,800
That's because we are training and evaluating at the same time.

76
00:06:00,800 --> 00:06:04,215
So, this model is still training.

77
00:06:04,215 --> 00:06:07,340
Let's wait until it finishes.

78
00:06:13,490 --> 00:06:16,785
And as the training progresses,

79
00:06:16,785 --> 00:06:20,830
TensoBoard can either refresh automatically.

80
00:06:20,830 --> 00:06:23,250
You have this under this setting here,

81
00:06:23,250 --> 00:06:25,380
reload data every 30 seconds,

82
00:06:25,380 --> 00:06:29,250
or you can hit the refresh button to refresh the data and

83
00:06:29,250 --> 00:06:36,130
see your training curves as they evolve during training.

84
00:06:45,310 --> 00:06:48,810
And the model is now trained.

85
00:06:48,810 --> 00:06:51,470
And if I refresh the last time here,

86
00:06:51,470 --> 00:06:55,360
I will see the final training curves.

87
00:06:55,360 --> 00:06:59,565
That's it. There is a lot to see in this training curves,

88
00:06:59,565 --> 00:07:01,110
you will learn that later.

89
00:07:01,110 --> 00:07:05,190
For the moment, we just see that our model is not training very well.

90
00:07:05,190 --> 00:07:08,235
The validation loss is not improving.

91
00:07:08,235 --> 00:07:10,605
But we already knew that.

92
00:07:10,605 --> 00:07:14,175
Now that the code works, data gets loaded,

93
00:07:14,175 --> 00:07:16,440
and we can see what is going in TensorBoard,

94
00:07:16,440 --> 00:07:19,900
we are ready to do some data science.