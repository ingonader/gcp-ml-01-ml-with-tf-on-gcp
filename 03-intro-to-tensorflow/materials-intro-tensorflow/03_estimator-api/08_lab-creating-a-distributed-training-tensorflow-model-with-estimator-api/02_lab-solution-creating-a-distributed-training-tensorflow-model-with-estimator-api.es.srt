1
00:00:00,640 --> 00:00:03,555
Hagamos el tercer codelab juntos.

2
00:00:03,555 --> 00:00:07,250
Este es sobre train_and_evaluate.

3
00:00:07,250 --> 00:00:11,400
Primero, como siempre,
localicemos los archivos del lab.

4
00:00:11,400 --> 00:00:16,030
Vamos a cloud.google.com/console

5
00:00:17,990 --> 00:00:23,140
y accedemos con la cuenta del lab.

6
00:00:32,840 --> 00:00:38,300
Luego, puede abrir
Cloud Shell con este botón

7
00:00:38,300 --> 00:00:41,120
y volver a conectarse
a su instancia de Datalab

8
00:00:41,120 --> 00:00:45,090
mediante datalab connect
seguido del nombre de la instancia

9
00:00:51,370 --> 00:00:54,280
En mi caso, es mylab.

10
00:01:02,100 --> 00:01:03,629
Se está conectando.

11
00:01:03,629 --> 00:01:08,180
Una vez conectado,
use el botón "Web preview".

12
00:01:08,180 --> 00:01:14,230
Hay que cambiar el puerto a 8081,
porque ese es el que usa Datalab.

13
00:01:14,230 --> 00:01:18,045
Y ahora estamos
en la interfaz de notebook habitual.

14
00:01:18,745 --> 00:01:22,670
Creemos un nuevo notebook
para escribir algunos comandos Bash

15
00:01:22,670 --> 00:01:26,285
a fin de recuperar nuestro código.

16
00:01:26,285 --> 00:01:30,040
Hacemos un git clone de este repositorio.

17
00:01:31,600 --> 00:01:39,300
Cuando esté listo, el repositorio
aparece aquí como "training-data-analyst".

18
00:01:39,300 --> 00:01:42,150
Los archivos para este tercer codelab

19
00:01:42,150 --> 00:01:49,770
están en "training-data-analyst",
"courses", "machine_learning"

20
00:01:50,590 --> 00:01:55,530
"deepdive" y, finalmente, "03_tensorflow".

21
00:01:56,090 --> 00:02:01,830
Este codelab es
"d_traineval.ipynb". Abrámoslo.

22
00:02:05,110 --> 00:02:08,509
Aquí, le pondremos
los toques finales a nuestro modelo.

23
00:02:09,709 --> 00:02:11,590
Veamos.

24
00:02:15,170 --> 00:02:18,035
No hay nada que cambiar
en la parte de carga de los datos.

25
00:02:18,035 --> 00:02:21,020
Ya lo hicimos.
Usamos conjuntos de datos

26
00:02:21,020 --> 00:02:25,075
para cargar datos CSV de un conjunto
de archivos CSV fragmentados.

27
00:02:27,375 --> 00:02:29,795
No cambiaremos los atributoss aún.

28
00:02:29,795 --> 00:02:31,670
Están bien por el momento.

29
00:02:32,140 --> 00:02:34,515
Esto es nuevo.
La función serving_input.

30
00:02:34,515 --> 00:02:38,155
La necesitamos a fin de preparar
el modelo para la implementación.

31
00:02:38,155 --> 00:02:41,610
Cuando el modelo entregue
predicciones desde una API de REST

32
00:02:41,610 --> 00:02:45,215
recibirá datos como un feed JSON.

33
00:02:45,215 --> 00:02:48,530
Por suerte, la API no nos obliga a usar

34
00:02:48,530 --> 00:02:53,055
un feed JSON exactamente igual
a nuestros datos de entrenamiento CSV.

35
00:02:53,055 --> 00:02:57,600
Tenemos la función serving_input,
que hace las adaptaciones necesarias.

36
00:02:58,000 --> 00:03:04,805
En ella, se define
el formato esperado del feed JSON

37
00:03:04,805 --> 00:03:09,610
con los nombres esperados,
y el formato y los tipos de valores

38
00:03:09,610 --> 00:03:13,050
especificados
como marcadores de posición de TensorFlow.

39
00:03:13,050 --> 00:03:17,090
Estos marcadores de posición
recibirán los valores del feed JSON.

40
00:03:17,760 --> 00:03:23,075
En este caso, supongamos
que no se necesitan más transofrmaciones

41
00:03:23,075 --> 00:03:26,270
por lo que decimos
que nuestros atributos son idénticos

42
00:03:26,270 --> 00:03:29,500
a los marcadores de posición
de atributos que acabamos de definir.

43
00:03:29,500 --> 00:03:33,775
Nuestro modelo puede entender
este diccionario de atributos como está.

44
00:03:34,985 --> 00:03:38,655
Estamos casi listos
para llamar, entrenar y evaluar.

45
00:03:38,655 --> 00:03:42,140
Solo necesitamos un poco de configuración.

46
00:03:43,380 --> 00:03:47,290
Elegimos un modelo: LinearRegressor.

47
00:03:48,290 --> 00:03:50,415
Definimos TrainSpec.

48
00:03:50,415 --> 00:03:55,810
Aquí es donde la función
de entrada de entrenamiento se inyecta.

49
00:03:57,090 --> 00:03:58,839
También, definimos un exportador

50
00:03:58,839 --> 00:04:02,390
aquí es LatestExporter,
que significa que queremos

51
00:04:02,390 --> 00:04:05,235
exportar el modelo listo
para la implementación

52
00:04:05,235 --> 00:04:06,995
al final del entrenamiento.

53
00:04:07,555 --> 00:04:12,575
El exportador necesita conocer
la función serving_input

54
00:04:12,575 --> 00:04:15,680
que acabamos de definir.

55
00:04:17,489 --> 00:04:19,890
Luego, definimos EvalSpec.

56
00:04:19,890 --> 00:04:23,420
Aquí es donde se incluye la función
de entrada de los datos de evaluación

57
00:04:23,420 --> 00:04:26,370
y ya que tanto las evaluaciones
como las exportaciones

58
00:04:26,370 --> 00:04:28,500
ocurren solo después de un control

59
00:04:28,500 --> 00:04:31,925
es conveniente
pasar el exportador también.

60
00:04:32,805 --> 00:04:35,460
Ahora, la configuración está lista.

61
00:04:36,340 --> 00:04:39,270
Iniciemos TensorBoard.

62
00:04:49,910 --> 00:04:54,400
TensorBoard se inició,
hacemos clic aquí para abrirlo

63
00:04:56,580 --> 00:04:59,635
y vemos un panel vacío por ahora.

64
00:04:59,635 --> 00:05:02,025
Todavía no comenzamos el entrenamiento.

65
00:05:02,695 --> 00:05:04,930
Hagamos eso.

66
00:05:08,030 --> 00:05:11,990
Ejecutemos la función
train_and_evaluate.

67
00:05:17,070 --> 00:05:19,600
Las métricas generadas
durante el entrenamiento

68
00:05:19,600 --> 00:05:22,110
se escriben
en el directorio de salida usual

69
00:05:22,110 --> 00:05:26,150
y TensorBoard
debe saber dónde encontrarlas.

70
00:05:26,150 --> 00:05:30,270
Es lo que especificamos
cuando lo iniciamos.

71
00:05:31,140 --> 00:05:36,280
Ahora que comenzamos el entrenamiento,
vemos nuestros registros de entrenamiento

72
00:05:36,300 --> 00:05:40,725
y deberíamos ver, en el sitio
de TensorBoard, nuestras curvas.

73
00:05:40,725 --> 00:05:41,580
Y aquí están.

74
00:05:41,580 --> 00:05:44,250
Aquí está nuestra pérdida promedio.

75
00:05:45,110 --> 00:05:49,400
Después de un momento, comenzamos
a ver la pérdida promedio calculada

76
00:05:49,400 --> 00:05:51,270
para nuestro conjunto de entrenamiento

77
00:05:51,270 --> 00:05:53,670
y también
para nuestro conjunto de evaluación.

78
00:05:53,670 --> 00:05:57,800
Eso es porque estamos entrenando
y evaluando al mismo tiempo.

79
00:06:01,670 --> 00:06:05,085
Este modelo sigue entrenando.

80
00:06:05,085 --> 00:06:07,600
Esperemos a que termine.

81
00:06:14,410 --> 00:06:17,545
A medida que el entrenamiento avanza

82
00:06:17,545 --> 00:06:20,830
TensorBoard puede
actualizarse automáticamente

83
00:06:20,830 --> 00:06:25,210
si usa esta configuración de aquí,
"Reload data every 30 seconds".

84
00:06:25,380 --> 00:06:28,033
O puede presionar
el botón de actualización

85
00:06:28,033 --> 00:06:35,820
para ver las curvas de entrenamiento
a medida que cambian durante el proceso.

86
00:06:46,330 --> 00:06:48,810
El modelo ya está entrenado.

87
00:06:49,830 --> 00:06:51,470
Si actualizo una última vez

88
00:06:51,470 --> 00:06:55,080
veré las curvas de entrenamiento finales.

89
00:06:56,060 --> 00:06:59,545
Eso es todo. Hay mucho que analizar
en estas curvas de entrenamiento.

90
00:06:59,545 --> 00:07:01,420
Aprenderá sobre eso más adelante.

91
00:07:01,420 --> 00:07:03,710
Por el momento,
solo vemos que nuestro modelo

92
00:07:03,710 --> 00:07:05,520
no está entrenando muy bien.

93
00:07:05,520 --> 00:07:08,235
La pérdida de validación no mejora.

94
00:07:08,875 --> 00:07:10,865
Pero ya sabíamos eso.

95
00:07:10,865 --> 00:07:14,175
Ahora que el código funciona,
los datos se cargan

96
00:07:14,175 --> 00:07:16,440
y podemos ver lo que pasa en TensorBoard

97
00:07:16,440 --> 00:07:19,900
estamos listos
para practicar ciencia de datos.