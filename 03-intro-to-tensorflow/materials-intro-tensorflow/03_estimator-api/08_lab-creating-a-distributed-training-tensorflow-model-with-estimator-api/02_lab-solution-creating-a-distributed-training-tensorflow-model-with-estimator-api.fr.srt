1
00:00:00,590 --> 00:00:03,555
Attaquons ensemble
notre troisième atelier de programmation.

2
00:00:03,555 --> 00:00:07,250
Cette fois, nous allons parler
de la fonction "train_and_evaluate".

3
00:00:07,250 --> 00:00:11,400
Comme d'habitude, commençons
par rechercher les fichiers de l'atelier.

4
00:00:11,400 --> 00:00:15,420
Accédez à cloud.google.com/console.

5
00:00:18,370 --> 00:00:22,640
Connectez-vous
avec votre compte d'atelier.

6
00:00:32,940 --> 00:00:38,300
Ensuite, cliquez sur ce bouton
pour ouvrir Cloud Shell,

7
00:00:38,300 --> 00:00:42,830
puis reconnectez-vous à votre instance
Datalab en saisissant "datalab connect",

8
00:00:42,830 --> 00:00:45,090
suivi du nom de votre instance.

9
00:00:51,020 --> 00:00:53,010
Dans mon cas, "mylab".

10
00:01:02,520 --> 00:01:08,190
Une fois connecté,
cliquez sur le bouton "Web preview",

11
00:01:08,190 --> 00:01:13,770
puis spécifiez
le port "8081" utilisé par Datalab.

12
00:01:14,620 --> 00:01:18,415
Nous sommes maintenant dans l'interface
de bloc-notes que nous connaissons déjà.

13
00:01:18,415 --> 00:01:22,170
Créons un nouveau bloc-notes
pour saisir quelques commandes bash

14
00:01:22,170 --> 00:01:26,285
et récupérer notre code,

15
00:01:26,285 --> 00:01:30,100
en saisissant "git clone", suivi du dépôt.

16
00:01:31,880 --> 00:01:36,570
Dès que c'est fait,
notre dépôt apparaît ici,

17
00:01:36,570 --> 00:01:38,650
sous le nom "training-data-analyst".

18
00:01:39,320 --> 00:01:42,470
Les fichiers de ce troisième atelier
de programmation se trouvent

19
00:01:42,470 --> 00:01:49,800
dans "training-data-analyst",
"courses", "machine_learning",

20
00:01:49,930 --> 00:01:55,500
"deepdive", et enfin "tensorflow".

21
00:01:56,050 --> 00:01:59,980
Cet atelier s'appelle "d_traineval".

22
00:02:00,240 --> 00:02:01,910
Ouvrons-le.

23
00:02:05,310 --> 00:02:08,509
C'est ici que nous allons apporter
la touche finale à notre modèle.

24
00:02:09,959 --> 00:02:10,820
Allons-y.

25
00:02:14,880 --> 00:02:18,035
Il n'y a rien à changer dans l'interface
de chargement des données.

26
00:02:18,035 --> 00:02:19,630
Nous l'avons déjà fait.

27
00:02:19,630 --> 00:02:22,835
Nous utilisons des ensembles de données
pour charger des données CSV

28
00:02:22,835 --> 00:02:25,405
à partir d'un ensemble
de fichiers CSV partitionnés.

29
00:02:27,345 --> 00:02:30,095
Nous n'avons pas non plus
à changer nos caractéristiques.

30
00:02:30,095 --> 00:02:31,410
Elles sont correctes.

31
00:02:32,070 --> 00:02:34,285
Voici une nouvelle fonction,
"serving_input".

32
00:02:34,285 --> 00:02:37,975
Elle va nous servir à préparer
notre modèle pour le déploiement.

33
00:02:38,555 --> 00:02:41,860
Lorsque le modèle diffusera
des prédictions à partir d'une API REST,

34
00:02:41,860 --> 00:02:45,215
il recevra des données
comme un flux JSON.

35
00:02:45,795 --> 00:02:49,450
Heureusement, l'API ne nous oblige pas
à utiliser un flux JSON

36
00:02:49,450 --> 00:02:52,735
qui ressemble exactement
à nos données d'entraînement CSV.

37
00:02:52,735 --> 00:02:56,600
La fonction "serving_input" est là
pour faire les adaptations nécessaires.

38
00:02:57,780 --> 00:03:04,995
Pourtant, ici, vous définissez
la forme attendue de votre flux JSON,

39
00:03:04,995 --> 00:03:07,130
avec les noms que vous attendez,

40
00:03:07,130 --> 00:03:10,310
et la forme
et le type de valeurs spécifiés

41
00:03:10,310 --> 00:03:12,695
comme des espaces réservés TensorFlow.

42
00:03:12,695 --> 00:03:17,090
Ces espaces réservés recevront
les valeurs lues à partir du flux JSON.

43
00:03:17,090 --> 00:03:23,145
Dans ce cas, disons que nous n'avons pas
besoin de transformations supplémentaires.

44
00:03:23,145 --> 00:03:27,330
Nos caractéristiques sont exactement
identiques aux espaces réservés

45
00:03:27,330 --> 00:03:28,650
que nous venons de définir.

46
00:03:29,320 --> 00:03:33,775
Notre modèle comprend ce dictionnaire
de caractéristiques en l'état.

47
00:03:35,095 --> 00:03:38,655
Nous sommes presque prêts pour l'appel,
l'entraînement et l'évaluation.

48
00:03:38,655 --> 00:03:42,370
Il ne manque plus
qu'une petite étape de configuration.

49
00:03:43,490 --> 00:03:46,830
Nous choisissons un modèle,
ici "LinearRegressor".

50
00:03:48,440 --> 00:03:50,595
Nous définissons une fonction "TrainSpec".

51
00:03:51,035 --> 00:03:54,130
C'est là que la fonction
"train_input" est intégrée.

52
00:03:57,090 --> 00:04:00,999
Nous définissons aussi
un exportateur, ici "LatestExporter",

53
00:04:00,999 --> 00:04:04,942
qui indique que nous voulons exporter
le modèle prêt pour le déploiement

54
00:04:04,942 --> 00:04:06,742
à la fin de l'entraînement.

55
00:04:07,505 --> 00:04:12,335
L'exportateur doit connaître
la fonction "serving_input"

56
00:04:12,335 --> 00:04:15,300
que nous venons de définir ici.

57
00:04:17,299 --> 00:04:19,890
Puis nous définissons
notre fonction "EvalSpec".

58
00:04:19,890 --> 00:04:23,230
C'est là que la fonction d'entrée
d'évaluation des données est ajoutée.

59
00:04:23,230 --> 00:04:26,940
Et comme les évaluations et exportations
se produisent uniquement

60
00:04:26,940 --> 00:04:28,345
après les points de contrôle,

61
00:04:28,345 --> 00:04:31,410
il est judicieux de transmettre
aussi notre exportateur ici.

62
00:04:32,935 --> 00:04:35,575
Nous sommes prêts,
et la configuration est terminée.

63
00:04:36,435 --> 00:04:38,600
Démarrons TensorBoard.

64
00:04:43,795 --> 00:04:44,795
Ici.

65
00:04:50,090 --> 00:04:51,730
TensorBoard est démarré.

66
00:04:51,730 --> 00:04:53,670
Nous pouvons cliquer ici pour y accéder.

67
00:04:56,810 --> 00:04:59,635
Notre tableau de bord
est vide pour l'instant.

68
00:04:59,635 --> 00:05:01,895
Nous n'avons pas encore
commencé l'entraînement.

69
00:05:02,545 --> 00:05:03,590
C'est parti.

70
00:05:08,030 --> 00:05:12,320
Exécutons cette fonction
"train_and_evaluate".

71
00:05:17,070 --> 00:05:20,090
Les métriques générées
pendant l'entraînement sont écrites

72
00:05:20,090 --> 00:05:25,790
dans notre répertoire de sortie habituel,
et TensorBoard doit savoir où les trouver.

73
00:05:25,920 --> 00:05:29,770
C'est ce que nous avons spécifié
en lançant cette fonction ici.

74
00:05:30,950 --> 00:05:33,300
Maintenant que nous avons
commencé l'entraînement,

75
00:05:33,300 --> 00:05:36,065
nous pouvons voir
nos journaux d'entraînement ici,

76
00:05:36,065 --> 00:05:38,960
et nos courbes doivent apparaître
dans TensorBoard.

77
00:05:40,690 --> 00:05:41,900
Et voilà, elles sont ici.

78
00:05:41,900 --> 00:05:44,040
Voici la perte moyenne.

79
00:05:45,140 --> 00:05:50,300
Et au bout d'un moment, la perte moyenne
calculée sur nos ensembles de données

80
00:05:50,300 --> 00:05:53,670
d'entraînement et d'évaluation
commence à s'afficher,

81
00:05:53,670 --> 00:05:57,250
car l'entraînement et l'évaluation
se font en même temps.

82
00:06:01,990 --> 00:06:04,215
Ce modèle est toujours en entraînement.

83
00:06:04,975 --> 00:06:07,340
Attendons la fin de l'entraînement.

84
00:06:14,650 --> 00:06:20,775
Pendant l'entraînement, TensorBoard
peut s'actualiser automatiquement.

85
00:06:20,775 --> 00:06:25,280
Pour cela, sélectionnez cette option,
"Reload data every 30s".

86
00:06:25,760 --> 00:06:28,660
Sinon, cliquez sur le bouton
d'actualisation pour actualiser

87
00:06:28,660 --> 00:06:35,660
les données et voir l'évolution
de vos courbes pendant l'entraînement.

88
00:06:46,310 --> 00:06:48,500
Le modèle est entraîné.

89
00:06:49,640 --> 00:06:54,520
Si j'actualise une dernière fois, je peux
voir les courbes d'entraînement finales.

90
00:06:56,110 --> 00:06:56,855
Et voilà.

91
00:06:56,855 --> 00:06:59,920
Il y a beaucoup de choses à voir
dans ces courbes d'entraînement,

92
00:06:59,920 --> 00:07:01,590
comme nous le verrons plus tard.

93
00:07:01,590 --> 00:07:03,180
Pour le moment, nous voyons juste

94
00:07:03,180 --> 00:07:05,685
que l'entraînement du modèle
n'est pas très efficace.

95
00:07:05,685 --> 00:07:10,305
La perte de validation ne s'améliore pas,
mais nous le savions déjà.

96
00:07:10,855 --> 00:07:14,175
Maintenant que le code fonctionne,
les données sont chargées,

97
00:07:14,175 --> 00:07:16,810
et nous pouvons voir
ce qu'il se passe dans TensorBoard.

98
00:07:16,810 --> 00:07:19,900
Nous sommes prêts à faire
un peu de science des données.