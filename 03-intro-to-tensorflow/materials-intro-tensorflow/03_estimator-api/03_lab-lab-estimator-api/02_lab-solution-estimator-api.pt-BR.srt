1
00:00:00,190 --> 00:00:03,522
Vamos ao nosso primeiro laboratório de
código estimador juntos.

2
00:00:03,522 --> 00:00:08,140
Para começar, precisamos localizar os
arquivos de laboratório de código.

3
00:00:08,140 --> 00:00:09,980
Vamos fazer juntos.

4
00:00:09,980 --> 00:00:17,450
Você acessa o cloud.google.com/console
e faz login com a conta de laboratório.

5
00:00:17,450 --> 00:00:19,660
Eu farei isso também.

6
00:00:30,700 --> 00:00:33,550
Agora, você precisa
selecionar um projeto.

7
00:00:33,550 --> 00:00:35,580
Às vezes, já está selecionado.

8
00:00:36,650 --> 00:00:39,760
Abra o Cloud Shell,
é este ícone aqui.

9
00:00:44,109 --> 00:00:50,836
No Cloud Shell, vamos digitar
"datalab create".

10
00:00:54,831 --> 00:00:59,050
Chamaremos a instância do
Datalab de mylab.

11
00:01:01,110 --> 00:01:08,614
E vamos criá-la na zona us-central1-a.

12
00:01:09,764 --> 00:01:13,660
Então, isso criará nossa primeira
instância do Datalab.

13
00:01:14,680 --> 00:01:17,389
Demora um pouco na primeira tentativa.

14
00:01:18,367 --> 00:01:21,257
Alguns minutos depois...

15
00:01:21,886 --> 00:01:25,888
Na próxima vez, você não precisa
recriar os dados da instância,

16
00:01:25,888 --> 00:01:30,815
basta se reconectar a eles digitando
"datalab connect" e

17
00:01:30,815 --> 00:01:33,959
o nome da instância. 
Mylab, no meu caso.

18
00:01:47,098 --> 00:01:52,030
E agora, localize o botão de
visualização da Web aqui.

19
00:01:53,140 --> 00:01:57,899
Altere a porta para 8081, que é
a usada pelo Datalab.

20
00:01:58,380 --> 00:02:00,370
E clique em "Visualizar".

21
00:02:00,370 --> 00:02:03,050
Isso abre uma interface
de bloco de notas familiar.

22
00:02:06,908 --> 00:02:10,759
A partir daqui, ainda precisamos
conseguir o código do GitHub.

23
00:02:10,759 --> 00:02:17,385
Então abrimos um bloco de notas para
digitar comandos bash nele,

24
00:02:18,635 --> 00:02:20,880
%bash.

25
00:02:21,720 --> 00:02:27,819
E clonaremos nosso repositório
de laboratórios de código

26
00:02:29,359 --> 00:02:32,191
no diretório local.

27
00:02:33,541 --> 00:02:36,120
Assim que isso for concluído,

28
00:02:36,120 --> 00:02:39,159
o diretório local aparecerá aqui.

29
00:02:47,488 --> 00:02:48,510
Aí está.

30
00:02:49,920 --> 00:02:53,454
Ele é chamado de
training-data-analyst, e ali

31
00:02:53,454 --> 00:02:57,804
você quer localizar
um diretório chamado courses,

32
00:02:58,404 --> 00:03:04,584
depois o machine_learning,
depois o deepdive.

33
00:03:07,094 --> 00:03:09,460
E TensorFlow.

34
00:03:09,460 --> 00:03:15,104
Nosso primeiro laboratório
é o b_estimator.ipynb.

35
00:03:16,707 --> 00:03:21,793
Portanto, neste exemplo, usaremos
o Pandas para ler dados de arquivos CSV

36
00:03:21,793 --> 00:03:25,260
que contêm informações
sobre corridas de táxi.

37
00:03:25,260 --> 00:03:29,630
O local de partida, o destino
e o número de passageiros.

38
00:03:29,630 --> 00:03:33,359
Treinaremos nosso modelo para
prever a tarifa de táxi.

39
00:03:34,580 --> 00:03:35,670
Então vamos lá.

40
00:03:37,816 --> 00:03:43,129
Primeiro, definimos os nomes de
coluna aqui, valor da tarifa, pickuplon,

41
00:03:43,129 --> 00:03:44,880
pickuplat etc.

42
00:03:46,167 --> 00:03:52,890
E usamos o Pandas para ler esses
dados de arquivos CSV.

43
00:03:52,890 --> 00:03:56,700
Um conjunto de dados para treino,
outro para dados de validação.

44
00:04:00,880 --> 00:04:05,201
Agora, usamos a funcionalidade
incorporada nos

45
00:04:05,201 --> 00:04:10,597
estimadores para fazer uma função
de entrada de nosso Pandas,

46
00:04:10,597 --> 00:04:15,594
chamada
tf.estimators.inputs.pandas_input_fn.

47
00:04:15,594 --> 00:04:20,702
A função permite especificar
os atributos como x aqui,

48
00:04:20,702 --> 00:04:24,920
e os rótulos-alvo como y aqui.

49
00:04:24,920 --> 00:04:28,750
Ela também lida com configurações padrão
para um conjunto de dados de treino,

50
00:04:28,750 --> 00:04:32,777
o tamanho do lote, o número de épocas
e também a reprodução aleatória

51
00:04:32,777 --> 00:04:36,950
com o queue_capacity, que é
simplesmente o buffer de fila aleatório.

52
00:04:38,370 --> 00:04:39,860
Vamos executar este.

53
00:04:41,410 --> 00:04:44,560
Criamos as colunas de atributo.

54
00:04:44,560 --> 00:04:46,580
Todas são numéricas.

55
00:04:46,580 --> 00:04:47,665
Então, chamamos

56
00:04:47,665 --> 00:04:51,170
tf.feature_column.numeric_column
para cada uma.

57
00:04:51,170 --> 00:04:54,850
A lista de colunas de atributo informa
ao modelo como fazer o backup dos dados

58
00:04:54,850 --> 00:04:56,920
no vetor de entrada.

59
00:05:00,069 --> 00:05:03,910
O modelo é instanciado bem aqui.

60
00:05:05,440 --> 00:05:07,770
Damos a lista de colunas de atributo e

61
00:05:07,770 --> 00:05:12,730
um diretório em que todos os dados de
saída serão gravados, aqui.

62
00:05:14,250 --> 00:05:15,480
Para treinar o modelo,

63
00:05:15,480 --> 00:05:19,830
chamamos a função de treino,
passando na função de entrada de dados.

64
00:05:19,830 --> 00:05:23,122
Função treino e de entrada de dados.

65
00:05:24,689 --> 00:05:30,639
É esse que consegue dados do frame
de dados do Pandas em nosso modelo.

66
00:05:33,596 --> 00:05:36,760
Portanto, o modelo está sendo
executado por 10 épocas.

67
00:05:36,760 --> 00:05:40,220
Você vê os registros de treinamento aqui.

68
00:05:40,220 --> 00:05:42,500
E terminou. Foi treinado.

69
00:05:42,500 --> 00:05:43,672
Não é ótimo?

70
00:05:43,672 --> 00:05:46,710
Por que não testar em nosso
conjunto de dados de validação?

71
00:05:46,710 --> 00:05:52,631
Para isso, chamamos
avaliações de modelo aqui.

72
00:05:53,791 --> 00:05:57,047
Analisando, desta vez, a função
de entrada de dados que consegue

73
00:05:57,047 --> 00:06:01,800
os dados do frame de dados
do Pandas de validação df_valid.

74
00:06:01,800 --> 00:06:03,240
Analisamos aqui.

75
00:06:07,756 --> 00:06:10,770
E conseguimos nossos resultados.

76
00:06:10,770 --> 00:06:17,428
O erro quadrático médio (RMSE) final
é de US$ 10.

77
00:06:17,428 --> 00:06:20,740
Bem, US$ 10 é um erro grande
para uma corrida de táxi.

78
00:06:20,740 --> 00:06:23,800
E não está nem perto da 
referência anterior de US$ 6.

79
00:06:23,800 --> 00:06:29,790
Vamos melhorar isso mais tarde, agora
que temos um código que funciona.

80
00:06:29,790 --> 00:06:32,619
Vamos ver se podemos usar
este modelo para previsões.

81
00:06:38,591 --> 00:06:41,402
Quando instanciamos o modelo novamente,
ele procura por um

82
00:06:41,402 --> 00:06:45,590
ponto de verificação no diretório do
modelo e se recarrega a partir dele.

83
00:06:45,590 --> 00:06:49,780
Como acabamos de treinar o modelo, temos
um ponto de verificação treinado nele

84
00:06:49,780 --> 00:06:51,629
e ele está pronto para previsões.

85
00:06:53,250 --> 00:06:58,110
Instanciamos aqui, passando o
mesmo diretório de saída.

86
00:07:01,852 --> 00:07:09,300
E a função de previsão, chamada
aqui, retorna um gerador Python.

87
00:07:09,300 --> 00:07:12,584
Nós o chamamos em loop
para conseguir as tarifas previstas.

88
00:07:14,214 --> 00:07:17,480
Bem aqui, e você vê as
tarifas previstas aqui

89
00:07:18,570 --> 00:07:22,690
E talvez isso explique
por que o RMSE era tão alto.

90
00:07:22,690 --> 00:07:26,550
O modelo basicamente prevê o
mesmo valor para cada viagem.

91
00:07:26,550 --> 00:07:28,860
Um modelo mais complexo ajudaria?

92
00:07:28,860 --> 00:07:31,600
Vamos testar, usando uma boa
rede neural profunda.

93
00:07:31,600 --> 00:07:35,680
Mantemos tudo como está, colunas de
atributos e funções de entrada,

94
00:07:35,680 --> 00:07:40,400
e mudamos o modelo de um regressor
linear para um regressor DNN

95
00:07:40,400 --> 00:07:42,140
com três camadas ocultas.

96
00:07:45,930 --> 00:07:47,990
Então vamos fazer isso.

97
00:07:47,990 --> 00:07:53,822
Instanciamos o regressor DNN aqui e
configuramos as camadas ocultas aqui.

98
00:07:53,822 --> 00:07:57,779
Então, 32 nodes no primeiro, 8 nodes no
segundo, 2 nodes no último.

99
00:08:00,022 --> 00:08:01,740
Vamos treinar isso.

100
00:08:01,740 --> 00:08:04,868
Ele treina novamente por dez épocas.

101
00:08:05,931 --> 00:08:13,704
E no final, chamaremos a
função model.predict novamente

102
00:08:13,704 --> 00:08:16,649
deste auxiliar print_rmse.

103
00:08:25,165 --> 00:08:27,940
Ele está treinando.

104
00:08:32,106 --> 00:08:33,559
Agora está validando.

105
00:08:35,634 --> 00:08:41,196
E o RMSE no conjunto de dados
de validação, desta vez, é US$ 11.

106
00:08:41,196 --> 00:08:43,610
Ainda é ruim.

107
00:08:43,610 --> 00:08:47,010
Não estamos batendo nosso modelo
de referência com nenhum dos modelos.

108
00:08:47,010 --> 00:08:47,720
Por quê?

109
00:08:47,720 --> 00:08:51,727
Podemos estar usando o TensorFlow
para aprendizado de máquina, mas

110
00:08:51,727 --> 00:08:53,583
ainda não estamos usando direito.

111
00:08:53,583 --> 00:08:56,980
O restante deste curso é sobre isso.

112
00:08:56,980 --> 00:09:00,800
Mas, se tivéssemos que
escolher entre os dois modelos,

113
00:09:00,800 --> 00:09:05,150
escolheríamos aquele com
o menor erro de validação.

114
00:09:05,150 --> 00:09:10,650
E, finalmente, mediríamos o RMSE nos dados
de teste com esse modelo escolhido.

115
00:09:10,650 --> 00:09:16,010
Este RMSE final pode ser publicado como
o desempenho objetivo do melhor modelo.

116
00:09:16,010 --> 00:09:21,200
Este é o procedimento padrão em ciência
de dados: treinamento, validação e teste.

117
00:09:21,200 --> 00:09:24,060
Cada um com conjuntos
de dados separados.

118
00:09:24,060 --> 00:09:27,101
Vamos tentar isso no nosso
conjunto de dados de referência.

119
00:09:27,101 --> 00:09:33,088
O RMSE no conjunto de dados
de referência é 9,41.

120
00:09:57,647 --> 00:10:03,774
E aí está, o RMSE no conjunto de
dados de referência é de US$ 10,5.

121
00:10:03,774 --> 00:10:08,124
Isto é muito mais do que a
referência original de US$ 6.

122
00:10:08,124 --> 00:10:13,964
E nem sequer bate nossas regras
baseadas em distância, RMSE de US$ 8.

123
00:10:13,964 --> 00:10:18,550
Não tema! Você aprendeu a
escrever um modelo do TensorFlow.

124
00:10:18,550 --> 00:10:23,350
Mas não para fazer todo o
necessário para melhorar o modelo

125
00:10:23,350 --> 00:10:24,790
e fazê-lo executar.

126
00:10:24,790 --> 00:10:27,030
Faremos isso nos próximos capítulos.

127
00:10:27,030 --> 00:10:30,415
No entanto, neste capítulo, teremos
o modelo TensorFlow pronto

128
00:10:30,415 --> 00:10:32,295
para essas melhorias.