最初のEstimator Codelabに
取りかかりましょう まず Codelabの
ファイルがある場所を見つけます その方法をお見せしましょう cloud.google.com/consoleに移動し
ラボのアカウントでこのようにログインします 次に プロジェクトを選択します すでに選択済みの場合もあります Cloud Shellを開きます
このアイコンです Cloud Shellで「datalab create」
（データラボの作成）と入力します Datalabインスタンスに
「mylab」という名前を付けましょう これをus-central1-aゾーンに作成します これで最初のDatalabインスタンスが
作成されます 初めてのときは 少し時間がかかります （数分後） 次回はインスタンスのデータを
再作成する必要はなく 再接続するだけです
それには「datalab connect」と入力し インスタンスのデータを入力します
ここでは「mylab」です ここに[ウェブでプレビュー]ボタンがあります [ポートの変更]でポートを8081に変更します
Datalabはこれを使います [変更してプレビュー]をクリックすると おなじみのノートブック
インターフェースが開きます ここからGitHubのコードを
取得する必要があります それで ノートブックを開いて
bashコマンドを入力します %bash さらにgit cloneで Codelabのリポジトリを
ローカルディレクトリにコピーします 完了するとすぐに ローカルディレクトリがここに表示されます できました training-data-analystという名前で この中にcoursesという
ディレクトリが見つかるはずです さらにその中にmachine_learning、
deepdive、 tensorflowがあります 最初のラボは「b_estimator.ipynb」です この例ではpandasを使って
CSVファイルからデータを読み込みます そこにはタクシーの乗車情報が含まれています 乗車の場所、降車の場所、乗客の数です モデルをトレーニングして
タクシー料金を予測します では取りかかりましょう まず列名をここで定義します fare_amount、pickuplon、pickuplatなどです pandasを使ってこのデータを
CSVファイルから読み込みます トレーニング用データセットが1つ
検証用データセットが1つです 次にEstimatorの組み込み機能を使って pandasからinput関数を作成します tf.estimators.inputs.pandas_input_fn
という名前です この関数でfeaturesをxとして
このように指定し ターゲットとなるlabelをyとして
指定できます また トレーニング データセット用の
標準設定も揃っています バッチサイズ、エポック数、シャッフルです queue_capacityは
シャッフルキューのバッファです これを実行しましょう 次にfeature column（特徴列）を作成します すべて数値列です それぞれに対して
tf.feature_column.numeric_columnを呼び出します feature column（特徴列）の一覧では データを入力ベクターに入れる方法を
モデルに指示します モデルはここでインスタンス化されます ここです feature_columnsの一覧と
ディレクトリを指定します そこに すべての出力データが書き込まれます モデルをトレーニングするには train関数を指定し
データ入力関数inputを渡します train ... そしてinput関数 これでpandasのデータフレームから
データをモデルに取得します モデルがエポック数10回で動作しています トレーニングのログはこれです トレーニングが終わりました 出来はどうでしょうか？ 検証用のデータセットで試しましょう そのためにmodel.evaluateを
このように呼び出します 解析しています
今回はデータ入力関数inputが df_validつまり検証用pandasデータフレームから
データを取得します ここで解析します 結果が出ました 最後のRMSE（平均二乗平方根誤差）は
$10です $10はタクシー料金としては大きな誤差です 前のベンチマークの$6からも遠いです あとでこれを改善します
今は この手元のコードを使って このモデルを予測に使えるか見てみましょう モデルを再びインスタンス化するとき modelディレクトリ内のチェックポイントを探し
そこからリロードします モデルのトレーニングが完了し
チェックポイントができたので 予測の準備ができました ここでインスタンス化して
同じ出力ディレクトリを渡します predict関数をここで呼び出して
Pythonジェネレーターを返します これをループの中で呼び出して
予測した料金を取得します ここで予測した料金を確認できます なぜRMSEが高かったのか
これでわかるでしょう モデルは基本的に すべての乗車で
同じ金額を予測します 複雑なモデルなら役立つでしょうか？ DNNを使って
試してみましょう feature_columns、input関数などを
全部このままにします モデルをlinearRegressorから 3つの隠れレイヤを持つ
DNNRegressorに変更します やってみましょう ここをDNNRegressorに変更し
ここで隠れレイヤを構成します 最初のは32ノード
2番目は8ノード、最後は2ノードです トレーニングしましょう 10回のエポック数でトレーニングします 最後にmodel.predict関数を再び print_rmseヘルパーから呼び出します トレーニングがずっと続きます 今 検証しています 検証用データセットのRMSEは
今回は$11です まだ悪いですね どちらのモデルも
ベンチマークモデルに負けています なぜ？ TensorFlowを機械学習に使っていますが たぶん使い方が悪いのでしょう このコースの残りの部分で
これを取り上げます でも 記録用に2つのモデルの
どちらかを選ぶ必要があるなら 検証エラーが低いものを選ぶでしょう そして最後に 選択したモデルを使って
テストデータでRMSEを測定するでしょう この最終RMSEを 最適モデルの
目標パフォーマンスとして公表できます データサイエンスの標準的な手順
つまりトレーニング、評価、テストでは それぞれ別個のデータセットを使用します ベンチマーク用のデータセットで試しましょう ベンチマーク用データセットの
RMSEは9.41です このように ベンチマーク用データセットの
RMSEは$10.5です これは元のベンチマーク
$6よりかなり多く しかも 距離ベースのルールRMSE
$8より悪いです ここまでTensorFlowのモデルの
作成方法を学びました しかし モデルを改善して パフォーマンスを向上させる必要があります それについては
後の章で見ていきます この章では
そのような改善を可能にするために TensorFlowモデルを準備していきます