1
00:00:00,000 --> 00:00:03,130
では 大きなMLジョブの処理方法と

2
00:00:03,130 --> 00:00:06,210
分散型トレーニングの
メリットを見ていきましょう

3
00:00:06,210 --> 00:00:08,750
すでにこのリストの最初の項目
つまり

4
00:00:08,750 --> 00:00:12,150
現実世界のモデルでの
困難な問題について説明しました

5
00:00:12,150 --> 00:00:14,765
次の項目 つまりスピードに進みます

6
00:00:14,765 --> 00:00:19,950
実際のモデルのトレーニングは
何時間も何週間も続きます

7
00:00:19,950 --> 00:00:22,220
トレーニングが数週間になる場合

8
00:00:22,220 --> 00:00:24,145
Googleは あきらめます

9
00:00:24,145 --> 00:00:28,125
こんな状況でモデルを最適化するのは
非現実的です

10
00:00:28,125 --> 00:00:32,700
クラスタに分散して
高速化する必要があります

11
00:00:32,700 --> 00:00:35,690
1台のマシンから多数のマシンにする過程は

12
00:00:35,690 --> 00:00:37,990
複雑に思えるかもしれませんが

13
00:00:37,990 --> 00:00:42,525
Estimator APIとML Engineが
クラスタを自動的に管理するので

14
00:00:42,525 --> 00:00:44,995
すぐに分散できます

15
00:00:44,995 --> 00:00:51,540
分散型トレーニングを実装する関数は
estimator.train_and_evaluateです

16
00:00:51,540 --> 00:00:54,670
この関数の名前からわかるとおり

17
00:00:54,670 --> 00:00:58,695
大きなトレーニングジョブの
評価とモニタリングもまた重要です

18
00:00:58,695 --> 00:01:00,305
これは後で確認します

19
00:01:00,305 --> 00:01:03,045
今は分散に注意を向けましょう

20
00:01:03,045 --> 00:01:07,100
ニューラルネットワークの
トレーニングの分散型モデルは 従来

21
00:01:07,100 --> 00:01:09,285
データ並列と呼ばれていました

22
00:01:09,285 --> 00:01:13,120
モデルは複数のワーカーに複製されます

23
00:01:13,120 --> 00:01:15,055
トレーニングの各ステップで

24
00:01:15,055 --> 00:01:17,195
データのバッチを読み込みます

25
00:01:17,195 --> 00:01:19,500
毎回異なるバッチが理想的です

26
00:01:19,500 --> 00:01:24,930
勾配を計算し 中央にある
パラメータサーバーにそれを送信します

27
00:01:24,930 --> 00:01:29,535
サーバーはニューラルネットワークモデルの
すべての重みとバイアスを保持します

28
00:01:29,535 --> 00:01:31,790
勾配が到達するとそれが適用され

29
00:01:31,790 --> 00:01:33,615
重みとバイアスが変更され

30
00:01:33,615 --> 00:01:39,240
更新後のモデルが
次のステップ用にワーカーに戻されます

31
00:01:39,240 --> 00:01:42,480
これを行うには多数の操作が必要です

32
00:01:42,480 --> 00:01:45,795
ワーカーを開始し
モデルのコピーを受け取り

33
00:01:45,800 --> 00:01:49,060
データがワーカーを流れ
パラメータサーバーを確立し

34
00:01:49,060 --> 00:01:51,060
例外やエラーを処理します

35
00:01:51,060 --> 00:01:53,230
インシデントが発生した場合

36
00:01:53,230 --> 00:01:57,580
フィールドワーカーが中断したところから
再開します

37
00:01:57,580 --> 00:01:59,635
こうしたことが行われると

38
00:01:59,635 --> 00:02:02,240
チェックポイントも複雑になります

39
00:02:02,240 --> 00:02:07,425
でも皆様にとって分散型はシンプルで
構成ファイルを作成するだけです

40
00:02:07,425 --> 00:02:11,500
定型のコードはすでにEstimator APIと

41
00:02:11,500 --> 00:02:15,775
estimator.train_and_evaluate関数で
作成済みです

42
00:02:15,775 --> 00:02:17,805
皆様は4つのことをします

43
00:02:17,805 --> 00:02:22,990
Estimatorを選択し、RunConfigを提供し、
トレーニングを提供し

44
00:02:22,990 --> 00:02:26,195
TrainSpecとEvalSpecでデータをテストします

45
00:02:26,195 --> 00:02:29,515
その後 train_and_evaluateを呼び出します

46
00:02:29,515 --> 00:02:31,990
ML Engine上で実行する際に

47
00:02:31,990 --> 00:02:37,055
クラスタサイズを指定済みであれば
分散型トレーニングが始まります

48
00:02:37,055 --> 00:02:38,895
詳しく見てみましょう

49
00:02:38,895 --> 00:02:40,735
まずRunConfigです

50
00:02:40,735 --> 00:02:44,205
ここでチェックポイントの
出力ディレクトリを指定します

51
00:02:44,205 --> 00:02:46,420
Estimatorのインスタンス化の時に

52
00:02:46,420 --> 00:02:48,540
これを構成することもできますが

53
00:02:48,540 --> 00:02:50,995
今ここで 他のチェックポイントと一緒に

54
00:02:50,995 --> 00:02:52,935
指定した方がすっきりします

55
00:02:52,935 --> 00:02:58,520
さらに ここでは
チェックポイントを確認する頻度と

56
00:02:58,520 --> 00:03:02,015
トレーニングログや概要の頻度も設定します

57
00:03:02,015 --> 00:03:04,005
それについては後で述べます

58
00:03:04,005 --> 00:03:09,690
TrainSpecではトレーニングデータ用の
入力関数inputを渡します

59
00:03:09,690 --> 00:03:13,410
適切にセットアップするには
Dataset APIを使用してください

60
00:03:13,410 --> 00:03:17,380
オプションで トレーニングの
ステップ数を制限できます

61
00:03:17,380 --> 00:03:21,865
デフォルトでは 入力データセットを
全部使うまでトレーニングされますが

62
00:03:21,865 --> 00:03:26,420
設定によっては その前に
多数のe-bugが発生することがあります

63
00:03:26,420 --> 00:03:30,990
eval_specでは テスト用
データセットを指定します

64
00:03:30,990 --> 00:03:34,070
モデルの動作を確認したい場合は

65
00:03:34,070 --> 00:03:39,685
トレーニングでまだ未使用のデータセットを
使って測定する必要があります

66
00:03:39,685 --> 00:03:43,960
通常はテスト用に取り分ける
データのサブセットです

67
00:03:43,960 --> 00:03:47,270
テストデータはeval_input関数で指定します

68
00:03:47,270 --> 00:03:50,725
ここでもDataset APIを使って
取得してください

69
00:03:50,725 --> 00:03:55,964
また 評価するテストデータのバッチ数や

70
00:03:55,964 --> 00:03:59,180
評価の発生頻度も指定します

71
00:03:59,180 --> 00:04:02,905
実装で 注意していただきたい
ことが1つあります

72
00:04:02,905 --> 00:04:07,625
分散型トレーニングでは
評価は専用サーバーで行われます

73
00:04:07,625 --> 00:04:12,785
最新のチェックポイントから
モデルにレスポンスし evalを実行します

74
00:04:12,785 --> 00:04:17,575
RunConfigで入力した
チェックポイントの頻度を超える頻度で

75
00:04:17,575 --> 00:04:20,839
評価を得ることはできません

76
00:04:20,839 --> 00:04:23,490
ただし頻度を減らすために

77
00:04:23,490 --> 00:04:27,530
throttleパラメータを eval_specに追加できます

78
00:04:27,530 --> 00:04:32,445
eval_specには exportersパラメータもありますね

79
00:04:32,445 --> 00:04:36,990
これは モデルを本番環境用に
エクスポートする方法を制御します

80
00:04:36,990 --> 00:04:39,510
これについては次の章で取り上げます

81
00:04:39,510 --> 00:04:41,845
まとめましょう

82
00:04:41,845 --> 00:04:43,945
Estimatorをインスタンス化して

83
00:04:43,945 --> 00:04:47,720
RunConfigをそれに渡し
ここでチェックポイントなどの

84
00:04:47,720 --> 00:04:51,960
モニタリングデータを書き込む回数と
出力先フォルダを設定できます

85
00:04:51,960 --> 00:04:56,735
次に train_spec eval_spec
データセットを設定し

86
00:04:56,735 --> 00:05:03,390
TrainSpecとEvalSpecの
データ入力関数inputでそれを提供すると

87
00:05:03,390 --> 00:05:06,775
トレーニングと評価の準備ができます

88
00:05:06,775 --> 00:05:10,560
ここでひと言 実施の際に
注意すべきアドバイスがあります

89
00:05:10,560 --> 00:05:12,260
データのシャッフルです

90
00:05:12,260 --> 00:05:17,360
ニューラルネットワークのトレーニングで使う
確率的勾配降下法アルゴリズムは

91
00:05:17,360 --> 00:05:20,435
よくシャッフルされたデータでのみ機能します

92
00:05:20,435 --> 00:05:23,790
Dataset APIの shuffle関数が役立ちます

93
00:05:23,790 --> 00:05:27,380
ただしディスク上でデータが
すでにシャッフル済みだと考えて

94
00:05:27,380 --> 00:05:29,580
これを使わない人もいるでしょう

95
00:05:29,580 --> 00:05:32,400
分散型トレーニングでは注意が必要です

96
00:05:32,400 --> 00:05:35,600
ディスク上ではよくシャッフルされた
データセットでも

97
00:05:35,600 --> 00:05:39,660
すべてのワーカーが
このデータセットから直接読み込む場合

98
00:05:39,660 --> 00:05:42,875
同じバッチデータを同時に読み込み

99
00:05:42,875 --> 00:05:45,245
同じ勾配を生成するでしょう

100
00:05:45,245 --> 00:05:48,360
分散型トレーニングのメリットが台無しです

101
00:05:48,360 --> 00:05:52,130
複数のワーカーが全部同じことをやります

102
00:05:52,130 --> 00:05:53,974
Datasetのshuffleでは

103
00:05:53,974 --> 00:05:58,350
ワーカーごとに別のランダムシードを使って
個別にシャッフルするので

104
00:05:58,350 --> 00:06:03,375
ディスク上でデータがシャッフル済みでも
ぜひ これをご使用ください

105
00:06:03,375 --> 00:06:05,745
さらに確実にしたい場合は

106
00:06:05,745 --> 00:06:10,290
細分化されたデータセットの
ファイル名リストもシャッフルできます

107
00:06:10,290 --> 00:06:13,960
list_filesはファイル名からなる
データセットを返します

108
00:06:13,960 --> 00:06:17,070
ですからshuffle_linesを呼び出してください