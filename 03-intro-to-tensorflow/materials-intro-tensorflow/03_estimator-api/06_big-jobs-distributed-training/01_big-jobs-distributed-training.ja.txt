では 大きなMLジョブの処理方法と 分散型トレーニングの
メリットを見ていきましょう すでにこのリストの最初の項目
つまり 現実世界のモデルでの
困難な問題について説明しました 次の項目 つまりスピードに進みます 実際のモデルのトレーニングは
何時間も何週間も続きます トレーニングが数週間になる場合 Googleは あきらめます こんな状況でモデルを最適化するのは
非現実的です クラスタに分散して
高速化する必要があります 1台のマシンから多数のマシンにする過程は 複雑に思えるかもしれませんが Estimator APIとML Engineが
クラスタを自動的に管理するので すぐに分散できます 分散型トレーニングを実装する関数は
estimator.train_and_evaluateです この関数の名前からわかるとおり 大きなトレーニングジョブの
評価とモニタリングもまた重要です これは後で確認します 今は分散に注意を向けましょう ニューラルネットワークの
トレーニングの分散型モデルは 従来 データ並列と呼ばれていました モデルは複数のワーカーに複製されます トレーニングの各ステップで データのバッチを読み込みます 毎回異なるバッチが理想的です 勾配を計算し 中央にある
パラメータサーバーにそれを送信します サーバーはニューラルネットワークモデルの
すべての重みとバイアスを保持します 勾配が到達するとそれが適用され 重みとバイアスが変更され 更新後のモデルが
次のステップ用にワーカーに戻されます これを行うには多数の操作が必要です ワーカーを開始し
モデルのコピーを受け取り データがワーカーを流れ
パラメータサーバーを確立し 例外やエラーを処理します インシデントが発生した場合 フィールドワーカーが中断したところから
再開します こうしたことが行われると チェックポイントも複雑になります でも皆様にとって分散型はシンプルで
構成ファイルを作成するだけです 定型のコードはすでにEstimator APIと estimator.train_and_evaluate関数で
作成済みです 皆様は4つのことをします Estimatorを選択し、RunConfigを提供し、
トレーニングを提供し TrainSpecとEvalSpecでデータをテストします その後 train_and_evaluateを呼び出します ML Engine上で実行する際に クラスタサイズを指定済みであれば
分散型トレーニングが始まります 詳しく見てみましょう まずRunConfigです ここでチェックポイントの
出力ディレクトリを指定します Estimatorのインスタンス化の時に これを構成することもできますが 今ここで 他のチェックポイントと一緒に 指定した方がすっきりします さらに ここでは
チェックポイントを確認する頻度と トレーニングログや概要の頻度も設定します それについては後で述べます TrainSpecではトレーニングデータ用の
入力関数inputを渡します 適切にセットアップするには
Dataset APIを使用してください オプションで トレーニングの
ステップ数を制限できます デフォルトでは 入力データセットを
全部使うまでトレーニングされますが 設定によっては その前に
多数のe-bugが発生することがあります eval_specでは テスト用
データセットを指定します モデルの動作を確認したい場合は トレーニングでまだ未使用のデータセットを
使って測定する必要があります 通常はテスト用に取り分ける
データのサブセットです テストデータはeval_input関数で指定します ここでもDataset APIを使って
取得してください また 評価するテストデータのバッチ数や 評価の発生頻度も指定します 実装で 注意していただきたい
ことが1つあります 分散型トレーニングでは
評価は専用サーバーで行われます 最新のチェックポイントから
モデルにレスポンスし evalを実行します RunConfigで入力した
チェックポイントの頻度を超える頻度で 評価を得ることはできません ただし頻度を減らすために throttleパラメータを eval_specに追加できます eval_specには exportersパラメータもありますね これは モデルを本番環境用に
エクスポートする方法を制御します これについては次の章で取り上げます まとめましょう Estimatorをインスタンス化して RunConfigをそれに渡し
ここでチェックポイントなどの モニタリングデータを書き込む回数と
出力先フォルダを設定できます 次に train_spec eval_spec
データセットを設定し TrainSpecとEvalSpecの
データ入力関数inputでそれを提供すると トレーニングと評価の準備ができます ここでひと言 実施の際に
注意すべきアドバイスがあります データのシャッフルです ニューラルネットワークのトレーニングで使う
確率的勾配降下法アルゴリズムは よくシャッフルされたデータでのみ機能します Dataset APIの shuffle関数が役立ちます ただしディスク上でデータが
すでにシャッフル済みだと考えて これを使わない人もいるでしょう 分散型トレーニングでは注意が必要です ディスク上ではよくシャッフルされた
データセットでも すべてのワーカーが
このデータセットから直接読み込む場合 同じバッチデータを同時に読み込み 同じ勾配を生成するでしょう 分散型トレーニングのメリットが台無しです 複数のワーカーが全部同じことをやります Datasetのshuffleでは ワーカーごとに別のランダムシードを使って
個別にシャッフルするので ディスク上でデータがシャッフル済みでも
ぜひ これをご使用ください さらに確実にしたい場合は 細分化されたデータセットの
ファイル名リストもシャッフルできます list_filesはファイル名からなる
データセットを返します ですからshuffle_linesを呼び出してください