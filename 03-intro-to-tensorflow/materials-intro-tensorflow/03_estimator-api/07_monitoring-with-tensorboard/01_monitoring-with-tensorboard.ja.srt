1
00:00:00,000 --> 00:00:04,725
TensorBoardでトレーニングを
モニタリングする方法をご紹介します

2
00:00:04,725 --> 00:00:07,385
完了した2項目に
チェックマークを付け

3
00:00:07,385 --> 00:00:08,745
残りは2つです

4
00:00:08,745 --> 00:00:11,390
train_and_evaluateをすでに使っているので

5
00:00:11,390 --> 00:00:15,300
トレーニングが進むにつれて
評価指標が得られます

6
00:00:15,300 --> 00:00:19,570
それを可視化するために
TensorBoardツールを使いましょう

7
00:00:19,570 --> 00:00:22,800
どんなトレーニングでも
これがベストプラクティスです

8
00:00:22,800 --> 00:00:26,130
グラフでトレーニングと評価の
曲線を比較すると

9
00:00:26,130 --> 00:00:29,055
役立つ情報がたくさん得られます

10
00:00:29,055 --> 00:00:31,260
私はtrain_and_evaluateを

11
00:00:31,260 --> 00:00:35,525
分散型トレーニングの時だけでなく
いつも使っています

12
00:00:35,525 --> 00:00:37,440
TensorBoardツールを使えば

13
00:00:37,440 --> 00:00:42,180
モデルがディスクに書き込むトレーニングと
評価指標を可視化できます

14
00:00:42,180 --> 00:00:46,275
TensorBoardはTensorFlow
インストール環境に標準で含まれる

15
00:00:46,275 --> 00:00:48,080
コマンドラインツールです

16
00:00:48,080 --> 00:00:52,450
RunConfigで指定した
出力ディレクトリを参照すると

17
00:00:52,450 --> 00:00:58,525
TensorBoardダッシュボードが
localhost:6006で表示されます

18
00:00:58,525 --> 00:01:03,060
作成済みのEstimatorには 定義済み
標準指標のセットがあるので

19
00:01:03,060 --> 00:01:05,595
他に構成するものは ありません

20
00:01:05,595 --> 00:01:09,865
たとえばトレーニングと評価の損失を
同じグラフで確認でき

21
00:01:09,865 --> 00:01:13,240
これはモデルの過剰適合を
確認するのに役立ちます

22
00:01:13,240 --> 00:01:15,719
Dense Neural Network Estimatorは

23
00:01:15,719 --> 00:01:20,115
ゼロを出力するニューロンの断片も追跡します

24
00:01:20,115 --> 00:01:24,220
ReLU活性化関数を使うときには
確かにこれが起きますが

25
00:01:24,220 --> 00:01:25,715
注意が必要です

26
00:01:25,715 --> 00:01:29,310
すべてゼロを出力する
ニューロンからなるネットワークは

27
00:01:29,310 --> 00:01:31,115
「死んで」います

28
00:01:31,115 --> 00:01:35,085
TensorBoardでは TensorFlowグラフも
確認できます

29
00:01:35,085 --> 00:01:36,780
これは デバッグする時や

30
00:01:36,780 --> 00:01:41,105
コードが生成するグラフを確認したい時に
役立つでしょう

31
00:01:41,105 --> 00:01:44,160
カスタムEstimatorの作成で

32
00:01:44,160 --> 00:01:47,850
独自のニューラルネットワーク層を
指定する場合

33
00:01:47,850 --> 00:01:51,180
tf.summary.**コマンドを使用すると

34
00:01:51,180 --> 00:01:55,785
さまざまなデータをログに記録し
TensorBoardで可視化できます

35
00:01:55,785 --> 00:01:59,825
たとえば 数値、テキスト
画像、音声ファイルも可能です

36
00:01:59,840 --> 00:02:04,605
Estimator APIでモデルに
1行追加するだけで出力が得られます

37
00:02:04,605 --> 00:02:07,410
「tf.summary.scalar」に続けて

38
00:02:07,410 --> 00:02:10,380
TensorBoardで見たいグラフの名前と

39
00:02:10,380 --> 00:02:12,750
プロットする値のテンソルです

40
00:02:12,750 --> 00:02:15,540
Estimator APIを使わない場合は

41
00:02:15,540 --> 00:02:17,700
追加のステップが必要です

42
00:02:17,700 --> 00:02:20,970
この資料で それを確認してください

43
00:02:20,970 --> 00:02:24,015
たとえば これはヒストグラムのプロットです

44
00:02:24,015 --> 00:02:28,640
独自の出力で起こり得る問題を
可視化するのに役立ちます

45
00:02:28,640 --> 00:02:29,990
左側は

46
00:02:29,990 --> 00:02:34,105
シグモイドで活性化された
ニューラルネットワーク層の

47
00:02:34,105 --> 00:02:37,230
すべての値のヒストグラムです

48
00:02:37,230 --> 00:02:41,120
問題がありますね
ゼロと1がピークになっています

49
00:02:41,130 --> 00:02:45,720
ほとんどのニューロンが飽和し
役に立たないでしょう

50
00:02:45,720 --> 00:02:49,995
バッチ正規化というテクニックで
これを修正できます

51
00:02:49,995 --> 00:02:53,415
これはバッチ正規化後の
同じ層の出力です

52
00:02:53,415 --> 00:02:58,445
役立つ範囲全体で ニューロンが
値を生成するようになりました

53
00:02:58,445 --> 00:03:00,950
より良い結果が
生成されるかどうかは

54
00:03:00,950 --> 00:03:02,430
モデルによりますが

55
00:03:02,430 --> 00:03:06,705
少なくともバッチ正規化が
機能しているのを確認できます

56
00:03:06,705 --> 00:03:09,300
画像や音声を扱うときは

57
00:03:09,300 --> 00:03:14,475
TensorBoardに専用のダッシュボードがあり
目や耳で状態を確認できます

58
00:03:14,475 --> 00:03:20,130
コードで関数summary.imageと
summary.audioを使えば

59
00:03:20,130 --> 00:03:29,099
画像や音声ファイルを表すテンソルを
記録することを指定できます

60
00:03:29,099 --> 00:03:33,945
そして TensorBoardの専用ダッシュボードに
それらが表示されます

61
00:03:33,945 --> 00:03:35,831
たとえばこれは

62
00:03:35,831 --> 00:03:39,981
飛行機の検出モデルの開発で
私が使った可視化です