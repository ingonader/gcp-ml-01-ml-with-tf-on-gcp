大きなデータセットと分散型トレーニングで
モデルをトレーニングしました TensorBoard曲線が終わりました
次の項目「デプロイ」は簡単です ML EngineのCloud Consoleで
何度かクリックすれば トレーニング済みモデルが
マネージドREST APIの裏で起動し JSONトラフィックを受け入れます ちよっと待って
JSONですか？ モデルは JSONの読み方がわかりません トレーニング/テストデータの
input関数はありますが JSONデータがRESTエンドポイントに
来ても処理できません ですから1つ追加します すでにEvalSpecで説明した
exportersパラメータを思い出してください これで完全なモデルが定義されます トレーニング済みパラメータの
チェックポイントを使って デプロイの準備ができるだけでなく さらに 追加の入力関数を使用し REST APIが受け取るJSONと
モデルが想定する特徴をマップします この関数の名前はserving_inputです キーポイントは 提供時とトレーニング時の入力が
しばしばまったく異なることです それを理解するために
もう一度詳しく確認しましょう TensorFlowでは
すべてのものがグラフです モデルをインスタンス化したときの
グラフがここにあります 予測の方がやや単純ですが
基本的にトレーニング時と推測時は同じで どちらも特徴を読み込んで
予測を生成します データソースを入力に接続しましょう トレーニングでは
training_input関数を使います Dataset API を使ってCSVファイルから
順次読み込む入力ノードを作成し トレーニングデータの
バッチをモデルに送ります これに似たパターンを
デプロイ済みモデルでも使います serving_input（提供入力）関数では REST APIが受け取るJSONと
モデルが想定する機能の間に TensorFlow変換を追加できます JSONの解析は必要ありません
ML Engineが自動的に処理します その他の変換を
ここで記述する必要があります 「RESTエンドポイントに入る すべての
データでserving_input関数が呼び出される」 とよく誤解されますが
それは間違いです これはモデルのインスタンス化時に
1回だけ実行されます そこで生成されるTensorFlowグラフは 一方で JSONパーサーに接続され
もう一方でモデルに接続されます JSON値から特徴に変換する方法を
自由に決められますが その際に必ずTensorFlowコマンドを
使ってください これにより変換のグラフが返されます グラフの断片を
いつまとめるのでしょうか？ exporterでserving_input関数を指定して exporterをeval_specに追加すると
接続が発生します exporterはチェックポイント付きモデル
および変換情報を エクスポートモデルファイルの中に保存し
デプロイの準備ができます どのチェックポイントが保存されるかは
exporterの種類によります 最もシンプルなのは このLatestExporterです これは利用できる最新のチェックポイントを
受け入れます ディスクにエクスポートされたモデルは
exportフォルダに入ります APIでこのexporterに
「pricing」という名前を付けたので pricingサブフォルダが作成されました この中の数字付きフォルダはそれぞれ
デプロイ準備ができたモデルです REST APIをテストするには JSONデータを
エンドポイントで送るだけです Google Cloud SDKの
gcloud ml-engine predictコマンドで JSONファイルのデータを使って
簡単にテストできます 構文は1つのJSONフィールド「instances」です この中にJSONオブジェクトの一覧が serving_input関数の想定する形式で
含まれます ここにsq_footageとprop_typeがあります 一覧のデータインスタンスは
自動的にバッチにまとまり serving_input関数が 面積の数値の一覧と
物件タイプ文字列の一覧を受け取ります これはデプロイしないでテストする
簡単な方法です gcloud ml-engine local predictコマンドでは ディスク上のエクスポートされた
モデルから予測を直接取得できます デプロイは不要です なお このコマンドでは
少し違う形式が想定されています JSONオブジェクトの一覧をファイルで提供し
1行に1つのオブジェクトです serving_input関数の一般的な使い方が
もう一つあります JPEG画像のデコードです 画像を処理するモデルを扱う場合 画像を常に圧縮して
ネットワーク経由で送るでしょう しかしモデルは
圧縮されていない画像を想定します serving_input関数で圧縮解除できます これがサンプルコードです JSONフィードから画像が
tf.string型として直接送られます これは TensorFlowではバイト文字列
つまりランダムなバイト一覧です JPEGはバイナリ形式ですが これを JSONで使えるテキスト文字列に変えるには
base64エンコードが必要です TensorFlowでは base64エンコードされたバイナリ文字列を
マークするカスタム JSON表記を採用します フィールド名の末尾に「_bytes」を付け
値をb64というJSONオブジェクトにして base64エンコードされた
文字列を値として指定します この表記によりbase64デコードが
自動的に始まります serving_input関数で
それを処理する必要はありません