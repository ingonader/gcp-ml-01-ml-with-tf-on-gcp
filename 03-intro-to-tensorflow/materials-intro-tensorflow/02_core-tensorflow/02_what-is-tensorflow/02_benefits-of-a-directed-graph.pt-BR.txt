Então, por que o TensorFlow usa
gráficos acíclicos direcionados para representar a computação? Portabilidade. O gráfico acíclico direcionado, o DAG, é uma representação independente
de linguagem do código em seu modelo. Você pode criar um DAG no Python,
armazená-lo em um modelo salvo e restaurá-lo em um programa C++
para previsões de baixa latência. Você pode usar o mesmo código Python
e executá-lo em CPUs e GPUs, de modo que ele ofereça
portabilidade de hardware e linguagem. De muitas maneiras, isso é semelhante
a como a Java Virtual Machine, a JVM, e a representação de código de byte ajudam
na capacidade do código Java. Como desenvolvedores, conseguimos escrever
código em uma linguagem de alto nível, Java, e executá-lo em
diferentes plataformas pela JVM. A própria JVM é muito eficiente
e direcionada para o SO e o hardware exatos, e é escrita em C ou C++. Algo muito parecido com o TensorFlow. Como desenvolvedores,
conseguimos escrever código em uma linguagem de alto nível,
o Python, e executá-lo em diferentes plataformas
pelo mecanismo de execução do TensorFlow. O mecanismo de execução do TensorFlow
é muito eficiente e está voltado para
o chip de hardware exato e os recursos dele, e é escrito em C++. A portabilidade entre dispositivos
oferece muita potência e flexibilidade. Por exemplo, este é um padrão comum. Você pode treinar um modelo TensorFlow
na nuvem, em muitos hardwares poderosos, e depois pegar esse modelo treinado e
colocá-lo em um dispositivo fora da borda. Talvez um smartphone ou até mesmo
um chip embutido. E você pode fazer previsões com o modelo
diretamente no próprio dispositivo. Lembra do app Google Tradutor
sobre o qual falamos no primeiro curso desta especialização? Esse app pode funcionar completamente
off-line porque um modelo de tradução treinado é armazenado no smartphone
e fica disponível para tradução off-line. Ele tende a ser um modelo menor
e menos poderoso do que o da nuvem por causa das limitações do poder de
processamento disponível em um smartphone. Mas o fato de o TensorFlow
poder fazer isso é muito legal e possível apenas devido à portabilidade fornecida
pela representação acíclica direcionada. Esses tipos de modelos menores e menos potentes normalmente são
implementados com o TensorFlow Lite. Falei sobre o treinamento na nuvem e depois fiz previsões em um dispositivo
de baixa potência, como um smartphone. Claro, mas você consegue treinar
o próprio modelo no smartphone? Ainda não, porque o treinamento do modelo
de ML tende a ser uma operação cara. Mas, cada vez mais, estamos fazendo algo
que está no meio do caminho. Agora, isso é algo que apenas
as pessoas mais avançadas em ML estão fazendo,
não é necessariamente difundido. Mas o que quero dizer com meio do caminho? Uma situação é que você treina um modelo
e depois o implanta em vários smartphones. Quando você faz uma previsão, o usuário diz "não, isso não está certo"
ou "mostre-me mais resultados como este". E, neste ponto, você quer
atualizar as ponderações do modelo para que reflitam
as preferências do usuário. Esse tipo de ajuste fino de um modelo
treinado é possível em um smartphone. O smartphone do usuário personaliza
o modelo localmente com base no uso, e é isso que é mostrado em A. No entanto, aqui está você,
ajustando o modelo para cada usuário. Talvez você não queira enviar
as preferências do usuário de volta ao seu sistema, de volta à nuvem, porque
pode haver dados confidenciais. Mas você pode configurar
o que é chamado de aprendizado federado, em que você agrega as atualizações de
muitos usuários, conforme mostrado em B. Esse agregado é como uma atualização
de ponderação em um lote de amostras, exceto que é proveniente
de diferentes usuários. Por isso, forma uma mudança de consenso,
e é isso que estamos mostrando em C, e essa mudança de consenso acontece
com o modelo compartilhado na nuvem. Então, você implanta
o modelo compartilhado, ajusta-o em dispositivos de usuários
diferentes e repete o processo. O TensorFlow é este
software portátil, poderoso e pronto para produção
para computação numérica. Ele é muito usado para
aprendizado de máquina, o repositório número um para
aprendizado de máquina no GitHub. Por que é tão usado? É muito usado entre os pesquisadores de
aprendizado profundo por causa da comunidade em torno dele e da capacidade de ampliá-lo
e fazer coisas legais e novas. É usado entre os engenheiros
de aprendizado de máquina devido à capacidade de produzir modelos
e fazer algo em grande escala. Os dois grupos colhem os benefícios
desse grande uso. Os pesquisadores querem ver os métodos
deles sendo amplamente utilizados, e implementá-los no TensorFlow
é uma maneira de garantir isso. Os engenheiros de ML querem preparar
os códigos para o futuro para poder usar
modelos mais novos assim que forem inventados,
e o TensorFlow os ajuda a fazer isso. No Google, deixamos o TensorFlow
com código aberto para beneficiar muitas outras empresas e porque vimos o potencial desse tipo
de suporte imenso da comunidade. Como o TensorFlow tem código aberto,
ele oferece um benefício importante. Você não fica preso a um fornecedor quando
usa o Cloud Machine Learning Engine no GCP porque o código que você escreve está no
TensorFlow, e ele tem código aberto.