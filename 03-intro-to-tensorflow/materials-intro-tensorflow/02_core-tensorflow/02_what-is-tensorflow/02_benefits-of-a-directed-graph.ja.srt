1
00:00:00,000 --> 00:00:04,810
TensorFlowで有向非巡回グラフ（DAG）を
使ってコンピュテーションを表すのは

2
00:00:06,010 --> 00:00:07,860
移植性が理由です

3
00:00:07,860 --> 00:00:15,070
DAGは言語に依存せずに
モデルのコードを表します

4
00:00:15,070 --> 00:00:19,650
PythonでDAGを作成し
モデルに保存して

5
00:00:19,650 --> 00:00:24,500
低レイテンシ予測用の
C++プログラムで復元できます

6
00:00:24,500 --> 00:00:29,660
同じPythonコードを使って
CPUとGPUの両方で実行できるので

7
00:00:29,660 --> 00:00:35,520
言語やハードウェアを超えた
移植性が備わります

8
00:00:35,520 --> 00:00:40,400
これは Java仮想マシン（JVM）と
バイトコード表記が

9
00:00:40,400 --> 00:00:45,560
Javaコードの機能に対応するのに似ています

10
00:00:45,560 --> 00:00:49,830
高水準言語のJavaで
記述したコードが

11
00:00:49,830 --> 00:00:54,680
JVMによって
プラットフォームで実行されます

12
00:00:54,680 --> 00:01:00,940
JVM自体は
特定のOSやハードウェア向けに

13
00:01:00,940 --> 00:01:04,670
CやC++で書かれた効率的なコードです

14
00:01:04,670 --> 00:01:07,580
TensorFlowも同様に

15
00:01:07,580 --> 00:01:12,480
高水準言語のPythonで
記述したコードが

16
00:01:12,480 --> 00:01:17,893
TensorFlow実行エンジンによって
プラットフォームで実行されます

17
00:01:17,893 --> 00:01:22,585
TensorFlow実行エンジンはとても効率的で

18
00:01:22,585 --> 00:01:26,590
特定のハードウェアのチップと機能に
的を絞って

19
00:01:26,590 --> 00:01:29,720
C++で書かれています

20
00:01:29,720 --> 00:01:35,660
デバイス間の移植性があるので
非常に強力で柔軟です

21
00:01:35,660 --> 00:01:38,410
たとえば これは共通パターンです

22
00:01:38,410 --> 00:01:43,600
TensorFlowモデルをクラウドや
高性能ハードウェアでトレーニングした後

23
00:01:43,600 --> 00:01:48,710
エッジにあるデバイスで
学習済みモデルを使用できます

24
00:01:48,710 --> 00:01:52,590
これは 携帯電話や
埋め込みチップでも可能でしょう

25
00:01:52,590 --> 00:01:57,330
そのデバイス自体で
モデルを使って予測できます

26
00:01:57,830 --> 00:02:00,000
この専門分野の最初のコースで

27
00:02:00,000 --> 00:02:04,010
Google翻訳アプリについて
お話ししましたが

28
00:02:04,010 --> 00:02:08,729
このアプリは完全にオフラインで機能します

29
00:02:08,729 --> 00:02:14,800
学習済み翻訳モデルが電話機に保存され
オフラインで翻訳できます

30
00:02:14,800 --> 00:02:18,736
電話機はクラウドに比べて
処理能力が限られているので

31
00:02:18,736 --> 00:02:22,746
モデルの規模や能力は
小さくなりますが

32
00:02:22,746 --> 00:02:27,824
TensorFlowに
こうした機能があるのは事実です

33
00:02:27,824 --> 00:02:35,290
これも有向非巡回表現で
移植性が備わっているおかげです

34
00:02:35,290 --> 00:02:38,190
こうした小規模で低機能のモデルは

35
00:02:38,190 --> 00:02:41,710
通常 TensorFlow Liteを使って実装されます

36
00:02:41,710 --> 00:02:44,150
クラウドでトレーニングした後

37
00:02:44,150 --> 00:02:48,200
小規模デバイスで予測すると
お話しましたが

38
00:02:48,200 --> 00:02:53,530
現在のところは
電話機でモデルをトレーニングできまません

39
00:02:53,530 --> 00:02:59,430
これはMLモデルトレーニングの
負荷が大きいからです

40
00:02:59,430 --> 00:03:03,140
徐々に実現に近づいており
「道半ば」です

41
00:03:03,140 --> 00:03:07,440
極めて先進的な
ML環境でのみ可能で

42
00:03:07,440 --> 00:03:11,110
あまり普及していません

43
00:03:11,110 --> 00:03:14,120
「道半ば」とはどんな状態でしょう

44
00:03:14,120 --> 00:03:19,040
あるモデルをトレーニングした後
さまざまな電話機にデプロイするとします

45
00:03:19,040 --> 00:03:22,970
そして予測を実行し

46
00:03:22,970 --> 00:03:26,830
ユーザーからの「これは間違いだ」
「もっとこんな結果が欲しい」

47
00:03:26,830 --> 00:03:28,620
という意見に対して

48
00:03:28,620 --> 00:03:34,240
ユーザーの好みに合うよう
モデルの重みを調整します

49
00:03:34,240 --> 00:03:39,720
学習済みモデルを微調整することは
電話機では可能です

50
00:03:39,720 --> 00:03:45,730
ユーザーの使い方に合わせて
モデルをパーソナライズできます

51
00:03:45,730 --> 00:03:48,750
この図の「A」にあたります

52
00:03:49,290 --> 00:03:54,150
ただし この場合はユーザーごとに
モデルを微調整しますが

53
00:03:54,150 --> 00:03:58,380
ユーザーの好みを
クラウドに戻すのは良くありません

54
00:03:58,380 --> 00:04:02,310
個人情報にかかわる可能性があるからです

55
00:04:02,310 --> 00:04:05,860
ただし フェデレーション
ラーニングは可能です

56
00:04:05,860 --> 00:04:11,500
「B」のように
多数のユーザーの更新が集計されます

57
00:04:11,500 --> 00:04:15,420
この集計は多くのユーザーから
得られるという点を除いて

58
00:04:15,420 --> 00:04:18,380
サンプルバッチの
重みの更新に似ています

59
00:04:18,380 --> 00:04:22,760
「C」のように
多数意見に基づく変更が形成され

60
00:04:22,760 --> 00:04:27,140
クラウド上のモデルに共有されます

61
00:04:27,140 --> 00:04:29,590
共有モデルをデプロイして

62
00:04:29,590 --> 00:04:34,120
さまざまなユーザーのデバイスで微調整し
洗浄して繰り返します

63
00:04:34,120 --> 00:04:37,580
TensorFlowは
移植性があり強力で

64
00:04:37,580 --> 00:04:41,520
本番環境にすぐに使える
数値処理ソフトウェアです

65
00:04:41,520 --> 00:04:43,880
機械学習の分野で人気が高く

66
00:04:43,880 --> 00:04:49,380
GitHubでは機械学習の第1位のリポジトリです

67
00:04:49,380 --> 00:04:51,570
これはなぜでしょうか

68
00:04:51,570 --> 00:04:55,500
ディープラーニング研究者のコミュニティでは

69
00:04:55,500 --> 00:05:00,620
これを拡張して新しいことができるので
人気があります

70
00:05:00,620 --> 00:05:02,910
機械学習エンジニアには

71
00:05:02,910 --> 00:05:07,700
モデルを本番環境で大規模に
実行できるので人気があります

72
00:05:07,700 --> 00:05:12,060
この 2つのグループでの人気が
相乗効果を生んでいます

73
00:05:12,060 --> 00:05:15,781
研究者は 自分の手法を
使ってもらいたいと考えます

74
00:05:15,781 --> 00:05:19,093
TensorFlowに実装すると
それが実現します

75
00:05:19,093 --> 00:05:23,150
MLエンジニアは
自分のコードの最新性を保ちたいと考え

76
00:05:23,150 --> 00:05:28,330
新しいモデルが発明されたら
すぐにTensorFlowで使えます

77
00:05:28,330 --> 00:05:31,980
GoogleはTensorFlowを
オープンソース化することで

78
00:05:31,980 --> 00:05:33,950
多くの企業を支援しています

79
00:05:33,950 --> 00:05:39,220
巨大なコミュニティに潜在する
サポートを認識しているからです

80
00:05:39,220 --> 00:05:44,160
オープンソースであることは
皆様にとっての利点です

81
00:05:44,160 --> 00:05:49,110
皆様はオープンソースのTensorFlowで
コードを書くため

82
00:05:49,110 --> 00:05:55,200
GCPでのCloud Machine Learning Engineの
利用にログインは不要です