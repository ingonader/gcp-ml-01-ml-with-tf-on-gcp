TensorFlowで有向非巡回グラフ（DAG）を
使ってコンピュテーションを表すのは 移植性が理由です DAGは言語に依存せずに
モデルのコードを表します PythonでDAGを作成し
モデルに保存して 低レイテンシ予測用の
C++プログラムで復元できます 同じPythonコードを使って
CPUとGPUの両方で実行できるので 言語やハードウェアを超えた
移植性が備わります これは Java仮想マシン（JVM）と
バイトコード表記が Javaコードの機能に対応するのに似ています 高水準言語のJavaで
記述したコードが JVMによって
プラットフォームで実行されます JVM自体は
特定のOSやハードウェア向けに CやC++で書かれた効率的なコードです TensorFlowも同様に 高水準言語のPythonで
記述したコードが TensorFlow実行エンジンによって
プラットフォームで実行されます TensorFlow実行エンジンはとても効率的で 特定のハードウェアのチップと機能に
的を絞って C++で書かれています デバイス間の移植性があるので
非常に強力で柔軟です たとえば これは共通パターンです TensorFlowモデルをクラウドや
高性能ハードウェアでトレーニングした後 エッジにあるデバイスで
学習済みモデルを使用できます これは 携帯電話や
埋め込みチップでも可能でしょう そのデバイス自体で
モデルを使って予測できます この専門分野の最初のコースで Google翻訳アプリについて
お話ししましたが このアプリは完全にオフラインで機能します 学習済み翻訳モデルが電話機に保存され
オフラインで翻訳できます 電話機はクラウドに比べて
処理能力が限られているので モデルの規模や能力は
小さくなりますが TensorFlowに
こうした機能があるのは事実です これも有向非巡回表現で
移植性が備わっているおかげです こうした小規模で低機能のモデルは 通常 TensorFlow Liteを使って実装されます クラウドでトレーニングした後 小規模デバイスで予測すると
お話しましたが 現在のところは
電話機でモデルをトレーニングできまません これはMLモデルトレーニングの
負荷が大きいからです 徐々に実現に近づいており
「道半ば」です 極めて先進的な
ML環境でのみ可能で あまり普及していません 「道半ば」とはどんな状態でしょう あるモデルをトレーニングした後
さまざまな電話機にデプロイするとします そして予測を実行し ユーザーからの「これは間違いだ」
「もっとこんな結果が欲しい」 という意見に対して ユーザーの好みに合うよう
モデルの重みを調整します 学習済みモデルを微調整することは
電話機では可能です ユーザーの使い方に合わせて
モデルをパーソナライズできます この図の「A」にあたります ただし この場合はユーザーごとに
モデルを微調整しますが ユーザーの好みを
クラウドに戻すのは良くありません 個人情報にかかわる可能性があるからです ただし フェデレーション
ラーニングは可能です 「B」のように
多数のユーザーの更新が集計されます この集計は多くのユーザーから
得られるという点を除いて サンプルバッチの
重みの更新に似ています 「C」のように
多数意見に基づく変更が形成され クラウド上のモデルに共有されます 共有モデルをデプロイして さまざまなユーザーのデバイスで微調整し
洗浄して繰り返します TensorFlowは
移植性があり強力で 本番環境にすぐに使える
数値処理ソフトウェアです 機械学習の分野で人気が高く GitHubでは機械学習の第1位のリポジトリです これはなぜでしょうか ディープラーニング研究者のコミュニティでは これを拡張して新しいことができるので
人気があります 機械学習エンジニアには モデルを本番環境で大規模に
実行できるので人気があります この 2つのグループでの人気が
相乗効果を生んでいます 研究者は 自分の手法を
使ってもらいたいと考えます TensorFlowに実装すると
それが実現します MLエンジニアは
自分のコードの最新性を保ちたいと考え 新しいモデルが発明されたら
すぐにTensorFlowで使えます GoogleはTensorFlowを
オープンソース化することで 多くの企業を支援しています 巨大なコミュニティに潜在する
サポートを認識しているからです オープンソースであることは
皆様にとっての利点です 皆様はオープンソースのTensorFlowで
コードを書くため GCPでのCloud Machine Learning Engineの
利用にログインは不要です