1
00:00:00,250 --> 00:00:03,390
Então, por que o TensorFlow usa
gráficos acíclicos direcionados

2
00:00:03,390 --> 00:00:05,010
para representar a computação?

3
00:00:06,010 --> 00:00:07,620
Portabilidade.

4
00:00:07,620 --> 00:00:09,220
O gráfico acíclico direcionado,

5
00:00:09,220 --> 00:00:15,070
o DAG, é uma representação independente
de linguagem do código em seu modelo.

6
00:00:15,070 --> 00:00:19,430
Você pode criar um DAG no Python,
armazená-lo em um modelo salvo

7
00:00:19,430 --> 00:00:24,500
e restaurá-lo em um programa C++
para previsões de baixa latência.

8
00:00:24,500 --> 00:00:30,240
Você pode usar o mesmo código Python
e executá-lo em CPUs e GPUs,

9
00:00:30,240 --> 00:00:35,520
de modo que ele ofereça
portabilidade de hardware e linguagem.

10
00:00:35,520 --> 00:00:40,000
De muitas maneiras, isso é semelhante
a como a Java Virtual Machine, a JVM,

11
00:00:40,000 --> 00:00:45,560
e a representação de código de byte ajudam
na capacidade do código Java.

12
00:00:45,560 --> 00:00:49,830
Como desenvolvedores, conseguimos escrever
código em uma linguagem de alto nível,

13
00:00:49,830 --> 00:00:54,680
Java, e executá-lo em
diferentes plataformas pela JVM.

14
00:00:54,680 --> 00:01:00,940
A própria JVM é muito eficiente
e direcionada para o SO e o hardware

15
00:01:00,940 --> 00:01:04,780
exatos, e é escrita em C ou C++.

16
00:01:04,780 --> 00:01:07,000
Algo muito parecido com o TensorFlow.

17
00:01:07,000 --> 00:01:09,720
Como desenvolvedores,
conseguimos escrever código

18
00:01:09,720 --> 00:01:12,490
em uma linguagem de alto nível,
o Python,

19
00:01:12,490 --> 00:01:17,893
e executá-lo em diferentes plataformas
pelo mecanismo de execução do TensorFlow.

20
00:01:18,443 --> 00:01:22,495
O mecanismo de execução do TensorFlow
é muito eficiente

21
00:01:22,495 --> 00:01:25,360
e está voltado para
o chip de hardware exato

22
00:01:25,360 --> 00:01:28,570
e os recursos dele, e é escrito em C++.

23
00:01:29,720 --> 00:01:35,660
A portabilidade entre dispositivos
oferece muita potência e flexibilidade.

24
00:01:35,660 --> 00:01:38,600
Por exemplo, este é um padrão comum.

25
00:01:38,600 --> 00:01:43,960
Você pode treinar um modelo TensorFlow
na nuvem, em muitos hardwares poderosos,

26
00:01:43,960 --> 00:01:49,080
e depois pegar esse modelo treinado e
colocá-lo em um dispositivo fora da borda.

27
00:01:49,080 --> 00:01:52,590
Talvez um smartphone ou até mesmo
um chip embutido.

28
00:01:52,590 --> 00:01:56,830
E você pode fazer previsões com o modelo
diretamente no próprio dispositivo.

29
00:01:58,100 --> 00:02:01,060
Lembra do app Google Tradutor
sobre o qual falamos

30
00:02:01,060 --> 00:02:03,750
no primeiro curso desta especialização?

31
00:02:03,750 --> 00:02:09,469
Esse app pode funcionar completamente
off-line porque um modelo de tradução

32
00:02:09,469 --> 00:02:14,800
treinado é armazenado no smartphone
e fica disponível para tradução off-line.

33
00:02:14,800 --> 00:02:18,736
Ele tende a ser um modelo menor
e menos poderoso do que o da nuvem

34
00:02:18,736 --> 00:02:22,746
por causa das limitações do poder de
processamento disponível em um smartphone.

35
00:02:22,746 --> 00:02:28,914
Mas o fato de o TensorFlow
poder fazer isso é muito legal e possível

36
00:02:28,914 --> 00:02:35,290
apenas devido à portabilidade fornecida
pela representação acíclica direcionada.

37
00:02:35,290 --> 00:02:36,880
Esses tipos de modelos menores

38
00:02:36,880 --> 00:02:41,710
e menos potentes normalmente são
implementados com o TensorFlow Lite.

39
00:02:41,710 --> 00:02:44,150
Falei sobre o treinamento na nuvem

40
00:02:44,150 --> 00:02:48,200
e depois fiz previsões em um dispositivo
de baixa potência, como um smartphone.

41
00:02:48,200 --> 00:02:51,930
Claro, mas você consegue treinar
o próprio modelo no smartphone?

42
00:02:53,490 --> 00:02:59,430
Ainda não, porque o treinamento do modelo
de ML tende a ser uma operação cara.

43
00:02:59,430 --> 00:03:03,140
Mas, cada vez mais, estamos fazendo algo
que está no meio do caminho.

44
00:03:03,140 --> 00:03:07,990
Agora, isso é algo que apenas
as pessoas mais avançadas em ML

45
00:03:07,990 --> 00:03:11,110
estão fazendo,
não é necessariamente difundido.

46
00:03:11,110 --> 00:03:13,450
Mas o que quero dizer com meio do caminho?

47
00:03:13,450 --> 00:03:19,520
Uma situação é que você treina um modelo
e depois o implanta em vários smartphones.

48
00:03:19,520 --> 00:03:21,060
Quando você faz uma previsão,

49
00:03:21,060 --> 00:03:26,340
o usuário diz "não, isso não está certo"
ou "mostre-me mais resultados como este".

50
00:03:26,340 --> 00:03:30,360
E, neste ponto, você quer
atualizar as ponderações do modelo

51
00:03:30,360 --> 00:03:34,240
para que reflitam
as preferências do usuário.

52
00:03:34,240 --> 00:03:39,720
Esse tipo de ajuste fino de um modelo
treinado é possível em um smartphone.

53
00:03:39,720 --> 00:03:45,740
O smartphone do usuário personaliza
o modelo localmente com base no uso,

54
00:03:45,740 --> 00:03:47,780
e é isso que é mostrado em A.

55
00:03:49,290 --> 00:03:54,150
No entanto, aqui está você,
ajustando o modelo para cada usuário.

56
00:03:54,150 --> 00:03:57,050
Talvez você não queira enviar
as preferências do usuário

57
00:03:57,055 --> 00:03:58,225
de volta ao seu sistema,

58
00:03:58,225 --> 00:04:02,310
de volta à nuvem, porque
pode haver dados confidenciais.

59
00:04:02,310 --> 00:04:05,650
Mas você pode configurar
o que é chamado de aprendizado federado,

60
00:04:05,650 --> 00:04:10,790
em que você agrega as atualizações de
muitos usuários, conforme mostrado em B.

61
00:04:11,520 --> 00:04:16,280
Esse agregado é como uma atualização
de ponderação em um lote de amostras,

62
00:04:16,280 --> 00:04:18,520
exceto que é proveniente
de diferentes usuários.

63
00:04:18,520 --> 00:04:22,690
Por isso, forma uma mudança de consenso,
e é isso que estamos mostrando em C,

64
00:04:22,690 --> 00:04:27,140
e essa mudança de consenso acontece
com o modelo compartilhado na nuvem.

65
00:04:27,140 --> 00:04:29,370
Então, você implanta
o modelo compartilhado,

66
00:04:29,370 --> 00:04:34,120
ajusta-o em dispositivos de usuários
diferentes e repete o processo.

67
00:04:34,120 --> 00:04:37,580
O TensorFlow é este
software portátil, poderoso

68
00:04:37,580 --> 00:04:41,520
e pronto para produção
para computação numérica.

69
00:04:41,520 --> 00:04:44,750
Ele é muito usado para
aprendizado de máquina,

70
00:04:44,750 --> 00:04:49,380
o repositório número um para
aprendizado de máquina no GitHub.

71
00:04:49,380 --> 00:04:50,480
Por que é tão usado?

72
00:04:51,400 --> 00:04:54,330
É muito usado entre os pesquisadores de
aprendizado profundo

73
00:04:54,330 --> 00:04:56,400
por causa da comunidade em torno dele

74
00:04:56,400 --> 00:05:00,620
e da capacidade de ampliá-lo
e fazer coisas legais e novas.

75
00:05:00,620 --> 00:05:03,360
É usado entre os engenheiros
de aprendizado de máquina

76
00:05:03,360 --> 00:05:07,700
devido à capacidade de produzir modelos
e fazer algo em grande escala.

77
00:05:07,700 --> 00:05:12,350
Os dois grupos colhem os benefícios
desse grande uso.

78
00:05:12,350 --> 00:05:15,851
Os pesquisadores querem ver os métodos
deles sendo amplamente utilizados,

79
00:05:15,851 --> 00:05:19,093
e implementá-los no TensorFlow
é uma maneira de garantir isso.

80
00:05:19,093 --> 00:05:22,060
Os engenheiros de ML querem preparar
os códigos para o futuro

81
00:05:22,060 --> 00:05:23,770
para poder usar
modelos mais novos

82
00:05:23,770 --> 00:05:28,330
assim que forem inventados,
e o TensorFlow os ajuda a fazer isso.

83
00:05:28,330 --> 00:05:32,590
No Google, deixamos o TensorFlow
com código aberto para beneficiar

84
00:05:32,590 --> 00:05:33,940
muitas outras empresas

85
00:05:33,940 --> 00:05:38,080
e porque vimos o potencial desse tipo
de suporte imenso da comunidade.

86
00:05:39,210 --> 00:05:44,280
Como o TensorFlow tem código aberto,
ele oferece um benefício importante.

87
00:05:44,280 --> 00:05:49,110
Você não fica preso a um fornecedor quando
usa o Cloud Machine Learning Engine no GCP

88
00:05:49,110 --> 00:05:54,950
porque o código que você escreve está no
TensorFlow, e ele tem código aberto.