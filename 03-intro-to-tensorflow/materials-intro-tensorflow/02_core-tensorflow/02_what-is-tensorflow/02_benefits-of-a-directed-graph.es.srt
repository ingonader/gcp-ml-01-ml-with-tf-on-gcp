1
00:00:00,180 --> 00:00:03,360
¿Por qué TensorFlow usa
grafos acíclicos dirigidos

2
00:00:03,360 --> 00:00:05,000
para representar los cálculos?

3
00:00:06,010 --> 00:00:07,135
Por su portabilidad.

4
00:00:07,605 --> 00:00:09,930
El grafo acíclico dirigido o DAG

5
00:00:10,110 --> 00:00:14,770
es una representación del código
de su modelo independiente del lenguaje.

6
00:00:15,030 --> 00:00:17,010
Puede crear un DAG en Python

7
00:00:17,280 --> 00:00:19,190
almacenarlo en un modelo guardado

8
00:00:19,410 --> 00:00:24,010
y restaurarlo en un programa de C++
para obtener predicciones de baja latencia.

9
00:00:24,440 --> 00:00:30,330
Puede usar el mismo código de Python
y ejecutarlo tanto en CPU como en GPU.

10
00:00:30,700 --> 00:00:34,990
Ofrece portabilidad
en términos del hardware y del lenguaje.

11
00:00:35,460 --> 00:00:36,795
En muchos sentidos

12
00:00:37,095 --> 00:00:40,420
esto es similar
a cómo la máquina virtual Java, JVM

13
00:00:40,560 --> 00:00:45,170
y su representación de bytecode,
ayudan a la portabilidad del código de Java.

14
00:00:45,500 --> 00:00:48,460
Como desarrolladores,
nos permite escribir código

15
00:00:48,460 --> 00:00:50,565
en un lenguaje de alto nivel, Java

16
00:00:50,725 --> 00:00:54,310
y hacer que se ejecute
en diferentes plataformas con la JVM.

17
00:00:54,680 --> 00:00:57,890
La JVM en sí es muy eficiente.

18
00:00:57,960 --> 00:01:01,770
Está orientada a un SO
y un hardware en particular

19
00:01:01,940 --> 00:01:03,820
y está escrita en C o C++.

20
00:01:04,720 --> 00:01:06,590
Ocurre algo muy similar con TensorFlow.

21
00:01:06,930 --> 00:01:09,650
Como desarrolladores,
podemos escribimos código

22
00:01:09,650 --> 00:01:11,990
en un lenguaje
de alto nivel, en este caso, Python

23
00:01:12,290 --> 00:01:15,646
y hacer que se ejecute
en distintas plataformas

24
00:01:15,986 --> 00:01:18,063
con el motor de ejecución de TensorFlow.

25
00:01:18,623 --> 00:01:22,295
El motor de ejecución
de TensorFlow es muy eficiente.

26
00:01:22,445 --> 00:01:26,510
Está orientado hacia un chip
de hardware específico y sus capacidades

27
00:01:26,730 --> 00:01:28,360
y está escrito en C++.

28
00:01:29,770 --> 00:01:35,110
La portabilidad entre dispositivos
posibilita mucha potencia y flexibilidad.

29
00:01:35,660 --> 00:01:38,270
Por ejemplo, este es un patrón común.

30
00:01:38,600 --> 00:01:43,810
Puede entrenar un modelo de TensorFlow
en la nube en mucho hardware muy potente

31
00:01:44,120 --> 00:01:48,450
y trasladar el modelo entrenado
a un dispositivo afuera del perímetro

32
00:01:49,080 --> 00:01:51,980
como un teléfono celular
o incluso un chip integrado.

33
00:01:52,480 --> 00:01:56,790
Y puede hacer predicciones
con el modelo desde el mismo dispositivo.

34
00:01:58,090 --> 00:02:01,020
¿Recuerda la aplicación
de Google Traductor de la que hablamos

35
00:02:01,020 --> 00:02:03,350
en el primer
curso de esta especialización?

36
00:02:03,690 --> 00:02:07,219
Esa aplicación puede funcionar
completamente sin conexión

37
00:02:07,439 --> 00:02:11,330
porque se almacena un modelo
de traducción entrenado en el teléfono

38
00:02:11,500 --> 00:02:14,240
y está disponible
para hacer traducciones sin conexión.

39
00:02:14,760 --> 00:02:18,766
Suele ser un modelo más pequeño
y menos potente que el de la nube

40
00:02:19,076 --> 00:02:21,536
debido a limitaciones
de la capacidad de procesamiento

41
00:02:21,536 --> 00:02:22,736
disponible en el teléfono.

42
00:02:22,996 --> 00:02:27,244
Pero el hecho de que TensorFlow
pueda hacerlo es una maravilla.

43
00:02:27,644 --> 00:02:31,290
Y eso es posible
solo gracias a la portabilidad

44
00:02:31,590 --> 00:02:34,650
que nos brinda
la representación acíclica dirigida.

45
00:02:35,290 --> 00:02:38,230
Estos modelos
más pequeños y menos potentes

46
00:02:38,380 --> 00:02:41,240
suelen implementarse con TensorFlow Lite.

47
00:02:41,750 --> 00:02:43,860
Hablé de entrenar en la nube

48
00:02:43,970 --> 00:02:47,650
y hacer predicciones en un dispositivo
de poca potencia, como un teléfono.

49
00:02:48,200 --> 00:02:52,240
Claro, pero ¿se puede entrenar
el modelo en sí en el teléfono?

50
00:02:53,490 --> 00:02:59,070
No en la actualidad porque entrenar
modelos de AA suele ser costoso.

51
00:02:59,430 --> 00:03:02,730
Pero cada vez hacemos más
algo que está a medio camino.

52
00:03:03,090 --> 00:03:08,500
Es algo que solo hacen
los actores más avanzados en el campo del AA.

53
00:03:08,950 --> 00:03:10,800
No está necesariamente generalizado.

54
00:03:11,160 --> 00:03:12,880
Pero ¿qué significa a medio camino?

55
00:03:13,360 --> 00:03:18,780
Un caso es que entrena un modelo
y lo implementa en muchos teléfonos.

56
00:03:19,440 --> 00:03:23,360
Cuando hace una predicción,
el usuario puede decir que no es buena

57
00:03:23,680 --> 00:03:25,930
o pedir más resultados como ese.

58
00:03:26,290 --> 00:03:27,550
En ese momento

59
00:03:27,720 --> 00:03:30,480
se pueden
actualizar los pesos del modelo

60
00:03:30,580 --> 00:03:33,750
para que reflejen
las preferencias de ese usuario.

61
00:03:34,240 --> 00:03:39,180
Estos ajustes de un modelo entrenado
pueden hacerse, sin dudas, en un teléfono.

62
00:03:39,760 --> 00:03:45,550
El teléfono del usuario personaliza
el modelo a nivel local según su uso.

63
00:03:45,740 --> 00:03:48,090
Eso es lo que se ve aquí en A.

64
00:03:49,230 --> 00:03:53,540
Sin embargo, aquí se está ajustando
el modelo para cada usuario.

65
00:03:54,150 --> 00:03:57,190
No es conveniente enviar
las preferencias de ese usuario

66
00:03:57,190 --> 00:03:59,375
de vuelta a su sistema en la nube

67
00:03:59,645 --> 00:04:01,840
ya que podría ser información personal.

68
00:04:02,290 --> 00:04:05,130
Pero puede configurar
lo que se llama aprendizaje federado

69
00:04:05,610 --> 00:04:09,540
en el que se agregan
las actualizaciones de muchos usuarios.

70
00:04:09,700 --> 00:04:10,970
Es lo que vemos aquí en B.

71
00:04:11,530 --> 00:04:13,740
Esta agregación es esencialmente

72
00:04:13,740 --> 00:04:16,360
una actualización
del peso de un lote de muestras

73
00:04:16,360 --> 00:04:18,230
solo que proviene de varios usuarios.

74
00:04:18,440 --> 00:04:20,790
Esto genera un cambio de consenso.

75
00:04:21,010 --> 00:04:22,540
Es lo que vemos en C.

76
00:04:22,690 --> 00:04:26,700
Este cambio ocurre
en el modelo compartido en la nube.

77
00:04:27,140 --> 00:04:29,180
Así, implementa el modelo compartido

78
00:04:29,350 --> 00:04:32,475
lo ajusta
en los dispositivos de distintos usuarios

79
00:04:32,785 --> 00:04:34,150
y se repite el proceso.

80
00:04:34,250 --> 00:04:39,430
TensorFlow es un software portable,
potente y listo para la producción

81
00:04:39,430 --> 00:04:41,060
para cálculos numéricos.

82
00:04:41,520 --> 00:04:44,750
Es particularmente popular
en el aprendizaje automático.

83
00:04:45,190 --> 00:04:48,670
Es el principal repositorio
de aprendizaje automático en GitHub.

84
00:04:49,380 --> 00:04:50,740
¿Por qué es tan popular?

85
00:04:51,540 --> 00:04:54,330
Entre los investigadores
de aprendizaje profundo es popular

86
00:04:54,510 --> 00:04:56,305
por la comunidad conformada

87
00:04:56,475 --> 00:05:00,080
y su capacidad
para extenderlo y encontrar usos nuevos.

88
00:05:00,550 --> 00:05:03,290
Entre los ingenieros
de aprendizaje automático es popular

89
00:05:03,360 --> 00:05:07,290
por su capacidad para llevar
modelos a producción y trabajar a escala.

90
00:05:07,700 --> 00:05:12,040
La popularidad entre estos dos grupos
se complementa entre sí.

91
00:05:12,350 --> 00:05:15,741
Los investigadores quieren
que sus métodos se usen ampliamente.

92
00:05:15,911 --> 00:05:18,943
Implementarlos en TensorFlow
es una forma de lograrlo.

93
00:05:19,103 --> 00:05:22,210
Los ingenieros de AA quieren
que su código esté listo para el futuro

94
00:05:22,250 --> 00:05:25,735
de manera que puedan adoptar
modelos nuevos apenas se inventen.

95
00:05:25,885 --> 00:05:27,970
TensorFlow los ayuda a hacerlo.

96
00:05:28,300 --> 00:05:31,180
En Google, hicimos
TensorFlow de código abierto

97
00:05:31,380 --> 00:05:33,790
porque puede ser
una gran ayuda para muchas empresas

98
00:05:33,860 --> 00:05:38,270
y porque vimos el potencial
de enorme apoyo comunitario.

99
00:05:39,130 --> 00:05:44,020
El hecho de que TensorFlow sea
de código abierto le da un beneficio clave.

100
00:05:44,250 --> 00:05:48,710
No está obligado a usar siempre
Cloud Machine Learning Engine en GCP

101
00:05:49,150 --> 00:05:52,105
porque el código que escriba
estará en TensorFlow

102
00:05:52,365 --> 00:05:54,870
y TensorFlow es de código abierto.