1
00:00:00,000 --> 00:00:06,100
ここまでのレッスンで
TensorFlowのデバッグ方法を見てきました

2
00:00:06,100 --> 00:00:11,230
エラーメッセージを確認し
問題のあるメソッドを特定して

3
00:00:11,230 --> 00:00:15,370
架空データを使って
エラーを修正しました

4
00:00:15,370 --> 00:00:18,410
ただし 見つけにくい条件下で

5
00:00:18,410 --> 00:00:23,340
発生する問題もあります

6
00:00:23,340 --> 00:00:27,620
途中まで問題なく
動作していたのに

7
00:00:27,620 --> 00:00:30,109
突然 なぜかエラーが発生し

8
00:00:30,109 --> 00:00:32,969
通常に戻ります

9
00:00:32,969 --> 00:00:38,290
入力値や実行システムの
条件に関連するエラーの場合は

10
00:00:38,290 --> 00:00:41,870
理由を特定できないことがあります

11
00:00:41,870 --> 00:00:46,997
この場合 プログラム全体を
デバッグする必要があり

12
00:00:46,997 --> 00:00:49,552
その方法は3つあります

13
00:00:49,552 --> 00:00:53,654
tf.Printは 特定の条件が
満たされる場合に

14
00:00:53,654 --> 00:00:56,135
テンソルの値を出力します

15
00:00:56,135 --> 00:01:00,051
tfdbgは対話型デバッガで

16
00:01:00,051 --> 00:01:04,800
TensorFlowセッションに
アタッチできます

17
00:01:04,800 --> 00:01:08,000
視覚的なTensorBoardでは

18
00:01:08,000 --> 00:01:11,350
タグを調べられますが

19
00:01:11,350 --> 00:01:13,470
評価指標、過剰適合、

20
00:01:13,470 --> 00:01:16,080
動作していない階層の確認などの

21
00:01:16,080 --> 00:01:19,410
トラブルシューティングができる

22
00:01:19,410 --> 00:01:23,274
ハイレベルなデバッガです

23
00:01:23,274 --> 00:01:26,443
これについては
後で説明します

24
00:01:26,443 --> 00:01:28,833
今はTensorBoardが

25
00:01:28,833 --> 00:01:35,091
強力なツールであることを
覚えておいてください

26
00:01:35,091 --> 00:01:37,971
もう一つ付け加えると

27
00:01:37,971 --> 00:01:44,020
TensorFlowプログラムのデフォルトの
ログレベルはWARNなので

28
00:01:44,020 --> 00:01:46,120
出力は少なめです

29
00:01:46,120 --> 00:01:49,750
ログメッセージを増やすには

30
00:01:49,750 --> 00:01:52,550
ログレベルを INFOに変更します

31
00:01:52,550 --> 00:01:57,600
この場合は
tf.loggingで冗長レベルを設定します

32
00:01:57,620 --> 00:02:04,060
レベルはDEBUG、INFO、
WARN、ERROR、FATALです

33
00:02:04,060 --> 00:02:09,600
冗長性はDEBUGが最も高く
FATALが最も低くなります

34
00:02:09,600 --> 00:02:15,240
開発ではINFO
本番環境ではWARNを使用します

35
00:02:15,240 --> 00:02:19,945
コマンドラインパラメータで
切り換えられます

36
00:02:19,945 --> 00:02:26,150
tf.Printは 特定のテンソル値を
記録するのに使用できます

37
00:02:26,150 --> 00:02:32,130
aをbで割ったとき
NAN（非数）が出力されるとします

38
00:02:32,130 --> 00:02:37,720
aの値とbの値を確認して
問題の原因を探ります

39
00:02:37,720 --> 00:02:39,641
ただしprint aを実行しても

40
00:02:39,641 --> 00:02:42,350
デバッグ出力が得られるだけで

41
00:02:42,350 --> 00:02:43,890
値は得られません

42
00:02:43,890 --> 00:02:47,970
値を得るには
テンソルを評価する必要があり

43
00:02:47,970 --> 00:02:52,370
aの値を毎回出力するのは
望ましくありません

44
00:02:52,370 --> 00:03:00,450
sをラップしてaとbを出力する
print_abをテンソルとして使います

45
00:03:00,450 --> 00:03:08,500
sがNANになるバッチのみを対象に
グラフのsをprint_abに置き換えます

46
00:03:08,500 --> 00:03:12,100
すると該当するものだけが
出力されます

47
00:03:12,100 --> 00:03:15,340
Datalabはログメッセージ用に
テンソルを使用するので

48
00:03:15,340 --> 00:03:18,548
独立プログラムを
使用します

49
00:03:18,548 --> 00:03:23,130
コードをファイルに
書き込んで実行します

50
00:03:23,130 --> 00:03:27,640
実行中のTensorFlowプログラムで
tf.Printをよく使用します

51
00:03:27,640 --> 00:03:32,000
稀なエラーを診断し
ログに情報をキャプチャします

52
00:03:32,000 --> 00:03:33,590
便利ですね

53
00:03:33,590 --> 00:03:39,280
TensorFlowには tf_debugという
対話型デバッガもあります

54
00:03:39,280 --> 00:03:41,720
コマンドラインで実行します

55
00:03:41,720 --> 00:03:46,430
TensorFlowプログラムを
独立プログラムとして実行し

56
00:03:46,430 --> 00:03:50,530
その際にコマンドラインフラグ
--debugを追加します

57
00:03:50,530 --> 00:03:55,270
これはリモート実行中の
デバッグにも有効で

58
00:03:55,270 --> 00:03:57,870
プログラムにアタッチできます

59
00:03:57,870 --> 00:04:01,567
デバッグ実験向けと評価プログラム向けの

60
00:04:01,567 --> 00:04:03,760
デバッグ用フックもあります

61
00:04:03,760 --> 00:04:07,240
ステップ単位でのコードの実行や

62
00:04:07,240 --> 00:04:10,550
ブレークポイントの設定などができます

63
00:04:10,550 --> 00:04:14,630
他の言語や環境でこのデバッガを
使用したことがあれば

64
00:04:14,630 --> 00:04:19,750
用語やステップなどを
よくご存知でしょう