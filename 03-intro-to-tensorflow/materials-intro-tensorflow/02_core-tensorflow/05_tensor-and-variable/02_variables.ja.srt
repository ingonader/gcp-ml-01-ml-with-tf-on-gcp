1
00:00:00,000 --> 00:00:03,480
変数はテンソルで
値は初期化され

2
00:00:03,480 --> 00:00:07,965
プログラムの実行時に
変更されます

3
00:00:07,965 --> 00:00:11,015
この例を詳しく見てみましょう

4
00:00:11,015 --> 00:00:13,730
forward_passという関数があります

5
00:00:13,730 --> 00:00:16,110
パラメータw、xを受け入れて

6
00:00:16,110 --> 00:00:18,480
それらを掛け合わせます

7
00:00:18,480 --> 00:00:22,285
これらはテンソルのため

8
00:00:22,285 --> 00:00:25,215
行列乗算になります

9
00:00:25,215 --> 00:00:28,084
train_loop関数では

10
00:00:28,084 --> 00:00:31,920
テンソルwを作成します

11
00:00:31,920 --> 00:00:37,515
このwは これまでのような
定数ではなく

12
00:00:37,515 --> 00:00:39,985
変数です

13
00:00:39,985 --> 00:00:42,050
weightsという名前が付き

14
00:00:42,050 --> 00:00:44,200
形状は1, 2です

15
00:00:44,200 --> 00:00:47,380
これは1行2列 つまり

16
00:00:47,380 --> 00:00:49,740
1x2行列です

17
00:00:49,740 --> 00:00:52,090
ここではwを初期化しません

18
00:00:52,090 --> 00:00:54,890
TensorFlowは

19
00:00:54,890 --> 00:00:59,720
遅延評価フレームワークなので
グラフを作成するだけです

20
00:00:59,720 --> 00:01:01,350
まだ実行しません

21
00:01:01,350 --> 00:01:03,980
wの初期化には

22
00:01:03,980 --> 00:01:08,445
「truncated_normal_initializer」
を使用します

23
00:01:08,445 --> 00:01:10,630
一般的なイニシャライザで

24
00:01:10,630 --> 00:01:14,290
TensorFlowニューラルネットワーク
プログラムで使われます

25
00:01:14,290 --> 00:01:17,310
変数を初期化して
乱数にします

26
00:01:17,310 --> 00:01:21,285
均一に分散せず
ガウス正規分布で

27
00:01:21,285 --> 00:01:25,950
ゼロ平均と単位分散を
使用します

28
00:01:25,950 --> 00:01:29,605
ガウス正規分布は
ロングテールになり

29
00:01:29,605 --> 00:01:32,205
極端な異常値を
取る可能性があります

30
00:01:32,205 --> 00:01:34,390
可能性は低いですが
あり得ます

31
00:01:34,390 --> 00:01:38,220
truncated_normalは
シグマの和乗算の

32
00:01:38,220 --> 00:01:42,060
切り捨てのようなものを実行します

33
00:01:42,060 --> 00:01:46,665
変数wは
トレーニングできます

34
00:01:46,665 --> 00:01:51,650
つまり トレーニング中に
変更できる変数です

35
00:01:51,650 --> 00:01:54,770
変数は
変わるものですので

36
00:01:54,770 --> 00:01:58,110
大半はトレーニング可能です

37
00:01:58,110 --> 00:02:01,830
これについては

38
00:02:01,830 --> 00:02:05,925
モデルサイズの削減や
移転学習で紹介します

39
00:02:05,925 --> 00:02:07,525
これはときどき

40
00:02:07,525 --> 00:02:13,330
グラフを静止させて変数を
固定するのに役立ちます

41
00:02:13,330 --> 00:02:16,625
Booleanフラグで それを行えます

42
00:02:16,625 --> 00:02:22,090
tf.get_variableを呼び出して
wを作成している点に注目してください

43
00:02:22,090 --> 00:02:26,290
TensorFlowコードで
tf.variableコンストラクタを呼び出して

44
00:02:26,290 --> 00:02:28,965
変数を作成できます

45
00:02:28,965 --> 00:02:32,425
こうした直接の呼び出しは
おすすめしません

46
00:02:32,425 --> 00:02:37,775
コース9で学ぶように
tf.get_variableを使用します

47
00:02:37,775 --> 00:02:44,370
この場合は状況に応じて 
変数を再利用したり

48
00:02:44,370 --> 00:02:48,075
新しく作成したりできます

49
00:02:48,075 --> 00:02:52,300
tf.get_variableに
慣れておくとよいでしょう

50
00:02:52,300 --> 00:02:55,710
次にforward_passを5回実行し

51
00:02:55,710 --> 00:03:01,650
反復ごとに
行列乗算の結果を保存します

52
00:03:01,650 --> 00:03:05,280
乗算を行った後
weightsを変更します

53
00:03:05,280 --> 00:03:08,090
ここでは 0.1を加えます

54
00:03:08,090 --> 00:03:10,005
勾配更新のようなものです

55
00:03:10,005 --> 00:03:12,060
実際には

56
00:03:12,060 --> 00:03:15,785
変更するweightsと
その方法を選択します

57
00:03:15,785 --> 00:03:18,105
ここではデモが目的ですから

58
00:03:18,105 --> 00:03:21,390
毎回 0.1を加えます

59
00:03:21,390 --> 00:03:23,820
セッションから

60
00:03:23,820 --> 00:03:28,250
xを渡すことで
train_loopを呼び出します

61
00:03:28,250 --> 00:03:31,520
xは[2, 3]行列です

62
00:03:31,520 --> 00:03:33,470
forward_passでは

63
00:03:33,470 --> 00:03:38,075
[1, 2]行列のwに
このxを掛けます

64
00:03:38,075 --> 00:03:43,930
[1, 2]に[2, 3]を掛けることで
[1, 3]行列が得られます

65
00:03:43,930 --> 00:03:48,680
これでグラフは完了ですが
変数を初期化する必要があります

66
00:03:48,680 --> 00:03:50,710
ただし 通常は

67
00:03:50,710 --> 00:03:54,020
global_variables_initializerを実行して

68
00:03:54,020 --> 00:03:58,675
グラフ内の変数を
一度にすべて初期化します

69
00:03:58,675 --> 00:04:04,400
さて ループの各ステップ後の
積の値に注目すると

70
00:04:04,400 --> 00:04:10,360
予想どおり
[1, 3]行列は毎回異なります

71
00:04:10,360 --> 00:04:13,820
学んだことを
まとめましょう

72
00:04:13,820 --> 00:04:19,320
まずget_variableを呼び出して
変数を作成します

73
00:04:19,320 --> 00:04:24,585
今回はコードを1行飛ばしました

74
00:04:24,585 --> 00:04:26,564
変数を作成するときは

75
00:04:26,564 --> 00:04:28,875
スコープを指定できます

76
00:04:28,875 --> 00:04:32,625
毎回 新しい変数を作成するのではなく

77
00:04:32,625 --> 00:04:36,465
再利用するようにします

78
00:04:36,465 --> 00:04:41,180
ここでは train_loopを一度だけ呼び出すので
重要ではないものの

79
00:04:41,180 --> 00:04:43,310
train_loopを再び呼び出すと

80
00:04:43,310 --> 00:04:46,725
weightsが前回の終わりから
再開します

81
00:04:46,725 --> 00:04:49,605
これが変数の作成と再利用です

82
00:04:49,605 --> 00:04:54,035
学んだ2つの目の点は 
変数の作成時に

83
00:04:54,035 --> 00:04:57,280
初期化の方法を
決めることです

84
00:04:57,280 --> 00:05:00,260
ニューラルネットワーク
トレーニングでは通常

85
00:05:00,260 --> 00:05:03,400
正規乱数と切り捨てを選びます

86
00:05:03,400 --> 00:05:05,345
3番目の点は

87
00:05:05,345 --> 00:05:10,695
グラフの作成時に
変数を使うことです

88
00:05:10,695 --> 00:05:13,615
4番目の点は

89
00:05:13,615 --> 00:05:16,315
変数を初期化することです

90
00:05:16,315 --> 00:05:19,340
通常は global_variables_initializerを
呼び出して

91
00:05:19,340 --> 00:05:22,925
すべての変数を一緒に初期化します

92
00:05:22,925 --> 00:05:25,530
初期化の後

93
00:05:25,530 --> 00:05:27,380
これは5番目の点ですが

94
00:05:27,380 --> 00:05:31,905
対象となるテンソルを評価します

95
00:05:31,905 --> 00:05:33,680
この例では

96
00:05:33,680 --> 00:05:36,425
xを使ってtrain_loopを呼び出します

97
00:05:36,425 --> 00:05:38,900
でも xは定数です

98
00:05:38,900 --> 00:05:41,380
これは現実的ですか

99
00:05:41,380 --> 00:05:45,040
プログラムに入力値を
ハードコーディングしますか

100
00:05:45,040 --> 00:05:48,605
プレースホルダで
グラフに値をフィードできます

101
00:05:48,605 --> 00:05:52,460
たとえば 読み取った値を
Pythonリストに入れ

102
00:05:52,460 --> 00:05:56,080
TensorFlowグラフにフィードできます

103
00:05:56,080 --> 00:06:00,060
aは スカラーを保持する
プレースホルダです

104
00:06:00,060 --> 00:06:02,930
bはaに4を掛けたものです

105
00:06:02,930 --> 00:06:06,590
aを出力すると
テンソルのデバッグ出力が得られます

106
00:06:06,590 --> 00:06:08,670
このテンソルは

107
00:06:08,670 --> 00:06:13,340
浮動小数点数を受け入れる
プレースホルダです

108
00:06:13,340 --> 00:06:15,625
bを評価する場合

109
00:06:15,625 --> 00:06:18,170
このsession.run(b)を調整できます

110
00:06:18,170 --> 00:06:22,145
bが依存するプレースホルダ値を
フィードする必要があります

111
00:06:22,145 --> 00:06:23,560
この場合

112
00:06:23,560 --> 00:06:28,530
aに対してリストか
数値numpy配列を渡す必要があります

113
00:06:28,530 --> 00:06:32,345
ここではfeed_dictを使用します

114
00:06:32,345 --> 00:06:34,850
このディクショナリはKey-Valueペア

115
00:06:34,850 --> 00:06:37,065
キーはプレースホルダで

116
00:06:37,065 --> 00:06:38,715
ここではaです

117
00:06:38,715 --> 00:06:41,655
値はnumpy配列のリストで

118
00:06:41,655 --> 00:06:44,860
ここでは1,2,3です

119
00:06:44,860 --> 00:06:46,485
これをフィードします

120
00:06:46,485 --> 00:06:48,325
bを評価すると

121
00:06:48,325 --> 00:06:51,150
aに4を掛けた値を得られるため

122
00:06:51,150 --> 00:06:53,800
4、8、12が出力されます