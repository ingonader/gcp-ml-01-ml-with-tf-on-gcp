1
00:00:00,000 --> 00:00:04,105
Wir haben gesehen, wie man
einen Graphen schreibt uns ausführt.

2
00:00:04,105 --> 00:00:08,030
Manchmal möchte man
aber den Graphen visualisieren

3
00:00:08,039 --> 00:00:10,155
und die Operationen sehen,

4
00:00:10,155 --> 00:00:12,690
welche Daten darin
einfließen und so weiter.

5
00:00:12,690 --> 00:00:16,890
Sie können auch die Architektur
der neuralen Netzwerke visualisieren.

6
00:00:16,890 --> 00:00:22,520
Mit einem tf.summary.FileWriter
kann der Graph ausgegeben werden.

7
00:00:22,520 --> 00:00:27,595
Lassen Sie den Sitzungsgraphen also
mit tf.summary.FileWriter ausgeben.

8
00:00:27,595 --> 00:00:29,725
Bei dieser Visualisierung des Graphen

9
00:00:29,725 --> 00:00:33,445
sollen die Tensoren wahrscheinlich
keine automatisch erzeugten Namen haben,

10
00:00:33,445 --> 00:00:36,415
zum Beispiel Ad_7 wie vorhin.

11
00:00:36,415 --> 00:00:39,610
Geben Sie also beim
Ausgeben und Visualisieren des Graphen

12
00:00:39,610 --> 00:00:44,050
den Datentensoren und Operationen Namen.

13
00:00:44,050 --> 00:00:47,330
Wenn Sie anschließend
dieses Programm ausführen,

14
00:00:47,330 --> 00:00:50,405
wird ein neues Verzeichnis
namens "summaries" angelegt.

15
00:00:50,405 --> 00:00:53,810
Es heißt "summaries", weil
dieser Name bei tf.summary.FileWriter

16
00:00:53,810 --> 00:00:57,690
als erstes Argument angegeben wurde.

17
00:00:57,690 --> 00:01:00,170
Sie können das
Verzeichnis beliebig benennen.

18
00:01:00,170 --> 00:01:05,005
In diesem Verzeichnis befindet
sich eine Datei mit einem Graphen.

19
00:01:05,005 --> 00:01:08,090
Der Graph ist in einem
dokumentierten Binärformat gespeichert,

20
00:01:08,090 --> 00:01:09,965
das für Menschen nicht lesbar ist.

21
00:01:09,965 --> 00:01:14,355
Wie macht man aus dieser
Ausgabedatei eine schöne Darstellung?

22
00:01:14,355 --> 00:01:16,270
Zur Visualisierung des Graphen

23
00:01:16,270 --> 00:01:18,915
dient ein Programm namens TensorBoard.

24
00:01:18,915 --> 00:01:21,490
Es ist im TensorFlow-
Lieferumfang enthalten.

25
00:01:21,490 --> 00:01:23,945
Sie können es daher
von DataLab aus aufrufen.

26
00:01:23,945 --> 00:01:27,670
Hier nun der Python-Code
zum Aufruf von TensorBoard.

27
00:01:27,670 --> 00:01:31,575
Er verweist auf das
Hauptverzeichnis namens "summaries".

28
00:01:31,575 --> 00:01:36,160
Die Benutzeroberfläche wird gestartet 
und wechselt zum Abschnitt "Graphen".

29
00:01:36,160 --> 00:01:39,330
Sie sehen eine Darstellung des Graphen

30
00:01:39,330 --> 00:01:43,050
mit x, y, z1, z2 und z3

31
00:01:43,050 --> 00:01:45,495
sowie den Operationen, die sie verbinden.

32
00:01:45,495 --> 00:01:47,890
Mit TensorBoard
kann man noch mehr machen.

33
00:01:47,890 --> 00:01:50,395
Das können Sie im nächsten Lab

34
00:01:50,395 --> 00:01:54,505
und in weiteren Labs
in der Spezialisierung ausprobieren.

35
00:01:54,505 --> 00:01:58,495
Da wir ML-Modelle
meist in DataLab entwickeln,

36
00:01:58,495 --> 00:02:03,660
ist es sehr praktisch, TensorBoard
direkt in DataLab starten zu können.

37
00:02:03,660 --> 00:02:07,040
Aber manchmal startet
man einen Trainingsjob,

38
00:02:07,040 --> 00:02:12,350
der vielleicht Stunden dauert,
und möchte das Training überwachen.

39
00:02:12,350 --> 00:02:16,570
Sie brauchen DataLab nicht
zum Starten von TensorBoard.

40
00:02:16,570 --> 00:02:20,655
TensorBoard wird,
wie gesagt, mit TensorFlow mitgeliefert.

41
00:02:20,655 --> 00:02:24,350
TensorFlow ist auch
in Cloud Shell installiert

42
00:02:24,350 --> 00:02:29,365
und Cloud Shell ist zwar
zu klein für maschinelles Lernen,

43
00:02:29,365 --> 00:02:32,415
reicht aber für TensorBoard aus.

44
00:02:32,415 --> 00:02:37,395
Hier eine Anleitung, wie Sie es von
Cloud Shell aus starten und unterstützen.

45
00:02:37,395 --> 00:02:40,090
Dazu wird auf ein Modellausgabe-Verzeichnis

46
00:02:40,090 --> 00:02:42,000
auf Google Cloud Storage verwiesen.

47
00:02:42,000 --> 00:02:46,090
Die Dokumentation dazu
ist in diesem Video verlinkt.