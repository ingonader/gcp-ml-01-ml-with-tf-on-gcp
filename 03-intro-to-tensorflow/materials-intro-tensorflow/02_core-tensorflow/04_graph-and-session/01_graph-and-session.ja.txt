グラフとセッションについて
見ていきましょう TensorFlowにおける 有向非巡回グラフ（DAG）は 他のグラフと同様に エッジとノードで構成されます エッジはデータを表します これらはn次元の配列であるテンソルを表します ノードはテンソルに対する
TensorFlow演算を表します 前のレッスンで考えた tf.addなどです TensorFlow DAGはテンソルと
それらのテンソルに対する演算で構成されます なぜTensorFlowは遅延評価を行うのでしょう それは グラフの実行時に
遅延評価によって 柔軟性がもたらされ
最適化が可能になるからです TensorFlowではグラフの処理や
コンパイルのほか DAGの途中に
送受信ノードを挿入できます リモートでも実行できます I/Oバウンドかどうか
GPU機能が必要かどうかに応じて TensorFlowでは
DAGのさまざまなパーツを 異なるデバイスに
割り当てることができます グラフが処理されている間は 量子化やデータ型の追加 デバッグノードの追加 値を書き出すための
サマリー作成が可能です テンソルはこれらのほか
add、matmul、constants、 variablesなどの演算を
読み取って処理します グラフのコンパイル時 TensorFlowは2つの演算を結合して
パフォーマンスを改善します たとえば 連続する2つのaddノードを 1つに結合できます TensorFlowのXLAコンパイラは DAGへの情報を使って
より速いコードを生成します これが 最適化のために
DAGを利用すべき理由の1つです 最も素晴らしい点は リモートで DAGを実行し
デバイスに割り当てられることです この点でのメリットは
際立っています 演算間の依存関係を表すために
明示的なエッジを使用することで 同時に実行できる複数の演算が
簡単に識別されます 演算間を流れる値を表すために
明示的なエッジを使用することで TensorFLowがプログラムを
パーティション化して CPU、GPU、TPUなど異なるマシンに接続された 複数のデバイスに分けることができます TensorFlowは これらのデバイス間で
必要なやり取りや調整を挿入します この図の色分けに注目してください グラフのいくつかの部分は
異なるデバイス上に存在します GPUか複数のコンピュータかは
関係ありません このモデルの主なメリットの1つは たくさんのタイプの複数のコンピュータに
計算を分散できることです DAGでは これが可能です Pythonコードを書くだけで TensorFlow実行システムがグラフを
最適化、分散します セッションクラスは 記述するPythonプログラムと
C++ランタイムの間の接続を表します セッションオブジェクトは
分散TensorFlowランタイムを使用して ローカルコンピュータ上の
デバイスと リモートデバイスへの
アクセスを提供します また グラフ情報を
キャッシュに保存します そのため 何度も同じ計算を実行できます TensorFlowグラフを 実行するには
tfセッションでの実行を呼び出します ここでは
評価するテンソルを指定します この例では2つのデータテンソル xとyを指定しています これらは定数で
1Dテンソルです テンソルzは xとyに対して
tf.addを呼び出した結果です 評価する際に Zに対して session.runを呼び出します scssは
tf.sessionのインスタンスです Pythonの withステートメントを使うと 完了時に セッションを
自動的に閉じることができます