1
00:00:00,000 --> 00:00:03,795
So far, we have seen how to write a graph and how to run it.

2
00:00:03,795 --> 00:00:06,090
But every once in a while,

3
00:00:06,090 --> 00:00:08,040
you want to visualize the graph,

4
00:00:08,040 --> 00:00:10,155
you want to see the operations,

5
00:00:10,155 --> 00:00:12,630
what data feeds into it, et cetera.

6
00:00:12,630 --> 00:00:16,890
You might also want to visualize the architecture of your neural networks.

7
00:00:16,890 --> 00:00:22,230
To write out the graph, use a tf.summary.FileWriter.

8
00:00:22,230 --> 00:00:27,075
So, use tf.summary.FileWriter to write out the session graph.

9
00:00:27,075 --> 00:00:29,725
Now, if you're going to visualize the graph,

10
00:00:29,725 --> 00:00:33,445
you probably don't want auto-generated tensor names,

11
00:00:33,445 --> 00:00:36,415
things like the Ad_7 that we saw before.

12
00:00:36,415 --> 00:00:39,610
So, if you're writing out and visualizing the graph,

13
00:00:39,610 --> 00:00:43,560
make sure to name your data tensors and your operations.

14
00:00:43,560 --> 00:00:47,330
Once you do that and you run this program,

15
00:00:47,330 --> 00:00:50,195
you will get a new directory called 'summaries'.

16
00:00:50,195 --> 00:00:53,810
Well, it's called summaries because it specified summaries as

17
00:00:53,810 --> 00:00:57,530
a first arg of tf.summary.FileWriter.

18
00:00:57,530 --> 00:00:59,960
You could name the directory whatever you want.

19
00:00:59,960 --> 00:01:04,575
And in that directory is a file that contains a graph.

20
00:01:04,575 --> 00:01:08,090
The graph is in a documented binary format,

21
00:01:08,090 --> 00:01:09,845
it's not really human-readable.

22
00:01:09,845 --> 00:01:14,035
So, how do you get a pretty visual from this output file?

23
00:01:14,035 --> 00:01:16,270
To visualize the graph,

24
00:01:16,270 --> 00:01:18,915
use a program called TensorBoard.

25
00:01:18,915 --> 00:01:21,490
It comes with the TensorFlow distribution,

26
00:01:21,490 --> 00:01:23,685
which means you can call it from DataLab.

27
00:01:23,685 --> 00:01:27,670
So, here's the Python code to invoke TensorBoard,

28
00:01:27,670 --> 00:01:31,385
pointing it to the top level directory called summaries.

29
00:01:31,385 --> 00:01:33,580
And then the UI that comes up,

30
00:01:33,580 --> 00:01:40,170
switch to the graphs section and you'll see a visual representation of your graph with x,

31
00:01:40,170 --> 00:01:43,050
y, z1, z2, and z3,

32
00:01:43,050 --> 00:01:45,285
and the operations that connect them.

33
00:01:45,285 --> 00:01:49,060
There is more that you can do with TensorBoard and you will get to play with

34
00:01:49,060 --> 00:01:53,485
it in the next lab and in other labs in the specialization.

35
00:01:53,485 --> 00:01:58,385
Since we tend to develop ML models in DataLab,

36
00:01:58,385 --> 00:02:03,510
being able to launch TensorBoard directly from DataLab is very convenient.

37
00:02:03,510 --> 00:02:07,120
But sometimes, you will launch off a training job and

38
00:02:07,120 --> 00:02:11,710
perhaps it takes a few hours and you want to monitor the training.

39
00:02:11,710 --> 00:02:16,570
You don't need to get into DataLab to start TensorBoard.

40
00:02:16,570 --> 00:02:20,395
Remember that I said TensorBoard comes with TensorFlow?

41
00:02:20,395 --> 00:02:24,090
Well, TensorFlow is also installed in CloudShell

42
00:02:24,090 --> 00:02:29,075
and while the CloudShell is too puny to do actual machine learning work,

43
00:02:29,075 --> 00:02:32,115
it's sufficient to run TensorBoard.

44
00:02:32,115 --> 00:02:36,315
So here, you have the directions on how to start and support from

45
00:02:36,315 --> 00:02:41,850
CloudShell pointing to a model output directory that's on Google Cloud Storage.

46
00:02:41,850 --> 00:02:46,090
You can find this documented on the website that's linked from this video.