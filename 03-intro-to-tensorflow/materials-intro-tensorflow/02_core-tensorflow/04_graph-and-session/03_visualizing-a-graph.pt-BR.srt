1
00:00:00,000 --> 00:00:03,795
Até agora, vimos como escrever um gráfico
e como executá-lo.

2
00:00:03,795 --> 00:00:06,090
Mas, de vez em quando,

3
00:00:06,090 --> 00:00:08,039
você quer visualizar o gráfico,

4
00:00:08,039 --> 00:00:10,155
quer ver as operações,

5
00:00:10,155 --> 00:00:12,630
quais dados são alimentados etc.

6
00:00:12,630 --> 00:00:16,890
Você também pode querer visualizar
a arquitetura de suas redes neurais.

7
00:00:16,890 --> 00:00:22,230
Para escrever o gráfico,
use um tf.summary.FileWriter.

8
00:00:22,230 --> 00:00:27,075
Portanto, use tf.summary.FileWriter
para escrever o gráfico da sessão.

9
00:00:27,075 --> 00:00:29,725
Agora, se você vai visualizar o gráfico,

10
00:00:29,725 --> 00:00:33,445
provavelmente não quer nomes de tensores
gerados automaticamente,

11
00:00:33,445 --> 00:00:36,415
como o add_7 que vimos antes.

12
00:00:36,415 --> 00:00:39,610
Então, se está escrevendo
e visualizando o gráfico,

13
00:00:39,610 --> 00:00:43,560
não deixe de nomear
seus tensores de dados e suas operações.

14
00:00:43,560 --> 00:00:47,330
Depois de fazer isso
e executar esse programa,

15
00:00:47,330 --> 00:00:50,195
você recebe um novo diretório
chamado "summaries".

16
00:00:50,195 --> 00:00:53,760
Bem, ele é chamado assim
porque especificou resumos

17
00:00:53,760 --> 00:00:57,530
como um primeiro argumento
de tf.summary.FileWriter.

18
00:00:57,530 --> 00:00:59,960
Você pode
colocar o nome que quiser no diretório.

19
00:00:59,960 --> 00:01:04,575
Nesse diretório, há um arquivo
que contém um gráfico.

20
00:01:04,575 --> 00:01:08,090
O gráfico está
em um formato binário documentado

21
00:01:08,090 --> 00:01:09,845
e ele não é legível.

22
00:01:09,845 --> 00:01:14,035
Então, como você consegue um visual bonito
desse arquivo de saída?

23
00:01:14,035 --> 00:01:16,270
Para visualizar o gráfico,

24
00:01:16,270 --> 00:01:18,915
use um programa chamado TensorBoard.

25
00:01:18,915 --> 00:01:21,490
Ele vem com a distribuição do TensorFlow,

26
00:01:21,490 --> 00:01:23,915
o que significa
que você pode chamá-lo pelo DataLab.

27
00:01:23,915 --> 00:01:27,670
Então, aqui está o código Python
para invocar o TensorBoard,

28
00:01:27,670 --> 00:01:31,385
apontando para o diretório
de nível superior chamado "summaries".

29
00:01:31,385 --> 00:01:33,580
Depois, na interface do usuário,

30
00:01:33,580 --> 00:01:39,290
mude para a seção de gráficos e você verá
uma representação visual do gráfico

31
00:01:39,290 --> 00:01:43,050
com x, y, z1, z2 e z3

32
00:01:43,050 --> 00:01:45,285
e as operações que os conectam.

33
00:01:45,285 --> 00:01:48,660
Há mais coisas que você pode fazer
com o TensorBoard, e você poderá

34
00:01:48,660 --> 00:01:53,035
brincar com ele no próximo laboratório
e em outros da especialização.

35
00:01:54,285 --> 00:01:58,385
Como tendemos a desenvolver
modelos de ML no DataLab,

36
00:01:58,385 --> 00:02:03,510
conseguir iniciar o TensorBoard
diretamente pelo DataLab é muito prático.

37
00:02:03,510 --> 00:02:07,120
Mas, às vezes, você inicia um
job de treinamento,

38
00:02:07,120 --> 00:02:11,620
talvez ele leve algumas horas
e você queira monitorar o treinamento.

39
00:02:12,210 --> 00:02:16,450
Você não precisa entrar no DataLab
para iniciar o TensorBoard.

40
00:02:16,980 --> 00:02:20,565
Lembra que eu disse
que o TensorBoard vem com o TensorFlow?

41
00:02:20,565 --> 00:02:24,090
Bem, o TensorFlow
também está instalado no CloudShell

42
00:02:24,090 --> 00:02:26,515
e, apesar de o CloudShell
ser muito insatisfatório

43
00:02:26,515 --> 00:02:29,075
para trabalhar de verdade
com aprendizado de máquina,

44
00:02:29,075 --> 00:02:32,115
ele é suficiente
para executar o TensorBoard.

45
00:02:32,115 --> 00:02:37,315
Então, aqui você tem instruções sobre
como iniciar o TensorBoard pelo CloudShell

46
00:02:37,315 --> 00:02:41,850
apontando para um diretório de saída do
modelo que está no Google Cloud Storage.

47
00:02:41,850 --> 00:02:46,010
Você pode encontrar isso documentado
no site com o link neste vídeo.