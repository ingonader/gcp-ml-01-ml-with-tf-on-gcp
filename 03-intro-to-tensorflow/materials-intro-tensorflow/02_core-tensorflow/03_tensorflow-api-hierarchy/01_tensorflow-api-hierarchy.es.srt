1
00:00:00,674 --> 00:00:04,940
En las lecciones anteriores,
hablamos de qué es TensorFlow.

2
00:00:05,400 --> 00:00:09,615
Ahora veamos
la jerarquía de API de TensorFlow.

3
00:00:10,745 --> 00:00:12,800
Como muchas bibliotecas de software

4
00:00:12,970 --> 00:00:16,310
TensorFlow contiene
diversas capas de abstracción.

5
00:00:16,660 --> 00:00:18,755
La capa de abstracción más baja

6
00:00:19,025 --> 00:00:23,495
se implementa para orientarse
a diferentes plataformas de hardware.

7
00:00:23,945 --> 00:00:26,105
A menos que su empresa fabrique hardware

8
00:00:26,295 --> 00:00:29,175
es poco probable
que haga algo en esta capa.

9
00:00:29,695 --> 00:00:33,890
La siguiente capa
es la API de TensorFlow de C++.

10
00:00:34,230 --> 00:00:37,305
Así se escribe
una aplicación personalizada de TensorFlow.

11
00:00:37,645 --> 00:00:40,300
Implementa la función que desea en C++

12
00:00:40,590 --> 00:00:43,655
y la registra
como una operación de TensorFlow.

13
00:00:44,085 --> 00:00:47,235
Consulte la documentación de TensorFlow
sobre cómo extender una aplicación.

14
00:00:47,905 --> 00:00:50,710
Luego, TensorFlow le da
un wrapper de Python

15
00:00:50,840 --> 00:00:54,895
que puede usar tal como
lo haría con una función existente.

16
00:00:55,625 --> 00:00:57,345
Sin embargo, en esta especialización

17
00:00:57,405 --> 00:01:00,215
supondremos que usted
no es un investigador de AA

18
00:01:00,375 --> 00:01:02,270
así que no tendrá que hacer esto.

19
00:01:02,750 --> 00:01:05,750
Pero si alguna vez necesita implementar
su propia aplicación personalizada

20
00:01:06,020 --> 00:01:07,520
lo haría con C++.

21
00:01:07,780 --> 00:01:09,025
No es difícil.

22
00:01:09,275 --> 00:01:11,540
TensorFlow es extensible de esta manera.

23
00:01:11,780 --> 00:01:14,365
La capa siguiente es
la API principal de Python.

24
00:01:14,615 --> 00:01:18,400
Contiene gran parte
del código de procesamiento numérico

25
00:01:18,720 --> 00:01:23,930
suma, resta, división,
multiplicación de matrices, etcétera.

26
00:01:24,290 --> 00:01:26,775
Crear variables y tensores

27
00:01:26,825 --> 00:01:29,795
obtener la forma
o la dimensión de un tensor

28
00:01:29,945 --> 00:01:33,820
todas las cuestiones básicas
de procesamiento numérico

29
00:01:34,060 --> 00:01:36,305
todo eso está en la API de Python.

30
00:01:36,475 --> 00:01:39,420
Luego, hay un conjunto
de módulos de Python

31
00:01:39,560 --> 00:01:41,860
con una representación de alto nivel

32
00:01:42,010 --> 00:01:44,980
de componentes útiles de redes neuronales.

33
00:01:45,340 --> 00:01:48,955
Por ejemplo, la manera de crear
una nueva capa de neuronas ocultas

34
00:01:49,095 --> 00:01:50,945
con una función de activación ReLU

35
00:01:51,735 --> 00:01:52,955
está en tf.layers.

36
00:01:53,495 --> 00:01:55,800
La forma de calcular
el error cuadrático medio

37
00:01:55,800 --> 00:01:57,530
de los datos a medida que llegan

38
00:01:58,090 --> 00:01:59,080
es tf.metrics.

39
00:01:59,580 --> 00:02:02,385
La manera de procesar
entropía cruzada con logits…

40
00:02:02,505 --> 00:02:05,590
Esto es común en problemas de clasificación
de medición de pérdida.

41
00:02:05,960 --> 00:02:09,150
La entropía cruzada
con logits: está en tf.losses.

42
00:02:09,330 --> 00:02:13,035
Estos módulos
proporcionan componentes útiles

43
00:02:13,265 --> 00:02:16,240
para compilar
modelos de NN personalizados.

44
00:02:16,840 --> 00:02:20,085
¿Por qué hago hincapié
en que son modelos personalizados?

45
00:02:20,575 --> 00:02:22,280
Porque muy a menudo

46
00:02:22,420 --> 00:02:25,015
no se requiere
un modelo de red neuronal personalizado.

47
00:02:25,115 --> 00:02:27,522
Muchas veces es suficiente

48
00:02:27,522 --> 00:02:29,770
usar una manera relativamente estándar

49
00:02:29,950 --> 00:02:32,560
de entrenar, evaluar y entregar modelos.

50
00:02:32,860 --> 00:02:35,210
No hace falta
personalizar la manera de entrenar.

51
00:02:35,370 --> 00:02:38,975
Puede usar una familia de optimizadores
de descenso de gradientes

52
00:02:39,205 --> 00:02:42,770
y hacer una propagación inversa de los pesos
en un proceso iterativo.

53
00:02:43,130 --> 00:02:44,115
En ese caso

54
00:02:44,385 --> 00:02:46,470
no escriba un bucle de sesión de bajo nivel.

55
00:02:46,640 --> 00:02:48,460
Simplemente use un estimador.

56
00:02:49,600 --> 00:02:54,575
Estimator es la API
de alto nivel en TensorFlow.

57
00:02:54,925 --> 00:02:57,230
Sabe cómo realizar 
el entrenamiento distribuido

58
00:02:57,450 --> 00:03:01,225
cómo evaluar, cómo crear un control

59
00:03:01,265 --> 00:03:02,735
cómo guardar un modelo

60
00:03:02,875 --> 00:03:04,550
y cómo configurarlo para su entrega.

61
00:03:04,740 --> 00:03:07,675
Viene con todas las funciones
preparadas de manera adecuada

62
00:03:07,745 --> 00:03:10,655
que se adapta a la mayoría
de los modelos de AA en producción.

63
00:03:11,845 --> 00:03:14,830
Si encuentra un ejemplo
de código de TensorFlow en Internet

64
00:03:15,410 --> 00:03:17,537
que no usa la API de Estimator

65
00:03:17,707 --> 00:03:19,245
simplemente ignórelo.

66
00:03:19,635 --> 00:03:22,230
Olvídese de eso. No vale la pena.

67
00:03:22,740 --> 00:03:25,780
Tendría que escribir mucho código
para la asignación de dispositivos

68
00:03:25,780 --> 00:03:27,855
la administración de memoria y distribución.

69
00:03:28,135 --> 00:03:30,000
Deje que Estimator lo haga por usted.

70
00:03:30,750 --> 00:03:34,060
Esas son las capas
de abstracción de TensorFlow.

71
00:03:34,740 --> 00:03:38,305
Cloud ML Engine
es ortogonal a esta jerarquía.

72
00:03:38,795 --> 00:03:42,785
Sin importar la capa de abstracción
en la que escriba su código de TensorFlow

73
00:03:43,385 --> 00:03:45,870
CMLE le ofrece un servicio administrado.

74
00:03:46,340 --> 00:03:48,445
Es TensorFlow alojado.

75
00:03:49,055 --> 00:03:53,520
Así, puede ejecutar TensorFlow en la nube,
en un clúster de máquinas

76
00:03:53,880 --> 00:03:58,430
sin tener que instalar software
ni administrar servidores.