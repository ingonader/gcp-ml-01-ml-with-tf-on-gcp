1
00:00:00,290 --> 00:00:03,404
In den vorherigen Lektionen
haben wir darüber gesprochen,

2
00:00:03,404 --> 00:00:05,480
was TensorFlow ist.

3
00:00:05,480 --> 00:00:10,645
Sehen wir uns nun die 
TensorFlow API-Hierarchie an.

4
00:00:10,645 --> 00:00:12,820
Wie die meisten Softwarebibliothenken

5
00:00:12,820 --> 00:00:16,510
hat auch TensorFlow
eine Reihe an Abstraktionsebenen.

6
00:00:16,510 --> 00:00:20,685
Die niedrigste Abstraktionsebene
ist die Ebene, die im Hinblick auf

7
00:00:20,685 --> 00:00:23,805
die verschiedenen Hardwareplattformen
implementiert wird.

8
00:00:23,805 --> 00:00:26,775
Es ist unwahrscheinlich,
dass Sie viel auf dieser Ebene machen,

9
00:00:26,775 --> 00:00:29,695
außer Ihr Unternehmen produziert Hardware.

10
00:00:29,695 --> 00:00:34,120
Die nächste Ebene
ist eine TensorFlow C++ API.

11
00:00:34,120 --> 00:00:37,695
So können Sie eine benutzerdefinierte
TensorFlow-Anwendung schreiben.

12
00:00:37,695 --> 00:00:40,590
Sie implementieren die
gewünschte Funktion in C++

13
00:00:40,590 --> 00:00:43,995
und registrieren sie 
als TensorFlow-Vorgang.

14
00:00:43,995 --> 00:00:47,715
Siehe die TensorFlow-Dokumentation
zur Erweiterung einer Anwendung.

15
00:00:47,715 --> 00:00:50,760
Von TensorFlow erhalten Sie 
dann einen Python-Wrapper,

16
00:00:50,760 --> 00:00:55,625
den Sie so wie eine
bestehende Funktion nutzen können.

17
00:00:55,625 --> 00:00:57,755
In dieser Spezialisierung nehmen wir an,

18
00:00:57,755 --> 00:01:02,615
dass Sie kein ML-Forscher sind,
daher müssen Sie das nicht tun.

19
00:01:02,615 --> 00:01:05,400
Sollten Sie jemals Ihre eigene
benutzerdefinierte Anwendung

20
00:01:05,400 --> 00:01:07,810
implementieren müssen,
würden Sie dies in C++ tun

21
00:01:07,810 --> 00:01:09,365
und das ist nicht so schwierig.

22
00:01:09,365 --> 00:01:11,790
TensorFlow ist auf diese Art erweiterbar.

23
00:01:11,790 --> 00:01:14,455
Die Core Python API auf der nächsten Ebene

24
00:01:14,455 --> 00:01:18,640
enthält einen Großteil des Codes
zur numerischen Verarbeitung.

25
00:01:18,640 --> 00:01:24,030
Addition, Subtraktion, Division,
Matrix-Multiplikation und so weiter.

26
00:01:24,030 --> 00:01:26,805
Die Erstellung von Variablen und Tensoren,

27
00:01:26,805 --> 00:01:29,895
das Erhalten der Form und
aller Dimensionen eines Tensors,

28
00:01:29,895 --> 00:01:33,900
die gesamte, grundlegende 
numerische Verarbeitung:

29
00:01:33,900 --> 00:01:36,375
Das alles ist in der Python API enthalten.

30
00:01:36,375 --> 00:01:39,620
Es gibt ein Set an Python-Modulen,

31
00:01:39,620 --> 00:01:45,380
die viele nützliche neuronale
Netzwerkkomponenten enthalten,

32
00:01:45,380 --> 00:01:49,110
z. B. eine Möglichkeit, 
eine neue Ebene versteckter Neuronen

33
00:01:49,110 --> 00:01:51,805
innerhalb einer ReLU-
Aktivierungsfunktion zu erstellen,

34
00:01:51,805 --> 00:01:53,435
und zwar mit tf.layers.

35
00:01:53,435 --> 00:01:56,115
Sie können die Wurzel
der mittleren Fehlerquadratsumme

36
00:01:56,115 --> 00:01:59,550
bei eingehenden Daten 
berechnen: tf.metrics.

37
00:01:59,550 --> 00:02:02,515
Sie können Kreuzentropien 
mit Logits berechnen.

38
00:02:02,515 --> 00:02:05,800
Dies ist eine übliche Verlustmessung
bei Klassifikationsproblemen.

39
00:02:05,800 --> 00:02:07,570
Kreuzentropie mit Logits

40
00:02:07,570 --> 00:02:09,395
ist in tf.losses enthalten.

41
00:02:09,395 --> 00:02:13,125
Diese Module bieten Ihnen
nützliche Komponenten

42
00:02:13,125 --> 00:02:16,680
zur Erstellung von
benutzerdefinierten NN-Modellen.

43
00:02:16,680 --> 00:02:20,465
Warum betone ich
benutzerdefinierte NN-Modelle?

44
00:02:20,465 --> 00:02:23,340
Oft benötigen Sie kein benutzerdefiniertes

45
00:02:23,340 --> 00:02:24,915
Modell für neuronale Netzwerke.

46
00:02:24,915 --> 00:02:29,750
Meistens genügen Ihnen die
relativ standardmäßigen Möglichkeiten

47
00:02:29,750 --> 00:02:32,640
für Training, Evaluierung und 
Bereitstellung von Modellen.

48
00:02:32,640 --> 00:02:35,840
Sie müssen nicht anpassen, 
wie Sie trainieren, sondern Sie nutzen

49
00:02:35,840 --> 00:02:39,185
eine Möglichkeit aus der Familie
der Gradientenverfahrensoptimierung

50
00:02:39,185 --> 00:02:43,090
und Sie propagieren die 
Gewichtungen zurück und tun dies iterativ.

51
00:02:43,090 --> 00:02:46,620
In diesem Fall schreiben Sie keine
untergeordnete Sitzungsschleife,

52
00:02:46,620 --> 00:02:49,400
sondern nutzen nur einen Estimator.

53
00:02:49,400 --> 00:02:54,842
Der Estimator ist die
übergeordnete API in TensorFlow.

54
00:02:54,842 --> 00:02:57,300
Dieser weiß,
wie verteiltes Training funktioniert,

55
00:02:57,300 --> 00:03:00,975
wie evaluiert und
ein Prüfpunkt erstellt wird,

56
00:03:00,975 --> 00:03:02,465
wie ein Modell gespeichert wird

57
00:03:02,465 --> 00:03:05,270
und welche Einrichtung
für die Bereitstellung notwendig ist.

58
00:03:05,270 --> 00:03:07,685
Alles ist auf vernünftige Art vorbereitet

59
00:03:07,685 --> 00:03:10,985
und passt für die meisten
ML-Modelle in der Produktion.

60
00:03:10,985 --> 00:03:15,290
Wenn Sie also einen Beispielcode
für TensorFlow im Internet sehen

61
00:03:15,290 --> 00:03:17,625
und dieser nicht die Estimator API nutzt,

62
00:03:17,625 --> 00:03:20,490
lassen Sie am besten die Finger davon,

63
00:03:20,490 --> 00:03:22,660
es lohnt sich nicht.

64
00:03:22,660 --> 00:03:24,600
Sie müssen eine Menge an Code schreiben

65
00:03:24,600 --> 00:03:27,955
für die Gerätezuordnung und 
die Speicherverwaltung und Verteilung.

66
00:03:27,955 --> 00:03:30,580
Lassen Sie den Estimator dies für Sie tun.

67
00:03:30,580 --> 00:03:34,340
Das sind die 
TensorFlow-Abstraktionsebenen.

68
00:03:34,340 --> 00:03:38,745
Cloud ML Engine ist orthogonal
in Bezug auf diese Hierarchie.

69
00:03:38,745 --> 00:03:43,075
Unabhängig von der Abstraktionsebene, auf
der Sie Ihren TensorFlow-Code schreiben,

70
00:03:43,075 --> 00:03:46,160
bietet CMLE einen verwalteten Dienst.

71
00:03:46,160 --> 00:03:49,135
TensorFlow wird gehostet,

72
00:03:49,135 --> 00:03:53,650
damit Sie TensorFlow auf der Cloud und
einem Gerätecluster ausführen können,

73
00:03:53,650 --> 00:03:58,590
ohne Software installieren
oder Server verwalten zu müssen.