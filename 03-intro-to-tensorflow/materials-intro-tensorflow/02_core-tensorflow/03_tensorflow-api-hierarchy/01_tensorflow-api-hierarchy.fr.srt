1
00:00:00,000 --> 00:00:02,314
Dans les leçons précédentes,

2
00:00:02,314 --> 00:00:05,470
il a été question de ce qu'est TensorFlow.

3
00:00:05,470 --> 00:00:10,745
Intéressons-nous maintenant
à la hiérarchie de l'API TensorFlow.

4
00:00:10,745 --> 00:00:12,980
Comme la plupart
des bibliothèques de logiciels,

5
00:00:12,980 --> 00:00:16,820
TensorFlow comporte un certain nombre
de couches d'abstraction.

6
00:00:16,820 --> 00:00:20,745
Le niveau d'abstraction le plus bas
est celui d'une couche mise en œuvre

7
00:00:20,745 --> 00:00:23,955
pour assurer l'adaptabilité à différentes
plates-formes matérielles.

8
00:00:23,955 --> 00:00:26,435
À moins que votre entreprise
ne fabrique du matériel,

9
00:00:26,435 --> 00:00:29,735
il est peu probable que vous ayez
beaucoup à vous en occuper.

10
00:00:29,735 --> 00:00:34,270
Le niveau suivant est celui
d'une API C++ de TensorFlow.

11
00:00:34,270 --> 00:00:37,715
Elle vous permet d'écrire une application
TensorFlow personnalisée.

12
00:00:37,715 --> 00:00:41,380
Il vous suffit pour cela de mettre
la fonction de votre choix en œuvre en C++,

13
00:00:41,380 --> 00:00:44,230
et de l'enregistrer
comme opération TensorFlow.

14
00:00:44,230 --> 00:00:44,862
Reportez-vous

15
00:00:44,862 --> 00:00:48,335
à la documentation de TensorFlow
relative à l'extension d'une application.

16
00:00:48,335 --> 00:00:50,920
TensorFlow vous fournira alors
un wrapper Python

17
00:00:50,920 --> 00:00:55,705
que vous pourrez utiliser tout comme
vous utiliseriez une fonction existante.

18
00:00:55,705 --> 00:00:57,425
Dans cette spécialisation toutefois,

19
00:00:57,425 --> 00:01:00,375
nous considérerons
que vous n'êtes pas chercheur en ML

20
00:01:00,375 --> 00:01:02,670
et que vous n'avez donc pas à faire ça.

21
00:01:02,670 --> 00:01:06,520
Mais si vous devez un jour mettre en œuvre
votre propre application personnalisée,

22
00:01:06,520 --> 00:01:07,860
vous pouvez le faire en C++,

23
00:01:07,860 --> 00:01:09,435
et ce n'est pas très compliqué.

24
00:01:09,435 --> 00:01:12,480
C'est ainsi que vous pouvez procéder
à l'extension de TensorFlow.

25
00:01:12,480 --> 00:01:14,595
L'API Core Python, le niveau suivant,

26
00:01:14,595 --> 00:01:18,900
contient la majeure partie
du code de traitement numérique :

27
00:01:18,900 --> 00:01:20,475
les additions, les soustractions,

28
00:01:20,475 --> 00:01:24,400
les divisions ou encore
les multiplications de matrices,

29
00:01:24,400 --> 00:01:26,805
la création de variables ou de Tensors,

30
00:01:26,805 --> 00:01:30,275
ou encore l'obtention de la forme
et de toutes les dimensions d'un Tensor.

31
00:01:30,275 --> 00:01:34,100
Toutes ces opérations de traitement
numérique de base se trouvent

32
00:01:34,100 --> 00:01:36,565
dans l'API Python.

33
00:01:36,565 --> 00:01:39,630
Il y a ensuite
un ensemble de modules Python

34
00:01:39,630 --> 00:01:45,510
ayant une représentation de haut niveau
de composants de réseau de neurones utiles.

35
00:01:45,510 --> 00:01:49,130
Il peut par exemple s'agir d'une façon
de créer une couche de neurones cachés

36
00:01:49,130 --> 00:01:53,525
assortie d'une fonction d'activation
ReLU (dans tf.layers),

37
00:01:53,525 --> 00:01:56,907
d'une façon de calculer la racine carrée
de l'erreur quadratique moyenne

38
00:01:56,907 --> 00:01:59,600
de données entrantes (dans tf.metrics),

39
00:01:59,600 --> 00:02:02,715
ou encore d'une façon de calculer
l'entropie croisée avec logits

40
00:02:02,715 --> 00:02:07,835
(une mesure de la perte courante
pour les problèmes de classification

41
00:02:07,835 --> 00:02:09,390
qui se trouve dans tf.losses).

42
00:02:09,390 --> 00:02:13,325
Ces modèles fournissent
des composants utiles

43
00:02:13,325 --> 00:02:16,790
pour la création de modèles
de réseaux de neurones personnalisés.

44
00:02:16,790 --> 00:02:18,932
Pour quelle raison
est-ce que je mets l'accent

45
00:02:18,932 --> 00:02:20,695
sur la notion de personnalisation ?

46
00:02:20,695 --> 00:02:22,470
Parce que la plupart du temps,

47
00:02:22,470 --> 00:02:25,750
vous n'avez pas besoin d'un modèle
de réseau de neurones personnalisé.

48
00:02:25,750 --> 00:02:28,610
Vous pouvez bien souvent
vous contenter, pour vos modèles,

49
00:02:28,610 --> 00:02:32,865
d'un mode d'entraînement, d'évaluation
et de diffusion relativement standard.

50
00:02:32,865 --> 00:02:36,150
Vous n'avez pas besoin de définir
un mode d'entraînement personnalisé.

51
00:02:36,150 --> 00:02:38,055
Utilisez l'une des possibilités offertes

52
00:02:38,055 --> 00:02:40,530
par une famille d'optimiseurs
de descente de gradient

53
00:02:40,530 --> 00:02:43,960
et effectuez une propagation amont
des pondérations de manière itérative.

54
00:02:43,960 --> 00:02:46,865
Dans ce cas, n'écrivez pas
de boucle de session de bas niveau.

55
00:02:46,865 --> 00:02:49,750
Utilisez simplement un Estimator.

56
00:02:49,750 --> 00:02:54,965
L'Estimator est l'API
de haut niveau de TensorFlow.

57
00:02:54,965 --> 00:02:57,555
Elle sait comment répartir l'entraînement,

58
00:02:57,555 --> 00:03:01,260
procéder à l'évaluation,
créer un point de contrôle,

59
00:03:01,260 --> 00:03:02,915
enregistrer un modèle,

60
00:03:02,915 --> 00:03:04,725
ou encore configurer la diffusion.

61
00:03:04,725 --> 00:03:08,110
Elle contient des informations
permettant de tout effectuer correctement

62
00:03:08,110 --> 00:03:10,297
pour la plupart des modèles
de machine learning

63
00:03:10,297 --> 00:03:11,395
utilisés en production.

64
00:03:11,395 --> 00:03:15,460
Donc, si vous voyez sur Internet
un exemple de code TensorFlow

65
00:03:15,460 --> 00:03:17,820
n'utilisant pas l'API Estimator,

66
00:03:17,820 --> 00:03:20,740
ignorez-le. Passez votre chemin.

67
00:03:20,740 --> 00:03:23,165
Il ne vaut pas la peine
que vous vous y intéressiez.

68
00:03:23,165 --> 00:03:26,160
Vous aurez à écrire beaucoup de code
pour affecter les appareils

69
00:03:26,160 --> 00:03:28,260
ainsi que pour gérer et répartir la mémoire.

70
00:03:28,260 --> 00:03:30,705
Laissez l'Estimator s'en charger pour vous.

71
00:03:30,705 --> 00:03:34,945
Nous venons donc de voir
les niveaux d'abstraction de TensorFlow.

72
00:03:34,945 --> 00:03:39,050
Cloud Machine Learning Engine est disponible
pour tous les niveaux de cette hiérarchie.

73
00:03:39,050 --> 00:03:41,082
Quelle que soit la couche d'abstraction

74
00:03:41,082 --> 00:03:43,475
pour laquelle vous écrivez
votre code TensorFlow,

75
00:03:43,475 --> 00:03:46,465
CMLE vous permet
de bénéficier d'un service géré.

76
00:03:46,465 --> 00:03:49,195
C'est la version hébergée de TensorFlow.

77
00:03:49,195 --> 00:03:53,890
Elle vous permet d'exécuter TensorFlow
dans le cloud sur un cluster de machines

78
00:03:53,890 --> 00:03:59,450
sans avoir à installer de logiciel
ni à gérer des serveurs.