1
00:00:00,490 --> 00:00:03,394
Sehen wir uns kurz die
TensorFlow-Codes und -Konzepte an,

2
00:00:03,394 --> 00:00:05,144
die in diesem Kurs behandelt wurden.

3
00:00:06,144 --> 00:00:08,080
Zuerst haben wir mit TensorFlow gelernt,

4
00:00:08,080 --> 00:00:12,040
wie wir eine verzögerte Bewertung 
und imperative Programme erstellen.

5
00:00:12,300 --> 00:00:15,245
Wir haben mit Grafiken, 
Sitzungen und Variablen gearbeitet

6
00:00:15,245 --> 00:00:17,555
und in den Labs Fehlerbehebung geübt.

7
00:00:17,595 --> 00:00:19,785
Anschließend
haben wir mit der Estimator API

8
00:00:19,885 --> 00:00:24,125
produktionsreife Modelle 
des maschinellen Lernens erstellt

9
00:00:24,325 --> 00:00:27,010
und gelernt, wie Training
auf Datasets durchgeführt wird,

10
00:00:27,010 --> 00:00:28,740
die für den Speicher zu groß sind,

11
00:00:28,780 --> 00:00:31,175
und wie diese
in TensorBoard überwacht werden.

12
00:00:31,515 --> 00:00:35,330
Schließlich haben wir gelernt,
wie verteilte TensorFlow-Modelle

13
00:00:35,330 --> 00:00:37,740
mit Cloud ML Engine skaliert werden.

14
00:00:38,780 --> 00:00:44,750
TensorFlow ist im Wesentlichen
eine leistungsstarke Open Source-Bibliothek

15
00:00:44,750 --> 00:00:48,775
für alle Arten numerischer Berechnungen,
nicht nur für maschinelles Lernen.

16
00:00:49,705 --> 00:00:53,350
Hier noch einmal ein Diagramm
aus unserer TensorFlow-Hierarchie.

17
00:00:53,830 --> 00:00:59,600
In den Labs wurden höhere Abstraktionsebenen
beim Schreiben von Modellcode verwendet.

18
00:00:59,820 --> 00:01:03,000
Wir erstellen ML-Modelle
meistens mit der Estimator API.

19
00:01:03,200 --> 00:01:05,690
Schließlich ermöglicht diese API
verteiltes Training.

20
00:01:05,690 --> 00:01:08,225
Wir können damit 
Bewertungen und Prüfpunkte erstellen,

21
00:01:08,225 --> 00:01:11,022
Modelle speichern
und TensorFlow-Bereitstellung einrichten.

22
00:01:11,215 --> 00:01:15,840
Das ist zweckmäßig und für die meisten
ML-Modelle und -Produktionen geeignet.

23
00:01:16,110 --> 00:01:19,955
Unabhängig von der
Abstraktionsebene des TensorFlow-Codes

24
00:01:19,955 --> 00:01:24,130
erhalten wir einen verwalteten Dienst,
den gehosteten TensorFlow.

25
00:01:24,200 --> 00:01:27,510
Wir können also in der Cloud
auf einem Cluster von Geräten schreiben,

26
00:01:27,510 --> 00:01:30,555
ohne Software zu installieren
oder Server zu verwalten.

27
00:01:31,745 --> 00:01:35,110
Wir haben die Infrastruktur
für Training und Bereitstellung besprochen,

28
00:01:35,110 --> 00:01:36,620
die wir einrichten müssten,

29
00:01:36,620 --> 00:01:39,800
um eigene Produktionsmodelle 
hosten und ausführen zu können.

30
00:01:40,130 --> 00:01:42,720
Cloud ML Engine bietet
die erforderlichen Maschinen,

31
00:01:42,750 --> 00:01:44,670
egal ob CPUs, GPUs oder TPUs,

32
00:01:44,670 --> 00:01:46,450
wenn sie benötigt werden.

33
00:01:46,640 --> 00:01:49,560
Es vereinfacht die Verwaltung
und ermöglicht Modelltraining

34
00:01:49,560 --> 00:01:51,780
basierend auf Vorhersagen.

35
00:01:51,840 --> 00:01:55,315
Es ist ein hoch skalierbarer Dienst,
der verteiltes Training vereinfacht.

36
00:01:55,770 --> 00:01:58,220
Und nicht nur das Training,
auch die Bereitstellung.

37
00:01:58,270 --> 00:02:00,660
In der Cloud kann auf
0 Maschinen skaliert werden,

38
00:02:00,665 --> 00:02:04,465
oder so viele, wie für viele 
Abfragen pro Sekunden benötigt werden.

39
00:02:05,475 --> 00:02:08,830
Wir haben die Bereitstellung 
des Vorhersagemodells für Taxigebühren

40
00:02:08,830 --> 00:02:10,960
in der Cloud ML Engine geübt.

41
00:02:11,430 --> 00:02:13,395
Das waren die Grundlagen von TensorFlow.

42
00:02:13,655 --> 00:02:16,930
Im nächsten Kurs erfahren Sie,
wie Sie Funktionen entwickeln können,

43
00:02:16,986 --> 00:02:19,516
um die Leistung Ihrer Modelle zu steigern.