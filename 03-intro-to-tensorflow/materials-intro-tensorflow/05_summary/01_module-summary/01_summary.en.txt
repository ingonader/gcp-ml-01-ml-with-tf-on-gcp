Let's do a quick recap of the TensorFlow code and concepts we've covered in this course. We started with core TensorFlow where you learned how to write lazy evaluation and imperative programs. You worked with graphs, sessions, and variables, and did a bit of debugging in your labs. Then we moved onto the estimator API where we created production-ready machine learning models the easy way, and learned how to train on large datasets that do not fit in memory and monitor them inside tensor board. Lastly, we ended with how to scale our distributed TensorFlow models with Cloud ML Engine. Recall that fundamentally, TensorFlow is an open source, high performance library for numerical computation, not just machine learning, any numerical computation. Let's revisit this diagram we've covered on your TensorFlow hierarchy. As you saw in your labs, you were largely working with higher levels of abstraction when writing model code. Mostly, we build our ML models using the estimator API. Recall that it knows how to do distributed training. It knows how to evaluate, how to create a checkpoint, how to save a model and how to set up TensorFlow serving. It comes with everything done in a sensible way that fits most ML models and production. Regardless of which abstraction layer you are writing your TensorFlow code at, seemingly gives you a managed service, its hosted TensorFlow. So you can write it on the cloud, on a cluster of machines without having to install any software or manage any servers. We discussed the training and serving infrastructure you would need to set up yourself if you wanted to host and run your own production models. Cloud ML Engine get you the machines you need whether CPUs or GPUs or TPUs when you need them. It simplifies the bookkeeping and ensures that the train models which you actually run at prediction time. It's a highly scalable service that makes distributed training easy. Not just training, though, also serving. On cloud, we can scale to zero machines or as many as you need to handle the large number of queries per second. We practiced deploying and serving our taxi fare prediction model on cloud ML engine. Well, that's a wrap on TensorFlow basics. Join us for the next course where you will learn how to do feature engineering so as to improve the performance of your models.