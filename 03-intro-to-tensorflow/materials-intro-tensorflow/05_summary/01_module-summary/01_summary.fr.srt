1
00:00:00,000 --> 00:00:02,854
Revenons rapidement sur le code
et les concepts TensorFlow

2
00:00:02,854 --> 00:00:04,934
que nous avons abordés durant ce cours.

3
00:00:06,074 --> 00:00:08,040
Nous avons commencé par les concepts clés

4
00:00:08,040 --> 00:00:10,280
sur la rédaction
des évaluations paresseuses

5
00:00:10,280 --> 00:00:11,910
et des programmes impératifs.

6
00:00:12,090 --> 00:00:15,095
Vous avez utilisé des graphiques,
des sessions et des variables,

7
00:00:15,095 --> 00:00:17,135
et vous vous êtes entraînés au débogage.

8
00:00:17,545 --> 00:00:19,795
Nous vous avons ensuite présenté
l'API Estimator

9
00:00:19,795 --> 00:00:24,135
qui permet de créer facilement
des modèles de ML prêts à être déployés

10
00:00:24,135 --> 00:00:25,382
et d'en entraîner d'autres

11
00:00:25,382 --> 00:00:28,172
avec des ensembles de données
trop grands pour la mémoire

12
00:00:28,172 --> 00:00:30,342
que l'on peut surveiller dans TensorBoard.

13
00:00:31,395 --> 00:00:33,820
Enfin, nous avons expliqué
comment faire évoluer

14
00:00:33,820 --> 00:00:36,720
les modèles TensorFlow distribués
grâce à Cloud ML Engine.

15
00:00:38,900 --> 00:00:41,435
Souvenez-vous que TensorFlow est
une bibliothèque

16
00:00:41,435 --> 00:00:45,165
à hautes performances
disponible en Open Source

17
00:00:45,165 --> 00:00:48,325
et destinée à tous les calculs numériques,
et non uniquement au ML.

18
00:00:49,745 --> 00:00:53,170
Réexaminons le schéma
sur la hiérarchie de TensorFlow.

19
00:00:53,630 --> 00:00:55,630
Comme vous l'avez vu durant les ateliers,

20
00:00:55,630 --> 00:00:59,300
l'écriture du code du modèle nécessite
d'importants niveaux d'abstraction.

21
00:00:59,810 --> 00:01:01,920
Nous concevons généralement
nos modèles de ML

22
00:01:01,920 --> 00:01:02,970
avec l'API Estimator.

23
00:01:03,300 --> 00:01:05,650
Elle permet de réaliser
un entraînement distribué,

24
00:01:05,650 --> 00:01:08,135
d'évaluer un modèle,
de créer des points de contrôle,

25
00:01:08,135 --> 00:01:10,955
d'enregistrer un modèle
et de configurer TensorFlow Serving.

26
00:01:10,955 --> 00:01:13,020
Elle s'occupe de tout
et fournit un résultat

27
00:01:13,020 --> 00:01:15,730
adapté à la plupart des modèles de ML
et à la production.

28
00:01:16,310 --> 00:01:19,915
Quel que soit le niveau d'abstraction
de votre code,

29
00:01:19,915 --> 00:01:23,920
Cloud ML Engine vous offre un service géré
qui comprend l'hébergement de TensorFlow.

30
00:01:24,130 --> 00:01:27,520
Vous pouvez écrire votre code
via un cluster de machines dans le cloud,

31
00:01:27,520 --> 00:01:30,415
sans avoir à installer de logiciel
ni à gérer des serveurs.

32
00:01:31,965 --> 00:01:35,180
Nous avons abordé les infrastructures
d'entraînement et de diffusion

33
00:01:35,180 --> 00:01:36,630
à configurer vous-même

34
00:01:36,630 --> 00:01:39,610
pour héberger et exécuter
vos propres modèles de production.

35
00:01:40,080 --> 00:01:42,610
Cloud ML Engine vous fournit
les machines nécessaires,

36
00:01:42,610 --> 00:01:46,170
que ce soit un processeur, un GPU
ou un TPU, lorsque vous en avez besoin.

37
00:01:46,560 --> 00:01:48,710
Autres avantages :
une comptabilité simplifiée

38
00:01:48,710 --> 00:01:51,625
et la garantie du fonctionnement
de vos modèles en production.

39
00:01:51,745 --> 00:01:55,010
C'est un service très évolutif
qui facilite l'entraînement distribué.

40
00:01:55,890 --> 00:01:58,020
Il en va de même pour la diffusion.

41
00:01:58,520 --> 00:02:01,360
Vous pouvez utiliser 
autant de machines que nécessaire

42
00:02:01,360 --> 00:02:03,835
pour gérer
un grand nombre de requêtes par seconde.

43
00:02:05,435 --> 00:02:08,870
Nous avons déployé et diffusé
notre modèle de prédiction de frais de taxi

44
00:02:08,870 --> 00:02:09,830
sur Cloud ML Engine.

45
00:02:10,990 --> 00:02:13,475
Voilà les principes de base de TensorFlow.

46
00:02:13,585 --> 00:02:16,920
Passez au cours suivant pour découvrir
l'extraction de caractéristiques

47
00:02:16,920 --> 00:02:19,415
afin d'améliorer
les performances de vos modèles.