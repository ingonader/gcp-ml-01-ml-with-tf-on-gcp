このコースの終わりに TensorFlowの
コードと概念の復習をしましょう まず コアTensorFlowで 遅延評価と
命令型プログラムの書き方を学びました グラフ、セッション、変数を扱い
デバッグもしました 次にEstimator APIで
すぐに使える機械学習モデルを作り メモリに収まり切らない
大量のデータでのトレーニングと モニタリングの方法を学びました 最後に 分散型TensorFlowモデルを Cloud ML Engineで
スケーリングする方法を学びました TensorFlowは本質的に
高性能な演算処理ライブラリであり 機械学習専用ではありません ツールキットの階層図を
再度見てみましょう モデルのコードは抽象化のレベルが
高いところで扱い 通常はEstimator APIを使って
MLモデルを構築します そのため分散型学習、評価、
チェックポイント作成、モデルの保存 TensorFlowサービスの設定ができ ほとんどの機械学習モデルに
適切な方法で処理されます どの抽象化レイヤで
TensorFlowコードを書いても TensorFlowをホストする
マネージドサービスが提供され ソフトウェアのインストールや
サーバーの管理は不要です 独自の予測モデルをホストし実行するには
トレーニングとインフラが必要ですが Cloud ML Engineが CPU、GPU、TPUなどの
必要に応じてマシンを用意するため 煩雑な作業が不要になり
モデルがスケジュールどおり動作します スケーラブルで
分散型トレーニングも配信も簡単です クラウドで マシン数ゼロから
必要な数まで自由にスケールできます Cloud ML Engineでタクシー料金予測モデルの
デプロイと配信を練習しました 基礎編のまとめでした 次のコースでは モデルのパフォーマンスを
高める方法を学びます