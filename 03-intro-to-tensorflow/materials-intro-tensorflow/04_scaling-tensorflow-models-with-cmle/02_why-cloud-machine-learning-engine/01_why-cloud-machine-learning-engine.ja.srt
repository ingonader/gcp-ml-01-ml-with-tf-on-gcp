1
00:00:00,000 --> 00:00:03,390
この図は以前お見せしました

2
00:00:03,390 --> 00:00:05,970
TensorFlowは
さまざまなハードウェアで動作します

3
00:00:05,970 --> 00:00:13,020
このコースの演習では 低レベルC++ API
ではなく Python APIを使います

4
00:00:13,065 --> 00:00:17,750
分散型トレーニング用の
抽象化レイヤはすでに確認しました

5
00:00:17,760 --> 00:00:21,845
分散型トレーニングを
本番環境の規模で実行します

6
00:00:21,845 --> 00:00:25,630
そのためにCloud ML Engineを
導入します

7
00:00:25,630 --> 00:00:32,480
まず メモリに収まる
小さなデータセットから始めます

8
00:00:32,490 --> 00:00:34,065
このようなデータセットで

9
00:00:34,065 --> 00:00:36,510
多くのMLフレームワークは充分です

10
00:00:36,510 --> 00:00:41,689
Pythonなどの言語には統計パッケージがあり

11
00:00:41,695 --> 00:00:45,630
実行に必要なのは3～4行のコードです

12
00:00:45,630 --> 00:00:48,810
TensorFlow EstimatorのAPIは

13
00:00:48,810 --> 00:00:52,110
小さなデータセットで
簡単によく機能する学習を決定できます

14
00:00:52,110 --> 00:00:57,934
ただし 実際に必要なのは本番環境の
エンタープライズサイズのデータセットです

15
00:00:57,960 --> 00:01:00,665
その大きさではメモリに収まりません

16
00:01:00,665 --> 00:01:04,545
だからパッケージをスケールアップして
高度にします

17
00:01:04,545 --> 00:01:06,930
データセットがメモリには大きすぎるので

18
00:01:06,930 --> 00:01:10,340
トレーニング中何度も繰り返す必要があります

19
00:01:10,340 --> 00:01:12,780
これは単一のマシンで可能ですが

20
00:01:12,780 --> 00:01:14,265
理想的ではありません

21
00:01:14,265 --> 00:01:18,570
トレーニング結果を何週間も待てませんよね？

22
00:01:18,570 --> 00:01:22,155
トレーニングは多数のマシンに
分散する必要がありました

23
00:01:22,155 --> 00:01:26,520
これは大量生産のように簡単ではありません

24
00:01:26,520 --> 00:01:30,184
勾配降下法の最適化などのアルゴリズムは
簡単ではないのです

25
00:01:30,184 --> 00:01:34,725
いわゆる パラメータサーバーの助けを得て
トレーナーをサポートすべきです

26
00:01:34,725 --> 00:01:38,185
パラメータサーバーは共有メモリを構成して

27
00:01:38,185 --> 00:01:40,890
各トレーナーを他から学習させます

28
00:01:40,890 --> 00:01:44,010
分散型トレーニングを使わずに

29
00:01:44,010 --> 00:01:47,340
必要なGPUのある巨大な単一マシンを
使いたくなるでしょう

30
00:01:47,340 --> 00:01:50,670
ほとんどの場合 これは近視眼的です

31
00:01:50,670 --> 00:01:54,450
1台の機能では
データセットの成長に間に合いません

32
00:01:54,450 --> 00:01:57,765
解決にはスケールアウトです

33
00:01:57,765 --> 00:02:00,870
データのサンプリングも短絡的な方法です

34
00:02:00,870 --> 00:02:04,875
データが小さいと
今のハードウェアでもMLできますが

35
00:02:04,875 --> 00:02:08,264
パフォーマンスの問題は解決していません

36
00:02:08,264 --> 00:02:13,169
利用可能な全データを使い
10倍収集するプランを考え出せるかどうか

37
00:02:13,169 --> 00:02:17,910
それが 魔法のように動作するMLと
そうでないMLの違いです

38
00:02:17,930 --> 00:02:22,755
たいていMLモデルの構築は
未加工データでただトレーニングするより

39
00:02:22,755 --> 00:02:25,425
人の分析でパフォーマンスを改善できます

40
00:02:25,425 --> 00:02:29,270
こうした分析を利用するのは
新たな特性での問題点を

41
00:02:29,270 --> 00:02:31,570
専門家が知っている場合です

42
00:02:31,570 --> 00:02:35,175
この特性は未加工データの前処理後
すぐに追加します

43
00:02:35,175 --> 00:02:39,170
たとえばスケーリングや
コーディングをしたときです

44
00:02:39,170 --> 00:02:42,870
本当に処理したいサイズのデータセットでは

45
00:02:42,870 --> 00:02:46,185
分散とクラウド上の処理が必要です

46
00:02:46,185 --> 00:02:49,320
MLでは いくつか自分で決めることがあります

47
00:02:49,320 --> 00:02:51,795
ノードの数、埋め込み

48
00:02:51,795 --> 00:02:55,050
畳み込み層のストライドサイズなどです

49
00:02:55,050 --> 00:02:59,750
モデルが複雑になると
値が正しいか迷ってきます

50
00:02:59,790 --> 00:03:02,010
手動でも自動でも

51
00:03:02,010 --> 00:03:05,130
ハイパーパラメータを探索して

52
00:03:05,130 --> 00:03:08,205
もっとよい選択がないか
確認する必要があります

53
00:03:08,205 --> 00:03:12,200
層の数やノードの数は
わかりやすいハイパーパラメータです

54
00:03:12,200 --> 00:03:13,770
ただしこのコースで学習しますが

55
00:03:13,770 --> 00:03:16,545
バケット数などの前処理の調整も

56
00:03:16,545 --> 00:03:19,790
ハイパーパラメータとして
扱うのがよいでしょう

57
00:03:19,790 --> 00:03:22,440
ここまではトレーニングについて説明しました

58
00:03:22,440 --> 00:03:25,830
トレーニング済みのモデルを
推測に使えるでしょうか？

59
00:03:25,830 --> 00:03:29,140
予測された特性が必要なアプリに

60
00:03:29,140 --> 00:03:32,910
直接MLモデルを埋め込むのは
あまり良い方法とは言えません

61
00:03:32,910 --> 00:03:37,290
良い方法はマイクロサービスで
モデルをラップして

62
00:03:37,290 --> 00:03:39,810
他のマイクロサービスと通信することです

63
00:03:39,810 --> 00:03:41,445
他のウェブアプリと同じです

64
00:03:41,445 --> 00:03:45,105
これでモデルの更新やAPテストで

65
00:03:45,105 --> 00:03:49,060
アプリのコアロジックを変えずにすみます

66
00:03:49,060 --> 00:03:50,670
マイクロサービスの変更だけです

67
00:03:50,670 --> 00:03:54,915
このモデルに適した量のハードウェアは
どうプロビジョニングしますか？

68
00:03:54,915 --> 00:03:59,460
優れたシステムは必要なときにマシンを追加して
自動スケーリングします

69
00:03:59,460 --> 00:04:02,070
クラウドならマシンをゼロ台から

70
00:04:02,070 --> 00:04:05,250
膨大なクエリ/秒に適した数まで
スケーリングできます

71
00:04:05,250 --> 00:04:07,770
ここで今後の心痛の種を取り除きましょう

72
00:04:07,770 --> 00:04:11,540
トレーニングの前に行う
前処理について説明しました

73
00:04:11,540 --> 00:04:13,065
注意してください

74
00:04:13,065 --> 00:04:17,834
同じ前処理は予測のときにも必要です

75
00:04:17,834 --> 00:04:20,760
トレーニング済みモデルと予測モデルとの違いは

76
00:04:20,760 --> 00:04:24,060
前処理以外にもたくさんあります

77
00:04:24,060 --> 00:04:28,680
Cloud Machine Learning Engineなら
この問題を減らせます

78
00:04:28,680 --> 00:04:30,660
ほとんど話題になりませんが

79
00:04:30,660 --> 00:04:35,680
予測の入力は一般的に
トレーニングとシステム的に異なります

80
00:04:35,700 --> 00:04:38,040
しかも微妙で検出しにくいのです

81
00:04:38,040 --> 00:04:40,430
しだいに列の平均が変化したり

82
00:04:40,430 --> 00:04:42,330
分散が大きくなったりします

83
00:04:42,330 --> 00:04:44,510
これはトレーニング設定スキルと呼ばれ

84
00:04:44,510 --> 00:04:48,690
検出には継続的なデータ収集と
再検証が必要です

85
00:04:48,690 --> 00:04:51,540
TensorFlowをそのまま使うのは
苦痛かもしれません

86
00:04:51,540 --> 00:04:55,235
ドライバーをインストールして
適切なマシンを用意し

87
00:04:55,235 --> 00:04:58,175
前処理の順序やスケーリングパラメータを

88
00:04:58,175 --> 00:04:59,795
管理しなければなりません

89
00:04:59,795 --> 00:05:01,965
Google Cloudがここで役に立ちます

90
00:05:01,965 --> 00:05:04,155
ビッグデータサービスを提供しています

91
00:05:04,155 --> 00:05:09,350
今日は Cloud Machine Learning Engine（CMLE）
について説明します

92
00:05:09,350 --> 00:05:12,150
CMLEでは必要なときに
必要なマシンを利用できます

93
00:05:12,150 --> 00:05:14,060
コスト管理がシンプルになり

94
00:05:14,060 --> 00:05:17,405
トレーニングしたモデルを
予測時に実行できます

95
00:05:17,405 --> 00:05:22,385
高度にスケーラブルで
分散型トレーニングとサービスが簡単です

96
00:05:22,385 --> 00:05:27,015
CMLEは前処理を分散して
パラメータサーバーを立ち上げ

97
00:05:27,030 --> 00:05:28,980
ハイパーパラメータも調整します

98
00:05:28,980 --> 00:05:32,080
予測ではMLモデルにREST APIからアクセスでき

99
00:05:32,080 --> 00:05:35,610
特性の前処理や作成が
すべて組み込まれています

100
00:05:35,610 --> 00:05:38,850
クライアントのコードは
未加工の入力変数を指定するだけです

101
00:05:38,850 --> 00:05:44,480
ログファイル、センサー、データベースから
収集したものから予測が返ります

102
00:05:44,485 --> 00:05:48,465
CMLEはサービスを
必要な数のマシンにスケーリングして

103
00:05:48,465 --> 00:05:52,470
クエリ数/秒を向上させます これは重要です

104
00:05:52,470 --> 00:05:56,955
トレーニングと予測では
品質を高める必要があります

105
00:05:56,955 --> 00:06:00,270
TensorFlowモデルの計算コストは
比較的安価です

106
00:06:00,270 --> 00:06:05,125
MLモデルから多数の予測を生成できます

107
00:06:05,125 --> 00:06:09,285
Google Cloud Datalabのノートブックや
Kaggleカーネルは

108
00:06:09,285 --> 00:06:13,470
モデル開発をすぐに始める基盤に適しています

109
00:06:13,470 --> 00:06:16,140
ノートブックではデータを実際に操作して

110
00:06:16,140 --> 00:06:17,955
新しい特性を見つけて探索できます

111
00:06:17,955 --> 00:06:20,145
成長するジョブの大規模トレーニングも
可能です

112
00:06:20,145 --> 00:06:22,810
コード、結果、ドキュメントが

113
00:06:22,810 --> 00:06:25,315
すべて読みやすいインターフェースで
表示されます

114
00:06:25,315 --> 00:06:31,050
クラウド上なので共有や共同作業の
サポートもありチュートリアルも豊富です

115
00:06:31,065 --> 00:06:35,280
Datalabはすぐに開始でき さまざまな
Google Cloudサービスを利用した

116
00:06:35,280 --> 00:06:39,200
コンピューティングの
スケールアウトもスムーズです

117
00:06:39,240 --> 00:06:42,555
この例ではApache Beamジョブを

118
00:06:42,555 --> 00:06:47,490
データフローで起動していますが
多数のVMに分散できます