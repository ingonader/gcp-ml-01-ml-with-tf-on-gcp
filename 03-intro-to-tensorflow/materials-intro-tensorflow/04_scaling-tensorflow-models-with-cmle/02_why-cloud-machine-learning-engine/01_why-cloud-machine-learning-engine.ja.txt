この図は以前お見せしました TensorFlowは
さまざまなハードウェアで動作します このコースの演習では 低レベルC++ API
ではなく Python APIを使います 分散型トレーニング用の
抽象化レイヤはすでに確認しました 分散型トレーニングを
本番環境の規模で実行します そのためにCloud ML Engineを
導入します まず メモリに収まる
小さなデータセットから始めます このようなデータセットで 多くのMLフレームワークは充分です Pythonなどの言語には統計パッケージがあり 実行に必要なのは3～4行のコードです TensorFlow EstimatorのAPIは 小さなデータセットで
簡単によく機能する学習を決定できます ただし 実際に必要なのは本番環境の
エンタープライズサイズのデータセットです その大きさではメモリに収まりません だからパッケージをスケールアップして
高度にします データセットがメモリには大きすぎるので トレーニング中何度も繰り返す必要があります これは単一のマシンで可能ですが 理想的ではありません トレーニング結果を何週間も待てませんよね？ トレーニングは多数のマシンに
分散する必要がありました これは大量生産のように簡単ではありません 勾配降下法の最適化などのアルゴリズムは
簡単ではないのです いわゆる パラメータサーバーの助けを得て
トレーナーをサポートすべきです パラメータサーバーは共有メモリを構成して 各トレーナーを他から学習させます 分散型トレーニングを使わずに 必要なGPUのある巨大な単一マシンを
使いたくなるでしょう ほとんどの場合 これは近視眼的です 1台の機能では
データセットの成長に間に合いません 解決にはスケールアウトです データのサンプリングも短絡的な方法です データが小さいと
今のハードウェアでもMLできますが パフォーマンスの問題は解決していません 利用可能な全データを使い
10倍収集するプランを考え出せるかどうか それが 魔法のように動作するMLと
そうでないMLの違いです たいていMLモデルの構築は
未加工データでただトレーニングするより 人の分析でパフォーマンスを改善できます こうした分析を利用するのは
新たな特性での問題点を 専門家が知っている場合です この特性は未加工データの前処理後
すぐに追加します たとえばスケーリングや
コーディングをしたときです 本当に処理したいサイズのデータセットでは 分散とクラウド上の処理が必要です MLでは いくつか自分で決めることがあります ノードの数、埋め込み 畳み込み層のストライドサイズなどです モデルが複雑になると
値が正しいか迷ってきます 手動でも自動でも ハイパーパラメータを探索して もっとよい選択がないか
確認する必要があります 層の数やノードの数は
わかりやすいハイパーパラメータです ただしこのコースで学習しますが バケット数などの前処理の調整も ハイパーパラメータとして
扱うのがよいでしょう ここまではトレーニングについて説明しました トレーニング済みのモデルを
推測に使えるでしょうか？ 予測された特性が必要なアプリに 直接MLモデルを埋め込むのは
あまり良い方法とは言えません 良い方法はマイクロサービスで
モデルをラップして 他のマイクロサービスと通信することです 他のウェブアプリと同じです これでモデルの更新やAPテストで アプリのコアロジックを変えずにすみます マイクロサービスの変更だけです このモデルに適した量のハードウェアは
どうプロビジョニングしますか？ 優れたシステムは必要なときにマシンを追加して
自動スケーリングします クラウドならマシンをゼロ台から 膨大なクエリ/秒に適した数まで
スケーリングできます ここで今後の心痛の種を取り除きましょう トレーニングの前に行う
前処理について説明しました 注意してください 同じ前処理は予測のときにも必要です トレーニング済みモデルと予測モデルとの違いは 前処理以外にもたくさんあります Cloud Machine Learning Engineなら
この問題を減らせます ほとんど話題になりませんが 予測の入力は一般的に
トレーニングとシステム的に異なります しかも微妙で検出しにくいのです しだいに列の平均が変化したり 分散が大きくなったりします これはトレーニング設定スキルと呼ばれ 検出には継続的なデータ収集と
再検証が必要です TensorFlowをそのまま使うのは
苦痛かもしれません ドライバーをインストールして
適切なマシンを用意し 前処理の順序やスケーリングパラメータを 管理しなければなりません Google Cloudがここで役に立ちます ビッグデータサービスを提供しています 今日は Cloud Machine Learning Engine（CMLE）
について説明します CMLEでは必要なときに
必要なマシンを利用できます コスト管理がシンプルになり トレーニングしたモデルを
予測時に実行できます 高度にスケーラブルで
分散型トレーニングとサービスが簡単です CMLEは前処理を分散して
パラメータサーバーを立ち上げ ハイパーパラメータも調整します 予測ではMLモデルにREST APIからアクセスでき 特性の前処理や作成が
すべて組み込まれています クライアントのコードは
未加工の入力変数を指定するだけです ログファイル、センサー、データベースから
収集したものから予測が返ります CMLEはサービスを
必要な数のマシンにスケーリングして クエリ数/秒を向上させます これは重要です トレーニングと予測では
品質を高める必要があります TensorFlowモデルの計算コストは
比較的安価です MLモデルから多数の予測を生成できます Google Cloud Datalabのノートブックや
Kaggleカーネルは モデル開発をすぐに始める基盤に適しています ノートブックではデータを実際に操作して 新しい特性を見つけて探索できます 成長するジョブの大規模トレーニングも
可能です コード、結果、ドキュメントが すべて読みやすいインターフェースで
表示されます クラウド上なので共有や共同作業の
サポートもありチュートリアルも豊富です Datalabはすぐに開始でき さまざまな
Google Cloudサービスを利用した コンピューティングの
スケールアウトもスムーズです この例ではApache Beamジョブを データフローで起動していますが
多数のVMに分散できます