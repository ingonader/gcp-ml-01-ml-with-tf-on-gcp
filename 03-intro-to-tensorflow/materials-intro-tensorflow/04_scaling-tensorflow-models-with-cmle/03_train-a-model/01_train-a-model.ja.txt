ML Engineモデルのトレーニング方法を
確認しましょう トレーニングを始める前に次の点を
確認してください 1. トレーニングデータを収集して準備し 前処理された特性を
整理、分割、エンジニアリングします 2. CMLEからアクセスできる
Cloud Storageなどに トレーニングデータを入れます CMLEにトレーニングジョブを送信するとき 一般にはロジックを
ファイルtask.pyとmodel.pyに分割します task.pyはコードのエントリポイントで ジョブレベルの詳細を開始します コマンドライン引数の解析、実行時間 出力先 ハイパーパラメータ
調整インターフェースなどです コアML実行のため
task.pyはmodel.pyを呼び出します model.pyはコアMLのタスクを処理します データのフェッチ、特性の定義 実際のトレーニングと評価です コンピュータ間のコードの共有には
常にパッケージ化が必要です トレーニング用にモデルを
CMLEに送信する場合も同様です TensorFlowとPythonは特に このような標準化されたパッケージと
構造を要求します パッケージが正しく動くか
ローカルで簡単にテストしましょう Python -mで直接呼び出して 正しくインポートできたか確認しましょう 次にgcloudを使用して
コードのローカルテストをします パッケージ構造が正しいか
正常性チェックができます 大丈夫ならトレーニングジョブを送信して
クラウドにスケールアウトできます ここでコマンドラインに
package-pathでコードの場所を追加し module-nameで実行ファイルを指定します scale-tierにはコードを実行する
ハードウェアの種類を指定します BASICにすると1つのマシンで実行します STANDARDなら小さなクラスタで実行します BASIC_GPUなら単一GPUで動作します TPU上で実行したいときはBASIC_TPUにします カスタムの階層を指定して
各マシンタイプを定義できます スケール階層は拡張し続けます CMLEのドキュメントで
現在のオプションを確認してください プロのヒントをお伝えします MLジョブでパフォーマンスを最高にするには Google Cloud Storageで
単一リージョンのバケットを選択してください デフォルトはマルチリージョンですが これはMLのトレーニングより
ウェブサービスに適しています