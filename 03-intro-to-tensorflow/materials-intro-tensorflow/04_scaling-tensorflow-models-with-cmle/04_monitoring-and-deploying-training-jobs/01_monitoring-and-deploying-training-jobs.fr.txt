Prenons un petit instant pour parler
du contrôle des tâches. Lorsque vous soumettez une tâche
à exécuter dans CMLE, vous pouvez la contrôler 
de différentes manières. La plus simple est de regarder
son état actuel. Vous saurez alors
si elle est en attente, en cours d'exécution ou déjà terminée. Pendant l'exécution, vous pouvez
inspecter les entrées de journal les plus récentes
pour cette tâche, ce que vous pouvez
aussi faire avec G Cloud. Enfin, lorsque vous exécutez
plusieurs tâches en parallèle, vous pouvez essayer la fonction
de liste et de filtre de G Cloud. La console Web GCP est dotée d'une IU
efficace pour le contrôle de vos tâches. Vous pouvez voir exactement
comment elles sont appelées, vérifier les journaux, et voir combien
de CPU et de mémoire elles consomment. L'inspection des entrées de journaux
peut vous aider à déboguer des problèmes techniques comme
les exceptions. Mais ce n'est pas fait pour analyser
les performances du ML. TensorBoard est là pour ça. Pour l'utiliser, vérifiez que votre tâche
enregistre des données récapitulatives sur l'emplacement Google Cloud Storage. Lorsque vous lancez TensorBoard,
indiquez simplement ce répertoire. Vous pouvez même gérer
plusieurs tâches par dossier. Maintenant que nous avons un modèle,
voyons ce que nous pouvons en faire. Une fois la tâche d'entraînement terminée,
nous avons un modèle TensorFlow prêt pour les prédictions. CMLE propose une infrastructure
efficace pour cela. Il crée une application prête pour le Web
à partir de votre modèle entraîné, et offre un service par lots
pour vos prédictions les moins sensibles aux latences. Il s'agit d'API REST. Vous pouvez donc faire des inférences
sûres et évolutives dans le langage de votre choix. Pour envoyer votre artefact de modèle TF
sur le cloud, vous devez créer une ressource d'inversion de modèle CMLE. Votre fichier 
de modèle TF entraîné individuel correspond à une version spécifique. Sur CMLE, un modèle est un groupe
de ces versions qui possède aussi une version par défaut. Cette couche d'abstraction
et de regroupement supplémentaire permet de migrer le trafic d'une
version de modèle TF vers la suivante. Il suffit de changer la version
par défaut du modèle. Voici un exemple simple
d'utilisation du modèle déployé à distance pour effectuer des prédictions
avec un appel REST. La prédiction en ligne de CMLE
repose sur un système sans serveur. Vous n'avez pas à vous soucier
des allocations de ressources. Elles évoluent pour vous.