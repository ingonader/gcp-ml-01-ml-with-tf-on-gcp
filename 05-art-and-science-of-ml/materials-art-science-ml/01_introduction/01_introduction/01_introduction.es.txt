Soy Fereshteh,
arquitecta de soluciones de Google. Como especialista en macrodatos
y aprendizaje automático ayudo a las empresas
a compilar canalizaciones de datos a gran escala
con Google Cloud Platform. Cuando mis clientes ya tienen suficientes
datos empresariales en la nube los ayudo a usar el aprendizaje automático para descubrir patrones ocultos
y responder preguntas interesantes. Bienvenidos al quinto curso
de la especialización. Para comenzar,
resumamos rápidamente los temas anteriores. Si comenzaron el curso desde el principio recordarán que, en el primer curso,
analizamos la función esencial que cumple el aprendizaje automático
en Google y cómo lo usamos internamente. No hay problema
si no comenzaron por el principio. Es su aprendizaje y pueden realizarlo
como mejor les parezca. En el segundo curso,
hablamos del aprendizaje automático su historia y algunos conceptos básicos por ejemplo, la formulación de problemas
como modelos de aprendizaje automático la medición del rendimiento de los modelos la optimización del entrenamiento y la generalización de modelos
para que tengan buen rendimiento en datos no visibles,
entre otros. En el tercer curso, presentamos TensorFlow una biblioteca de código abierto
para procesamiento numérico. Con su arquitectura flexible,
se pueden implementar modelos de AA en todo tipo de hardware y, lo más importante,
distribuir el procesamiento entre decenas cientos o miles de nodos
para resolver todo tipo de problemas. En el cuarto curso,
hablamos de ingeniería de funciones. Revisamos trucos y sugerencias
para aplicar sus conocimientos sobre dominios
a fin de diseñar sus propias funciones. Y esto nos lleva al curso actual,
The Art and Science of Machine Learning. El curso tiene seis módulos. En el primero,
descubrirán qué aspectos del AA requieren intuición, buen juicio y experimentación. Esto se conoce como el arte del AA. Conoceremos los pormenores
del entrenamiento de modelos. Realizaremos varios ajustes manuales
y veremos cómo influyen en el rendimiento de un modelo. Cuando conozcan estos detalles también llamados hiperparámetros pasarán al segundo módulo,
en el que aprenderán a configurarlos de forma automática. En el tercer módulo,
aumentaremos la dificultad con un poco de ciencia,
que usaremos en el módulo cuatro a fin de aprender
cómo entrenar redes neuronales. En el módulo cinco,
conocerán las incorporaciones que permiten representar objetos discretos, como palabras, mediante vectores valiosos. Hasta el módulo seis, trabajaremos
con los estimadores prediseñados de TensorFlow,
como DNN Regressor. En el módulo seis,
analizaremos detalladamente cómo compilar estimadores personalizados. ¿Listos?
Comencemos.