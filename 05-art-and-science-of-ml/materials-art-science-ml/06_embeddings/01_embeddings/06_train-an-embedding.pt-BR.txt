Imagine que você está criando uma incorporação para representar a
palavra-chave de um anúncio imobiliário. Vamos ignorar como escolher
essa palavra por enquanto. As palavras de um anúncio
são de linguagem natural, então o dicionário
possível é enorme. Nesse caso, seriam todas
as palavras em inglês. Dezenas de milhares
de palavras. Mesmo se ignorarmos palavras
raras e jargões científicos. Obviamente, mesmo
se a primeira camada escolher uma palavra do
anúncio e a outra codificá-la, a representação na memória
será como um vetor esparso. Assim, o TensorFlow pode usar
a memória de modo eficiente. Depois de codificar
uma representação, ela é transferida por
uma camada de três nós. Essa é a incorporação. Como usamos três nós na camada,
é uma incorporação tridimensional. Veja que, mesmo
que a palavra esparsa e a palavra incorporada
sejam colunas de recursos, estou mostrando-as como
camadas da rede neural. Isso porque, matematicamente, elas
são como outras camadas mais novas. Matematicamente,
uma incorporação não é diferente de outra
camada oculta na rede. Você pode ver isso como um
adaptador útil que permite que a rede incorpore dados
esparsos ou categóricos. É essencial mostrar que você
pode fazer isso com um problema de regressão ou classificação. Os pesos em uma rede plural
são aprendidos pela retropropagação, assim como em outras camadas. Vamos usar a incorporação nas
palavras do anúncio imobiliário como uma das entradas do modelo
que prevê o preço de venda. Podemos treinar o modelo com base
no preço histórico real de casas. Além da palavra usada no anúncio,
podemos usar o número de cômodos, número de quartos,
etc., como entradas. Esse é um problema de
regressão de dados estruturados. Assim como o problema do táxi. Viu o que acontece se você tentar
otimizar o peso de todas as camadas para minimizar os erros no
preço de venda previsto? Todos os pesos das camadas
precisam ser ajustados. Os pesos são ajustados de maneira
que os números incorporados a uma palavra
se tornem relevantes para a capacidade de
prever o preço de venda. Talvez se o anúncio incluir
palavras como vista ou lago, o preço seja maior, enquanto que uma palavra
como hipoteca abaixe o preço. O peso das camadas é
ajustado para aprender isso. Matematicamente, uma
incorporação não é diferente de outra camada
oculta na rede. Você pode ver isso
como um adaptador útil que permite que
uma rede incorpore dados esparsos ou categóricos. Os pesos de uma rede neural profunda
são aprendidos com a retropropagação, assim como em outras camadas. E você pode usar um
problema de regressão ou de classificação. Lembre-se de algo crucial sobre
a primeira camada, a azul. Ao contrário dos nós amarelos,
a camada azul não é codificada. Se você usar a palavra vista,
só um desses nós será ativado. Digamos que seja
este, em preto. Então, o peso dos links desse
nó preto para a próxima camada capturarão a relevância
da palavra para o problema. Assim, cada palavra é
representada por três números. Cada um dos três nós pode
ser considerado uma dimensão em que as palavras
são projetadas. Os pesos de borda
entre um filme e uma camada oculta
são os valores coordenados nessa projeção
de dimensão inferior.