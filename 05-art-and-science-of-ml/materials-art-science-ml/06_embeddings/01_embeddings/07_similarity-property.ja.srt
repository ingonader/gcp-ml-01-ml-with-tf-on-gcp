1
00:00:00,000 --> 00:00:04,229
埋め込みの説明はまず
映画IDの話から始めましたが

2
00:00:04,229 --> 00:00:06,960
映画IDはカテゴリ特徴です

3
00:00:06,960 --> 00:00:10,430
次に同じ例を広告の単語に
適用しましたが

4
00:00:10,430 --> 00:00:13,320
あれはテキスト特徴になります

5
00:00:13,320 --> 00:00:15,475
共通点は何でしょうか

6
00:00:15,475 --> 00:00:19,315
埋め込みはカテゴリやテキストの
特徴のみではなく

7
00:00:19,315 --> 00:00:21,590
もっと多くの用途があります

8
00:00:21,590 --> 00:00:26,295
これはMNISTと呼ばれる
機械学習の典型的な問題の例です

9
00:00:26,295 --> 00:00:31,940
スキャンされた手書きの数字を
認識するものですが

10
00:00:31,940 --> 00:00:37,850
それぞれの画像に含まれる
各ピクセルが入力情報になります

11
00:00:37,850 --> 00:00:41,350
これが生ビットマップというものです

12
00:00:41,350 --> 00:00:44,350
この画像は28x28なので

13
00:00:44,350 --> 00:00:49,060
このビットマップには784の
ピクセルが含まれています

14
00:00:49,060 --> 00:00:53,800
ですので784の数値の
配列を考えてみましょう

15
00:00:53,800 --> 00:00:58,355
配列の大半は
空白のピクセルに対応します

16
00:00:58,355 --> 00:01:02,180
ここでも埋め込みが有用になります

17
00:01:02,180 --> 00:01:08,530
784の数値を
疎テンソルとして表すのです

18
00:01:08,530 --> 00:01:14,505
基本的に手書きの数字が現れている
ピクセルのみを保存します

19
00:01:14,505 --> 00:01:18,800
数字が黒いピクセルのみを保存し

20
00:01:18,800 --> 00:01:23,160
それを3D埋め込みに渡します

21
00:01:23,160 --> 00:01:27,195
これで通常の2層の
ニューラルネットワークができるため

22
00:01:27,195 --> 00:01:30,555
必要に応じて
他の特徴を渡し

23
00:01:30,555 --> 00:01:35,005
次にそうしたラベルに基づいて
画像の実際の数字を予測するよう

24
00:01:35,005 --> 00:01:37,800
モデルをトレーニングします

25
00:01:37,800 --> 00:01:41,010
なぜここにロジット層が
あるかというと

26
00:01:41,010 --> 00:01:45,322
これらがニューラルネットワークの
出力層を形成するからです

27
00:01:45,322 --> 00:01:50,630
分類の問題では
出力はロジットでなければなりません

28
00:01:50,630 --> 00:01:55,365
線形分類器または
DNN分類器を使用する場合

29
00:01:55,365 --> 00:02:00,390
出力層は単一のロジットになります

30
00:02:00,390 --> 00:02:03,575
ただしそれは
出力が1つの場合だけです

31
00:02:03,575 --> 00:02:05,760
MNISTの問題では

32
00:02:05,760 --> 00:02:08,195
合計10のクラスがあります

33
00:02:08,195 --> 00:02:12,340
つまり0から1、2、…
9までの数字です

34
00:02:12,340 --> 00:02:15,619
そのため1つのロジットではなく

35
00:02:15,619 --> 00:02:18,330
ロジット層があることになります

36
00:02:18,330 --> 00:02:22,435
可能なそれぞれの数字について
1つのロジットがあるからです

37
00:02:22,435 --> 00:02:26,750
単一のロジットでなく
ロジット層がある場合

38
00:02:26,750 --> 00:02:33,440
すべての数字の確率の合計が
1になるという保証はありません

39
00:02:33,440 --> 00:02:36,375
これがSoftmaxの役割になります

40
00:02:36,375 --> 00:02:41,640
Softmaxは個々のロジットを正規化し
確率の合計が1になるようにします

41
00:02:41,640 --> 00:02:45,665
すみません 話が逸れました
埋め込みの話でしたね

42
00:02:45,665 --> 00:02:50,655
次に手書き文字を認識するよう
モデルをトレーニングします

43
00:02:50,655 --> 00:02:54,780
それぞれの画像は
3つの数値で表されます

44
00:02:54,780 --> 00:02:58,055
ただしカテゴリの場合と違い

45
00:02:58,055 --> 00:03:02,560
生ビットマップは
ワンホットエンコードされていません

46
00:03:02,560 --> 00:03:05,970
そのため個々のピクセルに
3つの数値はありません

47
00:03:05,970 --> 00:03:08,170
代わりに3つの数値は

48
00:03:08,170 --> 00:03:14,265
特定の画像で表示される
すべてのピクセルに対応しています

49
00:03:14,265 --> 00:03:18,600
TensorBoardではこうした埋め込みを
可視化できます

50
00:03:18,600 --> 00:03:24,250
784のピクセルそれぞれに対応する
3Dベクトルが可視化されます

51
00:03:24,250 --> 00:03:28,575
ここではラベルにそれぞれ異なる
色を割り当てていますので

52
00:03:28,575 --> 00:03:32,965
ご覧のとおり素晴らしい表示を
得ることができます

53
00:03:32,965 --> 00:03:40,730
3D空間内ですべての5、すべての7、
すべての0が集まっています

54
00:03:40,730 --> 00:03:46,565
言い換えればそれぞれの
手書き画像を表す3D数値が

55
00:03:46,565 --> 00:03:52,540
3D空間内で類似のアイテム同士が
近くなるように表示されています

56
00:03:52,540 --> 00:03:56,205
これはカテゴリ変数や
自然言語テキスト

57
00:03:56,205 --> 00:04:00,200
そして生ビットマップの
埋め込みでも同様です

58
00:04:00,200 --> 00:04:02,400
これらすべての共通点は

59
00:04:02,400 --> 00:04:04,660
みな疎だということです

60
00:04:04,660 --> 00:04:08,720
疎ベクトルのエンコーディングを
埋め込み列に渡し

61
00:04:08,720 --> 00:04:12,970
その埋め込み列を
DNNへの入力として使用して

62
00:04:12,970 --> 00:04:15,920
そのDNNをトレーニングすると

63
00:04:15,920 --> 00:04:20,760
トレーニングされた埋め込みは
この類似特性を持つことになります

64
00:04:20,760 --> 00:04:24,425
ただしそれはもちろん
データの量が十分であり

65
00:04:24,425 --> 00:04:28,445
トレーニングで良好な精度が
実現された場合です

66
00:04:28,445 --> 00:04:33,605
この類似特性は
他の状況でも活用できます

67
00:04:33,605 --> 00:04:40,225
たとえばこの曲と似た曲を
探す必要があるとします

68
00:04:40,225 --> 00:04:46,160
この場合 曲に関連する音声の
埋め込みを作成することができます

69
00:04:46,160 --> 00:04:52,005
まず音声クリップを探し
それを値の配列として表します

70
00:04:52,005 --> 00:04:55,320
次にMNIST画像の例と同様に

71
00:04:55,320 --> 00:04:59,040
その配列を埋め込み層に渡します

72
00:04:59,040 --> 00:05:04,100
それを使用して
妥当な機械学習の問題をトレーニングします

73
00:05:04,100 --> 00:05:08,940
たとえば音声信号を使用して
音楽のジャンルや次の音符を予測するよう

74
00:05:08,940 --> 00:05:12,530
モデルをトレーニングすることができます

75
00:05:12,530 --> 00:05:15,425
何を予測するようトレーニングするにしても

76
00:05:15,425 --> 00:05:21,265
埋め込みを利用すれば音声クリップの
低次元表現を得ることができます

77
00:05:21,265 --> 00:05:24,240
似たような曲を探すには

78
00:05:24,240 --> 00:05:28,790
単に2つのクリップ間
すなわちそれらの埋め込みの間の

79
00:05:28,790 --> 00:05:34,710
ユークリッド距離を計算すれば
それが2つの曲の類似性の尺度になります

80
00:05:34,710 --> 00:05:38,700
また埋め込みベクトルを
クラスタリングアルゴリズムへの

81
00:05:38,700 --> 00:05:41,940
入力として使用することもできます

82
00:05:41,940 --> 00:05:48,140
この類似性の概念は多様な特徴を
まとめて埋め込む際にも利用できます

83
00:05:48,140 --> 00:05:52,980
たとえば2種類の言語またはテキストと
それに対応する音声を使用して

84
00:05:52,980 --> 00:05:56,810
それらの類似性を定義することができます

85
00:05:56,810 --> 00:05:59,320
これら4つの例ではすべて

86
00:05:59,320 --> 00:06:02,630
埋め込みの数として3を使用しましたが

87
00:06:02,630 --> 00:06:05,680
もちろん別の数も使用できます

88
00:06:05,680 --> 00:06:08,685
しかしどんな数がよいでしょうか

89
00:06:08,685 --> 00:06:13,685
埋め込みの数は機械学習モデルの
ハイパーパラメータです

90
00:06:13,685 --> 00:06:17,970
さまざまな数の埋め込み次元を
試してみる必要があります

91
00:06:17,970 --> 00:06:20,455
トレードオフもあるからです

92
00:06:20,455 --> 00:06:27,480
高次元の埋め込みは入力値同士の関係を
より正確に表すことができますが

93
00:06:27,480 --> 00:06:33,520
次元の数が増えるほど
過学習の可能性も高まります

94
00:06:33,520 --> 00:06:38,405
またモデルも大きくなるため
トレーニングの時間も長くなります

95
00:06:38,405 --> 00:06:41,600
手始めとして有効なのは

96
00:06:41,600 --> 00:06:46,405
可能な値の総数の
4乗根を使用することです

97
00:06:46,405 --> 00:06:52,970
たとえば映画IDを埋め込むとして
カタログには50万件の映画があるため

98
00:06:52,970 --> 00:06:57,045
可能な値の総数は
50万だとします

99
00:06:57,045 --> 00:07:02,745
この場合手始めとして
50万の4乗根を使用します

100
00:07:02,745 --> 00:07:06,564
50万の平方根はおよそ700で

101
00:07:06,564 --> 00:07:09,885
700の平方根は約26です

102
00:07:09,885 --> 00:07:14,385
ですので25くらいから始めるとよいでしょう

103
00:07:14,385 --> 00:07:19,360
埋め込み次元の
ハイパーパラメータ調整を行う場合なら

104
00:07:19,360 --> 00:07:24,005
15から35くらいの
探索空間を指定するとよいでしょう

105
00:07:24,005 --> 00:07:26,850
もちろんこれは単なる目安です