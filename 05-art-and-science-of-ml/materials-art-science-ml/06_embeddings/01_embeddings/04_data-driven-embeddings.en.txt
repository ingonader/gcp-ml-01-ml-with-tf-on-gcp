In the previous lesson, we talked about creating embeddings manually using rules. We used attributes like the average age of the viewer, and the total ticket sales to take our movies which would have been in a 500,000 dimensional space, and project them into a two dimensional space. In the case of our two dimensional embedding, we gave our axis names like age, and ticket sold, children versus adult, arthouse versus blockbuster. However, it's not essential that these axis have names. What is important is that we went from 500,000 to two. Note that we did it by looking at attributes of the movies man manually. What is the impact of doing the dimensionality reduction from 500,000 to two? The 2D embedding that we have for each movie is associated with two real values, and so you can represent each movie by pointing 2D space. Why should we do this embedding? One key reason is this, let's say we are training a model to predict whether some user will like a movie. It is easier to train a model that has D inputs, than it is to train a model that has N input. Remember that N is much much larger than D.The fewer the number of input nodes, the fewer the weights that we have to optimize. This means that the model trains faster, and has less chance of overfitting. Embedding is a way of making the problem simpler. However, we have to do this dimensionality reduction in a way that we don't lose information. How could we come up with an appropriate embedding? You can learn embedding from the data as part of your normal training process. No separate training process is needed. First, take the original input, and represent the input as a one heart encoded array. Then, send it through an embedding layer. In this approach, the embedding layer is just a hidden layer with one unit per dimension. Because we're training a model with labels, the embedding get changed based on these labels. Intuitively, the hidden units discover how to organize the items in the D dimensional space in a way, so as to best optimize a final objective. There is a small problem though. How much memory is required to store the inputs? You have a categorical input variable, but 500,000 possible values. So you have to create 500,000 input nodes, and do matrix math of huge matrices.