Na lição passada, falamos sobre como criar
embeddings manualmente com regras. Usamos atributos como
a idade do espectador e as vendas de ingressos para projetar nossos filmes
que teriam 500 mil dimensões em um espaço bidimensional. No caso do embedding
bidimensional, demos aos eixos
nomes como idade e ingressos vendidos, criança
versus adulto, arte versus bilheteria. No entanto, não é essencial
que eles tenham nomes. O mais importante é que
passamos de 500 mil para dois. Para isso, vimos os atributos
dos filmes manualmente. Qual o impacto de reduzir as
dimensões de 500 mil para duas? O embedding em 2D para cada filme
está associado a dois valores reais e você pode representar cada filme
nesse espaço bidimensional. Por que fazer
esse embedding? Um motivo principal é este: digamos que estamos
treinando um modelo para prever se um usuário
gostará de um filme. É mais fácil treinar um
modelo com D entradas que um com N entradas. Lembre-se que N
é muito maior que D. Quanto menor o número
de nós de entrada, menos pesos
precisamos otimizar. Isso significa que o modelo
é treinado mais rapidamente e as chances de
sobreajuste são menores. O embedding
facilita o problema. No entanto, precisamos fazer essa redução de modo
a não perder informações. Como criar um
embedding adequado? Você pode aprender
o embedding dos dados como parte do processo
de treinamento. Não é preciso ter
um processo separado. Primeiro, veja
a entrada original e represente-a como
uma matriz codificada. Em seguida, envie-a por
uma camada de embedding. Nessa abordagem, a camada de
embedding é uma camada oculta com uma unidade por dimensão. Como estamos treinando
um modelo com rótulos, o embedding muda
com base nesses rótulos. Intuitivamente, as unidades
ocultas descobrem como organizar os
itens nas D dimensões para otimizar para
um objetivo final. Há um pequeno problema. Quanta memória é necessária
para armazenar a entrada? Você tem uma variável
de entrada categórica, mas 500 mil valores possíveis. Por isso, precisa criar
500 mil nós de entrada e fazer um cálculo
com matrizes enormes.