Bienvenue à tous pour cette nouvelle vidéo. Je m'appelle Lak et je dirige l'équipe chargée
de l'organisation de cette spécialisation. Dans ce module,
nous allons revoir un concept important : les représentations
vectorielles continues (RVC). Dans ce cours, nous voyons diverses choses dont tous ceux qui font du machine learning
doivent disposer dans leur boîte à outils. Nous nous intéressons
aux techniques de machine learning. Voyons maintenant en détail quels sont les avantages
des représentations vectorielles continues. Dans ce module, vous allez apprendre à utiliser les RVC
afin de gérer des données creuses pour que les modèles de machine learning
qui utilisent des données creuses consomment moins de mémoire
et s'entraînent plus rapidement. Les RVC constituent aussi une façon
d'effectuer une réduction des dimensions et, en ce sens, rendent les modèles
plus simples et plus généralisables. Nous allons donc utiliser les RVC comme façon de réduire les dimensions
des entrées problématiques et de généraliser davantage le modèle. Les représentations vectorielles
continues sont également utiles si l'on veut procéder
à un clustering des observations. Mais le domaine d'application des RVC
ne se limite pas à un modèle de ML unique. Elles fonctionnent souvent mieux lorsque l'on envisage des familles
de modèles de machine learning. La représentation vectorielle continue
créée pour un modèle peut être utilisée pour accélérer la création
d'un autre modèle de la même famille. Vous apprendrez donc
à créer des RVC réutilisables. Les RVC sont si utiles
que le fait d'en créer une peut être vu comme un problème
de machine learning à part entière. Vous pouvez avoir une équipe chargée
de gérer des RVC particulièrement importantes largement utilisées dans une entreprise. Vous pouvez voir une bonne RVC réutilisable
comme une bibliothèque de logiciels. Les RVC sont si utiles
qu'il peut être pratique de les visualiser. C'est possible grâce à TensorBoard.