埋め込みの説明はまず
映画IDの話から始めましたが 映画IDはカテゴリ特徴です 次に同じ例を広告の単語に
適用しましたが あれはテキスト特徴になります 共通点は何でしょうか 埋め込みはカテゴリやテキストの
特徴のみではなく もっと多くの用途があります これはMNISTと呼ばれる
機械学習の典型的な問題の例です スキャンされた手書きの数字を
認識するものですが それぞれの画像に含まれる
各ピクセルが入力情報になります これが生ビットマップというものです この画像は28x28なので このビットマップには784の
ピクセルが含まれています ですので784の数値の
配列を考えてみましょう 配列の大半は
空白のピクセルに対応します ここでも埋め込みが有用になります 784の数値を
疎テンソルとして表すのです 基本的に手書きの数字が現れている
ピクセルのみを保存します 数字が黒いピクセルのみを保存し それを3D埋め込みに渡します これで通常の2層の
ニューラルネットワークができるため 必要に応じて
他の特徴を渡し 次にそうしたラベルに基づいて
画像の実際の数字を予測するよう モデルをトレーニングします なぜここにロジット層が
あるかというと これらがニューラルネットワークの
出力層を形成するからです 分類の問題では
出力はロジットでなければなりません 線形分類器または
DNN分類器を使用する場合 出力層は単一のロジットになります ただしそれは
出力が1つの場合だけです MNISTの問題では 合計10のクラスがあります つまり0から1、2、…
9までの数字です そのため1つのロジットではなく ロジット層があることになります 可能なそれぞれの数字について
1つのロジットがあるからです 単一のロジットでなく
ロジット層がある場合 すべての数字の確率の合計が
1になるという保証はありません これがSoftmaxの役割になります Softmaxは個々のロジットを正規化し
確率の合計が1になるようにします すみません 話が逸れました
埋め込みの話でしたね 次に手書き文字を認識するよう
モデルをトレーニングします それぞれの画像は
3つの数値で表されます ただしカテゴリの場合と違い 生ビットマップは
ワンホットエンコードされていません そのため個々のピクセルに
3つの数値はありません 代わりに3つの数値は 特定の画像で表示される
すべてのピクセルに対応しています TensorBoardではこうした埋め込みを
可視化できます 784のピクセルそれぞれに対応する
3Dベクトルが可視化されます ここではラベルにそれぞれ異なる
色を割り当てていますので ご覧のとおり素晴らしい表示を
得ることができます 3D空間内ですべての5、すべての7、
すべての0が集まっています 言い換えればそれぞれの
手書き画像を表す3D数値が 3D空間内で類似のアイテム同士が
近くなるように表示されています これはカテゴリ変数や
自然言語テキスト そして生ビットマップの
埋め込みでも同様です これらすべての共通点は みな疎だということです 疎ベクトルのエンコーディングを
埋め込み列に渡し その埋め込み列を
DNNへの入力として使用して そのDNNをトレーニングすると トレーニングされた埋め込みは
この類似特性を持つことになります ただしそれはもちろん
データの量が十分であり トレーニングで良好な精度が
実現された場合です この類似特性は
他の状況でも活用できます たとえばこの曲と似た曲を
探す必要があるとします この場合 曲に関連する音声の
埋め込みを作成することができます まず音声クリップを探し
それを値の配列として表します 次にMNIST画像の例と同様に その配列を埋め込み層に渡します それを使用して
妥当な機械学習の問題をトレーニングします たとえば音声信号を使用して
音楽のジャンルや次の音符を予測するよう モデルをトレーニングすることができます 何を予測するようトレーニングするにしても 埋め込みを利用すれば音声クリップの
低次元表現を得ることができます 似たような曲を探すには 単に2つのクリップ間
すなわちそれらの埋め込みの間の ユークリッド距離を計算すれば
それが2つの曲の類似性の尺度になります また埋め込みベクトルを
クラスタリングアルゴリズムへの 入力として使用することもできます この類似性の概念は多様な特徴を
まとめて埋め込む際にも利用できます たとえば2種類の言語またはテキストと
それに対応する音声を使用して それらの類似性を定義することができます これら4つの例ではすべて 埋め込みの数として3を使用しましたが もちろん別の数も使用できます しかしどんな数がよいでしょうか 埋め込みの数は機械学習モデルの
ハイパーパラメータです さまざまな数の埋め込み次元を
試してみる必要があります トレードオフもあるからです 高次元の埋め込みは入力値同士の関係を
より正確に表すことができますが 次元の数が増えるほど
過学習の可能性も高まります またモデルも大きくなるため
トレーニングの時間も長くなります 手始めとして有効なのは 可能な値の総数の
4乗根を使用することです たとえば映画IDを埋め込むとして
カタログには50万件の映画があるため 可能な値の総数は
50万だとします この場合手始めとして
50万の4乗根を使用します 50万の平方根はおよそ700で 700の平方根は約26です ですので25くらいから始めるとよいでしょう 埋め込み次元の
ハイパーパラメータ調整を行う場合なら 15から35くらいの
探索空間を指定するとよいでしょう もちろんこれは単なる目安です