1
00:00:00,000 --> 00:00:03,557
Vous avez rapidement vu les représentations
vectorielles continues (RVC)

2
00:00:03,557 --> 00:00:07,345
avec les croisements de caractéristiques
dans le cours précédent,

3
00:00:07,345 --> 00:00:11,000
mais les RVC sont partout
dans le machine learning moderne

4
00:00:11,000 --> 00:00:13,950
et ne se limitent pas
aux croisements de caractéristiques,

5
00:00:13,950 --> 00:00:16,140
ni même aux données structurées.

6
00:00:16,140 --> 00:00:19,110
Vous les utiliserez en effet un peu

7
00:00:19,110 --> 00:00:22,830
dans les modèles d'images
et les modèles de textes.

8
00:00:22,830 --> 00:00:27,985
Je récapitule rapidement ce que vous savez
des représentations vectorielles continues.

9
00:00:27,985 --> 00:00:31,030
Il a été question de la possibilité
de création d'un modèle de ML

10
00:00:31,030 --> 00:00:34,355
permettant d'établir
des prédictions concernant le trafic

11
00:00:34,355 --> 00:00:39,490
(par exemple, le temps avant que le véhicule
suivant n'arrive à une intersection).

12
00:00:39,490 --> 00:00:42,560
Il y avait un certain nombre
d'entrées dans notre modèle,

13
00:00:42,560 --> 00:00:46,495
et notamment des entrées catégorielles
(heure du jour et jour de la semaine)

14
00:00:46,495 --> 00:00:49,085
dont il a plus particulièrement été question.

15
00:00:49,085 --> 00:00:49,790
Il a été dit

16
00:00:49,790 --> 00:00:52,635
que le modèle de machine learning
serait nettement amélioré

17
00:00:52,635 --> 00:00:56,565
si, au lieu de traiter l'heure du jour
et le jour de la semaine

18
00:00:56,565 --> 00:00:59,055
comme des entrées indépendantes,

19
00:00:59,055 --> 00:01:03,690
nous les concaténions pour créer
un croisement de caractéristiques.

20
00:01:03,690 --> 00:01:07,077
Il a été dit que, si nous procédions
à ce croisement de caractéristiques

21
00:01:07,077 --> 00:01:09,490
en utilisant un grand nombre
de buckets de hachage,

22
00:01:09,490 --> 00:01:14,475
chacun des buckets
ne contiendrait très probablement

23
00:01:14,475 --> 00:01:18,430
qu'une seule combinaison heure/jour.

24
00:01:18,430 --> 00:01:23,170
C'est à ce stade que les représentations
vectorielles continues sont intervenues.

25
00:01:23,170 --> 00:01:27,047
Il a été indiqué que, plutôt que
de procéder à un encodage one-hot

26
00:01:27,047 --> 00:01:28,615
du croisement de caractéristiques

27
00:01:28,615 --> 00:01:30,850
et de l'utiliser tel quel,

28
00:01:30,850 --> 00:01:33,917
il était possible de le transmettre
à une couche dense,

29
00:01:33,917 --> 00:01:38,215
puis d'entraîner le modèle pour qu'il prédise
le trafic comme précédemment.

30
00:01:38,215 --> 00:01:43,297
Cette couche dense, représentée
par les nœuds jaune et vert,

31
00:01:43,297 --> 00:01:45,440
crée une représentation vectorielle continue.

32
00:01:45,440 --> 00:01:49,145
Les représentations vectorielles continues
sont des nombres réels,

33
00:01:49,145 --> 00:01:53,940
car elles sont une somme pondérée
des valeurs du croisement de caractéristiques.

34
00:01:53,940 --> 00:01:55,475
Il est important de réaliser

35
00:01:55,475 --> 00:01:59,050
que les pondérations de la couche
de la représentation vectorielle continue

36
00:01:59,050 --> 00:02:02,720
(les nœuds jaune et vert)

37
00:02:02,720 --> 00:02:05,580
sont apprises à partir des données.

38
00:02:05,580 --> 00:02:10,664
Il se trouve que le fait d'entraîner
ces pondérations avec un ensemble de données

39
00:02:10,664 --> 00:02:13,404
pour résoudre un problème utile

40
00:02:13,404 --> 00:02:16,194
a un effet positif.

41
00:02:16,194 --> 00:02:22,270
Le croisement de caractéristiques
jour/heure a 168 valeurs uniques,

42
00:02:22,270 --> 00:02:23,890
mais nous en forçons le traitement

43
00:02:23,890 --> 00:02:28,835
pour qu'il soit simplement
représenté par deux nombres réels.

44
00:02:28,835 --> 00:02:34,470
Le modèle apprend donc à représenter
le croisement de caractéristiques

45
00:02:34,470 --> 00:02:37,335
dans un espace dimensionnel réduit.

46
00:02:37,335 --> 00:02:41,322
Il a été suggéré que le nœud vert
pourrait avoir plutôt tendance

47
00:02:41,322 --> 00:02:43,570
à capturer le trafic de piétons,

48
00:02:43,570 --> 00:02:47,150
et le nœud jaune plutôt le trafic automobile.

49
00:02:47,150 --> 00:02:52,110
Mais ce que capturent exactement
ces deux dimensions est sans importance.

50
00:02:52,110 --> 00:02:53,970
La chose importante est

51
00:02:53,970 --> 00:02:58,285
que toutes les informations relatives
à l'heure du jour et au jour de la semaine

52
00:02:58,285 --> 00:03:02,240
ayant trait au trafic au niveau
des intersections d'une ville

53
00:03:02,240 --> 00:03:06,759
sont converties pour ne plus
consister qu'en deux nombres.

54
00:03:06,759 --> 00:03:11,265
Si l'on fait cela pour un ensemble de données
suffisamment grand et de qualité suffisante,

55
00:03:11,265 --> 00:03:16,780
ces nombres ont une propriété très utile :

56
00:03:16,780 --> 00:03:20,915
les heures similaires en termes de trafic
sont mises en correspondance

57
00:03:20,915 --> 00:03:23,490
avec des nombres réels proches,

58
00:03:23,490 --> 00:03:26,870
tandis que les heures
différentes en termes de trafic

59
00:03:26,870 --> 00:03:30,905
sont mises en correspondance
avec des nombres réels différents.

60
00:03:30,905 --> 00:03:32,095
Il a ensuite été question

61
00:03:32,095 --> 00:03:35,165
du mode de création
d'une RVC dans TensorFlow.

62
00:03:35,165 --> 00:03:36,720
Pour créer une RVC,

63
00:03:36,720 --> 00:03:41,020
utilisez la méthode embedding_column
dans tf.feature_column

64
00:03:41,020 --> 00:03:46,000
et transmettez la colonne catégorielle
que vous voulez représenter.

65
00:03:46,000 --> 00:03:49,395
Cela fonctionne avec
n'importe quelle colonne catégorielle,

66
00:03:49,395 --> 00:03:52,250
et pas seulement
avec un croisement de caractéristiques.

67
00:03:52,250 --> 00:03:57,705
Vous pouvez utiliser embedding_column
pour n'importe quelle colonne catégorielle.

68
00:03:57,705 --> 00:04:01,012
Enfin, nous avons vu rapidement

69
00:04:01,012 --> 00:04:05,030
comment vous pourriez récupérer
les RVC apprises pour un problème

70
00:04:05,030 --> 00:04:09,940
afin de les appliquer à un problème
de machine learning similaire.

71
00:04:09,940 --> 00:04:11,182
Vous pourriez avoir appris

72
00:04:11,182 --> 00:04:16,325
à représenter l'heure du jour et le jour
de la semaine avec deux nombres réels

73
00:04:16,325 --> 00:04:19,645
en entraînant votre modèle
avec des données de trafic de Londres.

74
00:04:19,645 --> 00:04:23,102
Afin de gagner du temps, vous pourriez
utiliser les mêmes pondérations

75
00:04:23,102 --> 00:04:26,680
pour accélérer
la création du modèle de Francfort.

76
00:04:26,680 --> 00:04:31,870
Vous pourriez peut-être même utiliser
la RVC apprise avec le problème de trafic

77
00:04:31,870 --> 00:04:35,050
pour prédire le niveau d'audience
d'une émission de télévision.

78
00:04:35,050 --> 00:04:40,270
L'idée est que le trafic
et le niveau d'audience

79
00:04:40,270 --> 00:04:44,715
dépendent l'un comme l'autre
d'un même facteur latent :

80
00:04:44,715 --> 00:04:48,560
les habitants de la ville sont-ils
en déplacement, chez eux

81
00:04:48,560 --> 00:04:50,275
ou sur leur lieu de travail ?

82
00:04:50,275 --> 00:04:52,417
L'apprentissage par transfert
peut fonctionner

83
00:04:52,417 --> 00:04:55,079
avec des problèmes
apparemment très différents

84
00:04:55,079 --> 00:05:00,399
dès lors que ceux-ci ont
les mêmes facteurs latents.