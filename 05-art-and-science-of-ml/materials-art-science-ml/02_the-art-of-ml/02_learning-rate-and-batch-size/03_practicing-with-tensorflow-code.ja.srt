1
00:00:00,200 --> 00:00:03,345
さまざまな設定を見てきましたが

2
00:00:03,345 --> 00:00:05,639
TensorFlowコードでは
どのように表示されるのでしょう

3
00:00:05,639 --> 00:00:07,886
サンプルコードを詳しく見てみましょう

4
00:00:07,886 --> 00:00:11,840
入力関数でバッチサイズを制御します

5
00:00:11,840 --> 00:00:17,928
学習率はoptimizerアルゴリズム
FtrlOptimizerのパラメータです

6
00:00:17,928 --> 00:00:24,258
正則化率もoptimizerアルゴリズムの
パラメータです

7
00:00:24,258 --> 00:00:28,782
定義したoptimizerを
estimatorオブジェクトに渡します

8
00:00:28,782 --> 00:00:33,232
この場合 線形回帰クラスの
インスタンスです

9
00:00:33,232 --> 00:00:37,140
エポック数設定の代わりに
ステップ数定義が必要です

10
00:00:37,140 --> 00:00:42,060
エポック数が分散トレーニングでは
障害に強くないからです

11
00:00:42,060 --> 00:00:46,670
ステップ数はバッチサイズと
学習率に応じて調整します

12
00:00:46,670 --> 00:00:52,890
たとえば100回のエポックで
1,000個のサンプルを処理したい場合

13
00:00:52,890 --> 00:00:57,320
バッチサイズ1,000に対して
ステップ数100です

14
00:00:57,320 --> 00:01:01,770
バッチサイズ100に対しては
ステップ数1,000です

15
00:01:01,770 --> 00:01:08,580
基本的にステップ数の算出方法は
エポック数×サンプル数÷バッチサイズ です

16
00:01:08,580 --> 00:01:13,960
学習率を下げる場合は エポック数を増やした
トレーニングが必要です