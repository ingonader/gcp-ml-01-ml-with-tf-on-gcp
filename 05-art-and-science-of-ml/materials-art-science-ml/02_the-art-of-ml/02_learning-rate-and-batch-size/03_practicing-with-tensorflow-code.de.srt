1
00:00:00,200 --> 00:00:02,965
Wir kennen nun eine Menge Parameter,

2
00:00:02,965 --> 00:00:05,419
aber wie legen wir
sie im TensorFlow-Code fest?

3
00:00:05,419 --> 00:00:07,526
Sehen wir uns den Beispielcode näher an.

4
00:00:07,526 --> 00:00:11,640
Wir steuern die Batchgröße,
wir haben eine Eingabefunktion.

5
00:00:11,640 --> 00:00:17,520
Die Lernrate ist ein Parameter
des Optimierungsalgorithmus FtrlOptimizer.

6
00:00:18,670 --> 00:00:23,748
Auch die Regularisierungsrate ist
ein Parameter des Optimierungsalgorithmus.

7
00:00:23,748 --> 00:00:28,110
Nachdem der Optimierer definiert wurde,
übergeben wir ihn an das Estimator-Objekt.

8
00:00:28,110 --> 00:00:32,390
Hier ist das eine Instanz
der Klasse LinearRegressor der Estimators.

9
00:00:33,142 --> 00:00:36,890
Sie legen keine Epochenanzahl fest,
sondern definieren die Anzahl der Schritte.

10
00:00:36,890 --> 00:00:41,770
Bei verteiltem Training ist
die Epochenanzahl nicht fehlertolerant.

11
00:00:41,770 --> 00:00:46,480
Sie müssen die Anzahl der Schritte
je nach Batchgröße und Lernrate anpassen.

12
00:00:46,480 --> 00:00:52,710
Wenn Sie z. B. Daten für 100 Epochen
mit 1.000 Beispielen verarbeiten möchten,

13
00:00:52,710 --> 00:00:57,400
ist bei einer Batchgröße von 1.000
die Anzahl der Schritte 100.

14
00:00:57,400 --> 00:01:01,350
Bei einer Batchgröße von 100
ist die Anzahl der Schritte 1.000.

15
00:01:01,350 --> 00:01:04,460
Die Anzahl der Schritte
ist gleich der Anzahl der Epochen

16
00:01:04,460 --> 00:01:07,885
mal der Anzahl der Beispiele
geteilt durch die Batchgröße.

17
00:01:08,620 --> 00:01:13,740
Wenn Sie die Lernrate reduzieren,
müssen Sie für mehr Epochen trainieren.