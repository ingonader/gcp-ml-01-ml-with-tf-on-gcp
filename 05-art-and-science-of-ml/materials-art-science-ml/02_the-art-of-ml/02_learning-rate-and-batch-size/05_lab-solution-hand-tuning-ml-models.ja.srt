1
00:00:00,000 --> 00:00:04,050
このラボでは手動で
ハイパーパラメータを調整しました

2
00:00:04,050 --> 00:00:05,950
結果を復習しましょう

3
00:00:05,950 --> 00:00:12,780
簡単な線形回帰を実行して
住宅の部屋数に基づいて住宅価格を予測します

4
00:00:12,780 --> 00:00:17,235
RMSEで モデルの正確性を判断し

5
00:00:17,235 --> 00:00:21,965
学習率とバッチサイズを調整して
RMSEを改善します

6
00:00:21,965 --> 00:00:28,380
このラボに使用したデータは 1990年の
カリフォルニア州国勢調査に基づいています

7
00:00:28,380 --> 00:00:33,090
ここでPython Notebookに注目します

8
00:00:33,090 --> 00:00:36,700
最初は複数のライブラリを
ロードしているだけです

9
00:00:36,700 --> 00:00:40,270
警告が表示されますが無視してかまいません

10
00:00:40,270 --> 00:00:44,240
実行しているバージョンによっては
警告は出ません

11
00:00:44,240 --> 00:00:53,880
次にこのパブリックURLからデータセットを
PandasのDataFrameにロードします

12
00:00:53,880 --> 00:01:05,920
そしてデータの複数のレコードと統計を見て
データを分析します

13
00:01:05,920 --> 00:01:08,480
このデータセットには1つ問題があります

14
00:01:08,480 --> 00:01:13,825
粒度が世帯レベルではなく
街区レベルであることです

15
00:01:13,825 --> 00:01:16,850
使用する前に修正する必要があります

16
00:01:16,850 --> 00:01:18,710
そのため何ができますか

17
00:01:18,710 --> 00:01:25,465
街区レベルの部屋の総数に基づいて
新しいデータ列を作成するだけです

18
00:01:25,465 --> 00:01:29,390
それを同じく街区レベルの世帯数で割ります

19
00:01:29,390 --> 00:01:34,635
そうすると大まかな世帯あたりの
部屋数が得られます

20
00:01:34,635 --> 00:01:41,100
それをdescribeすると
このように統計が得られます

21
00:01:41,100 --> 00:01:46,370
モデルのトレーニングに入る前に
データセットを見てみましょう

22
00:01:46,370 --> 00:01:48,570
目的を思い出してください

23
00:01:48,570 --> 00:01:55,100
これが今 既存の2つの列を
分割して作成した部屋数の列です

24
00:01:55,100 --> 00:01:56,505
これが特徴となります

25
00:01:56,505 --> 00:01:59,260
つまり モデルへの入力です

26
00:01:59,260 --> 00:02:04,340
そしてモデルでは
住宅築年数の中央値を予測します

27
00:02:04,340 --> 00:02:11,120
つまり この列はラベルを構成します

28
00:02:11,120 --> 00:02:16,605
このセルでは 実際にトレーニング開始に
必要なものを定義します

29
00:02:16,605 --> 00:02:24,570
トレーニング関数、入力関数は
データフレームの関数です

30
00:02:26,770 --> 00:02:30,700
部屋数が特徴

31
00:02:30,700 --> 00:02:37,740
住宅築年数中央値がラベルです

32
00:02:37,740 --> 00:02:41,150
ここでは出力ディレクトリを定義しています

33
00:02:41,150 --> 00:02:49,290
また 常に出力ディレクトリの内容を削除して
ゼロから始めるようにします

34
00:02:49,290 --> 00:02:52,744
前述したようにこれは線形回帰になります

35
00:02:52,744 --> 00:02:54,430
それがここです

36
00:02:54,430 --> 00:02:57,120
TensorFlowライブラリの線形回帰を使用し

37
00:02:57,120 --> 00:03:01,855
特徴と出力ディレクトリを
そのestimatorに送り

38
00:03:01,855 --> 00:03:04,105
ここでトレーニングを開始します

39
00:03:04,105 --> 00:03:09,250
すでに述べたように RMSEに着目して
モデルのパフォーマンスを判断します

40
00:03:09,250 --> 00:03:10,955
それがここで行われます

41
00:03:10,955 --> 00:03:13,605
このセルを実行すると

42
00:03:17,955 --> 00:03:23,380
RMSEに対して
非常に大きな数値が報告されますが

43
00:03:23,380 --> 00:03:24,940
これはおかしいですね

44
00:03:24,940 --> 00:03:32,360
RMSEはそんなに大きな値ではなく
数百単位のはずだからです

45
00:03:32,360 --> 00:03:35,290
ここで起きているのはスケーリングです

46
00:03:35,290 --> 00:03:39,920
10万スケールで報告されているので
そのスケールの適用が必要です

47
00:03:39,920 --> 00:03:44,115
そうするとRMSEを
適切なスケールで見ることができます

48
00:03:44,115 --> 00:03:47,435
これを次のセルで行っています

49
00:03:47,435 --> 00:03:53,260
y値を説明したスケールで除算します

50
00:03:53,260 --> 00:03:55,910
残りは同じです

51
00:03:55,910 --> 00:03:58,860
ここでそれを実行すると

52
00:03:58,860 --> 00:04:04,105
誤差率7.4%になります

53
00:04:04,105 --> 00:04:08,810
最初にしては悪くありませんが
改善できるはずです

54
00:04:08,810 --> 00:04:10,770
次のセルで改善していきます

55
00:04:10,770 --> 00:04:13,500
学習率とバッチサイズを変更して

56
00:04:13,500 --> 00:04:18,000
誤差率がどう改善するかを見てみましょう

57
00:04:18,000 --> 00:04:20,850
スケールは変わりません

58
00:04:20,850 --> 00:04:26,740
ここでバッチサイズを10に定義します

59
00:04:26,740 --> 00:04:32,935
常に 出力ディレクトリを削除して
ゼロから始めます

60
00:04:32,935 --> 00:04:38,450
学習率は0.01にします

61
00:04:38,450 --> 00:04:40,080
ここでも線形回帰です

62
00:04:40,080 --> 00:04:44,140
コードの残りは変わりません

63
00:04:44,140 --> 00:04:51,070
違うのは バッチサイズが小さいので
ステップ数を増やす必要があることです

64
00:04:51,070 --> 00:04:53,465
それがここです

65
00:04:53,465 --> 00:04:57,060
次にRMSEを印字して結果を見ましょう

66
00:05:02,520 --> 00:05:09,740
学習率とバッチサイズを
変える前の誤差率は7.4でした

67
00:05:09,740 --> 00:05:15,595
少し変更すると3.6に低下しました

68
00:05:15,595 --> 00:05:20,565
最高のパフォーマンスを得られるように
ハイパーパラメータを調整してみましょう

69
00:05:20,565 --> 00:05:25,510
私が前回調整してみたところ
2.528という結果になりました

70
00:05:27,510 --> 00:05:32,600
このラボで扱う内容はほとんど終わりました

71
00:05:32,600 --> 00:05:36,830
よくある質問のひとつは

72
00:05:36,830 --> 00:05:42,390
「こうしたパラメータを調整する
標準的な方法があるか」です

73
00:05:42,390 --> 00:05:43,735
簡単に言えば

74
00:05:43,735 --> 00:05:48,935
異なるハイパーパラメータの効果はデータに
依存するため明確なルールはありません

75
00:05:48,935 --> 00:05:51,850
自分のデータでのテストが必要です

76
00:05:51,850 --> 00:05:56,050
ただ 指針となりうる
いくつかの経験則があります

77
00:05:56,050 --> 00:06:00,940
トレーニングの誤差をモニタリングすると
次第に低下するはずです

78
00:06:00,940 --> 00:06:04,060
通常は最初急激に低下します

79
00:06:04,060 --> 00:06:08,420
そしてトレーニングが収束するにつれて
最終的にプラトーに至ります

80
00:06:08,420 --> 00:06:12,885
トレーニングが収束しない場合
もっと長く実行してみてください

81
00:06:12,885 --> 00:06:15,810
トレーニング誤差の低下が遅すぎる場合

82
00:06:15,810 --> 00:06:19,480
学習率を上げると
低下が早くなる場合があります

83
00:06:19,480 --> 00:06:25,405
ただし 学習率が高すぎると
逆効果になる場合があります

84
00:06:25,405 --> 00:06:29,630
トレーニング誤差が大きく異なる場合
学習率を低下させてみてください

85
00:06:29,630 --> 00:06:36,980
学習率を低くし ステップ数かバッチサイズを
上げると 良い組み合わせとなる場合が多いです

86
00:06:36,980 --> 00:06:42,035
バッチサイズが小さすぎると
不安定になることもあります

87
00:06:42,035 --> 00:06:45,440
最初に100や1,000などの大きな値で試し

88
00:06:45,440 --> 00:06:49,090
低下が見られるまで値を小さくしていきます

89
00:06:49,090 --> 00:06:54,310
この経験則を厳密に適用しないでください
効果はデータに依存します

90
00:06:54,310 --> 00:06:57,210
常に試して 検証してください

91
00:06:58,780 --> 00:07:04,345
このラボの補足として
特徴を追加して結果を見てください

92
00:07:04,345 --> 00:07:06,800
そんなに長い時間はかかりません

93
00:07:06,800 --> 00:07:08,720
5分から10分ぐらいでしょう

94
00:07:08,720 --> 00:07:15,370
さらに多くの特徴を追加して
モデルの動作を確認できます