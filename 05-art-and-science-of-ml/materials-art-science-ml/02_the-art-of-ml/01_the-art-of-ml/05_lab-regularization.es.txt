El objetivo de este lab era experimentar
con las regularizaciones L1 y L2 y observar visualmente
sus efectos. Revisemos juntos los resultados. Inicié TensorFlow Playground
mediante el vínculo que aparece aquí. Antes de iniciar el bucle
de entrenamiento agregué algo de ruido
al conjunto de datos. Elegí 30. En vez de usar solo x1 y x2
como atributos también usé combinaciones de atributos. Primero, intenté entrenar sin regularizar,
para ver qué pasaba con mi modelo. Como era de esperar, la pérdida
del entrenamiento converge bien pero la pérdida de prueba se mantuvo alta. Fíjese en la forma
del modelo de entrenamiento. ¿Nota la forma extraña de la región azul? Claramente, el modelo
se estaba sobreajustando para aprender todo el ruido
de los datos de entrenamiento. Terminé con un mal modelo. No se puede generalizar. Luego, obligué a mi modelo a aplicar
la Navaja de Ockham para mantenerlo simple. Para penalizar la complejidad,
podemos aplicar la regularización L1. Después de hacerlo,
observé un rendimiento mucho mejor. La forma azul era mucho más suave
y cancelaba el ruido. La pérdida de prueba también
convergía muy bien. Sin duda, este modelo
es mucho mejor. Me gustaría que observara
los atributos que ignora el modelo. Note que no hay líneas
que salgan de x1 o x2 ni x1 multiplicado por x2. Recuerde que puede usar la regularización L1
como mecanismo de selección de atributos. Luego, probé la regularización L2. En comparación con L1,
no hubo selección de atributos. Los atributos más importantes tenían
asociados los pesos más grandes pero el resto seguía participando,
con pesos más bajos. Tal vez no se vea en la imagen,
pero mientras ejecutábamos esto las líneas que salían de x1, x2 y x1 por x2 se movían. Recuerde que el peso de un atributo se visualiza a través del grosor
de la línea que emana de él. No había ninguna curvatura extraña. La pérdida de prueba se veía muy bien. Parecía ser un buen modelo. Luego, traté de enfatizar
un poco más la simplicidad del modelo al aumentar la tasa de regularización. La cambié de 0.1 a 0.3. El rendimiento del modelo
mejoró de 0.179 a 0.160. Luego, decidí subirla aún más y configurar
la tasa de regularización en uno. Fue demasiado. Mi modelo no pudo aprender nada. Tal como los otros hiperparámetros ajustar la tasa de regularización
toma tiempo y paciencia. Para resumir,
los modelos complejos son malos. Una manera de simplificar el modelo
es aplicar la regularización y ajustar la tasa
hasta conseguir un rendimiento aceptable. Espero que esto lo ayude a familiarizarse
con el concepto de regularización.