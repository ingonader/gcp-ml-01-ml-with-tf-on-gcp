このラボの目標はL1とL2の正則化を体験し
その効果を視覚的に確認することでした 結果を検討しましょう このリンクを使用して
TensorFlow Playgroundを起動しました トレーニングループを始める前に
データセットにノイズを30追加しました X1とX2を特徴として使用しただけではなく
特徴クロスも使用しました 最初に正則化せずにトレーニングを試して
モデルのパフォーマンスを見ました 予想どおり トレーニング誤差は
きれいに収束します しかしテスト誤差は高いままです トレーニングモデルの形状に注意してください 青い部分の奇妙な形に気付きますか トレーニングデータ内の
すべてのノイズを学習するため 明らかにモデル自体が過剰適合しています 悪いモデルができてしまいました このモデルは一般化できません 次に強制的に「オッカムの剃刀」を
モデルに適用して簡潔にしました 複雑さにペナルティを課す方法のひとつは
L1正則化の適用でしたね その後 
パフォーマンスはずっと向上しました ノイズが消えると
青い形はずっと滑らかになりました テスト誤差もきれいに収束しました これは明らかに優れたモデルです 私のモデルが無視した特徴にも
注意を払ってください X1、X2、X1×X2から出る線が
ないことに注目してください L1正則化は特徴選択メカニズムとして
使えることを思い出してください 次にL2正則化を試行しました L1と異なり特徴選択はありません 最も関連性がある特徴には
強い重み付けが関連付けられました しかし 残りの特徴は依然として
弱い重み付けが働いています これはスクリーンショットでは
見えないかもしれませんが ライブでの実行時には
X1、X2、X1×X2から出る線は動きました 特徴の重み付けは その特徴から出ている線の
太さで可視化されるのでしたね 変な湾曲もありませんでした テスト誤差はきれいで良好でした 良いモデルに見えます 次にモデルの簡潔さをもう少し高めるため
正則化率を0.1から0.3に上げました モデルのパフォーマンスは0.179から
0.160ポイントに改善しました そしてさらに正則化率を上げて
1に設定しました これは行きすぎで
モデルは何も学習できませんでした 他のハイパーパラメータと同様に
正則化率の調整には時間と忍耐が必要です 要するに複雑なモデルは使えません モデルを簡潔にする方法のひとつは
正則化の適用です そして許容できるパフォーマンスになるまで
正則化率を調整します このラボが正則化の概念を
知る助けになれば幸いです