Welcome to the first module in course number five. In this module, you will learn about the art of machine learning. We will review aspects of machine learning that require intuition, judgment, and experimentation to find the right balance and what's good enough. Never perfect. It's all about shades of grey. No black and white fax roots, sorry. You'll learn how to generalize your model using regularization techniques. In previous courses, we discussed the issue of overfitting and underfeeding. The goal is to generalize a model, so that it performs well on unseen test data not just training data. Often this comes at the cost of increased training error. There are many strategies used in the ML to solve this problem. They are collectively known as regularization. We will discuss the most common techniques and play with them in our favorite Tensorflow playground. Then you'll learn about the effects of hyperparameters, such as batch size and learning rate on your model performance. You will manually adjust them in the lab to find the right balance. We will then introduce the rather vast topic of model optimization and some of the most common algorithms. You will learn how to specify the optimization methods in your Tensorflow code. We will conclude the module with a lab, where you get hands on with Tensorflow. You will manually adjust the knobs and see their effects in action.