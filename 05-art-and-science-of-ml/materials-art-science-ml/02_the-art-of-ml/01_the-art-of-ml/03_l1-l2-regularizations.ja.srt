1
00:00:00,520 --> 00:00:05,680
モデルの複雑さにペナルティを課す
正則化を行っていくわけですが

2
00:00:05,680 --> 00:00:09,190
ここでモデルの複雑さの
測定方法が問題になります

3
00:00:09,190 --> 00:00:15,720
L1とL2の正則化法はともにモデルの複雑さを
重みベクトルの大きさで表し

4
00:00:15,720 --> 00:00:17,950
それを抑制しようとします

5
00:00:17,950 --> 00:00:19,270
線形代数では

6
00:00:19,270 --> 00:00:25,370
ベクトルの大きさはノルム関数で
表されることを覚えておきましょう

7
00:00:25,370 --> 00:00:29,200
L1とL2のノルム関数を簡単に見てみましょう

8
00:00:29,200 --> 00:00:35,060
重みベクトルの次元数は何でもかまいませんが
2次元空間で可視化すると簡単です

9
00:00:35,060 --> 00:00:42,590
w0=a、w1=bのベクトルは
緑色の矢印のようになります

10
00:00:42,590 --> 00:00:46,360
このベクトルの大きさはどれくらいでしょうか

11
00:00:46,360 --> 00:00:49,110
すぐに cだと考えるかもしれません

12
00:00:49,110 --> 00:00:54,960
原点からのユークリッド距離という
高校で学習する最も一般的な方法だからです

13
00:00:54,960 --> 00:01:00,380
cは(aの平方 + bの平方)の平方根です

14
00:01:00,380 --> 00:01:06,780
これは線形代数でL2ノルムと呼ばれ
式では二重縦線と添字2で示しますが

15
00:01:06,780 --> 00:01:11,160
2は既知のデフォルトなので
添字は省略可能です

16
00:01:11,160 --> 00:01:17,880
L2ノルムはすべてのベクトル成分の
平方値の和の平方根として計算されます

17
00:01:17,880 --> 00:01:23,040
しかし これがベクトルの大きさを計算する
唯一の方法ではありません

18
00:01:23,040 --> 00:01:26,010
別の一般的な計算方法はL1ノルムです

19
00:01:26,010 --> 00:01:30,490
L1はaの絶対値とbの絶対値の和を測定します

20
00:01:30,490 --> 00:01:33,800
ここで黄色にハイライトされている経路です

21
00:01:33,800 --> 00:01:38,420
モデルの複雑さの定義方法を探していることを
思い出してください

22
00:01:38,420 --> 00:01:41,470
正則化法としてL1とL2を使用しました

23
00:01:41,470 --> 00:01:46,880
ここではモデルの複雑さを
重みベクトルの大きさの形で測定しました

24
00:01:46,880 --> 00:01:54,700
つまり 重みベクトルの大きさを特定の値より
小さくできれば目標を達成したと言えます

25
00:01:54,700 --> 00:02:00,880
重みベクトルのL2ノルムが特定の値よりも
小さいという意味を可視化しましょう

26
00:02:00,880 --> 00:02:02,610
特定の値を1とします

27
00:02:02,610 --> 00:02:05,810
L2は原点からのユークリッド距離です

28
00:02:05,810 --> 00:02:12,840
そのため目的のベクトルは
この原点を中心に半径1の円内にあるべきです

29
00:02:12,840 --> 00:02:18,340
L1ノルムを特定の値以下にする場合
どうなりますか

30
00:02:18,340 --> 00:02:22,500
重みベクトルが存在できる領域は
この黄色いダイヤ形になります

31
00:02:22,500 --> 00:02:24,310
一番重要な点は

32
00:02:24,310 --> 00:02:30,550
L1正則化の適用時に特定の重みの最適値が
0になる可能性があることです

33
00:02:30,550 --> 00:02:36,515
これは注目している最適領域が
極端なダイヤ形だからです

34
00:02:36,515 --> 00:02:41,396
L2正則化で見られる
きれいな円形とは対照的です

35
00:02:42,736 --> 00:02:49,300
ベクトルノルムを使用してモデルを
正則化するという問題に戻りましょう

36
00:02:49,300 --> 00:02:55,220
これはweight decayとしても知られる
L2の正則化適用方法です

37
00:02:55,220 --> 00:02:59,140
重み値を原点近くに
維持しようとしていましたが

38
00:02:59,140 --> 00:03:03,430
2D空間では重みベクトルは円内に限定されます

39
00:03:03,430 --> 00:03:06,360
この考えは簡単に3D空間に拡大できますが

40
00:03:06,360 --> 00:03:10,140
3Dを超えると可視化が
難しくなるので試さないでください

41
00:03:10,140 --> 00:03:14,730
機械学習で100%正直であるため
数学面で少しうそをつきます

42
00:03:14,730 --> 00:03:20,110
L2ノルムの平方を使って
導関数の計算を単純化します

43
00:03:20,110 --> 00:03:23,177
ここに新しいパラメータλがあります

44
00:03:23,177 --> 00:03:26,245
この単純なスカラー値を使って

45
00:03:26,245 --> 00:03:33,614
トレーニング誤差の最小化に対して
モデルの単純さをどの程度重視するかを制御します

46
00:03:33,614 --> 00:03:38,020
これは明示的に設定する必要がある
もう1つの調整パラメータです

47
00:03:38,020 --> 00:03:43,070
残念ながら特定の問題に対する
最適値はデータに依存します

48
00:03:43,070 --> 00:03:47,620
そのため 手動であれ自動であれ
調整が必要です

49
00:03:47,620 --> 00:03:50,570
ハイパーパラメータ調整などの
ツールを使用しますが

50
00:03:50,570 --> 00:03:53,900
この点は次のモジュールで扱います

51
00:03:53,900 --> 00:04:00,530
L1正則化を適用するには
L2ノルムをL1ノルムと入れ替えるだけですが

52
00:04:00,530 --> 00:04:04,470
結果は大きく異なる可能性があります

53
00:04:04,470 --> 00:04:09,190
L1正則化は
スパースなソリューションになります

54
00:04:09,190 --> 00:04:15,450
ここでのスパースとは 一部の重みで
最適値が0になるという事実を意味します

55
00:04:15,450 --> 00:04:18,500
最適領域のダイヤ形を覚えているでしょうか

56
00:04:18,500 --> 00:04:23,539
L1正則化のこの特性は
特徴選択メカニズムとして広く使用されます

57
00:04:23,539 --> 00:04:29,890
特徴選択は重みのサブセットを
0にすることでMLの問題を単純化します

58
00:04:29,890 --> 00:04:35,320
そして重み0は支障なく切り捨てられない
本質的特徴を示しています