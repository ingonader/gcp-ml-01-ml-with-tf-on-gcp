Bienvenido al primer módulo
del curso número 5. En este módulo, conocerá
el arte del aprendizaje automático. Veremos aspectos del AA
que requieren de intuición, criterio y experimentación para encontrar
el equilibrio correcto pero nunca perfecto. Aquí importan las áreas grises. Esto no es blanco o negro. Aprenderá a generalizar un modelo
usando técnicas de regularización. En cursos anteriores, hablamos acerca
del sobreajuste y la sobregeneralización. El objetivo es generalizar un modelo para que tenga buen rendimiento
con datos de prueba no conocidos y no solo de entrenamiento. La desventaja es que habrá
más errores de entrenamiento. Se usan muchas estrategias en el AA
para resolver este problema. Se conocen como "regularización". Hablaremos de las técnicas más comunes y experimentaremos
con ellas en TensorFlow Playground. Luego, conocerá los efectos
de los hiperparámetros como el tamaño de lote
y la tasa de aprendizaje en el rendimiento del modelo. Los ajustaremos manualmente en el lab
para encontrar el equilibrio correcto. Luego, veremos un tema muy amplio:
la optimización de modelos y algunos de los algoritmos más comunes. Aprenderá
a especificar los métodos de optimización en su código de TensorFlow. Concluiremos este módulo con un lab en el que practicaremos con TensorFlow. Realizará ajustes manuales
y verá los efectos que producen.