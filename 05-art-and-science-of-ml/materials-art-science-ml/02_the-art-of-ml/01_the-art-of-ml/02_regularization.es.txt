Comencemos con la primera sección
de este módulo: regularización. Nuestro objetivo al entrenar el modelo
es minimizar el valor de la pérdida. Si traza la curva de pérdida en los datos de entrenamiento
y los de prueba se verá más o menos así. El gráfico muestra la pérdida
en el eje y frente al tiempo en el eje x. ¿Nota algo extraño? El valor de pérdida desciende
en los datos de entrenamiento pero comienza a subir
en cierto punto en los datos de prueba. Eso no es bueno. Claramente, tenemos algo de sobreajuste que parece correlacionarse con la cantidad
de iteraciones de entrenamiento. ¿Qué podemos hacer? Podríamos reducir la cantidad
de iteraciones del entrenamiento. La interrupción anticipada
sin duda es una opción pero deben de haber mejores formas. Aquí aparece la regularización. Usemos nuestra intuición
en TensorFlow Playground. Seguramente usó Playground
en cursos anteriores. Para que lo recuerde TensorFlow Playground
es una herramienta para visualizar cómo aprenden las redes neuronales. La usamos bastante en esta especialización
para entender conceptos fácilmente. Mire la pantalla con atención. Hay algo extraño aquí. Note que una región
en la parte inferior izquierda que tiende a azul pero no hay nada en los datos
que sugiera azul. La decisión del modelo es un poco extraña. ¿Por qué cree que sucede esto? ¿Ve el grosor relativo de las 5 líneas
de la entrada a la salida? Estas líneas muestran el peso relativo
de los cinco atributos. Las líneas que salen de x1 y x2 son mucho más gruesas
que las de las combinaciones de atributos. Las combinaciones de atributos
contribuyen mucho menos al modelo que los atributos
normales no combinados. Si eliminamos todas las combinaciones,
obtenemos un modelo más sensato. Pruébelo para ver la manera en que
los límites curvos que sugieren un sobreajuste desaparecen y la pérdida de prueba converge. Después de 1,000 iteraciones la pérdida de prueba
debería tener un valor ligeramente menor que cuando había
combinaciones de atributos. Sus resultados pueden variar un poco,
según el conjunto de datos que tenga. Los datos de este ejercicio
son datos lineales más ruido. Si usa un modelo demasiado complicado,
como el que tenía muchas combinaciones es más probable que el ruido se introduzca
en los datos de entrenamiento lo que hará que el modelo funcione mal
en los datos de prueba. Claramente, la interrupción anticipada
no servirá en este caso. Necesitamos controlar
la complejidad del modelo. ¿Cómo podemos medir la complejidad
para poder evitarla? Concluimos que, en general,
los modelos más simples son mejores. No queremos cocinar
con todas las especias en el anaquel. Hay todo un campo que aborda esto que se llama teoría
de la generalización (teoría G) que se dedica a definir
el marco de trabajo estadístico. Lo más fácil que uno puede hacer
es seguir su intuición basándose en los principios establecidos
en el siglo XIV por Guillermo de Ockham. Cuando entrenamos un modelo, aplicamos
el principio de la Navaja de Ockham como nuestra guía heurística
que favorece los modelos simples con menos suposiciones
para el entrenamiento. Revisemos algunas de las técnicas
de regularización más comunes que nos pueden ayudar
a poner en práctica este principio. La idea es penalizar
la complejidad del modelo. Hasta ahora, en nuestro
proceso de entrenamiento hemos intentado minimizar la pérdida
en los datos del modelo. Debemos equilibrar
con respecto a la complejidad del modelo. Antes de ver cómo medir
la complejidad de un modelo veamos por qué hablamos de equilibrar la complejidad
con relación a la pérdida. La verdad es que los modelos
demasiado simplificados son inútiles. Si lo llevamos a un extremo,
terminaremos con un modelo nulo. Debemos encontrar el equilibrio correcto entre la simplicidad y el ajuste preciso
de los datos de entrenamiento. Espero que ahora esté claro
por qué este enfoque tiene más sentido
que la interrupción anticipada. La regularización es uno de los campos
de investigación más importantes del AA. Se han publicado muchas técnicas
y aparecerán más. Ya hablamos
de la interrupción anticipada. También comenzamos
a explorar el grupo de métodos conocidos como penalizaciones
por norma de parámetros. También existen métodos de aumento
del conjunto de datos robustez frente al ruido,
representación dispersa, entre otros. En este módulo, revisaremos
los métodos de regularización L1 y L2 del grupo de técnicas de
penalizaciones por norma de parámetros. Antes de eso recordemos cuál es el problema
que resolvemos con la regularización. La regularización es cualquier técnica
que nos ayude a generalizar un modelo. Un modelo generalizado funciona bien
no solo con datos de entrenamiento sino también con datos
de prueba no conocidos.