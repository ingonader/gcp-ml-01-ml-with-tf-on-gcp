A primeira seção deste módulo
é sobre a regularização. Nossa meta ao treinar o modelo
é minimizar o valor de perda. Se você fizer a curva de perda nos dados de
treinamento e de teste, ela pode ser assim. O gráfico mostra a perda
no eixo Y e o tempo no eixo X. Percebeu alguma coisa errada? O valor de perda está descendo nos dados de treinamento,
mas aumenta nos de teste. Isso não pode ser bom. Há claramente um sobreajuste, que parece relacionado ao
número de iterações de treinamento. Como podemos resolver isso? Podemos reduzir o número de
iterações de treinamento e parar antes. A parada antecipada
é uma opção, mas há opções melhores. Aqui entra a regularização. Vamos usar a intuição no
TensorFlow Playground. Você já o viu e usou
em cursos anteriores. Lembrete rápido: o TensorFlow Playground
é uma ferramenta útil para visualizar o aprendizado
das redes neurais. Nós o usamos muito nesta
especialização para ver os conceitos. Observe a tela. Há algo estranho aqui. Há uma região no canto inferior
esquerdo que tende para o azul. Os dados não sugerem o azul. Essa decisão do modelo
é meio aleatória. Por que isso acontece? Percebe a grossura das cinco linhas
que vão da entrada para a saída? Elas mostram o peso
relativo dos cinco recursos. As linhas que
emanam de X1 e X2 são mais grossas que
as dos cruzamentos. Os cruzamentos
contribuem muito menos para o modelo que
os recursos comuns. Remover os cruzamentos
oferece um modelo mais saudável. Tente você mesmo e veja
como os limites curvos que sugerem sobreajuste
desaparecem e o teste converge. Depois de mil iterações,
a perda do teste será um valor um pouco menor
que estes cruzamentos. Seus resultados podem variar
dependendo do conjunto de dados. Os dados deste exercício
são lineares, mais o ruído. Se você usar um modelo complicado,
como um com vários cruzamentos e com a oportunidade de incluir
o ruído nos dados de treinamento, o custo de gerar o modelo é um
desempenho ruim nos dados de teste. A parada antecipada
não ajuda nesse caso, por causa da complexidade do
modelo que precisamos controlar. Mas como medir a
complexidade e evitá-la? Concluímos que modelos mais simples
geralmente são melhores. Não queremos cozinhar
com todos os temperos. Há um campo de pesquisa chamado
teoria de generalização ou GT que define a
estrutura estatística. A maneira mais fácil
é usar a intuição, com base nos princípios de
William de Occam, do século 14. Ao treinar o modelo, aplicamos
o princípio da navalha de Occam como guia heurístico para favorecer
modelos simples com menos suposições. Vamos ver algumas das técnicas de regularização
mais comuns que podem ajudar
a aplicar esse princípio. A ideia é penalizar a
complexidade do modelo. Até agora, no
processo de treinamento, tentamos minimizar a perda
dos dados que o modelo recebe. Precisamos equilibrar
a perda e a complexidade. Antes de falar sobre como medir
a complexidade do modelo, vamos entender porque equilibrar
a complexidade e a perda. Na verdade, modelos
simples demais são inúteis. Se você levar isso ao extremo, terminará sem modelo nenhum. Precisamos encontrar
o equilíbrio certo entre simplicidade e ajuste preciso
dos dados de treinamento. Espero que você tenha
entendido que essa abordagem é mais íntegra que
a parada antecipada. A regularização é um dos maiores campos
de pesquisa do aprendizado de máquina. Há várias técnicas publicadas
e mais no futuro. Já mencionamos
a parada antecipada. Também começamos
a explorar os métodos nas penalidades de
normas de parâmetro. Também há métodos de
aumento do conjunto de dados, robustez do ruído, representação
esparsa e muito mais. Neste módulo, veremos
melhor os métodos de regularização L1 e L2 do grupo de
penalidades de normas de parâmetros. Antes disso, vamos lembrar qual problema
a regularização resolve. Regularização é qualquer técnica
que ajuda a generalizar um modelo. Um modelo generalizado
tem bom desempenho nos dados de treinamento
e em dados de teste novos.