Cet atelier vous a permis d'expérimenter
les régularisations L1 et L2 et d'observer visuellement leurs effets. Examinons ensemble les résultats. J'ai lancé Tensorflow Playground
à l'aide du lien indiqué à l'écran. Avant de démarrer
la boucle d'entraînement, j'ai ajouté du bruit dans l'ensemble
de données (niveau réglé sur 30). Au lieu d'utiliser seulement
les caractéristiques X1 et X2, j'ai également intégré
des croisements de caractéristiques. J'ai d'abord essayé
un entraînement sans régularisation pour observer le comportement du modèle. Comme attendu, la "perte d'entraînement"
a correctement convergé, mais la "perte de test" est restée
à un niveau élevé. Observez la forme
du modèle d'entraînement ! Avez-vous remarqué
la forme étrange de la région bleue ? Cela indique clairement
que le modèle s'est surajusté de lui-même pour apprendre tout le bruit
contenu dans les données d'entraînement. Eh bien, on peut dire
que j'ai élaboré un mauvais modèle. Il est impossible de le généraliser. Ensuite, j'ai forcé mon modèle
à appliquer le rasoir d'Ockham et à "rester simple". Souvenez-vous qu'un moyen
de pénaliser la complexité est d'appliquer la régularisation L1. Après avoir procédé ainsi, j'ai pu constater que le modèle
était bien plus performant. La forme bleue était beaucoup plus lisse
et le bruit avait disparu. En outre, la "perte de test"
convergeait correctement. Ce modèle est de bien meilleure qualité. Je souhaite aussi
que vous prêtiez attention aux caractéristiques ignorées
par mon modèle. Notez qu'aucune ligne n'émane de X1,
de X2 ou de X1X2. Rappelez-vous,
la régularisation L1 peut être utilisée comme mécanisme de
sélection de caractéristiques. Ensuite, j'ai essayé la régularisation L2. Ici, il n'y avait aucun mécanisme 
de sélection de caractéristiques. J'ai attribué un poids important
aux caractéristiques essentielles, et un poids plus faible
aux autres caractéristiques. Cela n'est pas visible
sur la capture d'écran, mais lors de l'exécution, un mouvement était perceptible sur
les lignes provenant de X1, X2 et X1X2. Souvenez-vous que le poids
d'une caractéristique est représenté par l'épaisseur de la ligne
qui émane de cette caractéristique. Je n'ai pas constaté de courbure extrême, la perte de test
était normale, régulière... Un bon modèle en somme. Ensuite, j'ai essayé de mettre un peu plus
l'accent sur la simplicité du modèle en augmentant le taux de régularisation. Je suis passée de 0,1 à 0,3. La performance du modèle s'est améliorée,
elle est passée de 0,179 à 0,160. Puis j'ai décidé d'aller encore plus loin et de régler
le taux de régularisation sur 1. C'était beaucoup trop. Mon modèle ne pouvait plus rien apprendre. Comme pour les autres hyperparamètres, le réglage du taux de régularisation
nécessite du temps et de la patience. En résumé, les modèles complexes
sont de mauvais modèles. Pour conserver un modèle simple,
vous pouvez appliquer la régularisation et ajuster progressivement le taux jusqu'à ce que vous obteniez
une performance acceptable. J'espère que ceci vous aidera à mieux comprendre
le concept de régularisation.