Beginnen wir mit dem ersten Abschnitt
dieses Moduls: Regularisierung. Das Trainingsziel für ein Modell ist
die Minimierung des Verlustwerts. Ein Graph der Verlustkurve für Trainings- und Testdaten kann wie hier aussehen. Der Graph zeigt den Verlust auf der Y-Achse
gegenüber der Zeit auf der X-Achse an. Fällt Ihnen etwas auf? Der Verlustwert verringert sich
bei den Trainingsdaten wie gewünscht, nimmt bei den Testdaten
nach einiger Zeit aber wieder zu. Das ist nicht gut. Hier ist eindeutig
eine Überanpassung erfolgt. Es scheint eine Beziehung
zur Anzahl der Trainingsläufe zu bestehen. Wir gehen wir da heran? Wir könnten die Anzahl der Läufe
verringern und vorzeitig stoppen. Vorzeitiges Stoppen ist definitiv möglich, es muss aber eine bessere Option geben. Hier kommt die Regularisierung ins Spiel. Lassen wir unserer Intuition
in TensorFlow Playground freien Lauf. Sie kennen diesen Playground
bereits aus früheren Kursen. TensorFlow Playground
ist ein praktisches kleines Tool, um zu visualisieren, 
wie neurale Netzwerke lernen. Wir nutzen es
sehr oft in dieser Spezialisierung, um Konzepte intuitiv zu begreifen. Sehen Sie sich diesen Bildschirm an. Irgendetwas ist hier seltsam. Unten links
ist ein Bereich, der ins Blaue geht. In den Daten weist nichts auf blau hin. Die Modellentscheidung ist seltsam. Warum ist das der Fall? Sie sehen die fünf relativ dicken Linien
von der Eingabe zur Ausgabe. Diese Linien zeigen
die relative Gewichtung der fünf Merkmale. Die Linien von x1 und x2 sind deutlich dicker
als die von den Merkmalkreuzungen. Die Merkmalkreuzungen tragen also
wesentlich weniger zum Modell bei als die normalen, ungekreuzten Merkmale. Das Entfernen aller Merkmalkreuzungen
führt zu einem brauchbareren Modell. Sie sollten dies ausprobieren. Sie stellen fest, dass der Grenzbereich
aufgrund der Überanpassung verschwindet und der Testverlust konvergiert. Nach 1.000 Durchläufen sollte
der Testverlust geringer sein als dort, wo die Merkmalkreuzungen verwendet wurden. Ihre Ergebnisse können abhängig
vom Dataset etwas anders aussehen. Die Daten in dieser Übung
sind lineare Daten plus Rauschen. Wenn Ihr Modell zu komplex ist,
z. B. zu vielen Kreuzungen hat, kann es sich an das Rauschen
in den Trainingsdaten anpassen. Bietet das Modell allerdings bei Testdaten
schlechte Leistung, ist das nicht gut. Vorzeitiges Stoppen ist hier keine Lösung. Wir müssen
die Modellkomplexität verändern. Wie messen wir Modellkomplexität
und wie vermeiden wir sie? Wir haben gelernt,
dass einfachere Modell meist besser sind. Nicht jedes Gewürz im Regal
muss ins Essen. Mit diesem Thema beschäftigt sich
die Generalisierungstheorie oder G-Theorie. Dabei geht es um das Definieren
des statistischen Frameworks. Die einfachste Herangehensweise
ist allerdings die Intuition. Dies basiert auf den Prinzipien
aus dem 14. Jh. von William Ockham. Beim Modelltraining wenden wir
das Prinzip von Ockhams Rasiermesser an. Wir ziehen einfachere Modelle
mit weniger Annahmen zum Training vor. Beschäftigen wir uns mit
den gängigsten Regularisierungstechniken, mit denen wir
dieses Prinzip praktisch anwenden können. Modellkomplexität soll bestraft werden. Bisher haben wir
in unserem Trainingsprozess versucht, Datenverlust für das Modell zu minimieren. Wir müssen dies
gegen die Modellkomplexität abwägen. Bevor wir darüber reden,
wie wir Modellkomplexität messen, müssen wir klären, warum Komplexität
und Verlust ausgeglichen sein sollen. Fakt ist,
stark vereinfachte Modelle sind nutzlos. Wenn Sie dort übertreiben,
haben Sie am Ende kein Modell mehr. Wir benötigen die richtige Balance zwischen Einfachheit
und exakt angepassten Trainingsdaten. Mittlerweile sollte klar sein,
warum dieser Ansatz dem Prinzip eher gerecht wird
als vorzeitiges Stoppen. Regularisierung ist
im Bereich maschinelles Lernen eines der größeren Forschungsfelder. Viele Techniken wurden veröffentlicht
und weitere werden folgen. Wir haben
vorzeitiges Stoppen bereits erwähnt. Wir haben auch die Methoden untersucht, die sich zusammenfassen lassen
unter Parameternormabzüge. Zudem gibt es
die Methoden zur Dataset-Vergrößerung, Unempfindlichkeit gegen Rauschen,
spärliche Darstellung und mehr. In diesem Modul sehen wir uns
die L1- und L2-Regularisierungen an, die unter Parameternormabzüge fallen. Vorher erinnern wir uns aber, welches Problem
Regularisierung für uns löst. Regularisierung bezieht sich auf eine
Technik zur Modellgeneralisierung. Ein generalisiertes Modell
ist leistungsstark, nicht nur bei Trainingsdaten,
sondern auch bei unbekannten Testdaten.