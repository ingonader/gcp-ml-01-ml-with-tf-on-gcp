Let's start with the first section of this module; Regularization. Remember our global training a model is to minimize the loss value. If you craft the loss curve, both on the training and test data, it may look something like this. The graph shows loss on the Y-axis versus time on the X-axis. Notice anything wrong here? Yeah, the loss value is nicely trending down on the training data but shoots upwards at some point on the test data. That can't be good. Clearly some amount of overfitting is going on here, it seems to be correlated with the number of training iterations. How could we address this? We could reduce the number of training iteration and stop early. Early stopping is definitely an option, but there must be better ones. Here's where regularization comes into the picture. Let's take our intuition using Tensorflow playground. You must have seen and used this playground in previous courses. But to quickly remind you, Tensorflow playground is a handy little tool for visualizing how neural networks learn. we extensively use it throughout this specialization to intuitively grasp the concepts. Let me draw your attention to the screen. There is something odd going on here. That is a region in the bottom left that's hinting towards blue, there is nothing in the data suggesting blue. The model decision is kind of crazy. Why do you think that is? Notice the relative thickness of the five lines running from input to output? These lines show the relative weight of the five features. The lines emanating from X1 and X2 are much thicker than those coming from the feature crosses. So the feature crosses are contributing far less to the model than the normal uncrossed features. Removing all the feature crosses gives a sanier model. You should try this for yourself and see how curved boundaries suggestive of overfitting disappears and test loss converges. After 1000 iterations, test loss should be a slightly lower value than the feature crosses there in play. Although your results may vary a bit depending on the dataset. The data in this exercise is basically linear data plus noise. If you use a model that's too complicated such as the one with too many crosses, be given the opportunity to fit to the noise in the training data, after that the costs of making the model perform badly on test data. Clearly early stopping cannot help us here. As the model complexity that we need to bring under control. But how could we measure model complexity and avoid it? We concluded that simpler models are usually better. We don't want to cook with every spice in the spice rack. There's a whole field around this called generalization theory or GT theory, that goes about defining the statistical framework. The easiest way to think about it though, is by intuition, based on 14th century principles laid out by William Ockham. While training model, we will apply Ockham's Razor principle as our heuristic guide in favoring simpler models with less assumptions about the training. Let's look into some of the most common regularization techniques that can help us apply this principle in practice. The idea is to penalize model complexity. So far in our training process, we've been trying to minimize loss of the data given the model. We need to balance that against the complexity of the model. Before we talk about how to measure model complexity, let's pause and understand why we said balance complexity against loss. The truth is that oversimplified models are useless. If you take it to the extreme, you will end up with no model. We need to find the right balance between simplicity and accurate fitting of the training data. I hope by now it's clear why this approach is arguably more principled than early stopping. Regularization is one of the major fields of research within machine learning. There are many published techniques and more to come. We already mentioned early stopping. We also started exploring the group of methods under the umbrella parameter norm penalties. There are also data set augmentation methods, noise robustness, sparse representation, and many more. In this module, we will have a closer look at L1 and L2 regularization methods from Parameter Norm Penalties Group of Techniques. But before we do that, let's quickly remind ourselves what problem regularization is solving for us. Regularization refers to any technique that helps generalize a model. A generalized model performs well not just on training data but also on never seen test data.