In diesem Lab sollten Sie mit L1-
und L2-Regularisierung experimentieren und die Auswirkungen beobachten. Schauen wir uns die Ergebnisse
zusammen an. Ich habe TensorFlow Playground
über den hier angezeigten Link gestartet. Vor dem Start der Trainingsschleife habe ich dem Dataset Rauschen
mit einem Wert von 30 hinzugefügt. Anstatt nur x1 und x2
als Merkmale zu verwenden, habe ich auch Merkmalkreuzungen verwendet. Zuerst habe ich
ohne Regularisierung trainiert, um mein Modell einzuordnen. Das Trainingsverlust
konvergierte wie erwartet gut, doch blieb der Testverlust hoch. Sehen Sie sich
die Form des Trainingsmodells an. Bemerken Sie
die seltsame Form des blauen Bereichs? Das Modell hat sich klar überangepasst, um das Rauschen
in den Trainingsdaten zu erlernen. Ich habe das Modell am Ende ruiniert. Es kann nicht generalisiert werden. Danach habe ich mein Modell angewiesen,
das Sparsamkeitsprinzip anzuwenden. Ein Weg, Komplexität zu bestrafen,
war das Anwenden der L1-Regularisierung. Danach ergab sich
eine deutlich bessere Leistung. Die blaue Form war glatter
und konnte das Rauschen unterdrücken. Auch der Testverlust konvergierte gut. Dies ist eindeutig ein besseres Modell. Achten Sie auf die Merkmale,
die von meinem Modell ignoriert wurden. Von x1, x2
und x1 mal x2 gehen keine Linien aus. Ich kann die L1-Regularisierung nämlich
zur Merkmalauswahl verwenden. Danach habe ich
die L2-Regularisierung probiert. Im Gegensatz zu L1
fand keine Merkmalauswahl statt. Die relevantesten Merkmale
hatten eine starke Gewichtung, der Rest wurde aber weiterhin
mit geringerer Gewichtung berücksichtigt. Dies ist im Screenshot
vielleicht nicht ersichtlich, doch beim Ausführen zeigten die Linien
aus x1, x2 und x1 mal x2 Bewegung. Die Gewichtung eines Merkmals wird durch die Dicke
der von ihr ausgehenden Linie dargestellt. Auch der Graph war nicht ungewöhnlich. Der Testverlust sah gut aus. Ergebnis war ein gutes Modell. Dann habe ich
mehr Wert auf Modelleinfachheit gelegt, indem ich
die Regularisierungsrate erhöht habe. Ich änderte sie von 0,1 auf 0,3. Die Modellleistung
verbesserte sich von 0,179 zu 0,160. Mit einer Regularisierungsrate von 1
wollte ich dies dann weiter verstärken. Das war aber zu viel. Mein Modell konnte gar nichts lernen. Wie bei den anderen Hyperparametern erfordert die Anpassung
der Regularisierungsrate Zeit und Geduld. Zusammengefasst
sind komplexe Modelle schlecht. Wir können unser Modell einfach halten,
indem wir Regularisierung anwenden und die Rate anpassen, bis wir
eine annehmbare Leistung erreichen. Ich hoffe, ich konnte Ihnen das Konzept
der Regularisierung vermitteln.