1
00:00:00,340 --> 00:00:02,190
Nous savons que nous allons utiliser

2
00:00:02,190 --> 00:00:05,520
des méthodes de régularisation
qui pénalisent la complexité du modèle.

3
00:00:05,520 --> 00:00:08,800
Nous devons maintenant nous demander
comment mesurer cette complexité.

4
00:00:09,170 --> 00:00:13,630
Les méthodes de régularisation L1 et L2
représentent la complexité du modèle

5
00:00:13,630 --> 00:00:17,950
en tant que magnitude du vecteur de poids
et tentent de garder cela sous contrôle.

6
00:00:17,950 --> 00:00:20,830
Rappelez-vous qu'en algèbre linéaire,

7
00:00:20,830 --> 00:00:25,380
la magnitude d'un vecteur est représentée
par la fonction normative.

8
00:00:25,380 --> 00:00:29,200
Examinons rapidement
les fonctions normatives L1 et L2.

9
00:00:29,200 --> 00:00:31,820
Le vecteur de poids peut avoir
de multiples dimensions,

10
00:00:31,830 --> 00:00:35,240
mais il est plus facile de le visualiser
dans un espace bidimensionnel.

11
00:00:35,240 --> 00:00:42,430
Un vecteur avec w0=a et w1=b
ressemblerait ainsi à cette flèche verte.

12
00:00:42,430 --> 00:00:44,830
Mais quelle est la magnitude
de ce vecteur ?

13
00:00:46,320 --> 00:00:50,260
Vous pourriez instantanément penser "C",
car vous appliquez la méthode

14
00:00:50,260 --> 00:00:53,090
la plus communément enseignée
à l'école secondaire,

15
00:00:53,090 --> 00:00:55,010
la distance euclidienne de l'origine.

16
00:00:55,010 --> 00:00:59,329
C correspondrait à la racine carrée
de la somme a² + b².

17
00:01:00,440 --> 00:01:03,800
En algèbre linéaire,
on appelle cela la "norme L2".

18
00:01:03,800 --> 00:01:06,690
Pour la représenter,
on utilise des barres verticales doubles

19
00:01:06,690 --> 00:01:10,440
et l'indice 2, ou aucun indice,
car 2 est la valeur par défaut.

20
00:01:11,160 --> 00:01:12,980
La norme L2 est calculée comme suit :

21
00:01:12,980 --> 00:01:15,220
racine carrée de la somme
des valeurs au carré

22
00:01:15,220 --> 00:01:17,140
de toutes les composantes du vecteur.

23
00:01:17,710 --> 00:01:21,890
Mais ce n'est pas la seule méthode
pour calculer la magnitude d'un vecteur.

24
00:01:23,030 --> 00:01:26,010
Une autre méthode couramment employée
est la norme L1.

25
00:01:26,010 --> 00:01:30,300
La norme L1 est calculée comme suit :
somme des valeurs absolues de a et b,

26
00:01:30,300 --> 00:01:33,100
ce qui correspond
au tracé jaune sur ce graphique.

27
00:01:33,830 --> 00:01:35,750
Souvenez-vous que nous cherchons

28
00:01:35,750 --> 00:01:37,990
un moyen de définir
la complexité du modèle.

29
00:01:37,990 --> 00:01:41,650
Nous avons employé les normes L1 et L2
en tant que méthodes de régularisation.

30
00:01:41,650 --> 00:01:45,860
Ici, la complexité du modèle est mesurée
sous la forme d'un vecteur de poids.

31
00:01:46,730 --> 00:01:50,490
En d'autres termes, si nous maintenons
la magnitude du vecteur de poids

32
00:01:50,490 --> 00:01:54,060
à un niveau inférieur à une certaine
valeur, nous atteignons notre objectif.

33
00:01:54,640 --> 00:01:58,100
Voyons maintenant ce que signifie
concrètement le fait que la norme L2

34
00:01:58,100 --> 00:02:01,930
de notre vecteur de poids soit inférieure
à une certaine valeur, par exemple 1.

35
00:02:01,930 --> 00:02:05,620
Comme L2 correspond à
la distance euclidienne de l'origine,

36
00:02:05,620 --> 00:02:11,520
le vecteur devrait être délimité par
un cercle de rayon 1 centré sur l'origine.

37
00:02:12,910 --> 00:02:16,410
Lorsque nous tentons de maintenir
la norme L1 sous une certaine valeur,

38
00:02:16,410 --> 00:02:21,120
la zone dans laquelle le vecteur de poids
peut résider correspond au diamant jaune.

39
00:02:22,060 --> 00:02:26,660
Le plus important à retenir ici est que,
quand vous appliquez la régularisation L1,

40
00:02:26,660 --> 00:02:30,040
la valeur optimale de certains poids
peut au final être égale à zéro.

41
00:02:30,550 --> 00:02:36,050
La forme extrême de "diamant"
de cette région optimale est intéressante,

42
00:02:36,050 --> 00:02:39,285
car elle est totalement différente
de la forme circulaire lisse

43
00:02:39,285 --> 00:02:41,196
offerte par la régularisation L2.

44
00:02:42,831 --> 00:02:45,510
Mais revenons au problème
qui nous préoccupe :

45
00:02:45,510 --> 00:02:48,710
comment régulariser notre modèle
à l'aide d'une norme vectorielle ?

46
00:02:49,300 --> 00:02:52,135
Voici comment vous devez appliquer
la régularisation L2,

47
00:02:52,135 --> 00:02:54,445
également connue
sous le nom de "perte de poids".

48
00:02:54,825 --> 00:02:56,710
Pour rappel, nous tentons de conserver

49
00:02:56,710 --> 00:02:58,850
des valeurs pondérales
proches de l'origine.

50
00:02:58,850 --> 00:03:03,270
Dans un espace 2D, le vecteur poids
serait confiné à l'intérieur d'un cercle.

51
00:03:03,270 --> 00:03:05,990
Vous pouvez facilement
étendre le concept à un espace 3D,

52
00:03:05,990 --> 00:03:08,340
mais au-delà
la visualisation est trop difficile.

53
00:03:08,340 --> 00:03:09,340
N'essayez même pas !

54
00:03:10,050 --> 00:03:12,870
Pour être tout à fait honnête,
en machine learning,

55
00:03:12,870 --> 00:03:14,930
nous trichons un peu
avec les mathématiques.

56
00:03:14,930 --> 00:03:18,920
Nous utilisons le carré de la norme L2
pour simplifier le calcul des dérivées.

57
00:03:20,090 --> 00:03:23,087
Notez qu'il y a ici un nouveau paramètre,
le paramètre "lambda".

58
00:03:23,087 --> 00:03:26,525
Il s'agit d'une valeur scalaire simple
qui nous permet de contrôler

59
00:03:26,525 --> 00:03:31,581
l'équilibre entre simplicité du modèle et
minimisation des erreurs d'entraînement.

60
00:03:33,514 --> 00:03:37,730
C'est un autre paramètre de réglage
qui doit être explicitement défini.

61
00:03:37,730 --> 00:03:41,130
Malheureusement, la meilleure valeur
pour un problème spécifique dépend

62
00:03:41,130 --> 00:03:42,400
des données.

63
00:03:42,830 --> 00:03:47,220
Nous devons donc définir ce paramètre
manuellement ou automatiquement

64
00:03:47,220 --> 00:03:50,170
à l'aide d'un outil
de réglages d'hyperparamètres,

65
00:03:50,170 --> 00:03:52,340
dont je vous parlerai
dans le prochain module.

66
00:03:53,840 --> 00:03:56,170
Pour appliquer la régularisation L1,

67
00:03:56,170 --> 00:04:00,430
il suffit de remplacer la norme L2
par la norme L1.

68
00:04:00,430 --> 00:04:03,370
Attention toutefois,
le résultat pourrait être très différent.

69
00:04:04,560 --> 00:04:08,820
La régularisation L1 se traduit
par des solutions clairsemées.

70
00:04:08,970 --> 00:04:12,330
Dans le présent contexte, le terme
"clairsemées" fait référence au fait

71
00:04:12,330 --> 00:04:15,680
que certains des poids auront in fine
une valeur optimale égale à zéro.

72
00:04:15,680 --> 00:04:18,670
Vous rappelez-vous de la forme en diamant
de la zone optimale ?

73
00:04:18,670 --> 00:04:21,559
Cette propriété de la régularisation L1
utilise intensivement

74
00:04:21,559 --> 00:04:23,700
un mécanisme
de sélection de caractéristiques.

75
00:04:23,700 --> 00:04:26,788
La sélection de caractéristiques
simplifie les problématiques ML,

76
00:04:26,788 --> 00:04:30,070
car elle permet de ramener
un sous-ensemble de poids à zéro.

77
00:04:30,070 --> 00:04:33,212
Vous pouvez ainsi identifier
les sous-ensembles de caractéristiques

78
00:04:33,212 --> 00:04:35,332
impossibles à supprimer en toute sécurité.