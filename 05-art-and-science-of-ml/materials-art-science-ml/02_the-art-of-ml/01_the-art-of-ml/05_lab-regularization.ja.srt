1
00:00:00,000 --> 00:00:07,245
このラボの目標はL1とL2の正則化を体験し
その効果を視覚的に確認することでした

2
00:00:07,245 --> 00:00:09,685
結果を検討しましょう

3
00:00:09,685 --> 00:00:13,995
このリンクを使用して
TensorFlow Playgroundを起動しました

4
00:00:13,995 --> 00:00:18,800
トレーニングループを始める前に
データセットにノイズを30追加しました

5
00:00:18,800 --> 00:00:25,030
X1とX2を特徴として使用しただけではなく
特徴クロスも使用しました

6
00:00:25,030 --> 00:00:29,685
最初に正則化せずにトレーニングを試して
モデルのパフォーマンスを見ました

7
00:00:29,685 --> 00:00:33,305
予想どおり トレーニング誤差は
きれいに収束します

8
00:00:33,305 --> 00:00:35,500
しかしテスト誤差は高いままです

9
00:00:35,500 --> 00:00:37,925
トレーニングモデルの形状に注意してください

10
00:00:37,925 --> 00:00:41,010
青い部分の奇妙な形に気付きますか

11
00:00:41,010 --> 00:00:44,350
トレーニングデータ内の
すべてのノイズを学習するため

12
00:00:44,350 --> 00:00:47,680
明らかにモデル自体が過剰適合しています

13
00:00:47,680 --> 00:00:50,455
悪いモデルができてしまいました

14
00:00:50,455 --> 00:00:52,635
このモデルは一般化できません

15
00:00:52,635 --> 00:00:57,530
次に強制的に「オッカムの剃刀」を
モデルに適用して簡潔にしました

16
00:00:57,530 --> 00:01:02,440
複雑さにペナルティを課す方法のひとつは
L1正則化の適用でしたね

17
00:01:02,440 --> 00:01:06,210
その後 
パフォーマンスはずっと向上しました

18
00:01:06,210 --> 00:01:09,770
ノイズが消えると
青い形はずっと滑らかになりました

19
00:01:09,770 --> 00:01:12,570
テスト誤差もきれいに収束しました

20
00:01:12,570 --> 00:01:14,635
これは明らかに優れたモデルです

21
00:01:14,635 --> 00:01:18,570
私のモデルが無視した特徴にも
注意を払ってください

22
00:01:18,570 --> 00:01:26,730
X1、X2、X1×X2から出る線が
ないことに注目してください

23
00:01:26,730 --> 00:01:31,630
L1正則化は特徴選択メカニズムとして
使えることを思い出してください

24
00:01:31,630 --> 00:01:34,285
次にL2正則化を試行しました

25
00:01:34,285 --> 00:01:37,740
L1と異なり特徴選択はありません

26
00:01:37,740 --> 00:01:41,085
最も関連性がある特徴には
強い重み付けが関連付けられました

27
00:01:41,085 --> 00:01:45,135
しかし 残りの特徴は依然として
弱い重み付けが働いています

28
00:01:45,135 --> 00:01:48,035
これはスクリーンショットでは
見えないかもしれませんが

29
00:01:48,035 --> 00:01:56,440
ライブでの実行時には
X1、X2、X1×X2から出る線は動きました

30
00:01:56,440 --> 00:02:02,690
特徴の重み付けは その特徴から出ている線の
太さで可視化されるのでしたね

31
00:02:02,690 --> 00:02:05,220
変な湾曲もありませんでした

32
00:02:05,220 --> 00:02:07,190
テスト誤差はきれいで良好でした

33
00:02:07,190 --> 00:02:08,865
良いモデルに見えます

34
00:02:08,865 --> 00:02:17,590
次にモデルの簡潔さをもう少し高めるため
正則化率を0.1から0.3に上げました

35
00:02:17,590 --> 00:02:22,560
モデルのパフォーマンスは0.179から
0.160ポイントに改善しました

36
00:02:22,560 --> 00:02:27,825
そしてさらに正則化率を上げて
1に設定しました

37
00:02:27,825 --> 00:02:30,955
これは行きすぎで
モデルは何も学習できませんでした

38
00:02:30,955 --> 00:02:38,520
他のハイパーパラメータと同様に
正則化率の調整には時間と忍耐が必要です

39
00:02:38,520 --> 00:02:41,550
要するに複雑なモデルは使えません

40
00:02:41,550 --> 00:02:46,755
モデルを簡潔にする方法のひとつは
正則化の適用です

41
00:02:46,755 --> 00:02:53,390
そして許容できるパフォーマンスになるまで
正則化率を調整します

42
00:02:53,390 --> 00:02:56,910
このラボが正則化の概念を
知る助けになれば幸いです