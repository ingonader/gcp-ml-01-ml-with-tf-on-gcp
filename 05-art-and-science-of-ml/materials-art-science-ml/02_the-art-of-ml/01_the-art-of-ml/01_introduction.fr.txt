Bienvenue dans le premier module
du cinquième cours. Dans ce module, vous allez apprendre
l'art du machine learning. Nous examinerons les aspects du ML
dans lesquels intuition, jugement et expérimentation sont requis
pour trouver le bon équilibre et un modèle assez bon,
mais pas parfait. Tout est question de nuances. Rien n'est tout blanc ou tout noir. Vous allez apprendre
à généraliser votre modèle à l'aide de techniques de régularisation. Nous avons déjà parlé des problèmes
de surapprentissage et sous-apprentissage. Le but est de généraliser le modèle, pour qu'il soit aussi efficace
sur des données de test inconnues que sur les données d'entraînement. Cela implique souvent une augmentation
des erreurs d'entraînement, mais de nombreuses stratégies ML
permettent de pallier ce problème. Elles sont réunies
sous le terme "régularisation". Nous parlerons
des techniques les plus courantes et les appliquerons dans
notre environnement TensorFlow préféré. Je vous parlerai ensuite
des effets des hyperparamètres, tels que la taille des lots
et le rythme d'apprentissage, sur les performances de votre modèle. Vous les ajusterez manuellement
pour trouver le bon équilibre. Nous aborderons ensuite le vaste thème
de l'optimisation des modèles, et je vous parlerai
des algorithmes les plus courants. Vous apprendrez
à spécifier les méthodes d'optimisation dans votre code TensorFlow. Pour conclure ce module, vous allez vous familiariser
avec TensorFlow dans un atelier. Vous ajusterez manuellement les boutons
et constaterez leurs effets en action.