Nous savons que nous allons utiliser des méthodes de régularisation
qui pénalisent la complexité du modèle. Nous devons maintenant nous demander
comment mesurer cette complexité. Les méthodes de régularisation L1 et L2
représentent la complexité du modèle en tant que magnitude du vecteur de poids
et tentent de garder cela sous contrôle. Rappelez-vous qu'en algèbre linéaire, la magnitude d'un vecteur est représentée
par la fonction normative. Examinons rapidement
les fonctions normatives L1 et L2. Le vecteur de poids peut avoir
de multiples dimensions, mais il est plus facile de le visualiser
dans un espace bidimensionnel. Un vecteur avec w0=a et w1=b
ressemblerait ainsi à cette flèche verte. Mais quelle est la magnitude
de ce vecteur ? Vous pourriez instantanément penser "C",
car vous appliquez la méthode la plus communément enseignée
à l'école secondaire, la distance euclidienne de l'origine. C correspondrait à la racine carrée
de la somme a² + b². En algèbre linéaire,
on appelle cela la "norme L2". Pour la représenter,
on utilise des barres verticales doubles et l'indice 2, ou aucun indice,
car 2 est la valeur par défaut. La norme L2 est calculée comme suit : racine carrée de la somme
des valeurs au carré de toutes les composantes du vecteur. Mais ce n'est pas la seule méthode
pour calculer la magnitude d'un vecteur. Une autre méthode couramment employée
est la norme L1. La norme L1 est calculée comme suit :
somme des valeurs absolues de a et b, ce qui correspond
au tracé jaune sur ce graphique. Souvenez-vous que nous cherchons un moyen de définir
la complexité du modèle. Nous avons employé les normes L1 et L2
en tant que méthodes de régularisation. Ici, la complexité du modèle est mesurée
sous la forme d'un vecteur de poids. En d'autres termes, si nous maintenons
la magnitude du vecteur de poids à un niveau inférieur à une certaine
valeur, nous atteignons notre objectif. Voyons maintenant ce que signifie
concrètement le fait que la norme L2 de notre vecteur de poids soit inférieure
à une certaine valeur, par exemple 1. Comme L2 correspond à
la distance euclidienne de l'origine, le vecteur devrait être délimité par
un cercle de rayon 1 centré sur l'origine. Lorsque nous tentons de maintenir
la norme L1 sous une certaine valeur, la zone dans laquelle le vecteur de poids
peut résider correspond au diamant jaune. Le plus important à retenir ici est que,
quand vous appliquez la régularisation L1, la valeur optimale de certains poids
peut au final être égale à zéro. La forme extrême de "diamant"
de cette région optimale est intéressante, car elle est totalement différente
de la forme circulaire lisse offerte par la régularisation L2. Mais revenons au problème
qui nous préoccupe : comment régulariser notre modèle
à l'aide d'une norme vectorielle ? Voici comment vous devez appliquer
la régularisation L2, également connue
sous le nom de "perte de poids". Pour rappel, nous tentons de conserver des valeurs pondérales
proches de l'origine. Dans un espace 2D, le vecteur poids
serait confiné à l'intérieur d'un cercle. Vous pouvez facilement
étendre le concept à un espace 3D, mais au-delà
la visualisation est trop difficile. N'essayez même pas ! Pour être tout à fait honnête,
en machine learning, nous trichons un peu
avec les mathématiques. Nous utilisons le carré de la norme L2
pour simplifier le calcul des dérivées. Notez qu'il y a ici un nouveau paramètre,
le paramètre "lambda". Il s'agit d'une valeur scalaire simple
qui nous permet de contrôler l'équilibre entre simplicité du modèle et
minimisation des erreurs d'entraînement. C'est un autre paramètre de réglage
qui doit être explicitement défini. Malheureusement, la meilleure valeur
pour un problème spécifique dépend des données. Nous devons donc définir ce paramètre
manuellement ou automatiquement à l'aide d'un outil
de réglages d'hyperparamètres, dont je vous parlerai
dans le prochain module. Pour appliquer la régularisation L1, il suffit de remplacer la norme L2
par la norme L1. Attention toutefois,
le résultat pourrait être très différent. La régularisation L1 se traduit
par des solutions clairsemées. Dans le présent contexte, le terme
"clairsemées" fait référence au fait que certains des poids auront in fine
une valeur optimale égale à zéro. Vous rappelez-vous de la forme en diamant
de la zone optimale ? Cette propriété de la régularisation L1
utilise intensivement un mécanisme
de sélection de caractéristiques. La sélection de caractéristiques
simplifie les problématiques ML, car elle permet de ramener
un sous-ensemble de poids à zéro. Vous pouvez ainsi identifier
les sous-ensembles de caractéristiques impossibles à supprimer en toute sécurité.