Das kennen Sie wahrscheinlich schon. Sie sollten es im zweiten Kurs
mit der Einführung in ML gesehen haben. Wir haben gelernt, dass ML-Modelle
mathematische Funktionen mit Parametern und Hyperparametern sind. Ein Parameter ist eine reelle Variable
und ändert sich beim Modelltraining wie auch die Gewichtungen und
Verzerrungen, die wir schon kennen. Ein Hyperparameter hingegen ist eine
vor dem Training festgelegte Einstellung, die sich danach nicht mehr ändert. Beispiele für Hyperparameter sind
Lernrate, Regulierungsrate, Batchgröße, Anzahl versteckter Ebenen im neuronalen
Netz und Anzahl Neuronen auf jeder Ebene. Da Sie nun die Unterschiede zwischen
Parametern und Hyperparametern kennen, wollen wir uns den
Hyperparametern zuwenden. Parameter werden durch den
Trainingsalgorithmus angepasst. Die Hyperparameter
müssen wir richtig festlegen. Im vorherigen Modul haben wir
einige Hyperparameter manuell geändert. Zum Beispiel haben wir gelernt, dass
Batchgröße und Lernrate wichtig sind. Hier habe ich einige Diagramme aus
Andrej Karpathys großartigem Artikel, den ich sehr empfehlen kann. Er visualisiert das Problem sehr gut. Sie sehen auf der linken Seite,
dass bei geringer Lernrate, wie bei dem blauen Graphen hier, 
Verbesserungen linear sind. Aber Sie erzielen oft nicht
die bestmögliche Leistung. Bei einer hohen Lernrate,
wie im grünen Graphen hier, erzielen Sie zunächst
eine exponentielle Verbesserung, aber oft nicht die bestmögliche Leistung. Einer sehr hohe Lernrate, der gelbe
Graph, führt manchmal nirgendwohin. Oft gibt es eine perfekte Lernrate, wie z. B. die rote hier. Aber sie kommt nur selten vor. Was sagen diese
Graphen über die Batchgröße aus? Auf der rechten Seite sehen Sie
eine Verlustkurve mit hohem Rauschen. Das liegt an der geringen Batchgröße. Sie wissen inzwischen,
dass eine zu hohe Batchgröße die Vorgänge deutlich verlangsamen kann. Diese Graphen sind
im Verhältnis zu Epochen dargestellt, doch TensorFlow kann mit Epochen nicht viel anfangen. Sie müssen die Epochen herausfinden,
indem Sie berechnen, wie viele Schritte mit einer bestimmten
Batchgröße einer Epoche entsprechen. Das heißt, Sie müssen herausfinden, wie viele Schritte Sie
mit einer bestimmten Batchgröße benötigen, um Ihr Dataset einmal zu durchlaufen.