1
00:00:00,000 --> 00:00:04,605
Practiquemos con la redes neuronales
y el TensorFlow Playground.

2
00:00:04,605 --> 00:00:07,065
En este lab de zona de pruebas
para redes neuronales

3
00:00:07,065 --> 00:00:08,580
usaremos TensorFlow Playground

4
00:00:08,580 --> 00:00:11,310
para probar y crear redes
neuronales para aprender datos.

5
00:00:11,310 --> 00:00:13,710
Quiero que resuelva
estos problemas de dos formas.

6
00:00:13,710 --> 00:00:16,070
Primero, vamos a probar
entrenar los modelos

7
00:00:16,070 --> 00:00:17,850
con la ingeniería
de funciones manual.

8
00:00:17,850 --> 00:00:20,830
con la que usamos nuestros
conocimientos para intentar adivinar

9
00:00:20,830 --> 00:00:23,430
la combinación y transformación
de funciones correctas

10
00:00:23,430 --> 00:00:24,390
para aprender datos.

11
00:00:24,390 --> 00:00:25,990
Después, vamos a pasarle el mando

12
00:00:25,990 --> 00:00:27,570
al poder de las redes neuronales

13
00:00:27,570 --> 00:00:30,300
y agregaremos más capas y neuronas
con un conjunto simple

14
00:00:30,300 --> 00:00:34,065
de funciones de entrada para ver si puede
hacer la ingeniería de funciones sola.

15
00:00:34,065 --> 00:00:35,925
Bienvenidos al TensorFlow Playground

16
00:00:35,925 --> 00:00:38,490
En este lab, vamos a ver
si la ingeniería de funciones

17
00:00:38,490 --> 00:00:41,565
puede tener un mejor rendimiento
que las redes neuronales.

18
00:00:41,565 --> 00:00:43,820
Tengo la sensación de
que no sucederá.

19
00:00:43,820 --> 00:00:45,100
Investiguemos

20
00:00:45,860 --> 00:00:48,390
En este diagrama

21
00:00:48,390 --> 00:00:53,150
buscamos clasificar
estos puntos azules y naranjas.

22
00:00:53,150 --> 00:00:54,750
Es un problema de clasificación.

23
00:00:54,750 --> 00:00:57,840
Como verá, parecen
dos círculos concéntricos.

24
00:00:57,840 --> 00:01:00,000
Pero en este caso
hay mucha contaminación

25
00:01:00,000 --> 00:01:03,090
Una gran mezcla.

26
00:01:04,610 --> 00:01:09,340
Vamos a ver el rendimiento
de X1 y X2 en el entrenamiento.

27
00:01:10,840 --> 00:01:14,400
Como verá, no hay mucho aprendizaje.

28
00:01:14,400 --> 00:01:17,400
Está todo difuso y hay bastante blanco.

29
00:01:17,400 --> 00:01:19,640
No es definitivo

30
00:01:19,640 --> 00:01:22,060
de acuerdo con el ajusto de aquí: -101.

31
00:01:22,060 --> 00:01:25,220
No aprendió mucho,
Veamos si lo podemos mejorar.

32
00:01:25,220 --> 00:01:28,095
Con la ingeniería de funciones,
sé que este es un círculo.

33
00:01:28,095 --> 00:01:31,005
Así que hago X1 al cuadrado
y X2 al cuadrado

34
00:01:31,005 --> 00:01:34,040
y probaré eso.

35
00:01:34,980 --> 00:01:37,290
Ahora sí, parece una elipse.

36
00:01:37,780 --> 00:01:41,966
Eso significa que casi
está descifrando esta función.

37
00:01:42,880 --> 00:01:44,380
Sabemos que es un círculo

38
00:01:44,380 --> 00:01:45,750
pero hay mucha contaminación

39
00:01:45,750 --> 00:01:47,465
por lo que no es claro.

40
00:01:49,215 --> 00:01:52,120
Quizás pueda bajar
la pérdida de 0.275.

41
00:01:52,120 --> 00:01:53,900
Intentaré
deshacerme de X1 y X2

42
00:01:53,900 --> 00:01:56,583
las formas lineales.
intentémoslo ahora.

43
00:01:58,796 --> 00:01:59,865
2.85

44
00:02:00,720 --> 00:02:02,715
Tiene una forma más circular.

45
00:02:02,715 --> 00:02:05,790
Pero la pérdida de prueba
está un poco mejor.

46
00:02:06,890 --> 00:02:09,647
Veamos si podemos hacer lo mismo
con las redes neuronales.

47
00:02:09,647 --> 00:02:12,525
Volvamos a X1 y X2

48
00:02:12,525 --> 00:02:15,855
que, como vimos antes,
fueron deficientes.

49
00:02:15,855 --> 00:02:19,246
Agreguemos una capa oculta
y dos neuronas adicionales.

50
00:02:22,791 --> 00:02:27,975
Como puede ver, le resulta difícil
descifrar qué función es.

51
00:02:28,519 --> 00:02:31,950
El problema es que no hay
suficiente capacidad en estas dos neuronas

52
00:02:31,950 --> 00:02:34,615
ni una representación dimensional
lo suficientemente alta

53
00:02:34,615 --> 00:02:36,215
para aprender
esta distribución.

54
00:02:36,215 --> 00:02:37,995
Detengámonos aquí y veamos.

55
00:02:37,995 --> 00:02:39,150
Agreguemos otra neurona.

56
00:02:39,150 --> 00:02:42,250
Quizás sea la capacidad suficiente
para aprender esta función.

57
00:02:43,280 --> 00:02:44,270
Muy bien.

58
00:02:44,270 --> 00:02:49,635
Sigue sin funcionar bien.

59
00:02:52,965 --> 00:02:53,985
Miren eso.

60
00:02:53,985 --> 00:02:55,540
Le lleva mucho tiempo

61
00:02:55,540 --> 00:02:58,810
pero de a poco está descifrando
la forma de la función.

62
00:02:58,810 --> 00:03:02,540
Es una especie de rectángulo.

63
00:03:02,540 --> 00:03:06,440
Eso significa que [inaudible]

64
00:03:06,440 --> 00:03:10,355
de la cantidad de neuronas que
pueden representar esta distribución.

65
00:03:10,355 --> 00:03:13,540
Vemos si funciona mejor
con una sola neurona adicional.

66
00:03:16,308 --> 00:03:17,330
Miren ahora.

67
00:03:17,330 --> 00:03:19,020
Lo hizo mucho más rápido.

68
00:03:19,020 --> 00:03:21,000
Solo tenemos cuatro neuronas.

69
00:03:21,000 --> 00:03:25,192
Vemos qué pasa si agregamos
muchas neuronas adicionales.

70
00:03:27,534 --> 00:03:29,490
Configuremos
todo en cuatro.

71
00:03:30,754 --> 00:03:32,260
Veamos qué sucede.

72
00:03:33,373 --> 00:03:34,692
Entrenaré.

73
00:03:37,269 --> 00:03:38,921
Es bastante más lento.

74
00:03:38,921 --> 00:03:41,765
Hay más cantidad para procesar
con todas las capas

75
00:03:41,765 --> 00:03:44,005
Pero creo que lo logrará.

76
00:03:44,790 --> 00:03:47,290
Me preocupa que sobreajuste un poco.

77
00:03:48,524 --> 00:03:50,675
Ya no es una forma circular simple.

78
00:03:50,675 --> 00:03:52,480
Es una especie de polígono

79
00:03:52,480 --> 00:03:56,110
por lo que está sobreajustando los datos
y la pérdida de prueba no es buena

80
00:03:56,110 --> 00:03:58,055
está más alta que antes.

81
00:03:59,930 --> 00:04:01,950
Veamos otras distribuciones.

82
00:04:03,215 --> 00:04:05,910
Esta es la distribución exclusiva clásica

83
00:04:05,910 --> 00:04:09,260
en la que X e Y son positivos o negativos

84
00:04:09,260 --> 00:04:14,240
tenemos azules, y con
el "o exclusivo" está la clase naranja,

85
00:04:14,240 --> 00:04:17,540
Veamos si podemos aprender
solo con X1 y X2.

86
00:04:21,412 --> 00:04:23,069
Al igual que antes

87
00:04:23,069 --> 00:04:27,515
X1 y X2 no son lo suficientemente potentes
para poder describir esta función.

88
00:04:27,515 --> 00:04:29,480
Se ve cero en todo el tablero.

89
00:04:30,187 --> 00:04:33,223
Veamos si podemos descifrarlo
con la ingeniería de funciones.

90
00:04:34,410 --> 00:04:35,850
Con la ingeniería
de funciones

91
00:04:35,850 --> 00:04:38,475
ingresaré X1 y X2
porque sé que son correctos.

92
00:04:38,885 --> 00:04:40,461
Iniciemos el entrenamiento.

93
00:04:42,104 --> 00:04:46,205
La pérdida de prueba es 0.07.
Eso es excelente

94
00:04:46,951 --> 00:04:49,010
Lo encontró muy fácilmente

95
00:04:49,010 --> 00:04:52,220
aquí está el peso, 0.19.
Excelente.

96
00:04:52,220 --> 00:04:54,800
Hay un poco de contaminación
así que no es perfecto

97
00:04:54,800 --> 00:04:57,635
pero en gran parte
lo descifró muy bien.

98
00:04:58,344 --> 00:05:00,240
Veamos si el aprendizaje automático

99
00:05:00,240 --> 00:05:03,255
con redes neuronales
puede hacerlo mejor.

100
00:05:03,850 --> 00:05:06,330
Volveré a usar X1 y X2

101
00:05:06,330 --> 00:05:08,950
y agregaré una capa oculta.

102
00:05:08,950 --> 00:05:10,850
Ahora, lo probaré.

103
00:05:10,850 --> 00:05:13,440
Quiero conseguir
la menor cantidad posible.

104
00:05:13,440 --> 00:05:17,670
Así que intentaré usar
solo dos neuronas para aprender esto.

105
00:05:18,932 --> 00:05:19,920
Sin embargo,

106
00:05:19,920 --> 00:05:21,720
no logra descifrarlo.

107
00:05:21,720 --> 00:05:24,910
No tiene la complejidad ni la capacidad
suficiente en este modelo

108
00:05:24,910 --> 00:05:27,240
Detengámonos y agreguemos
una tercera neurona.

109
00:05:28,463 --> 00:05:30,631
Volvamos a entrenar.

110
00:05:33,826 --> 00:05:34,960
Como puede ver

111
00:05:34,960 --> 00:05:37,605
tiene dificultades
para aprender esta función.

112
00:05:37,605 --> 00:05:39,450
Quizás está en el perímetro

113
00:05:39,450 --> 00:05:42,260
y tengo que esperar un poco más
para que la aprenda.

114
00:05:42,260 --> 00:05:44,340
Pero parece estar atascado.

115
00:05:44,340 --> 00:05:46,875
Quizás con otra inicialización
se corrija.

116
00:05:46,875 --> 00:05:48,236
Veamos…

117
00:05:50,392 --> 00:05:52,065
Probamos todo

118
00:05:52,065 --> 00:05:54,020
y pareciera haber aprendido la función.

119
00:05:54,020 --> 00:05:57,930
Parece un reloj de arena en diagonal.

120
00:05:57,930 --> 00:06:00,540
Sin embargo, esa no es la función.

121
00:06:00,540 --> 00:06:02,115
La pérdida es mucho más alta.

122
00:06:02,115 --> 00:06:03,570
Probemos con cuatro

123
00:06:03,570 --> 00:06:05,386
para ver si funciona.

124
00:06:07,853 --> 00:06:10,040
Sigue pareciendo un reloj de arena

125
00:06:10,040 --> 00:06:12,800
pero se está convirtiendo en
una serie de cuadrados

126
00:06:12,800 --> 00:06:15,470
que es la forma real de la función.
Está mejorando.

127
00:06:16,328 --> 00:06:18,620
Probemos agregando otras más

128
00:06:18,620 --> 00:06:22,852
y veamos si sobreajusta.

129
00:06:28,556 --> 00:06:31,575
Es mucho más lento
y tiene pérdida de entrenamiento.

130
00:06:32,677 --> 00:06:36,425
Pero tienen más forma de cuadrados.

131
00:06:38,205 --> 00:06:39,910
Excelente.

132
00:06:45,150 --> 00:06:48,375
Probemos otro tipo de distribución.

133
00:06:49,465 --> 00:06:50,910
Aquí tenemos una espiral.

134
00:06:50,910 --> 00:06:53,500
Dos espirales,
una alrededor de la otra.

135
00:06:53,500 --> 00:06:55,713
Parece una imagen de la galaxia.

136
00:06:55,713 --> 00:06:58,810
Veamos si se puede entrenar
con X1 y X2.

137
00:06:59,490 --> 00:07:01,080
Dudo mucho que sea posible.

138
00:07:02,241 --> 00:07:03,580
Como se puede ver aquí

139
00:07:03,580 --> 00:07:05,885
que no logró aprender
la distribución para nada.

140
00:07:05,885 --> 00:07:07,790
Está muy cerca de cero

141
00:07:07,790 --> 00:07:10,035
y no puede decidir
qué es cada cosa.

142
00:07:10,035 --> 00:07:12,930
Podemos probar usar
algo de ingeniería de funciones.

143
00:07:13,681 --> 00:07:14,972
Probemos.

144
00:07:15,700 --> 00:07:16,866
¿Qué les parece?

145
00:07:17,144 --> 00:07:19,690
Probemos con círculos.

146
00:07:20,977 --> 00:07:22,710
No funciona.
Agreguemos esto.

147
00:07:22,710 --> 00:07:24,120
El seno y el coseno

148
00:07:24,120 --> 00:07:27,178
o seno(X1) y seno(X2).

149
00:07:28,194 --> 00:07:31,570
Tengo seis funciones sin procesar aquí

150
00:07:31,570 --> 00:07:33,045
y pareciera descifrarlo

151
00:07:33,045 --> 00:07:34,230
como se puede ver arriba

152
00:07:34,230 --> 00:07:36,390
y un poco en esta parte.

153
00:07:36,390 --> 00:07:39,570
Hay una brecha grande aquí
y no sé dónde está yendo.

154
00:07:39,570 --> 00:07:43,370
Se está extrapolando mucho aquí.

155
00:07:43,370 --> 00:07:45,000
No funcionó muy bien.

156
00:07:45,000 --> 00:07:46,830
Está estancado.

157
00:07:47,450 --> 00:07:50,245
Veamos si lo podemos hacer mejor
con las redes neuronales.

158
00:07:50,245 --> 00:07:52,150
Desactivemos todo esto

159
00:07:52,949 --> 00:07:54,350
y agreguemos una capa oculta.

160
00:07:54,350 --> 00:07:57,100
Comencemos con dos neuronas
y veamos si funciona.

161
00:07:59,307 --> 00:08:03,515
Como se ve aquí, no es mucho mejor
que con X1 y X2 simplemente.

162
00:08:04,457 --> 00:08:06,990
No hay suficiente capacidad
para aprender este modelo.

163
00:08:06,990 --> 00:08:09,602
Probemos con tres y veamos si aprende.

164
00:08:12,800 --> 00:08:16,615
Funciona un poco mejor que antes
con algo de extrapolación aquí.

165
00:08:16,615 --> 00:08:19,160
Sin embargo, no es mejor
que con las seis o siete

166
00:08:19,160 --> 00:08:21,749
funciones activadas aquí.

167
00:08:25,267 --> 00:08:27,310
Agreguemos una neurona más

168
00:08:29,058 --> 00:08:30,558
y otra capa.

169
00:08:31,645 --> 00:08:33,470
Veamos si así funciona.

170
00:08:34,752 --> 00:08:37,730
Muy bien. Tenemos una pérdida
de entrenamiento

171
00:08:37,730 --> 00:08:40,639
muy baja, pero la pérdida
de prueba no es muy buena.

172
00:08:41,509 --> 00:08:44,148
Está como atascado.

173
00:08:45,300 --> 00:08:48,695
Agreguemos más capas ocultas.

174
00:08:49,682 --> 00:08:51,719
Configurémoslas en cuatro.

175
00:08:52,011 --> 00:08:53,180
Quizás sean suficientes.

176
00:08:54,468 --> 00:08:56,240
Veamos qué obtenemos.

177
00:08:57,740 --> 00:08:59,170
Ambas descendieron un poco.

178
00:09:00,376 --> 00:09:04,035
Pero no ha tomado una decisión,
ya que toda la pantalla está en blanco.

179
00:09:04,794 --> 00:09:07,190
Allí está, tengo un punto de inflexión.

180
00:09:07,758 --> 00:09:09,630
La pérdida disminuyó mucho.

181
00:09:11,760 --> 00:09:15,035
Pero la pérdida de prueba está subiendo.

182
00:09:16,350 --> 00:09:19,660
Y ahora quedó plana.
No tiene la capacidad suficiente.

183
00:09:20,895 --> 00:09:24,350
Configuremos el máximo y agreguemos
ocho neuronas en cada capa.

184
00:09:24,350 --> 00:09:29,290
Ojalá sean suficientes para aprender
esta función compleja y contaminada.

185
00:09:31,158 --> 00:09:32,156
Muy bien.

186
00:09:33,754 --> 00:09:35,728
Iniciemos el entrenamiento.

187
00:09:37,525 --> 00:09:40,920
Va muy lento con este entrenamiento.

188
00:09:41,704 --> 00:09:45,880
Esperemos que encuentre una forma
de descifrar esta función.

189
00:09:47,700 --> 00:09:49,880
La pérdida de entrenamiento
está descendiendo.

190
00:09:49,880 --> 00:09:52,099
La pérdida de prueba está aumentando.

191
00:10:01,609 --> 00:10:04,220
La pérdida de prueba se está nivelando.

192
00:10:06,386 --> 00:10:07,640
Cuando realicen esto

193
00:10:07,640 --> 00:10:09,575
sus resultados pueden variar bastante

194
00:10:09,575 --> 00:10:11,963
por la regularización
aleatoria de la red.

195
00:10:12,170 --> 00:10:13,710
Probemos otra cosa.

196
00:10:17,558 --> 00:10:20,250
Quizás sea un poco más prometedora.

197
00:10:27,075 --> 00:10:29,195
Esta parece ser un poco más prometedora.

198
00:10:30,707 --> 00:10:33,389
Lo que está haciendo
es aprender estas formas de aquí.

199
00:10:34,188 --> 00:10:35,473
Rellenando.

200
00:10:37,948 --> 00:10:42,259
Parece que sobreajustamos porque
la pérdida de prueba se está apartando.

201
00:10:42,455 --> 00:10:43,770
Eso es un problema.

202
00:10:51,124 --> 00:10:52,200
Listo.

203
00:10:52,200 --> 00:10:53,715
Como se puede ver

204
00:10:53,715 --> 00:10:55,795
incluso con esta cantidad de red

205
00:10:55,795 --> 00:10:59,000
no podemos aprender
bien esta distribución.

206
00:10:59,000 --> 00:11:01,305
Obtenemos todas
estas extrapolaciones

207
00:11:02,741 --> 00:11:04,509
y estas estimaciones amplias.

208
00:11:04,509 --> 00:11:07,180
Eso no tendrá un buen resultado
en la pérdida de prueba.

209
00:11:07,180 --> 00:11:08,400
Veamos ahora.

210
00:11:08,400 --> 00:11:10,799
La pérdida de prueba
está bajando de pronto.

211
00:11:10,825 --> 00:11:11,965
Excelente.

212
00:11:21,660 --> 00:11:24,173
Está descifrando más
la función aprendida.

213
00:11:25,016 --> 00:11:29,046
Pero va muy lento
dado que la red es tan grande.

214
00:11:33,232 --> 00:11:34,965
Entre cada una de estas capas

215
00:11:34,965 --> 00:11:37,505
hay 64 pesos

216
00:11:37,505 --> 00:11:39,240
porque tengo seis capas

217
00:11:39,240 --> 00:11:41,850
es decir, 6 por 64.

218
00:11:41,850 --> 00:11:45,885
Sin incluir los pesos entre
la capa de función y la capa superior.

219
00:11:47,190 --> 00:11:49,482
Donde hay ocho entre cada una.

220
00:11:52,067 --> 00:11:54,255
Listo. Excelente.

221
00:11:54,895 --> 00:11:57,020
Está aprendiendo
esta función bastante bien.

222
00:11:57,020 --> 00:11:59,470
Sin embargo, estas extrapolaciones

223
00:11:59,470 --> 00:12:00,840
e interpolaciones de aquí

224
00:12:00,840 --> 00:12:05,162
como este pico naranja
que ingresa en la espiral.

225
00:12:09,025 --> 00:12:11,300
Pero está mejorando
un poco con el tiempo.

226
00:12:11,300 --> 00:12:13,640
La pérdida de prueba sigue bajando.

227
00:12:14,428 --> 00:12:18,210
Sin embargo, esta forma
significa mucho sobreajuste.

228
00:12:23,030 --> 00:12:24,873
Listo.

229
00:12:25,719 --> 00:12:30,335
Finalmente, pudo encontrar las formas
de todo esto con las redes neuronales

230
00:12:30,335 --> 00:12:33,140
que a veces lo descifra mejor

231
00:12:33,140 --> 00:12:36,200
o al menos descifra,
su forma

232
00:12:36,200 --> 00:12:38,200
como en el caso de la espiral.