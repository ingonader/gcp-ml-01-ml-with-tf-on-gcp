1
00:00:00,480 --> 00:00:04,150
Bonjour, je m'appelle Ryan. Je suis chercheur
en machine learning chez Google,

2
00:00:04,150 --> 00:00:09,180
et j'adore appliquer les maths et le ML
au big data pour mieux comprendre le monde.

3
00:00:09,180 --> 00:00:14,446
Après avoir couvert l'art du ML,
nous allons maintenant parler de science,

4
00:00:14,446 --> 00:00:17,590
notamment des réseaux de neurones
et des pratiques d'apprentissage.

5
00:00:17,590 --> 00:00:20,220
Initialement, nous avons traité
de la régularisation L2,

6
00:00:20,220 --> 00:00:22,610
qui aide à réduire
les pondérations de paramètres,

7
00:00:22,610 --> 00:00:26,620
et de l'incidence du taux d'apprentissage
et de la taille de lot sur l'apprentissage.

8
00:00:26,620 --> 00:00:29,190
Nous avons alors abordé
le réglage des hyperparamètres,

9
00:00:29,190 --> 00:00:31,340
qui est une boucle d'optimisation externe,

10
00:00:31,340 --> 00:00:35,540
pour identifier les hyperparamètres permettant
d'obtenir le modèle généralisable optimal.

11
00:00:35,540 --> 00:00:41,530
Nous avons aussi appris à effectuer
la régularisation L1 et un arrêt prématuré

12
00:00:41,530 --> 00:00:46,010
pour créer des modèles généralisables creux,
sans oublier la régression logistique

13
00:00:46,010 --> 00:00:48,820
et en quoi elle peut influer
sur les performances du modèle.

14
00:00:48,820 --> 00:00:52,016
Maintenant, nous allons expliquer
la science des réseaux de neurones

15
00:00:52,016 --> 00:00:53,934
et les bonnes pratiques d'apprentissage.

16
00:00:53,934 --> 00:00:58,064
Enfin, nous aborderons les réseaux de neurones
à classes multiples et leurs emplois.