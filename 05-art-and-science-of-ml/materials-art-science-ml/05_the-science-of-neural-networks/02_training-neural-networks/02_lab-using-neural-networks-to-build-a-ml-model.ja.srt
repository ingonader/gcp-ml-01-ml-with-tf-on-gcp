1
00:00:00,000 --> 00:00:02,960
では新しい知識を実践して

2
00:00:02,960 --> 00:00:06,035
TensorFlowでNNを使い
MLモデルを構築します

3
00:00:06,035 --> 00:00:10,380
NNを使ってMLモデルを構築する
新しいラボを始めます

4
00:00:10,380 --> 00:00:12,840
このラボでは準備済みのEstimator

5
00:00:12,840 --> 00:00:15,700
DNNReggressorクラスを
TensorFlowで使用して

6
00:00:15,700 --> 00:00:19,205
多数の特徴を基に住宅費の平均値を予測します

7
00:00:19,205 --> 00:00:22,500
データは国勢調査データに基づいています

8
00:00:22,500 --> 00:00:24,690
このデータは街区レベルなので

9
00:00:24,690 --> 00:00:27,925
特徴はその街区の総部屋数や

10
00:00:27,925 --> 00:00:32,685
その街区の総住居者数を表します
コードに戻ります

11
00:00:32,685 --> 00:00:35,880
コードを詳細に見ながらTensorFlowで

12
00:00:35,880 --> 00:00:39,195
DNNクラスのRegressorを使って
NNを構築する方法を説明します

13
00:00:39,195 --> 00:00:43,490
ここではNNの使用方法を学びます

14
00:00:43,490 --> 00:00:48,530
カリフォルニアの国勢調査に基づく
住宅データを使います

15
00:00:48,530 --> 00:00:50,230
データは街区レベルなので

16
00:00:50,230 --> 00:00:51,735
特徴を表します

17
00:00:51,735 --> 00:00:53,150
その街区の総部屋数と

18
00:00:53,150 --> 00:00:55,990
その街区の総住居者数です

19
00:00:55,990 --> 00:00:59,375
この2つの特徴で住宅価値を評価しましょう

20
00:00:59,375 --> 00:01:01,020
まず設定します

21
00:01:01,020 --> 00:01:03,915
最初のセルで必要なライブラリをロードします

22
00:01:03,915 --> 00:01:06,185
math、shutil、numpy

23
00:01:06,185 --> 00:01:09,260
pandas, tensorflowをインポートします

24
00:01:09,260 --> 00:01:13,075
多数の結果を得るため
verbosityをinfoにします

25
00:01:13,075 --> 00:01:16,135
pandasの再編成の設定を確認します

26
00:01:16,135 --> 00:01:20,085
ここでこのURLからデータセットを
ロードします

27
00:01:20,085 --> 00:01:23,940
住宅トレーニングデータをpandaの
データフレームに入れます

28
00:01:23,940 --> 00:01:26,125
次はデータを精査します

29
00:01:26,125 --> 00:01:29,235
作業前に少しデータを見ておきます

30
00:01:29,235 --> 00:01:32,220
各列に統計値のまとめを出力します

31
00:01:32,220 --> 00:01:33,430
平均、標準偏差

32
00:01:33,430 --> 00:01:36,720
最大、最小、分位点などが含まれます

33
00:01:36,720 --> 00:01:40,130
まずデータフレームの見出しを出力します

34
00:01:40,130 --> 00:01:44,200
例としてデータセットの最初の5行のみを
出力します

35
00:01:44,200 --> 00:01:47,050
緯度、経度、平均住宅築年数

36
00:01:47,050 --> 00:01:50,020
総部屋数、総寝室数、住居者数、世帯数

37
00:01:50,020 --> 00:01:52,535
平均収入、平均住宅価値です

38
00:01:52,535 --> 00:01:54,140
これがここのラベルです

39
00:01:54,140 --> 00:01:56,725
こうした特徴で予測することです

40
00:01:56,725 --> 00:01:59,190
では実際の予測値を見てみましょう

41
00:01:59,190 --> 00:02:01,115
df.describeの処理です

42
00:02:01,115 --> 00:02:02,630
表示されるのはカウント

43
00:02:02,630 --> 00:02:04,130
平均、標準偏差

44
00:02:04,130 --> 00:02:06,540
最小値、25パーセンタイル

45
00:02:06,540 --> 00:02:09,699
50パーセンタイル、75パーセンタイル
最大値です

46
00:02:09,699 --> 00:02:13,865
すべてがかなり単純に見えますが

47
00:02:13,865 --> 00:02:16,050
ここはまだ街区レベルです

48
00:02:16,050 --> 00:02:20,830
これを住宅レベルで行う方法を見つける必要が
あります

49
00:02:20,830 --> 00:02:24,480
これを行うには
部屋数を知りたい場合

50
00:02:24,480 --> 00:02:27,490
街区全体の総部屋数を

51
00:02:27,490 --> 00:02:30,050
その街区の総世帯数で割ります

52
00:02:30,050 --> 00:02:33,215
これで住宅当たりの平均部屋数がわかります

53
00:02:33,215 --> 00:02:34,870
寝室も同様です

54
00:02:34,870 --> 00:02:36,695
寝室数を調べたら

55
00:02:36,695 --> 00:02:41,110
街区全体の総寝室数を

56
00:02:41,110 --> 00:02:44,215
その街区の世帯数で割って平均寝室数を求めます

57
00:02:44,215 --> 00:02:47,505
住宅当たりの人数では

58
00:02:47,505 --> 00:02:49,760
その街区の総住民数を

59
00:02:49,760 --> 00:02:51,775
世帯数で割ります

60
00:02:51,775 --> 00:02:54,190
その住宅の平均居住者数と同じです

61
00:02:54,190 --> 00:02:56,785
df.describeを行うには

62
00:02:56,785 --> 00:02:58,755
ここの元の列を見ます

63
00:02:58,755 --> 00:03:02,050
ただしここには新しい列を追加しています

64
00:03:02,050 --> 00:03:04,560
これは住宅当たりの平均部屋数

65
00:03:04,560 --> 00:03:06,330
住宅当たりの平均寝室数

66
00:03:06,330 --> 00:03:08,875
住宅当たりの平均住居者数です

67
00:03:08,875 --> 00:03:15,005
次はこれらの住居者統計値をドロップし

68
00:03:15,005 --> 00:03:17,890
街区レベルの統計値

69
00:03:17,890 --> 00:03:19,630
総部屋数、総寝室数

70
00:03:19,630 --> 00:03:24,850
居住者数、世帯数など
すべての列を定位置にドロップします

71
00:03:24,850 --> 00:03:26,345
新データフレームはなし

72
00:03:26,345 --> 00:03:27,670
df.describeでは

73
00:03:27,670 --> 00:03:30,825
新しい特徴はここにあります

74
00:03:30,825 --> 00:03:32,440
古い特徴はそこです

75
00:03:32,440 --> 00:03:36,260
これは今回のラベルです
以前使ったものはもうありません

76
00:03:36,260 --> 00:03:39,025
これは住宅レベルのビューです

77
00:03:39,025 --> 00:03:42,300
ではNNモデルを構築して

78
00:03:42,300 --> 00:03:45,295
特徴データを適切なフォーマットに入れます

79
00:03:45,295 --> 00:03:48,565
ここで行うのは特徴列の作成です

80
00:03:48,565 --> 00:03:51,070
特徴列は基本的に

81
00:03:51,070 --> 00:03:54,360
使用するモデルの適切な表現にデータを入れます

82
00:03:54,360 --> 00:03:58,030
すでに浮動小数点表記になっていても

83
00:03:58,030 --> 00:04:03,745
列で浮動小数点になるかどうかを決定する
必要があります

84
00:04:03,745 --> 00:04:05,950
そしてここでは

85
00:04:05,950 --> 00:04:08,555
ご覧のようにループしています

86
00:04:08,555 --> 00:04:11,570
すべての列と平均住宅築年数

87
00:04:11,570 --> 00:04:13,130
平均収入、部屋数

88
00:04:13,130 --> 00:04:15,780
寝室数、住居者数です

89
00:04:15,780 --> 00:04:19,325
その後もう少し特徴エンジニアリングを行います

90
00:04:19,325 --> 00:04:23,299
longitudeという
新しい特徴列を作ります

91
00:04:23,299 --> 00:04:27,665
数値の経度が入る
bucketized_columnになり

92
00:04:27,665 --> 00:04:31,680
間隔は線形空間

93
00:04:31,680 --> 00:04:37,275
-124.3～-114.3の5刻みになります

94
00:04:37,275 --> 00:04:39,150
次に特徴列latitudeでも

95
00:04:39,150 --> 00:04:40,775
同じことを行います

96
00:04:40,775 --> 00:04:47,670
ただしlatitudeの範囲は32.5～42で
これに10のバケットが入ります

97
00:04:48,790 --> 00:04:53,555
これを行っているのは
カリフォルニアが縦長だからです

98
00:04:53,555 --> 00:04:56,150
そのためlatitudeの
バケット数が多く

99
00:04:56,150 --> 00:04:59,215
10バケットで
longitudeは5バケット

100
00:04:59,215 --> 00:05:02,215
特徴列の名前を出力します

101
00:05:02,215 --> 00:05:04,900
ここに平均収入、住宅当たりの人数

102
00:05:04,900 --> 00:05:06,810
部屋数、平均住居築年数

103
00:05:06,810 --> 00:05:09,315
経度、寝室数、緯度があります

104
00:05:09,315 --> 00:05:11,800
いいですね しかしまず

105
00:05:11,800 --> 00:05:15,210
これをトレーニングと評価データセットに
分割します

106
00:05:15,210 --> 00:05:19,810
これでトレーニングしながらモデルの進捗状況を
確認できます

107
00:05:19,810 --> 00:05:23,120
そのためにランダムマスクを作成し

108
00:05:23,120 --> 00:05:25,535
データフレーム長をチェックします

109
00:05:25,535 --> 00:05:28,885
多数のランダム値を

110
00:05:28,885 --> 00:05:30,565
一様分布から作成し

111
00:05:30,565 --> 00:05:32,200
値が0.8未満の場合は

112
00:05:32,200 --> 00:05:34,460
このマスクベクトルに保存します

113
00:05:34,460 --> 00:05:38,990
このマスクベクトルがデータフレームの長さで

114
00:05:38,990 --> 00:05:40,200
trueまたはfalseです

115
00:05:40,200 --> 00:05:43,085
これをブールマスクと呼びます

116
00:05:43,085 --> 00:05:45,555
ブールマスクをデータマスクに適用します

117
00:05:45,555 --> 00:05:49,195
このマスクがtrueだった場合は

118
00:05:49,195 --> 00:05:51,780
行がトレーニング済みデータフレームに入り

119
00:05:51,780 --> 00:05:54,805
値がtrueでない場合は

120
00:05:54,805 --> 00:05:56,700
波形記号がここにありますが

121
00:05:56,700 --> 00:05:58,755
値は評価データフレームに入ります

122
00:05:58,755 --> 00:06:03,110
これにより80%が
トレーニングデータフレームに分割され

123
00:06:03,110 --> 00:06:06,195
残り20%のデータが評価データフレームに
入ります

124
00:06:06,195 --> 00:06:07,880
スケール因子もあります

125
00:06:07,880 --> 00:06:10,885
ご覧のように100,000です

126
00:06:10,885 --> 00:06:14,510
ここでラベルをスケーリングするためです

127
00:06:14,510 --> 00:06:16,460
ラベルが大きすぎます

128
00:06:16,460 --> 00:06:18,885
まったく異なるスケールがあります

129
00:06:18,885 --> 00:06:22,395
これらの範囲は10万やほぼ100万ですが

130
00:06:22,395 --> 00:06:26,740
これらはずっと小さく
浮動小数点数が1桁または2桁です

131
00:06:26,740 --> 00:06:28,950
ではそれを行います

132
00:06:28,950 --> 00:06:30,370
バッチサイズも作成して

133
00:06:30,370 --> 00:06:31,670
100に設定します

134
00:06:31,670 --> 00:06:35,080
各データフレームで同時に100行に設定します

135
00:06:35,080 --> 00:06:38,640
トレーニング中の入力関数も
作成する必要があります

136
00:06:38,640 --> 00:06:43,350
そこで適切なEstimator
pandas入力関数を使用します

137
00:06:43,350 --> 00:06:45,300
ここでxは特徴です

138
00:06:45,300 --> 00:06:48,900
これでテンソルの辞書を作成し

139
00:06:48,900 --> 00:06:50,430
その出力になります

140
00:06:50,430 --> 00:06:55,585
これがその列の平均住宅価値の
トレーニングデータフレームを変換します

141
00:06:55,585 --> 00:07:00,140
これをyに読み込み
これがラベルのテンソルになります

142
00:07:00,140 --> 00:07:01,810
エポックの数は1になり

143
00:07:01,810 --> 00:07:04,670
バッチサイズを基に
シャッフルします

144
00:07:04,670 --> 00:07:06,730
ここには

145
00:07:06,730 --> 00:07:08,800
評価の入力関数があります

146
00:07:08,800 --> 00:07:12,485
再度pandas入力関数を使って
処理を行います

147
00:07:12,485 --> 00:07:15,490
入力データフレームに
[inaudible]を使います

148
00:07:15,490 --> 00:07:16,990
shuffle = Falseにします

149
00:07:16,990 --> 00:07:18,855
再現性が必要なので

150
00:07:18,855 --> 00:07:22,360
評価セットをシャッフルしません

151
00:07:22,360 --> 00:07:24,855
ここでrmseという関数も作り

152
00:07:24,855 --> 00:07:27,930
モデルのRMSEを出力します

153
00:07:27,930 --> 00:07:31,905
その名前を呼び出し
関連する入力関数を呼び出します

154
00:07:31,905 --> 00:07:34,595
ここでは測定基準を作成します

155
00:07:34,595 --> 00:07:37,090
Estimatorのmodel.evaluateにします

156
00:07:37,090 --> 00:07:38,790
Estimatorはモデルです

157
00:07:38,790 --> 00:07:41,100
これを入力関数として渡します

158
00:07:41,100 --> 00:07:44,530
これが入力関数になり
print_rmseに渡されます

159
00:07:44,530 --> 00:07:47,190
これを1ステップで行います

160
00:07:47,510 --> 00:07:49,615
これに関する正しい情報は

161
00:07:49,615 --> 00:07:52,170
この測定基準がoutだということです

162
00:07:52,170 --> 00:07:53,480
dictionaryにします

163
00:07:53,480 --> 00:07:54,755
回帰問題があります

164
00:07:54,755 --> 00:07:57,100
そのため最後は損失

165
00:07:57,100 --> 00:07:59,850
平均損失、グローバルステップになります

166
00:07:59,850 --> 00:08:04,120
次にこのデータセットのRMSEを出力し
答えは

167
00:08:04,120 --> 00:08:05,950
平方根が必要です

168
00:08:05,950 --> 00:08:08,615
現在の平均損失はMSEです

169
00:08:08,615 --> 00:08:10,770
RMSEから平方根をチェックし

170
00:08:10,770 --> 00:08:13,645
ここでスケールによる乗算を行っています

171
00:08:13,645 --> 00:08:18,635
そのため正しい価格単位、平均住宅価値に
戻れます

172
00:08:18,635 --> 00:08:20,760
Linear Reggressorを準備します

173
00:08:20,760 --> 00:08:22,160
出力ディレクトリです

174
00:08:22,160 --> 00:08:24,960
ここにトレーニングのファイルが保存されます

175
00:08:24,960 --> 00:08:27,615
チェックポイントやイベントログ

176
00:08:27,615 --> 00:08:30,370
保存されたモデルなどです

177
00:08:30,370 --> 00:08:33,429
毎回新たに開始できるようこれを削除します

178
00:08:33,429 --> 00:08:35,294
このツリーのすべてを削除し

179
00:08:35,294 --> 00:08:37,380
フォルダを空にします

180
00:08:37,380 --> 00:08:39,985
カスタムオプティマイザを作成します

181
00:08:39,985 --> 00:08:41,850
これが線形回帰です
そこで

182
00:08:41,850 --> 00:08:44,250
Follow the Regularized Leader
オプティマイザを使用します

183
00:08:44,250 --> 00:08:46,530
通常これが最適な選択です

184
00:08:46,530 --> 00:08:49,280
学習率を0.01にして

185
00:08:49,280 --> 00:08:51,000
モデルを作成します

186
00:08:51,000 --> 00:08:52,370
Estimatorを作ります

187
00:08:52,370 --> 00:08:54,040
Linear Regressorです

188
00:08:54,040 --> 00:08:56,730
モデルディレクトリを渡します

189
00:08:56,730 --> 00:08:58,630
必要なものを入れ

190
00:08:58,630 --> 00:09:01,470
特徴列を入れて特徴列の値を渡します

191
00:09:01,470 --> 00:09:03,110
これらはそのテンソルです

192
00:09:03,110 --> 00:09:06,190
オプティマイザはカスタムの
Leaderです

193
00:09:06,190 --> 00:09:09,060
ここではトレーニングを
ステップの数だけ行います

194
00:09:09,060 --> 00:09:11,060
ここでのトレーニングは100回です

195
00:09:11,060 --> 00:09:12,940
データフレームとは異なります

196
00:09:12,940 --> 00:09:16,430
これはトレーニングを
100エポック行うという意味です

197
00:09:16,430 --> 00:09:18,565
model.trainを呼び出し

198
00:09:18,565 --> 00:09:20,140
入力関数を渡します

199
00:09:20,140 --> 00:09:21,740
トレーニングの入力関数です

200
00:09:21,740 --> 00:09:24,500
ステップ数はここで作成したステップ数です

201
00:09:24,500 --> 00:09:25,960
モデルをトレーニングします

202
00:09:25,960 --> 00:09:29,300
最後にモデルのRMSEを出力します

203
00:09:29,300 --> 00:09:33,100
評価の入力関数を呼び出します

204
00:09:33,100 --> 00:09:35,805
そのように評価の入力関数セットになります

205
00:09:35,805 --> 00:09:38,600
ご覧のようにトレーニングを行う場合

206
00:09:38,600 --> 00:09:41,210
ここにデフォルトのconfigがあり

207
00:09:41,210 --> 00:09:45,325
これを変更してチェックポイントを作成し
トレーニングプロセスを開始します

208
00:09:45,325 --> 00:09:46,800
ステップ1で損失を計算

209
00:09:46,800 --> 00:09:49,540
こうなります
次は1秒間に実施したステップ数

210
00:09:49,540 --> 00:09:51,270
トレーニングが進むと

211
00:09:51,270 --> 00:09:53,140
損失は低下するはずです

212
00:09:53,140 --> 00:09:59,175
ご覧のように評価の最終平均損失は0.93です

213
00:09:59,175 --> 00:10:01,590
グローバルステップは137

214
00:10:01,590 --> 00:10:04,345
総損失は3,141です

215
00:10:04,345 --> 00:10:10,000
評価は評価セットのスケールで乗算します

216
00:10:10,000 --> 00:10:14,315
RMSEは96,583ドルです

217
00:10:14,315 --> 00:10:17,855
RMSEは本質的に残余の標準偏差です

218
00:10:17,855 --> 00:10:19,750
残余では

219
00:10:19,750 --> 00:10:22,190
予測と実際のラベルに差があります

220
00:10:22,190 --> 00:10:25,370
次はDNNRegressorでの改善を
確認します

221
00:10:25,370 --> 00:10:27,095
すべて前と同じですが

222
00:10:27,095 --> 00:10:29,580
AdamOptimizerを使用します

223
00:10:29,580 --> 00:10:33,850
[inaudible]リーダーより
DNNReggressorに適しています

224
00:10:33,850 --> 00:10:38,100
またLinearRegressorから
DNNReggressorに変更します

225
00:10:38,100 --> 00:10:41,250
他はすべて前と同じように渡します

226
00:10:41,250 --> 00:10:43,830
ただし隠れユニットを追加します

227
00:10:43,830 --> 00:10:46,865
ここに1、2、3層あります

228
00:10:46,865 --> 00:10:49,170
隠れニューロンは最初の層には100

229
00:10:49,170 --> 00:10:50,975
2番目の層には50

230
00:10:50,975 --> 00:10:52,870
最終層に20あります

231
00:10:52,870 --> 00:10:54,735
特徴列も渡します

232
00:10:54,735 --> 00:10:56,370
作成したオプティマイザ

233
00:10:56,370 --> 00:10:58,215
今回はAdamを使います

234
00:10:58,215 --> 00:11:01,035
ドロップアウトは10%です

235
00:11:01,035 --> 00:11:03,240
これはドロップアウト確率で

236
00:11:03,240 --> 00:11:06,420
キープ確率ではなく
他の分離にあります

237
00:11:06,420 --> 00:11:09,230
また前と同じくステップ数も作成します

238
00:11:09,230 --> 00:11:11,760
前と同じくトレーニングし
RMSEを出力しました

239
00:11:11,760 --> 00:11:13,730
改善されるか見てみましょう

240
00:11:13,730 --> 00:11:15,380
既定のconfigのトレーニングでは

241
00:11:15,380 --> 00:11:18,100
すべてが前と同じように行われます

242
00:11:18,100 --> 00:11:19,890
最終ステップでは

243
00:11:19,890 --> 00:11:22,830
トレーニングの平均損失は0.67です

244
00:11:22,830 --> 00:11:27,175
これはすでに良い兆候です
以前の0.93より低下しました

245
00:11:27,175 --> 00:11:32,280
しかしこれのRMSEは81,974ドルです

246
00:11:32,280 --> 00:11:36,600
標準偏差は前回と比べてかなり小さくなりました

247
00:11:36,600 --> 00:11:38,900
このモデルが改善されました

248
00:11:38,900 --> 00:11:40,950
これをもっと複雑にして

249
00:11:40,950 --> 00:11:43,305
もっと複雑なアルゴリズムも使えます

250
00:11:43,305 --> 00:11:45,590
つまりNNを使えば

251
00:11:45,590 --> 00:11:49,050
線形回帰より高い性能を簡単に得られるという
ことです

252
00:11:49,120 --> 00:11:52,090
最後にこれをTensorBoardで呼び出し

253
00:11:52,090 --> 00:11:54,940
その進捗状況を確認できます