では新しい知識を実践して TensorFlowでNNを使い
MLモデルを構築します NNを使ってMLモデルを構築する
新しいラボを始めます このラボでは準備済みのEstimator DNNReggressorクラスを
TensorFlowで使用して 多数の特徴を基に住宅費の平均値を予測します データは国勢調査データに基づいています このデータは街区レベルなので 特徴はその街区の総部屋数や その街区の総住居者数を表します
コードに戻ります コードを詳細に見ながらTensorFlowで DNNクラスのRegressorを使って
NNを構築する方法を説明します ここではNNの使用方法を学びます カリフォルニアの国勢調査に基づく
住宅データを使います データは街区レベルなので 特徴を表します その街区の総部屋数と その街区の総住居者数です この2つの特徴で住宅価値を評価しましょう まず設定します 最初のセルで必要なライブラリをロードします math、shutil、numpy pandas, tensorflowをインポートします 多数の結果を得るため
verbosityをinfoにします pandasの再編成の設定を確認します ここでこのURLからデータセットを
ロードします 住宅トレーニングデータをpandaの
データフレームに入れます 次はデータを精査します 作業前に少しデータを見ておきます 各列に統計値のまとめを出力します 平均、標準偏差 最大、最小、分位点などが含まれます まずデータフレームの見出しを出力します 例としてデータセットの最初の5行のみを
出力します 緯度、経度、平均住宅築年数 総部屋数、総寝室数、住居者数、世帯数 平均収入、平均住宅価値です これがここのラベルです こうした特徴で予測することです では実際の予測値を見てみましょう df.describeの処理です 表示されるのはカウント 平均、標準偏差 最小値、25パーセンタイル 50パーセンタイル、75パーセンタイル
最大値です すべてがかなり単純に見えますが ここはまだ街区レベルです これを住宅レベルで行う方法を見つける必要が
あります これを行うには
部屋数を知りたい場合 街区全体の総部屋数を その街区の総世帯数で割ります これで住宅当たりの平均部屋数がわかります 寝室も同様です 寝室数を調べたら 街区全体の総寝室数を その街区の世帯数で割って平均寝室数を求めます 住宅当たりの人数では その街区の総住民数を 世帯数で割ります その住宅の平均居住者数と同じです df.describeを行うには ここの元の列を見ます ただしここには新しい列を追加しています これは住宅当たりの平均部屋数 住宅当たりの平均寝室数 住宅当たりの平均住居者数です 次はこれらの住居者統計値をドロップし 街区レベルの統計値 総部屋数、総寝室数 居住者数、世帯数など
すべての列を定位置にドロップします 新データフレームはなし df.describeでは 新しい特徴はここにあります 古い特徴はそこです これは今回のラベルです
以前使ったものはもうありません これは住宅レベルのビューです ではNNモデルを構築して 特徴データを適切なフォーマットに入れます ここで行うのは特徴列の作成です 特徴列は基本的に 使用するモデルの適切な表現にデータを入れます すでに浮動小数点表記になっていても 列で浮動小数点になるかどうかを決定する
必要があります そしてここでは ご覧のようにループしています すべての列と平均住宅築年数 平均収入、部屋数 寝室数、住居者数です その後もう少し特徴エンジニアリングを行います longitudeという
新しい特徴列を作ります 数値の経度が入る
bucketized_columnになり 間隔は線形空間 -124.3～-114.3の5刻みになります 次に特徴列latitudeでも 同じことを行います ただしlatitudeの範囲は32.5～42で
これに10のバケットが入ります これを行っているのは
カリフォルニアが縦長だからです そのためlatitudeの
バケット数が多く 10バケットで
longitudeは5バケット 特徴列の名前を出力します ここに平均収入、住宅当たりの人数 部屋数、平均住居築年数 経度、寝室数、緯度があります いいですね しかしまず これをトレーニングと評価データセットに
分割します これでトレーニングしながらモデルの進捗状況を
確認できます そのためにランダムマスクを作成し データフレーム長をチェックします 多数のランダム値を 一様分布から作成し 値が0.8未満の場合は このマスクベクトルに保存します このマスクベクトルがデータフレームの長さで trueまたはfalseです これをブールマスクと呼びます ブールマスクをデータマスクに適用します このマスクがtrueだった場合は 行がトレーニング済みデータフレームに入り 値がtrueでない場合は 波形記号がここにありますが 値は評価データフレームに入ります これにより80%が
トレーニングデータフレームに分割され 残り20%のデータが評価データフレームに
入ります スケール因子もあります ご覧のように100,000です ここでラベルをスケーリングするためです ラベルが大きすぎます まったく異なるスケールがあります これらの範囲は10万やほぼ100万ですが これらはずっと小さく
浮動小数点数が1桁または2桁です ではそれを行います バッチサイズも作成して 100に設定します 各データフレームで同時に100行に設定します トレーニング中の入力関数も
作成する必要があります そこで適切なEstimator
pandas入力関数を使用します ここでxは特徴です これでテンソルの辞書を作成し その出力になります これがその列の平均住宅価値の
トレーニングデータフレームを変換します これをyに読み込み
これがラベルのテンソルになります エポックの数は1になり バッチサイズを基に
シャッフルします ここには 評価の入力関数があります 再度pandas入力関数を使って
処理を行います 入力データフレームに
[inaudible]を使います shuffle = Falseにします 再現性が必要なので 評価セットをシャッフルしません ここでrmseという関数も作り モデルのRMSEを出力します その名前を呼び出し
関連する入力関数を呼び出します ここでは測定基準を作成します Estimatorのmodel.evaluateにします Estimatorはモデルです これを入力関数として渡します これが入力関数になり
print_rmseに渡されます これを1ステップで行います これに関する正しい情報は この測定基準がoutだということです dictionaryにします 回帰問題があります そのため最後は損失 平均損失、グローバルステップになります 次にこのデータセットのRMSEを出力し
答えは 平方根が必要です 現在の平均損失はMSEです RMSEから平方根をチェックし ここでスケールによる乗算を行っています そのため正しい価格単位、平均住宅価値に
戻れます Linear Reggressorを準備します 出力ディレクトリです ここにトレーニングのファイルが保存されます チェックポイントやイベントログ 保存されたモデルなどです 毎回新たに開始できるようこれを削除します このツリーのすべてを削除し フォルダを空にします カスタムオプティマイザを作成します これが線形回帰です
そこで Follow the Regularized Leader
オプティマイザを使用します 通常これが最適な選択です 学習率を0.01にして モデルを作成します Estimatorを作ります Linear Regressorです モデルディレクトリを渡します 必要なものを入れ 特徴列を入れて特徴列の値を渡します これらはそのテンソルです オプティマイザはカスタムの
Leaderです ここではトレーニングを
ステップの数だけ行います ここでのトレーニングは100回です データフレームとは異なります これはトレーニングを
100エポック行うという意味です model.trainを呼び出し 入力関数を渡します トレーニングの入力関数です ステップ数はここで作成したステップ数です モデルをトレーニングします 最後にモデルのRMSEを出力します 評価の入力関数を呼び出します そのように評価の入力関数セットになります ご覧のようにトレーニングを行う場合 ここにデフォルトのconfigがあり これを変更してチェックポイントを作成し
トレーニングプロセスを開始します ステップ1で損失を計算 こうなります
次は1秒間に実施したステップ数 トレーニングが進むと 損失は低下するはずです ご覧のように評価の最終平均損失は0.93です グローバルステップは137 総損失は3,141です 評価は評価セットのスケールで乗算します RMSEは96,583ドルです RMSEは本質的に残余の標準偏差です 残余では 予測と実際のラベルに差があります 次はDNNRegressorでの改善を
確認します すべて前と同じですが AdamOptimizerを使用します [inaudible]リーダーより
DNNReggressorに適しています またLinearRegressorから
DNNReggressorに変更します 他はすべて前と同じように渡します ただし隠れユニットを追加します ここに1、2、3層あります 隠れニューロンは最初の層には100 2番目の層には50 最終層に20あります 特徴列も渡します 作成したオプティマイザ 今回はAdamを使います ドロップアウトは10%です これはドロップアウト確率で キープ確率ではなく
他の分離にあります また前と同じくステップ数も作成します 前と同じくトレーニングし
RMSEを出力しました 改善されるか見てみましょう 既定のconfigのトレーニングでは すべてが前と同じように行われます 最終ステップでは トレーニングの平均損失は0.67です これはすでに良い兆候です
以前の0.93より低下しました しかしこれのRMSEは81,974ドルです 標準偏差は前回と比べてかなり小さくなりました このモデルが改善されました これをもっと複雑にして もっと複雑なアルゴリズムも使えます つまりNNを使えば 線形回帰より高い性能を簡単に得られるという
ことです 最後にこれをTensorBoardで呼び出し その進捗状況を確認できます