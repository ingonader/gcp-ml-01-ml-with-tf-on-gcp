NNの詳細やその効率的な トレーニング方法を学びました 最適な一般化も行いました 次はマルチクラスのNNを説明し マルチクラス分類の問題を扱います またシグモイド関数です 調整済み確率を得られます これは2項分類問題の正規回帰で役立ちます または正クラスの確率が見つかります その確率を1から引くと 負クラスに入ります クラスが3つ以上ある場合はどうしますか？ 多数のマルチクラス問題があります この例はオペラ劇場のチケットの種類です モデルは推奨する座席の種類です 座席は4種類あるとします ピット、ストール サークル、スイートです 各座席の種類の確率を得たいなら クラスが多すぎるので
通常の2項分類は使えません ピットが正クラスなら 負クラスは？ 残りのクラスはどうしますか？ 考えられるのはマルチクラス分類問題から 複数の2項分類問題への変換です これは「1対全部」または「1対残り」手法です この手法では各クラスを繰り返し処理します 各繰り返しで
あるクラスを正クラスにし 残りの全クラスをまとめて負クラスに入れます このようにして正クラスに入る確率を予測し 反対に他のクラスに入らない確率を予測します 重要なことは
出力するのは確率であり クラスレベルではないことです そのため1つのサンプルに対して マルチクラスの予測では
曖昧度が作成されません 正クラスに選択した各クラスを
モデルでトレーニングしたら 機械学習の最も重要な部分に移動しました
予測です 予測でトレーニング済みの2項分類モデルにより 予測サンプルを送ると モデルが最高の確率または信頼スコアを生成し 私たちが全体的な予測済みクラスを選択します これは素晴らしい解決策に思えますが 複数の問題が伴います まず信頼スコアというスキルは 各2項分類モデルによって異なるため 全体的な予測に偏りが生じます ただしそうでない場合でも 2項分類モデルでは データ分布が非常に不均衡になります
各クラスの負クラスは 正クラスとして現在マークされている クラスを除く他の全クラスの合計になるためです この不均衡問題を修正できるのは
「1対1」方法です ここにあるのは各クラスのモデルではなく クラスの二元組み合わせモデルです 任意のクラスがある場合 n x (n - 1)を2で割った数だけ モデルが存在します
n位の2乗になります この例の4クラスではモデルは6つですが 画像のコンペティションのように クラスが1000あったら モデルは499,500になります 各モデルが予測済みラベルに対して1票出力し 各モデルの正クラスラベルに+1または+0します すべての票が累計され
得票数が最大のクラスが勝ちになります しかしこれでは曖昧性問題が解決しません 入力分布に基づくと 異なるクラスの得票数が同じになりうるためです こうした大きな欠点のないマルチクラス分類の
実行方法はあるのでしょうか？ 考えられるのはNNを使用した
「1対全部」方法で 各クラスに複数のモデルを作成する代わりに 考えうる各クラスに固有の出力を持つ
モデルを1つ作成します 各例に対してこのモデルを
「特定のクラス」対「他の全クラス」の 信号でトレーニングできます そのためラベルの設計には注意が必要です trueクラスに1つだけ作成せずに クラスの数の長さのベクトルを作成します ここでtrueクラスに当たるのは1 残りは0になります このようにtrueクラスに当たる
シグモイドニューロンが1に近づいたら 報酬を与え 他のニューロンが1に近づいたら罰を与えます 誤差が大きければ重みのネットワークを通じて
誤差逆伝送を行います ただし新しい数百万のクラスには
問題が生じる場合があります 数百万の出力ニューロンです 数百万の損失計算の後に 数百万の誤差が生じ誤差逆伝搬が行われます 計算コストが高額になります もっといい方法は？ 単に制約を追加すると 出力の合計が1になります これで出力が確率として解釈されます この正規化関数をソフトマックスと呼びます 各ノードには
W x X + bを 全ノードの合計で割った指数関数があります これで全ノードが0と1の間になり 全確率が1になります このように各例で 各クラスの正規化確率を得られます 次にargmaxでクラスを探します 予測したラベルより高い確率です TensorFlowではWとXの適用メッシュ 偏りノードとして最終層のロジットを計算し 1がある場合は結果に追加します これでクラスの数のバッチサイズが
テンソル形状になります ラベルがワンホットエンコーディングされ 各例のtrueクラスが1 他のクラスが0を取得します そのためクラスの数ごとの バッチサイズのテンソル形状にもなります TensorFlowの softmax_cross_entropy_with_logits関数
で ラベルはソフトになります つまり クラスが相互に排他的であっても 確率はその必要がありません たとえばクラスが3つあったら ミニバッチはそのラベルが 0.15、0.8、0.05になっていたかも
しれません ワンホットエンコーディングでなくても 合計すると1になるため
これらは有効な確率分布です softmax_cross_entropy_with_logits
でロジットをラベルと比べます 結果は形状のテンソル、バッチサイズになります TensorFlow 1.5+では
この関数のv2が作成され v1の関数セットが非推奨となりました ミニバッチの平均損失を得るには 出力でreduce_meanを使用します 便宜のためTensorFlowでは sparse_softmax_cross_entropy_with_logits
を使用できます この場合ワンハイエンコーディングまたは ソフトエンコーディングを捨て ゼロとクラス数から1を引いた数の間の trueクラスのインデックスを渡します つまりラベルは形状のテンソル、バッチサイズに
なります 関数の出力はまだ以前の形状のテンソル
バッチサイズと同じです それでもそのテンソルのreduce_meanで
ミニバッチの平均損失を求めます 両方のソフトマックス関数では クラスが相互に排他的なため
これらのみを使用します たとえば画像1は犬のみの写真で 画像2は猫のみの写真ですが 画像3が犬と猫の両方の写真だとしたら
どうしますか？ そしてML問題では それを知りたいと思います ソフトマックスを使って各確率を得ますが そのargmaxをラベルとします そのためモデルの画像に応じて ラベルが犬になったり 猫になったりします これは使えません 知りたいのは
両方が写っているかどうかと 他のクラスがあるかどうかです これはマルチクラスマルチラベル分類問題です ここでは
0から1の各クラスの確率が必要です TensorFlowはこれを行うのに
適した関数です sigmoid_cross_entropy_with_logitsは クラス数のテンソルごとにバッチサイズを
返します 各例の各出力ノードを評価する必要があります 各出力ノードはそこにつながる重みも意味します 1ステップの出力ノードネットワーク100個は 100ステップの出力ネットワーク1つと同じです 非常に高価で クラスが非常に多い場合
スケーリングが困難です このソフトマックスの近似値を求め 巨大なマルチクラス問題の計算コストを
削減できる方法が必要です ソフトマックスの近似値バージョンが存在します Candidate Sampingは正ラベルをすべて
計算しますが 負レベルではすべてを計算せずに ランダムサンプリングします 計算を大幅に減らします 負のサンプル数は Candidate Samplingの重要な
ハイパーパラメータです 明白な理由により
常に低く見積もられます TensorFlowではsample softmax loss
関数を使えます ソフトマックスの近似値を求めるには Noise-Contrastive Estimationで 出力分布のモデリングを使って ソフトマックスの分母の近似値を求めます ロジットの指数関数の合計が含まれます これにより計算コストが安い近似値算出法で 損失が見つかります 分母の合計で全クラスを評価する必要は
ありません Candidate Samplingは
より直感的であり 良好なモデルは不要です Noise-Contrastiveには良好な
モデルが必要です 出力のモデリング分布に依存しているためです トレーニング中にはこうした関数を使用しますが 推論の評価では 精度向上のため
完全なソフトマックスを使用します そのためには既定のパーティション化戦略を modeからdivに変更し トレーニング、評価、予測間で損失が
一定になるようにします この分類出力では ラベルと確率の両方が相互排他的な場合 ＿＿を使用します ラベルが相互排他的で 確率はそうでない場合
＿＿を使用します ラベルが相互排他的でない場合 ＿＿を使用します 正解はAです この分類出力では 相互排他的なラベルと確率の両方がある場合 softmax_cross_entropy_with_logits_v2
を使います この場合
各例にtrueクラスは1つしかなく trueクラスにソフトラベルを与え trueクラスでのワンホットは不要だが 0と1の間の各クラスの値の組み合わせは
その合計が1である限り どの組み合わせにもなり得ます ラベルが相互排他的で 確率が違う場合に使うのは
sparse_softmax_cross_entropy_with_logitsです ソフトラベルは使えませんが モデルのデータサイズを生成できます 各例のクラス数のベクトルではなく
ラベルを圧縮して trueクラスのインデックスにできます ラベルが相互排他的でない場合は softmax_cross_entropy_with_logits
を使います このように考えうる各クラスの確率を得て 各クラスの信頼スコアを得られます これは複数のクラスが入っている画像や 各クラスの存在を知りたい場合に役立ちます