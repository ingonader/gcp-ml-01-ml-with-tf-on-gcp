Welcome back. In this module, we are going to be learning about how to write custom estimators. In this course, we're looking at a variety of things that every ML practitioners should have in their toolkit. And while canned estimators will take you a long way, there will be instances when you will want to go beyond canned estimators. In order to do that, you will learn how to write a custom estimator. By writing a custom estimator, you'll be able to gain greater control over the module function itself, while still taking advantage of the estimator API and its ability to distribute the training and evaluation of your model. Finally, I'll use this opportunity to explain the relationship between TensorFlow and Keras, because this is a question I get a lot. Keras comes into play when you think of custom estimators because Keras provides a convenient way to write the model function for a custom estimator. Keras, if you haven't heard of it, is a very intuitive opensource front end to deep learning models. We'll look at Keras models briefly in this module. So you will also learn how to incorporate Keras models into the estimator framework. Recall that the estimator API does quite a few things for us. It solves problems associated with out of memory data, using the data set API. It gives us a handy way to distribute our training and evaluation by providing the train and evaluate function. It exports summaries so that not only can we train and evaluate, we can also monitor. It allows us to export checkpoints at the time we evaluate. The checkpoints themselves provide fault recovery. The exporting allows a model to be easily deployed so that in production, we can serve predictions from a trained model. The evaluation metrics also allow for hyper parameter tuning. But mainly I like the estimator because it gives us a quick model. How quick? We saw this in the third course of the specialization. If you want to train a model to predict housing prices, you can fit the entire training code to read out of memory data sets and train the model, you can fit that entire training code into one slide. Adding the ability to do distributor training, not just large data sets, but to do training on many machines in a fault tolerant way, meant a few extra concepts of specifying the training and evaluation parameters and how long and how often to do these things. Also, we had to specify an expert signature, so we could productionize the model. Still the pre-built estimator is very simple code that makes a lot of hard things easy to accomplish by means of the powerful train and evaluate function. Still there are situations where canned estimators can be insufficient. You can use pre-built or canned estimators only if a canned estimator exists for the exact thing that you want to do. The TensorFlow team tries to capture the most common types of models, but obviously there will never be a canned model for every variation that you need. In that case, you will want to take advantage of as much of the estimator capability as you can, while being able to change the mathematical model being used. The idea is that you, as a data scientist, wants to define the layout of the neural network, the last function, the way you format the outputs, but you will rarely be concerned about changing the way workers and parameter servers communicate. So use estimators built in functionality for all that stuff but retain fine grained control over the model itself. Incidentally, what Keras does is that it allows us to write our own model. If you're using Keras, you might want to write a model using Keras, but train and evaluate the Keras model using estimator. So, using kerastorator model is just another example of the kind of flexibility that you might want, and that is what we're going to talk about in this model.