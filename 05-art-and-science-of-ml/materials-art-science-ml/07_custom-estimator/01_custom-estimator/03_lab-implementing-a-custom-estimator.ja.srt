1
00:00:00,000 --> 00:00:05,005
このラボでは カスタムEstimatorを
書く方法を習得します

2
00:00:05,005 --> 00:00:07,885
あるTensorFlow関数を想定します

3
00:00:07,885 --> 00:00:12,870
この関数は入力テンソルセットを受け入れて
出力テンソルを作成します

4
00:00:12,870 --> 00:00:17,225
この関数をEstimatorフレームワークに
組み込むのが目標です

5
00:00:17,225 --> 00:00:21,680
そうすることでEstimatorの
高水準のメリットが得られます

6
00:00:21,680 --> 00:00:26,569
実際には Estimatorを使わない
モデルに取り組んでいる場合

7
00:00:26,569 --> 00:00:30,875
なんらかの方法でデータを読み込んで
モデルを出力します

8
00:00:30,875 --> 00:00:33,960
今回はモデルのこのような部分を
実質的に捨て去って

9
00:00:33,960 --> 00:00:37,390
モデルの数学的なコアだけを残します

10
00:00:37,390 --> 00:00:41,900
このモデルは入力テンソルを
出力テンソルに変換します

11
00:00:41,900 --> 00:00:44,560
このラボで学ぶ点は

12
00:00:44,560 --> 00:00:48,735
Estimatorフレームワーク、
カスタムモジュール関数を含めて

13
00:00:48,735 --> 00:00:51,555
モデルをラップする方法です

14
00:00:51,555 --> 00:00:56,340
これをスライドで示すために
ある時系列モデルを使用します

15
00:00:56,340 --> 00:00:59,250
この時系列モデルが実際に
どのように動作するかは

16
00:00:59,250 --> 00:01:00,710
気にしないでください

17
00:01:00,710 --> 00:01:03,540
シーケンスモデルについては
あとで見ていくので

18
00:01:03,540 --> 00:01:05,945
今は ブラックボックスと見なします

19
00:01:05,945 --> 00:01:11,205
基本的にどう機能するかを
示すための外部ラッパーです

20
00:01:11,205 --> 00:01:13,065
さてここで

21
00:01:13,075 --> 00:01:16,205
import tensorflowに進みます

22
00:01:16,205 --> 00:01:21,485
一連のデータを作成して
シミュレーションします

23
00:01:21,485 --> 00:01:25,900
各データは基本的に
偏角が異なる正弦波です

24
00:01:25,900 --> 00:01:28,010
作成されるさまざまな周波数で

25
00:01:28,010 --> 00:01:29,560
この正弦波ができます

26
00:01:29,560 --> 00:01:33,040
ここに この時系列の
5つの例があります

27
00:01:33,040 --> 00:01:36,055
実際にこのデータを多数
作成します

28
00:01:36,055 --> 00:01:38,575
そして このデータでトレーニングします

29
00:01:38,575 --> 00:01:43,110
つまりニューラルネットワークに
9個の値を与えます

30
00:01:43,110 --> 00:01:45,405
0、1、2、3...

31
00:01:45,405 --> 00:01:47,105
8まで進みます

32
00:01:47,105 --> 00:01:52,270
9個の値を与えて
10個目を予測させます

33
00:01:52,270 --> 00:01:56,490
多数の既存データに基づいて学習させ

34
00:01:56,490 --> 00:02:03,700
8個いや9個の値に基づいて
10番目がどんな値になるか学習させます

35
00:02:03,710 --> 00:02:05,375
これを行うには

36
00:02:05,375 --> 00:02:07,950
CSVファイルを作成します

37
00:02:07,950 --> 00:02:10,369
to_csvでファイルに名前を指定し

38
00:02:10,369 --> 00:02:14,350
シーケンスが何個必要かを伝えます

39
00:02:14,350 --> 00:02:17,235
次にファイルを開き

40
00:02:17,235 --> 00:02:21,210
書き込んで時系列を作成します
（create_time_series）

41
00:02:21,210 --> 00:02:23,785
時列系の数はN個です

42
00:02:23,785 --> 00:02:27,440
この場合は train.csv.n=1000として

43
00:02:27,440 --> 00:02:30,505
1000個のシーケンスを含む
ファイルができます

44
00:02:30,505 --> 00:02:33,670
train.csvには
1000個のシーケンスが含まれます

45
00:02:33,670 --> 00:02:37,780
value.csvには
50個のシーケンスが含まれます

46
00:02:37,780 --> 00:02:41,675
すべてカンマで区切られます

47
00:02:41,675 --> 00:02:44,890
これを実行できます

48
00:02:44,890 --> 00:02:46,355
実行すると

49
00:02:46,355 --> 00:02:50,695
train.csvの最初の5列が見えます

50
00:02:50,695 --> 00:02:52,495
これが最初の5列です

51
00:02:52,495 --> 00:02:56,005
そして value.csvの最初の5列です

52
00:02:56,005 --> 00:03:00,750
これは実際には1個の時系列です

53
00:03:00,750 --> 00:03:05,535
これが
トレーニング入力特徴（features）になり

54
00:03:05,535 --> 00:03:08,640
そして これがラベルになります

55
00:03:08,640 --> 00:03:12,005
モデルにこれを学習させます

56
00:03:12,005 --> 00:03:14,440
これを使うのは
どんなときですか

57
00:03:14,440 --> 00:03:16,665
皆様が時系列を扱わないとしても

58
00:03:16,665 --> 00:03:20,665
こんな状況を考えると役立つでしょう

59
00:03:20,665 --> 00:03:25,890
たとえば 皆さんが
小売店を経営しているとします

60
00:03:25,890 --> 00:03:28,240
何千個もの商品があります

61
00:03:28,240 --> 00:03:32,100
各商品には季節性があります

62
00:03:32,100 --> 00:03:40,075
過去8期間または9期間の履歴データを見て

63
00:03:40,075 --> 00:03:42,955
そこから10期目を予測します

64
00:03:42,955 --> 00:03:44,370
基本的にこうします

65
00:03:44,370 --> 00:03:49,100
しかし 1つの株式市場の
将来値を予測しようとする場合

66
00:03:49,100 --> 00:03:52,050
こういう時系列とは異なり

67
00:03:52,050 --> 00:03:56,850
ものすごく長い1つの時系列です

68
00:03:56,850 --> 00:04:02,010
一方ここでは
何千個もの短い時系列があるので

69
00:04:02,010 --> 00:04:04,710
まったく別の問題になります

70
00:04:04,710 --> 00:04:07,500
この問題は小売店の例で

71
00:04:07,500 --> 00:04:09,310
何千個もの商品があり

72
00:04:09,310 --> 00:04:11,445
それぞれに季節性があります

73
00:04:11,445 --> 00:04:13,515
すべての商品の季節性から

74
00:04:13,515 --> 00:04:18,150
季節性という考え方を
学習させたいと思います

75
00:04:18,150 --> 00:04:24,235
1つの商品だけの時系列を見て
次を予測させます

76
00:04:24,235 --> 00:04:26,710
これが今回の
トレーニング用データセットです

77
00:04:26,710 --> 00:04:29,400
これに基づきモデルをトレーニングします

78
00:04:29,400 --> 00:04:32,530
循環ニューラルモデル（RNN）を
トレーニングします

79
00:04:32,530 --> 00:04:36,740
ここでも モデル自体の
内部については気にせず

80
00:04:36,740 --> 00:04:39,565
実装方法に注目してください

81
00:04:39,565 --> 00:04:43,170
この場合もTensorFlowをインポートし

82
00:04:43,170 --> 00:04:45,730
データを読み込む必要があります

83
00:04:45,730 --> 00:04:49,830
データは基本的に
シーケンスの長さ（SEQ_LEN）です

84
00:04:49,830 --> 00:04:53,700
デフォルトは[0.0]

85
00:04:53,700 --> 00:04:58,250
0からSEQ_LENまでのxrange（範囲）の
すべての浮動小数点数です

86
00:04:58,250 --> 00:04:59,955
10個の数字があります

87
00:04:59,955 --> 00:05:02,710
バッチサイズですが
何個でしょうか

88
00:05:02,710 --> 00:05:04,265
最急降下を計算するので

89
00:05:04,265 --> 00:05:06,675
バッチサイズは20になります

90
00:05:06,675 --> 00:05:10,680
データの時系列（TIMESERIES_COL）は
rawdataです

91
00:05:11,150 --> 00:05:12,790
このシーケンスで

92
00:05:12,790 --> 00:05:15,280
出力の数（N_OUTPUTS）は1つです

93
00:05:15,280 --> 00:05:16,905
これが最終出力です

94
00:05:16,905 --> 00:05:18,950
入力の数（N_INPUTS）は

95
00:05:18,950 --> 00:05:22,350
シーケンス長から
出力数を引いたものです

96
00:05:22,350 --> 00:05:25,490
言い換えると 最初の9個が入力 そして

97
00:05:25,490 --> 00:05:27,295
最後の1個が出力です

98
00:05:27,295 --> 00:05:31,305
定義する場合は これが定数セットです

99
00:05:31,305 --> 00:05:34,335
次に 読み込んだデータセットを書き出します

100
00:05:34,340 --> 00:05:37,260
これは入力関数を作るようなものです

101
00:05:37,260 --> 00:05:40,905
ここで decode_csvとline（列）は

102
00:05:40,905 --> 00:05:46,140
「すべてを浮動小数点数として
読み込みなさい」と指示し

103
00:05:46,140 --> 00:05:49,340
すべてのデータ つまり
10個の数値が得られますが

104
00:05:49,340 --> 00:05:52,890
一度に1つのバッチを読み込みます

105
00:05:52,890 --> 00:05:55,245
ですから これは1列ではありません

106
00:05:55,245 --> 00:05:59,290
実際にデータは標準的に
20列に相当します

107
00:05:59,290 --> 00:06:01,585
バッチごとに読み込むからです

108
00:06:01,585 --> 00:06:03,520
これは20列です

109
00:06:03,520 --> 00:06:08,340
そのうち最初の9つを切り分けて

110
00:06:08,340 --> 00:06:10,315
これらが入力になります

111
00:06:10,315 --> 00:06:12,215
そして最後の列を切り分けて

112
00:06:12,215 --> 00:06:14,170
これがラベルになります

113
00:06:14,170 --> 00:06:16,100
これが操作の内容です

114
00:06:16,100 --> 00:06:20,595
最初の9個の値を切り分けて
それらが入力（inputs）になり

115
00:06:20,595 --> 00:06:22,260
最後の値がラベルです

116
00:06:22,260 --> 00:06:29,470
inputsの長さはバッチサイズ
幅は9です

117
00:06:29,470 --> 00:06:36,075
labelsの高さはバッチサイズ
幅は1つまり出力数です

118
00:06:36,075 --> 00:06:39,575
このようなデータを取り入れます

119
00:06:39,575 --> 00:06:44,570
すべて別個の値ですが
それらを一緒に重ねて（stack）

120
00:06:44,570 --> 00:06:47,250
行列（マトリックス）が得られます

121
00:06:47,250 --> 00:06:48,620
これが入力です

122
00:06:48,620 --> 00:06:50,360
これを重ねて行列にし

123
00:06:50,360 --> 00:06:52,520
これも重ねて行列にします

124
00:06:52,520 --> 00:06:55,080
行列の第2ディメンションは1ですが

125
00:06:55,080 --> 00:06:56,800
まだ行列にはなく

126
00:06:56,800 --> 00:06:58,735
一連のリストです

127
00:06:58,735 --> 00:07:00,870
リストではなく行列が必要なので

128
00:07:00,870 --> 00:07:03,285
スタック（stack）がこれを行います

129
00:07:03,285 --> 00:07:06,415
次に TIMESERIES_COL生データ（rawdata）

130
00:07:06,415 --> 00:07:10,765
テンソルinputsを指定し
featuresとlabelsを返すことができます

131
00:07:10,765 --> 00:07:12,970
featuresには1つだけが含まれ

132
00:07:12,970 --> 00:07:15,800
1つの特徴を含む辞書です

133
00:07:15,800 --> 00:07:18,460
その特徴は行列です

134
00:07:18,460 --> 00:07:21,590
以前は すべての特徴が単一列でした

135
00:07:21,590 --> 00:07:24,005
しかしこの特徴は行列です

136
00:07:24,005 --> 00:07:26,537
このため ここでstack（積み重ね）します

137
00:07:26,537 --> 00:07:29,895
次にデータセットを
どのように読み込みますか

138
00:07:29,905 --> 00:07:31,750
データセットを読み込むとき

139
00:07:31,750 --> 00:07:34,490
ファイル名では 実際に
ファイルパスを与えます

140
00:07:34,490 --> 00:07:37,515
ですから globを行って

141
00:07:37,515 --> 00:07:40,805
ワイルドカードに合う
すべてのファイルを照合します

142
00:07:40,805 --> 00:07:42,535
たとえば file_listです

143
00:07:42,535 --> 00:07:44,885
それをテキスト行として読み込み

144
00:07:44,885 --> 00:07:47,925
decode_csvを呼び出して
データセットを返し

145
00:07:47,925 --> 00:07:52,570
トレーニングの場合は
データセットをシャッフルします

146
00:07:52,570 --> 00:07:55,215
評価ではシャッフルは必要ないので

147
00:07:55,215 --> 00:07:57,250
ここではシャッフルしません

148
00:07:57,250 --> 00:07:59,845
トレーニングでは
無制限に読み込み

149
00:07:59,845 --> 00:08:04,900
評価で読み込む場合は
データセット全体を一度に読み込むので

150
00:08:04,900 --> 00:08:06,710
epochの数は1です

151
00:08:06,710 --> 00:08:09,670
epochの回数だけ
データセットを繰り返します

152
00:08:09,670 --> 00:08:11,780
評価では1度だけ行います

153
00:08:11,780 --> 00:08:16,185
トレーニングでは永久にこれを行い
バッチサイズで一括処理します

154
00:08:16,185 --> 00:08:18,545
一度に20行つまり

155
00:08:18,545 --> 00:08:20,945
一度に20個のシーケンスです

156
00:08:20,945 --> 00:08:23,205
次にイテレータを返します

157
00:08:23,205 --> 00:08:26,945
これがデータセットの読み込みです

158
00:08:26,945 --> 00:08:29,065
さて ここでは

159
00:08:29,065 --> 00:08:33,800
モデル自体がどう動作するかは
気にせず

160
00:08:33,800 --> 00:08:36,775
重要な点は この行列simple_rnnで

161
00:08:36,775 --> 00:08:41,515
features、labels、modeを受け入れ

162
00:08:41,515 --> 00:08:46,690
featuresからシーケンスXを取り出し

163
00:08:46,690 --> 00:08:49,755
さらに操作を進めて

164
00:08:49,755 --> 00:08:51,555
この部分は気にせず

165
00:08:51,555 --> 00:08:54,110
やがて predictionsに達します

166
00:08:54,110 --> 00:08:57,250
これが時系列モデルの出力です

167
00:08:57,250 --> 00:08:59,770
入力が提供されると

168
00:08:59,770 --> 00:09:01,775
出力が得られます

169
00:09:01,775 --> 00:09:04,135
すべてのモデル関数は
だいたいこんな感じです

170
00:09:04,135 --> 00:09:07,870
次に 損失関数を決める必要があります

171
00:09:08,580 --> 00:09:11,185
時系列の問題ですから

172
00:09:11,185 --> 00:09:13,360
最後の値を予測します

173
00:09:13,360 --> 00:09:15,410
つまり値の予測です

174
00:09:15,410 --> 00:09:20,090
これは回帰/分類のどちらですか？
回帰ですね

175
00:09:20,090 --> 00:09:24,385
ですから loss（損失）は
平均2乗誤差になります

176
00:09:24,385 --> 00:09:26,175
2乗平均平方根誤差と

177
00:09:26,175 --> 00:09:29,195
平均2乗誤差のどちらでも使用できます

178
00:09:29,205 --> 00:09:32,609
トレーニングオペレーションでは
lossを最小化し

179
00:09:32,609 --> 00:09:34,880
特定の学習率learning_rateと

180
00:09:34,880 --> 00:09:37,140
特定のoptimizerを使用します

181
00:09:37,140 --> 00:09:42,465
評価指標は今回はrmce
つまり2乗平均平方根誤差で

182
00:09:42,465 --> 00:09:45,110
labelsとpredictionsをここで提供します

183
00:09:45,110 --> 00:09:49,275
トレーニングでも
評価でもない場合は

184
00:09:49,275 --> 00:09:52,915
loss、train op、eval metricsは
どれもnoneです

185
00:09:52,915 --> 00:09:55,380
ラベルがないのでnoneになります

186
00:09:55,380 --> 00:09:57,910
ラベルがないと予測できません

187
00:09:57,910 --> 00:09:59,605
評価できず

188
00:09:59,605 --> 00:10:01,990
トレーニングやlossもできません

189
00:10:01,990 --> 00:10:04,375
これらのオペレーションを
すべてnoneにします

190
00:10:04,375 --> 00:10:08,430
予測辞書（predictions_dict）は
出力predictionsです

191
00:10:08,430 --> 00:10:12,040
それに「predicted」という名前を付けます

192
00:10:12,040 --> 00:10:16,180
エクスポートでは
regression export outputsという名前です

193
00:10:16,180 --> 00:10:22,375
これらのprediction（予測）を取り入れて
書き出します

194
00:10:22,375 --> 00:10:25,020
この場合は 書き出される
埋め込みがないので

195
00:10:25,020 --> 00:10:26,720
1つだけ書き出します

196
00:10:26,720 --> 00:10:28,955
複数の内容を書き出す場合は

197
00:10:28,955 --> 00:10:30,985
これは辞書にすぎないので

198
00:10:30,985 --> 00:10:37,085
このように下の部分で
「embedding」と入力し

199
00:10:37,085 --> 00:10:42,190
上の埋め込みのここに
テンソルがあるとしましょう

200
00:10:42,190 --> 00:10:45,290
このweightテンソルが埋め込みだとします

201
00:10:45,290 --> 00:10:49,340
下に行ってembedding weightと
指定するだけです

202
00:10:49,340 --> 00:10:51,160
モデルのエクスポートでは

203
00:10:51,160 --> 00:10:53,630
2つのものがエクスポートされます

204
00:10:53,630 --> 00:10:56,710
回帰出力と埋め込みです

205
00:10:56,710 --> 00:10:58,535
これが完了したら

206
00:10:58,535 --> 00:11:01,130
estimator specを書き出すことができます

207
00:11:01,130 --> 00:11:03,560
その際 modeと
prediction dictを渡し

208
00:11:03,560 --> 00:11:06,420
さらに loss、train op、eval metricsなど

209
00:11:06,420 --> 00:11:09,535
エクスポートしたいものを渡します

210
00:11:09,535 --> 00:11:11,800
これで ほとんど説明できました

211
00:11:11,800 --> 00:11:14,870
残りの内容はすでに学んだことと
基本的に同じです

212
00:11:14,870 --> 00:11:17,805
トレーニング/検証関数を作成します

213
00:11:17,805 --> 00:11:20,400
パラメータや入力関数は不要です

214
00:11:20,400 --> 00:11:23,635
ここでは単にget trainだけです

215
00:11:23,635 --> 00:11:27,630
train.csvを渡してモードはtrain

216
00:11:27,630 --> 00:11:31,845
serving input関数では
TIMESERIES_COLが必要です

217
00:11:31,845 --> 00:11:34,360
すべて浮動小数点数です

218
00:11:34,360 --> 00:11:36,740
train and evaluateを呼び出し

219
00:11:36,740 --> 00:11:39,685
スタンドアロンモジュールとして試し

220
00:11:39,685 --> 00:11:43,105
さらに MLエンジンでもトレーニングできます

221
00:11:43,105 --> 00:11:48,050
BUCKETを qwiklabsバケットに
必ず変更してください