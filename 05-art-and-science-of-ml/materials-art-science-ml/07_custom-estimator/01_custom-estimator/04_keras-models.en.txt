We looked at how to write a custom estimator if the code to go from input to tensor to output tensor was written using TensorFlow. We wrap the code and the function that return an EstimatorSpec and then we pass that function to the base class Estimator. How does this work with Keras? And what is Keras anyway? Keras is a high-level neural networks API. It supports both convolutional networks and recurring neural networks. However, unlike TensorFlow, Keras is not an implementation of CNNs or RNNs. What Keras is, is that it's a high level neural networks API written in Python but which supports TensorFlow as a backend. In other words, when you call a Keras function it turns around and calls a set of TensorFlow functions to implement that functionality. Besides TensorFlow, Keras also supports running on top of other neural network implementations like CNTK and theano. Keras is meant to be very easy to use and fast for prototyping. Here for example is a sequence classification model written in Keras, there are classes for things like embedding LSDMs, Dropout, et cetera. So Keras allows you to think about the architecture of your model and not focus on the low level implementation. For example, to create an embedding in TensorFlow you'd create an embedding column, and in order to do that, you have to take the training data and make a categorical column first. You don't need to worry about these sorts of implementation details in Keras. Of course that also means that if you want to do something different about how to carry out the pre-processing before you get to the embeddings, you'll have to delve deep into the Keras documentation. There is no easy lunch and there is often a trade-off between simplicity and expressiveness. In any case you will often see data scientists believe their models using Keras. However keras is meant for fast prototyping, it does not handle distributor training or scale predictions. For that, for productionization, we will want to use the Estimator API. So oftentimes you will take ML prototypes written in Keras and you will have to operationalize them. So what do you have to do? To get the hint, let's look a bit more at the code. Let's not worry about the details in the code but notice that in the first few lines of code, a layered architecture gets created. Once the model is created it's compiled passing in the last function, the optimization method and the evaluation metrics. What does this remind you of? Write the model function in a custom estimator. So how do we mix Keras and the Estimator API? The answer is that once you have a compiled Keras model you can get an estimator. Older Keras code might be importing the standalone version of Keras. Change the import statements if necessary to import TF.Keras. So notice that I now have from TensorFlow import Keras. Keras is now part of TensorFlow call, so you can do this. Then simply call Keras.estimator.model_to_estimator passing in the compiled model and this gives you back an estimator. Throw away the model that fits the model that evaluates that's being called. So how do you train this model? You will use this estimator the way you normally use an estimator, with a training input function, evaluation input function, trains spec, eval spec, exporter, et cetera and pass them into train and evaluate. This is the way to productionize a Keras model. One thing to be aware of is that the linkage between the input function and the Keras model is through a naming convention. If you have a Keras layer named XYZ, then in the features dictionary return from the input function you should have a feature named XYZ underscore input. Let's look at a quick demo of this I'll be using the same notebook as earlier but using an example Keras model just for demonstration purposes.