ご覧のように
L1正則化によって 複雑なモデルが大幅に小さく
一般化可能なモデルになりました すべての特徴を選択した
状態で開始し 間には2つの隠れ層があるため 多くの関係が
線で表されていました トレーニングの際には個々の重みは
有効でしたが非常に弱く 多くの特徴は出力が
非常に小さなものでした またデータが適合すると思われる
良好な円ではなく うまく一般化されそうにない
長方形の歪んだ円が表示されていました ここに正則化を加えることで
不要な特徴がすべて0になり 線も細くなりグレー表示されました 残った特徴は
X1二乗とX2二乗のみでした これはこれらを合計すると
円の等式ができるからで 当然これが学習される
形状になります これが真の分布ですので モデルはうまく一般化される
ことがわかります