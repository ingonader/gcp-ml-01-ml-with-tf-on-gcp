1
00:00:01,240 --> 00:00:04,270
Damit sind wir am Ende
des fünften und letzten Kurses

2
00:00:04,270 --> 00:00:08,250
der Spezialisierung zu maschinellem Lernen
mit der Google Cloud Platform angelangt.

3
00:00:08,250 --> 00:00:12,910
Im ersten Kurs ging es darum, Probleme
für maschinelles Lernen zu formulieren.

4
00:00:12,910 --> 00:00:16,540
Im zweiten Kurs haben wir gelernt,
wie maschinelles Lernen funktioniert

5
00:00:16,540 --> 00:00:19,600
und wie man gute Datasets
für maschinelles Lernen erstellt.

6
00:00:19,600 --> 00:00:21,000
Im dritten Kurs haben wir,

7
00:00:21,000 --> 00:00:25,940
TensorFlow-Modelle geschrieben, um
Probleme für maschinelles Lernen zu lösen.

8
00:00:25,940 --> 00:00:28,650
Damit sind wir mit den Grundlagen vertraut.

9
00:00:28,650 --> 00:00:32,770
Im vierten Kurs haben wir,
Feature Engineering durchgeführt,

10
00:00:32,770 --> 00:00:36,290
um die Modellleistung zu verbessern.

11
00:00:36,290 --> 00:00:39,380
In diesem Kurs,
dem fünften Kurs, besprechen wir

12
00:00:39,380 --> 00:00:43,840
weitere Techniken zur Verbesserung
der Genauigkeit von ML-Modellen.

13
00:00:43,840 --> 00:00:47,400
Dieser Kurs für maschinelles Lernen
umfasst zehn Abschnitte,

14
00:00:47,400 --> 00:00:49,555
Sie haben also die Hälfte absolviert.

15
00:00:49,555 --> 00:00:51,080
Wie viel wissen Sie schon?

16
00:00:51,080 --> 00:00:53,200
Wie viel mehr müssen Sie noch lernen?

17
00:00:53,200 --> 00:00:57,810
Es gibt einige Artikel,
die diese Fragen beleuchten.

18
00:00:57,810 --> 00:01:01,800
Ein berühmter Artikel von Google heißt

19
00:01:01,800 --> 00:01:04,550
"The Unreasonable Effectiveness of Data".

20
00:01:04,550 --> 00:01:09,629
Ein weiterer Artikel
aus dem Jahr 2018 untersucht,

21
00:01:09,629 --> 00:01:15,150
wie vorhersehbar die Skalierung von
Deep Learning-Modellen mit mehr Daten ist.

22
00:01:15,150 --> 00:01:18,910
Dies ist ein Graph aus dem zweiten Artikel

23
00:01:18,910 --> 00:01:21,695
zur Qualität
von Übersetzungen mit maschinellem Lernen

24
00:01:21,695 --> 00:01:24,050
mit mehr Daten und einem größeren Modell.

25
00:01:24,050 --> 00:01:28,000
Der Graph hilft Ihnen,
die Abläufe zu interpretieren.

26
00:01:28,000 --> 00:01:29,950
Es ist zwar eine Zeichnung,

27
00:01:29,950 --> 00:01:34,400
basiert aber auf echter empirischer Arbeit
mit einer großen Bandbreite von Modellen.

28
00:01:34,400 --> 00:01:39,680
Als Erstes sollte man beachten,
dass ein größeres Dataset

29
00:01:39,680 --> 00:01:44,320
die Genauigkeit
eines Modells erheblich steigert.

30
00:01:44,320 --> 00:01:47,960
Zusätzliche Daten sind enorm hilfreich.

31
00:01:47,960 --> 00:01:54,870
Andererseits hat ein besseres Modell
mit wenig Daten keinen so großen Einfluss,

32
00:01:54,870 --> 00:01:57,200
bessere Modelle bringen also nicht mehr.

33
00:01:57,200 --> 00:01:59,912
Bleiben Sie bei einfachen Modellen,

34
00:01:59,912 --> 00:02:03,785
mit vorgefertigten Schätzern
erreichen Sie sehr viel.

35
00:02:03,785 --> 00:02:05,710
Ab einem bestimmten Zeitpunkt aber

36
00:02:05,710 --> 00:02:09,130
sinkt die Fehlerquote nicht mehr,
wenn Sie weitere Daten hinzufügen.

37
00:02:09,130 --> 00:02:12,760
An diesem Punkt sollten Sie es
mit Hyperparameter-Abstimmung versuchen.

38
00:02:12,760 --> 00:02:15,840
Das ist es, was ich mit
zusätzlichen Berechnungen meine,

39
00:02:15,840 --> 00:02:19,390
meist erhöht das die Genauigkeit deutlich.

40
00:02:19,390 --> 00:02:23,870
Die Kunst des ML ist also:
Investieren in Datenerfassung,

41
00:02:23,870 --> 00:02:29,560
Datenumwandlung und -verbesserung,
gefolgt von Hyperparameter-Abstimmung.

42
00:02:30,990 --> 00:02:35,120
Wir hoffen, Sie in der nächsten
Spezialisierung wiederzusehen.

43
00:02:35,120 --> 00:02:38,360
Darin geht es um
maschinelles Lernen im großen Maßstab

44
00:02:38,360 --> 00:02:42,785
und um spezialisierte Modelle 
für maschinelles Lernen für Bilder,

45
00:02:42,785 --> 00:02:45,319
Sequenzen und Empfehlungen.

46
00:02:45,319 --> 00:02:47,919
Vielen Dank und bis bald.