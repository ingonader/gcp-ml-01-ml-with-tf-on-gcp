1
00:00:01,240 --> 00:00:04,310
Llegamos al final del quinto y último curso

2
00:00:04,540 --> 00:00:07,850
de la especialización
sobre aprendizaje automático en GCP.

3
00:00:08,170 --> 00:00:12,400
En el primer curso,
aprendimos a formular problemas de AA.

4
00:00:12,830 --> 00:00:16,260
En el segundo curso,
aprendimos cómo funciona el AA

5
00:00:16,410 --> 00:00:18,970
y cómo crear
buenos conjuntos de datos para el AA.

6
00:00:19,620 --> 00:00:23,200
En el tercer curso,
escribimos modelos de TensorFlow

7
00:00:23,370 --> 00:00:25,610
para solucionar problemas
de aprendizaje automático.

8
00:00:25,760 --> 00:00:27,930
Hasta ese punto,
aprendimos lo básico.

9
00:00:28,660 --> 00:00:32,480
En el cuarto curso,
aprendimos a usar la ingeniería de funciones

10
00:00:32,720 --> 00:00:35,680
para mejorar el rendimiento
de nuestros modelos.

11
00:00:36,200 --> 00:00:40,170
En el quinto curso,
aprendimos más técnicas

12
00:00:40,290 --> 00:00:43,390
para mejorar la precisión
de los modelos de aprendizaje automático.

13
00:00:43,940 --> 00:00:46,960
Planeamos un conjunto
de diez cursos sobre aprendizaje automático.

14
00:00:47,300 --> 00:00:49,710
Así que estamos a la mitad del camino.

15
00:00:50,150 --> 00:00:53,170
¿Cuánto sabe?
¿Y cuánto más necesita aprender?

16
00:00:54,090 --> 00:00:57,950
Podemos consultar algunos artículos
para responder estas preguntas.

17
00:00:58,510 --> 00:01:01,300
Uno de ellos es muy conocido
y lo creó Google.

18
00:01:01,560 --> 00:01:04,419
Se llama
The unreasonable effectiveness of data.

19
00:01:04,819 --> 00:01:08,864
El otro artículo es más reciente,
de 2018

20
00:01:09,154 --> 00:01:11,790
y analiza el aumento de la predictibilidad

21
00:01:12,000 --> 00:01:14,720
de los modelos de aprendizaje profundo
con más datos.

22
00:01:15,380 --> 00:01:19,000
Este es un gráfico real del segundo artículo

23
00:01:19,310 --> 00:01:23,960
sobre la calidad de la traducción con AA
con más datos y un modelo más grande.

24
00:01:24,740 --> 00:01:27,660
Con este gráfico,
puede interpretar lo ocurrido.

25
00:01:28,080 --> 00:01:29,810
Pese a que es un dibujo

26
00:01:30,000 --> 00:01:34,230
se basa en un trabajo empírico real
con varios modelos.

27
00:01:35,090 --> 00:01:36,635
Lo primero que podemos ver

28
00:01:36,735 --> 00:01:39,680
es que a mayor tamaño
de los conjuntos de datos

29
00:01:40,050 --> 00:01:43,970
la precisión del modelo
incrementa significativamente.

30
00:01:44,510 --> 00:01:47,655
Es muy útil contar con muchos datos.

31
00:01:48,465 --> 00:01:49,650
Por otra parte

32
00:01:49,760 --> 00:01:52,850
usar un modelo más preciso,
pero con menos datos

33
00:01:53,110 --> 00:01:57,180
no influirá mucho en los resultados,
ya que estos modelos no suelen funcionar.

34
00:01:57,380 --> 00:01:59,315
Prefiera modelos simples

35
00:01:59,725 --> 00:02:03,360
y el estimador estándar hará su trabajo.

36
00:02:04,080 --> 00:02:05,560
En algún momento

37
00:02:05,790 --> 00:02:08,990
las mejoras de errores se estancan
cuando agrega más datos.

38
00:02:09,450 --> 00:02:12,590
En punto debe usar
el ajuste de hiperparámetros.

39
00:02:12,960 --> 00:02:15,180
Es decir, usar más procesamiento.

40
00:02:15,340 --> 00:02:18,910
Por lo general,
la precisión aumentará considerablemente.

41
00:02:19,500 --> 00:02:21,000
¿Qué es el arte del AA?

42
00:02:21,910 --> 00:02:26,380
Es invertir en la recolección,
el aumento y enriquecimiento de los datos.

43
00:02:26,710 --> 00:02:29,740
Luego,
terminamos con el ajuste de hiperparámetros.

44
00:02:30,990 --> 00:02:32,825
En la siguiente especialización

45
00:02:33,175 --> 00:02:34,720
en la que espero que participe

46
00:02:34,880 --> 00:02:38,010
aprenderá a aplicar el AA
a gran escala

47
00:02:38,240 --> 00:02:41,600
y a crear modelos
de aprendizaje automático especializados

48
00:02:41,750 --> 00:02:45,070
para imágenes,
secuencias y recomendaciones.

49
00:02:45,430 --> 00:02:47,100
Gracias.
Nos vemos pronto.