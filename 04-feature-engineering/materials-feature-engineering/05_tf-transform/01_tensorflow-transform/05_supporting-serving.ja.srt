1
00:00:00,000 --> 00:00:04,720
変換関数で評価データセットを変換し

2
00:00:04,720 --> 00:00:08,410
変換後の評価データを書き出しました

3
00:00:08,410 --> 00:00:13,660
AnalyzeAndTransformDatasetの
使用対象は

4
00:00:13,660 --> 00:00:16,650
トレーニングデータでした

5
00:00:16,650 --> 00:00:21,080
評価データには
TransformDatasetを使用しました

6
00:00:21,080 --> 00:00:25,780
前処理済みの特徴をBeamで作成しましたが

7
00:00:25,780 --> 00:00:30,670
前処理では
Pythonコードを使用できませんでした

8
00:00:30,670 --> 00:00:35,220
TensorFlow関数のみを
使用する必要がありました

9
00:00:35,220 --> 00:00:41,970
その理由は
関数が予測グラフの一部であるためです

10
00:00:41,970 --> 00:00:44,860
グラフの一部である理由は

11
00:00:44,860 --> 00:00:48,045
ユーザーがモデルに生データを渡し

12
00:00:48,045 --> 00:00:52,060
モデルで必要な前処理を行うためです

13
00:00:52,060 --> 00:00:55,525
呼び出す関数をどう判断するのでしょうか

14
00:00:55,525 --> 00:00:59,569
呼び出す関数をモデルで判断するには

15
00:00:59,569 --> 00:01:02,735
transform関数を保存します

16
00:01:02,735 --> 00:01:05,060
ここにそれを表示しています

17
00:01:05,060 --> 00:01:10,205
transform関数を
トレーニング済みモデルとともに

18
00:01:10,205 --> 00:01:19,510
metadataというディレクトリに保存し
入力関数でmetadataを取得します

19
00:01:19,510 --> 00:01:24,755
3つすべての入力関数を使用します

20
00:01:24,755 --> 00:01:29,460
まずトレーニングと評価の入力関数です

21
00:01:29,460 --> 00:01:32,575
前処理済みの特徴を読み取ります

22
00:01:32,575 --> 00:01:39,745
そこで変換済みメタデータに対応する
スキーマを指定します

23
00:01:39,745 --> 00:01:46,600
前処理済みの特徴を読み取るように
トレーニングと評価の入力関数を変更します

24
00:01:46,600 --> 00:01:49,760
TensorFlow変換には

25
00:01:49,760 --> 00:01:54,695
build_training_inputという
ヘルパー関数があります

26
00:01:54,695 --> 00:01:59,460
これを トレーニングと評価の
両方で使用するために

27
00:01:59,460 --> 00:02:04,535
モードに応じて
input_paths 変数が train_data_paths

28
00:02:04,535 --> 00:02:09,320
または eval_data_pahts を指すように
変更します

29
00:02:09,320 --> 00:02:14,205
処理入力関数は生データを受け入れるため

30
00:02:14,205 --> 00:02:20,620
変換後のメタデータではなく
生データのメタデータを渡します

31
00:02:20,620 --> 00:02:23,815
生データだけでは不十分です

32
00:02:23,815 --> 00:02:29,410
前処理コード内の
TensorFlow関数も利用できます

33
00:02:29,410 --> 00:02:33,960
オペレーションは
saved_model.pbに保存されています

34
00:02:33,960 --> 00:02:38,340
ここでも
便利なTensorFlow変換ヘルパー関数

35
00:02:38,340 --> 00:02:43,400
build_parsing_transforming_serving_input
を使用します

36
00:02:43,400 --> 00:02:47,020
生データスキーマを基にJSONを解析し

37
00:02:47,020 --> 00:02:51,900
saved_model.pbのTensorFlow
オペレーションで生データを変換し

38
00:02:51,900 --> 00:02:53,880
モデルに返します

39
00:02:53,880 --> 00:02:59,325
クライアントコードは
生入力変数を渡すだけです

40
00:02:59,325 --> 00:03:00,930
前と同じです

41
00:03:00,930 --> 00:03:06,530
入力処理関数は入力変数を受け取り
前と同じように処理します

42
00:03:06,530 --> 00:03:10,250
生データを受け取りモデルに渡します

43
00:03:11,380 --> 00:03:13,830
モデルの仕組みを説明します

44
00:03:13,830 --> 00:03:19,885
DNNリグレッサやモデルでは
DHUで文字列を処理できません

45
00:03:19,885 --> 00:03:24,645
動作する理由は
前処理で記述したすべてのコードが

46
00:03:24,645 --> 00:03:27,995
モデルグラフ自体の一部となっているためです

47
00:03:27,995 --> 00:03:34,350
モデルでメタデータを読み取り
前処理コードに組み込んでいるのです

48
00:03:34,350 --> 00:03:38,090
これがTensorFlow変換の仕組みです

49
00:03:38,090 --> 00:03:42,020
タクシー料金の予測で使用してみましょう