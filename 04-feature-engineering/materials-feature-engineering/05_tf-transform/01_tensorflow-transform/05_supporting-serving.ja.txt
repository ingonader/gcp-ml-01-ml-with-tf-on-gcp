変換関数で評価データセットを変換し 変換後の評価データを書き出しました AnalyzeAndTransformDatasetの
使用対象は トレーニングデータでした 評価データには
TransformDatasetを使用しました 前処理済みの特徴をBeamで作成しましたが 前処理では
Pythonコードを使用できませんでした TensorFlow関数のみを
使用する必要がありました その理由は
関数が予測グラフの一部であるためです グラフの一部である理由は ユーザーがモデルに生データを渡し モデルで必要な前処理を行うためです 呼び出す関数をどう判断するのでしょうか 呼び出す関数をモデルで判断するには transform関数を保存します ここにそれを表示しています transform関数を
トレーニング済みモデルとともに metadataというディレクトリに保存し
入力関数でmetadataを取得します 3つすべての入力関数を使用します まずトレーニングと評価の入力関数です 前処理済みの特徴を読み取ります そこで変換済みメタデータに対応する
スキーマを指定します 前処理済みの特徴を読み取るように
トレーニングと評価の入力関数を変更します TensorFlow変換には build_training_inputという
ヘルパー関数があります これを トレーニングと評価の
両方で使用するために モードに応じて
input_paths 変数が train_data_paths または eval_data_pahts を指すように
変更します 処理入力関数は生データを受け入れるため 変換後のメタデータではなく
生データのメタデータを渡します 生データだけでは不十分です 前処理コード内の
TensorFlow関数も利用できます オペレーションは
saved_model.pbに保存されています ここでも
便利なTensorFlow変換ヘルパー関数 build_parsing_transforming_serving_input
を使用します 生データスキーマを基にJSONを解析し saved_model.pbのTensorFlow
オペレーションで生データを変換し モデルに返します クライアントコードは
生入力変数を渡すだけです 前と同じです 入力処理関数は入力変数を受け取り
前と同じように処理します 生データを受け取りモデルに渡します モデルの仕組みを説明します DNNリグレッサやモデルでは
DHUで文字列を処理できません 動作する理由は
前処理で記述したすべてのコードが モデルグラフ自体の一部となっているためです モデルでメタデータを読み取り
前処理コードに組み込んでいるのです これがTensorFlow変換の仕組みです タクシー料金の予測で使用してみましょう