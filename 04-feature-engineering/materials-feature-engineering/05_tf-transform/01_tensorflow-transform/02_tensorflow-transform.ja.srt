1
00:00:00,000 --> 00:00:05,325
ご説明したとおり 特徴エンジニアリングは
3か所で処理できます

2
00:00:05,325 --> 00:00:09,615
1つはTensorFlow自体の中です

3
00:00:09,615 --> 00:00:13,755
特徴列を使用して特徴辞書をラップし

4
00:00:13,755 --> 00:00:16,545
任意のTensorFlowコードを追加します

5
00:00:16,545 --> 00:00:22,250
TensorFlowコードとGPU/TPUを使う
効率的な方法です

6
00:00:22,250 --> 00:00:26,820
任意のTensorFlowコードと言ったのは

7
00:00:26,820 --> 00:00:33,185
このコードが モデル関数の一部、
TensorFlowグラフの一部として

8
00:00:33,185 --> 00:00:35,265
実行されるからです

9
00:00:35,265 --> 00:00:40,365
社内データベースをクエリして
値を挿入することはできません

10
00:00:40,365 --> 00:00:44,490
C++でTensorFlowを記述して
呼び出すことはできますが

11
00:00:44,490 --> 00:00:46,215
それは別の話です

12
00:00:46,215 --> 00:00:53,280
また 実行できるのは
この入力値のみに依存する処理だけです

13
00:00:53,280 --> 00:00:58,705
つまり ローリング平均の計算などは
実行が難しいと言えます

14
00:00:58,705 --> 00:01:04,500
後で 時系列を処理しているような
シーケンスモデルを紹介します

15
00:01:04,500 --> 00:01:09,545
複数の入力値がありますが
その入力がシーケンスになっています

16
00:01:09,545 --> 00:01:13,590
TensorFlow処理の制限は

17
00:01:13,590 --> 00:01:17,985
単一入力しか前処理できないことです

18
00:01:17,985 --> 00:01:25,130
TensorFlowモデルは シーケンスモデルを除いて
通常 ステートレスです

19
00:01:26,110 --> 00:01:28,510
前の2つの章では

20
00:01:28,510 --> 00:01:36,370
Apache Beamを使ったCloud Dataflowでの
前処理と特徴の作成について説明しました

21
00:01:36,370 --> 00:01:42,630
Dataflowを使用すると
任意のPythonコードやJavaコードを実行でき

22
00:01:42,630 --> 00:01:47,040
複数の入力値をステートフルに処理できます

23
00:01:47,040 --> 00:01:51,510
たとえば時間枠の平均を計算します

24
00:01:51,510 --> 00:01:57,085
過去1時間に交差点を通った
自転車の平均数などです

25
00:01:57,085 --> 00:02:08,340
ただし これを行うには予測コードも
パイプライン内で実行する必要があります

26
00:02:08,340 --> 00:02:14,799
この時間枠での平均は
パイプラインが必要になる良い例です

27
00:02:14,799 --> 00:02:23,620
では 必要なのが最小値や最大値のみで
値を増減するのが目的の場合や

28
00:02:23,620 --> 00:02:28,955
カテゴリを数値に変換する
ボキャブラリを得たい場合はどうでしょうか

29
00:02:28,955 --> 00:02:32,275
予測でDataflowパイプラインを実行し

30
00:02:32,275 --> 00:02:37,534
単に最小値と最大値を取得するのは
無駄に思われるかもしれません

31
00:02:37,534 --> 00:02:40,845
ここでtf.transformを投入します

32
00:02:40,845 --> 00:02:44,490
これは2つの方法のハイブリッドです

33
00:02:44,490 --> 00:02:49,405
TensorFlow変換では
TensorFlowメソッドに制限されますが

34
00:02:49,405 --> 00:02:52,665
TensorFlowの効率性を活かせます

35
00:02:52,665 --> 00:02:56,840
トレーニングデータセット全体の
集約も使用できます

36
00:02:56,840 --> 00:03:01,895
これは tf.transformは
トレーニングではDataflowを使用し

37
00:03:01,895 --> 00:03:05,915
予測中はTensorFlowのみを使用するためです

38
00:03:05,915 --> 00:03:09,440
TensorFlow変換の仕組みを見てみましょう

39
00:03:09,440 --> 00:03:17,500
TensorFlow変換は
Apache BeamとTensorFlowのハイブリッドです

40
00:03:17,500 --> 00:03:22,420
Dataflowの前処理は
パイプラインでのみ実行可能です

41
00:03:22,420 --> 00:03:27,240
入力ストリーミングデータの観点で考えます

42
00:03:27,240 --> 00:03:30,415
IoTデータやフライトデータなどです

43
00:03:30,415 --> 00:03:35,380
Dataflowパイプラインは
予測を伴う場合があり

44
00:03:35,380 --> 00:03:39,715
その予測を呼び出して
Bigtableに保存する場合があります

45
00:03:39,715 --> 00:03:42,940
その予測はその後60秒以内の

46
00:03:42,940 --> 00:03:46,495
ウェブページ訪問者すべてに適用されます

47
00:03:46,495 --> 00:03:50,220
この時点で新しい予測を利用できます

48
00:03:50,220 --> 00:03:54,195
つまりDataflowは

49
00:03:54,195 --> 00:03:59,095
機械学習モデルの
バックエンドでの前処理に適しています

50
00:03:59,095 --> 00:04:06,105
ステートの維持が必要な
時間枠などの前処理に使用します

51
00:04:06,105 --> 00:04:13,225
機械学習モデルのオンザフライ前処理には
TensorFlowが適しています

52
00:04:13,225 --> 00:04:20,680
入力値のみに基づく前処理に使用します

53
00:04:20,680 --> 00:04:26,290
この図の点線内のすべてを
TensorFlowグラフに投入すると

54
00:04:26,290 --> 00:04:31,680
クライアントは
ウェブアプリケーションを呼び出して

55
00:04:31,680 --> 00:04:35,950
すべての処理を簡単に完了できます

56
00:04:35,950 --> 00:04:39,980
では これらの中間の場合を考えてみます

57
00:04:39,980 --> 00:04:48,245
データセット内の最小値や最大値をもとに
入力をスケーリングしたい場合などです

58
00:04:48,245 --> 00:04:50,790
そのような場合は

59
00:04:50,790 --> 00:04:55,950
Dataflow内でデータを分析して
データセット全体を処理し

60
00:04:55,950 --> 00:04:57,510
最小値と最大値を見つけ

61
00:04:57,510 --> 00:05:00,600
変換とDataflowを実行し

62
00:05:00,600 --> 00:05:04,035
個別の入力値を増減させます

63
00:05:04,035 --> 00:05:07,245
ここで tf.transformの出番です

64
00:05:07,245 --> 00:05:11,555
Apache BeamとTensorFlowの
ハイブリッドです

65
00:05:11,555 --> 00:05:14,260
この仕組みを理解するために

66
00:05:14,260 --> 00:05:19,815
前処理には2つの段階があることを
思い出してください

67
00:05:19,815 --> 00:05:22,920
入力生データをスケーリングして

68
00:05:22,920 --> 00:05:26,335
勾配降下法の処理を改善したいとします

69
00:05:26,335 --> 00:05:31,560
そのためには
トレーニングデータセット全体の

70
00:05:31,560 --> 00:05:36,625
数値特徴の最小値と最大値を
見つける必要があります

71
00:05:36,625 --> 00:05:41,025
次にトレーニングデータセットで計算された

72
00:05:41,025 --> 00:05:46,035
最小値と最大値により
各入力値をスケーリングします

73
00:05:46,035 --> 00:05:52,025
今度は カテゴリ型変数のキーのボキャブラリを
検索する場合を考えます

74
00:05:52,025 --> 00:05:57,420
車の製造元という
カテゴリ型特徴があるとします

75
00:05:57,420 --> 00:06:00,920
トレーニングデータセット全体を処理し

76
00:06:00,920 --> 00:06:04,640
特定の特徴のすべての値を見つけます

77
00:06:04,640 --> 00:06:08,520
つまり すべての製造元のリストを取得します

78
00:06:08,520 --> 00:06:13,785
見つかった製造元の数が20であった場合

79
00:06:13,785 --> 00:06:19,520
製造元の列を長さ20のベクターに
ワンホットエンコーディングします

80
00:06:19,540 --> 00:06:22,425
ご理解いただけたでしょうか

81
00:06:22,425 --> 00:06:28,440
最初のステップではデータセット全体を
一度トラバースしています

82
00:06:28,440 --> 00:06:31,640
これは分析フェーズと呼ばれます

83
00:06:31,640 --> 00:06:38,770
2番目のステップは
入力データのオンザフライ変換です

84
00:06:38,770 --> 00:06:43,045
これは変換フェーズと呼ばれます

85
00:06:43,045 --> 00:06:47,570
BeamとTensorFlowの
どちらのテクノロジーが

86
00:06:47,570 --> 00:06:52,760
トレーニングデータセットの
分析に適しているでしょうか？

87
00:06:52,760 --> 00:06:57,480
BeamとTensorFlowの
どちらのテクノロジーが

88
00:06:57,480 --> 00:07:04,010
入力データのオンザフライ変換に
適しているでしょうか？

89
00:07:04,010 --> 00:07:10,990
答えは 分析にはBeam
変換にはTensorFlowが適しています

90
00:07:10,990 --> 00:07:16,005
tf.transformには
2つのPTransformがあります

91
00:07:16,005 --> 00:07:20,760
AnalyzeAndTransformDatasetは
Beamで実行され

92
00:07:20,760 --> 00:07:25,450
前処理済みの
トレーニングデータセットを作成します

93
00:07:25,450 --> 00:07:30,390
TransformDatasetは
Beamで実行されて

94
00:07:30,390 --> 00:07:33,480
評価データセットを作成します

95
00:07:33,480 --> 00:07:36,825
最小値と最大値などの計算では

96
00:07:36,825 --> 00:07:40,965
分析の対象は
トレーニングデータセットのみです

97
00:07:40,965 --> 00:07:43,780
評価データセットは使用できません

98
00:07:43,780 --> 00:07:50,850
評価データセットは トレーニングデータの
最小値/最大値を使用してスケーリングされます

99
00:07:50,850 --> 00:07:55,070
では 評価の最大値の方が大きい場合は
どうすればよいでしょう

100
00:07:55,070 --> 00:07:58,780
これはたとえば モデルをデプロイした後で

101
00:07:58,780 --> 00:08:03,280
予測時になって
さらに大きい値が見つかるような状況です

102
00:08:03,280 --> 00:08:04,825
条件は同じです

103
00:08:04,825 --> 00:08:10,310
評価データセットから最小値/最大値や
ボキャブラリは計算できません

104
00:08:10,310 --> 00:08:12,270
この制限は変わりません

105
00:08:12,270 --> 00:08:16,685
ただし 呼び出された変換コードは

106
00:08:16,685 --> 00:08:21,430
予測時にTensorFlow内で実行されます

107
00:08:22,610 --> 00:08:27,870
つまり 2つのフェーズがあるということです

108
00:08:27,870 --> 00:08:30,345
まずは分析フェーズです

109
00:08:30,345 --> 00:08:34,684
トレーニングデータセットの作成中に
Beam内で実行されます

110
00:08:34,684 --> 00:08:37,155
次に変換フェーズです

111
00:08:37,155 --> 00:08:41,710
これは予測時にTensorFlowで実行されます

112
00:08:41,710 --> 00:08:47,320
さらに Beam内で実行されて
トレーニング/評価データセットが作成されます