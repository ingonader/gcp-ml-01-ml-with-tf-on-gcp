1
00:00:00,000 --> 00:00:04,230
In this lab, we will look at how to use TensorFlow transfrom.

2
00:00:04,230 --> 00:00:09,780
We will write a beam pipeline to analyze and transform the training data.

3
00:00:09,780 --> 00:00:12,640
And in that same beam pipeline,

4
00:00:12,640 --> 00:00:16,260
we'll also transform the evaluation data and

5
00:00:16,260 --> 00:00:20,325
we will save the transform function so that we could use it during prediction.

6
00:00:20,325 --> 00:00:22,260
We'll modify the training and

7
00:00:22,260 --> 00:00:26,850
evaluation input functions to read these pre-processed files.

8
00:00:26,850 --> 00:00:29,520
And then we'll train the model as normal.

9
00:00:29,520 --> 00:00:32,895
But because we have pre-processed the data,

10
00:00:32,895 --> 00:00:36,510
we'll be able to do this pre-processing at scale over

11
00:00:36,510 --> 00:00:40,485
very large data sets during training using data flow,

12
00:00:40,485 --> 00:00:44,790
and we'll be able to carry out the pre-processing efficiently as

13
00:00:44,790 --> 00:00:49,095
part of the model graph in TensorFlow during serving.

14
00:00:49,095 --> 00:00:54,000
So this is a way by which you can take advantage of the scale of Cloud doing

15
00:00:54,000 --> 00:00:59,310
a pre-processing over multiple CPUs in a very distributed way,

16
00:00:59,310 --> 00:01:03,940
and take advantage of the efficiency of CPUs,

17
00:01:03,940 --> 00:01:08,650
GPUs and TensorFlow processing units during prediction.

18
00:01:08,650 --> 00:01:12,790
So go ahead and open up Qwiklabs and try out this Lab.