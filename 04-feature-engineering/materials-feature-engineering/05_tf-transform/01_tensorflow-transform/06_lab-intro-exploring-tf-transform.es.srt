1
00:00:00,330 --> 00:00:04,080
En este lab,
veremos cómo utilizar TensorFlow Transform.

2
00:00:04,410 --> 00:00:06,440
Escribiremos una canalización de Beam

3
00:00:06,470 --> 00:00:09,450
para analizar y transformar
los datos de entrenamiento.

4
00:00:10,040 --> 00:00:12,230
En esa misma canalización de Beam

5
00:00:12,700 --> 00:00:15,465
también transformaremos
los datos de evaluación

6
00:00:16,045 --> 00:00:18,145
y guardaremos la función de transformación

7
00:00:18,305 --> 00:00:20,190
para usarla durante la predicción.

8
00:00:20,620 --> 00:00:24,130
Modificaremos las funciones entrantes
de entrenamiento y evaluación

9
00:00:24,340 --> 00:00:26,460
para que lean
estos archivos preprocesados.

10
00:00:27,310 --> 00:00:29,315
Luego,
entrenaremos el modelo como siempre.

11
00:00:29,935 --> 00:00:32,902
Sin embargo,
dado que ya preprocesamos los datos

12
00:00:32,902 --> 00:00:34,820
podremos realizar el preprocesamiento

13
00:00:34,820 --> 00:00:37,935
a gran escala
con conjuntos de datos muy grandes

14
00:00:37,935 --> 00:00:40,260
durante el entrenamiento con Dataflow.

15
00:00:40,810 --> 00:00:44,015
Y podremos realizar
el preprocesamiento con eficiencia

16
00:00:44,505 --> 00:00:49,060
como parte del gráfico del modelo
en TensorFlow durante la entrega.

17
00:00:49,280 --> 00:00:53,210
Esta es una forma
de aprovechar la escala de Cloud.

18
00:00:53,660 --> 00:00:59,150
El preprocesamiento se hace
de manera distribuida en múltiples CPU

19
00:00:59,430 --> 00:01:05,130
y se aprovecha
la eficiencia de las CPU, las GPU

20
00:01:05,270 --> 00:01:07,380
y las unidades
de procesamiento de TensorFlow

21
00:01:07,470 --> 00:01:08,680
durante la predicción.

22
00:01:09,085 --> 00:01:11,895
Abra Qwiklabs y pruebe este lab.