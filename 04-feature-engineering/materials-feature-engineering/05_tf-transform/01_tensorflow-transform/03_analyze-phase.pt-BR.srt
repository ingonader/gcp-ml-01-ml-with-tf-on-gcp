1
00:00:00,000 --> 00:00:02,920
Vamos ver a fase de análise.

2
00:00:02,920 --> 00:00:07,075
Você analisa o
conjunto de dados de treinamento.

3
00:00:07,075 --> 00:00:11,260
Primeiro, é preciso dizer
ao Beam que tipo de dados esperar.

4
00:00:11,260 --> 00:00:14,275
Para isso, defina um esquema.

5
00:00:14,275 --> 00:00:20,365
Na primeira linha, eu defino um
dicionário chamado raw_data_schema

6
00:00:20,365 --> 00:00:24,555
e adiciono entradas a
todas as colunas de string.

7
00:00:25,585 --> 00:00:29,085
Esta string é o tipo
de dados do TensorFlow.

8
00:00:29,645 --> 00:00:37,605
Para atualizar o esquema,
adicione as colunas tf.float32.

9
00:00:38,735 --> 00:00:42,605
Isso me dá um
esquema de dados brutos

10
00:00:42,605 --> 00:00:47,875
com todas as colunas que serão
processadas pelo Beam no DataFlow.

11
00:00:48,505 --> 00:00:52,810
O esquema é usado para
criar um modelo de metadados.

12
00:00:53,750 --> 00:00:58,340
Execute a PTransform
de análise e transformação

13
00:00:58,340 --> 00:01:03,525
no conjunto de treinamento para
receber os dados pré-processados

14
00:01:03,525 --> 00:01:05,495
e a função de transformação.

15
00:01:06,215 --> 00:01:11,185
Primeiro, execute
beam.io.read para ler os dados.

16
00:01:11,185 --> 00:01:16,645
Isso é semelhante aos canais
do Beam do módulo anterior.

17
00:01:17,255 --> 00:01:19,765
Aqui, estou lendo no BigQuery.

18
00:01:20,225 --> 00:01:24,375
Filtre os dados que você
não quer usar no treinamento.

19
00:01:24,375 --> 00:01:29,215
Estou usando uma função
is_valid que não está neste slide,

20
00:01:29,215 --> 00:01:31,115
mostrarei esse
método mais tarde.

21
00:01:31,835 --> 00:01:37,030
Depois, colete os dados
da leitura e do filtro

22
00:01:37,030 --> 00:01:40,375
e os metadados
brutos do slide anterior

23
00:01:40,375 --> 00:01:45,065
e transmita para o conjunto de dados de
análise e transformação PTransform.

24
00:01:45,605 --> 00:01:49,985
O Beam executará essa
transformação de maneira distribuída

25
00:01:49,985 --> 00:01:55,550
e fará a análise solicitada
no método de pré-processamento.

26
00:01:55,550 --> 00:01:58,295
Também mostrarei
esse método mais tarde.

27
00:01:58,745 --> 00:02:02,890
Por hora, os métodos is_valid
e de pré-processamento

28
00:02:02,890 --> 00:02:06,745
são executados pelo Beam
no conjunto de treinamento

29
00:02:06,745 --> 00:02:09,305
para filtrar e pré-processar.

30
00:02:10,235 --> 00:02:14,335
Os dados pré-processados
são retornados em uma coleção P,

31
00:02:14,335 --> 00:02:18,545
ou coleção paralela, que chamo
de conjunto de dados transformado.

32
00:02:19,125 --> 00:02:22,550
Observe que as
transformações realizadas

33
00:02:22,550 --> 00:02:27,170
no pré-processamento
são salvas no segundo valor,

34
00:02:27,180 --> 00:02:30,560
na função de transformação.
Isso é importante.

35
00:02:31,190 --> 00:02:34,350
Escreva os dados transformados.

36
00:02:34,830 --> 00:02:41,645
Estou escrevendo como TFRecords, o
formato mais eficiente para o TensorFlow.

37
00:02:41,645 --> 00:02:45,685
Para isso, posso usar a PTransform

38
00:02:45,685 --> 00:02:49,095
WriteToTFRecord da
transformação do TensorFlow.

39
00:02:49,695 --> 00:02:52,905
Os arquivos serão
automaticamente fragmentados.

40
00:02:53,495 --> 00:02:56,520
Mas observe qual esquema é usado.

41
00:02:56,960 --> 00:03:01,390
Não é o esquema de dados brutos,
é o esquema transformado.

42
00:03:01,390 --> 00:03:02,590
Por quê?

43
00:03:03,820 --> 00:03:05,030
Claro,

44
00:03:05,030 --> 00:03:08,165
o que estamos escrevendo
são os dados transformados

45
00:03:08,151 --> 00:03:11,376
e pré-processados,
não os dados brutos.