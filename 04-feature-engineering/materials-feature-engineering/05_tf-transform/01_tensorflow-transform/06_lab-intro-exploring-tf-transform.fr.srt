1
00:00:00,000 --> 00:00:04,230
Dans cet atelier, nous verrons
comment utiliser TensorFlow Transform.

2
00:00:04,230 --> 00:00:08,370
Nous écrirons un pipeline Beam
pour analyser et transformer

3
00:00:08,370 --> 00:00:09,780
les données d'entraînement.

4
00:00:09,780 --> 00:00:13,120
Dans ce pipeline,
nous transformerons aussi

5
00:00:13,120 --> 00:00:16,390
les données d'évaluation et enregistrerons

6
00:00:16,390 --> 00:00:20,325
la fonction de transformation
pour l'utiliser lors de la prédiction.

7
00:00:20,325 --> 00:00:22,260
Nous modifierons les fonctions d'entrée

8
00:00:22,260 --> 00:00:26,850
d'entraînement et d'évaluation
pour lire les fichiers prétraités.

9
00:00:26,850 --> 00:00:29,520
Nous entraînerons ensuite
le modèle comme d'habitude.

10
00:00:29,520 --> 00:00:32,895
Comme nous aurons prétraité les données,

11
00:00:32,895 --> 00:00:36,510
nous pourrons effectuer
ce prétraitement à l'échelle

12
00:00:36,510 --> 00:00:40,485
sur de très grands ensembles de données
lors de l'entraînement avec Dataflow.

13
00:00:40,485 --> 00:00:44,790
Nous pourrons aussi effectuer
le prétraitement efficacement

14
00:00:44,790 --> 00:00:49,095
dans le cadre du graphique du modèle
dans TensorFlow lors de la diffusion.

15
00:00:49,095 --> 00:00:54,000
Il s'agit d'une manière
de tirer parti de l'échelle du cloud

16
00:00:54,000 --> 00:00:59,310
en effectuant un prétraitement sur de
multiples processeurs de façon distribuée

17
00:00:59,310 --> 00:01:03,940
et de profiter
de l'efficacité des processeurs,

18
00:01:03,940 --> 00:01:08,650
des GPU et des unités de traitement
TensorFlow lors de la prédiction.

19
00:01:08,650 --> 00:01:12,790
Je vous invite donc à lancer Qwiklabs
et à essayer cet atelier.