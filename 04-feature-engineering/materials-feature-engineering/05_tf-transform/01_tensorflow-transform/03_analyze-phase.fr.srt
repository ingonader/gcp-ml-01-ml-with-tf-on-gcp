1
00:00:00,000 --> 00:00:02,920
Abordons à présent la phase d'analyse.

2
00:00:02,920 --> 00:00:07,075
Souvenez-vous que vous analysez
l'ensemble de données d'entraînement.

3
00:00:07,075 --> 00:00:11,260
Vous devez commencer par dire à
Beam le type de données à attendre.

4
00:00:11,260 --> 00:00:14,275
Pour ce faire, vous devez
configurer un schéma.

5
00:00:14,275 --> 00:00:20,365
Dans la première ligne, je configure un
dictionnaire appelé "raw_data_schema".

6
00:00:20,365 --> 00:00:25,005
J'ajoute des entrées
à toutes les colonnes à chaîne.

7
00:00:25,005 --> 00:00:29,315
Ici, la chaîne est un type
de données TensorFlow.

8
00:00:29,315 --> 00:00:38,625
Puis, je mets à jour "raw_data_schema"
en ajoutant les colonnes "tf.float32".

9
00:00:38,625 --> 00:00:42,605
Après cela, j'obtiens un dictionnaire
"raw_data_schema" contenant toutes

10
00:00:42,605 --> 00:00:48,115
les colonnes de l'ensemble de données qui
seront traitées par Beam dans Dataflow.

11
00:00:48,115 --> 00:00:53,130
"raw_data_schema" est utilisé pour
créer un modèle de métadonnées.

12
00:00:53,130 --> 00:00:58,760
La prochaine étape est l'exécution d'un
"PTransform analyze-and-transform" dans

13
00:00:58,760 --> 00:01:02,262
l'ensemble de données
pour récupérer les données

14
00:01:02,262 --> 00:01:05,765
d'entraînement prétraitées
et la fonction "transform".

15
00:01:05,765 --> 00:01:11,185
Utilisez d'abord "beam.io.Read"
pour lire les données d'entraînement.

16
00:01:11,185 --> 00:01:17,035
Cette méthode ressemble aux pipelines
Beam vus dans le module Beam précédent.

17
00:01:17,035 --> 00:01:19,765
Ici, je lis les données depuis BigQuery.

18
00:01:19,765 --> 00:01:24,375
Filtrez ensuite les données
que vous ne voulez pas entraîner.

19
00:01:24,375 --> 00:01:29,215
Pour ce faire, j'utilise une fonction
"is_valid" qui n'apparaît pas ici.

20
00:01:29,215 --> 00:01:31,395
Je vous montrerai cette méthode plus tard.

21
00:01:31,395 --> 00:01:37,050
Prenez ensuite les données brutes
obtenues après lecture et filtrage, ainsi

22
00:01:37,050 --> 00:01:40,805
que les métadonnées des données brutes
obtenues dans la diapositive précédente,

23
00:01:40,805 --> 00:01:43,025
puis passez-les dans

24
00:01:43,025 --> 00:01:45,245
"PTransformAnalyzeandTransformDataset".

25
00:01:45,245 --> 00:01:49,985
Beam exécute
cette transformation de façon distribuée

26
00:01:49,985 --> 00:01:55,550
et réalise toutes les analyses, demandées
dans la méthode, grâce à "preprocess".

27
00:01:55,550 --> 00:01:58,455
Je vous monterai également
cette méthode plus tard.

28
00:01:58,455 --> 00:02:04,750
Pour le moment, les méthodes "is_valid"
et "preprocess" sont exécutées par Beam

29
00:02:04,750 --> 00:02:09,775
sur l'ensemble de données d'entraînement
pour les filtrer et les prétraiter.

30
00:02:09,775 --> 00:02:14,335
Les données prétraitées
reviennent dans une PCollection,

31
00:02:14,335 --> 00:02:18,805
une collection parallèle que
j'appelle "transformed_dataset".

32
00:02:18,805 --> 00:02:22,550
Remarquez
que les transformations réalisées

33
00:02:22,550 --> 00:02:27,170
dans "preprocess" sont enregistrées
dans la seconde valeur de renvoi,

34
00:02:27,170 --> 00:02:30,770
la fonction "transform_fn".
Cette information est importante.

35
00:02:30,770 --> 00:02:34,510
Prenez les données transformées
"transformed_data" et écrivez-les,

36
00:02:34,510 --> 00:02:41,645
ici en tant que "TFRecords", le format
le plus efficace pour TensorFlow.

37
00:02:41,645 --> 00:02:45,685
Pour ce faire,
j'utilise le droit "PTransform"

38
00:02:45,685 --> 00:02:49,545
de "TFRecords" inclus
dans TensorFlow Transform.

39
00:02:49,545 --> 00:02:53,105
Les fichiers seront fermés
automatiquement.

40
00:02:53,105 --> 00:02:56,640
Mais remarquez quel schéma est utilisé.

41
00:02:56,640 --> 00:03:01,390
Non pas le schéma des données brutes,
mais le schéma transformé.

42
00:03:01,390 --> 00:03:05,030
Pourquoi ? Parce que, bien sûr,

43
00:03:05,030 --> 00:03:08,165
nous écrivons des données transformées,

44
00:03:08,165 --> 00:03:12,680
les données prétraitées,
pas les données brutes.