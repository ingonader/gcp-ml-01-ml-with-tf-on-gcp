前処理関数は入力データを変換する関数です Beamではデータセット分析/変換の
一部としてこの関数を呼び出します TensorFlowの前処理で実行する内容は 処理入力関数の一部として呼び出されます つまりTensorFlowグラフに追加され 処理中にTensorFlowで実行できます TensorFlowグラフの一部として
実行されるため 前処理関数は
TensorFlowで呼び出せるものに限られます 通常のPython関数は呼び出せません 前処理は
TensorFlowグラフの一部であるためです 例を見てみましょう この例では一連の入力を前処理します 入力のデータ型は何でしょうか テンソル値のディクショナリです これは処理入力関数からの戻り値であり 読み取られた生データです 入力関数は特徴を返します さらにラベルも返されます 特徴はdict（ディクショナリ）です 分析フェーズ中にTF変換が実行され P変換からのデータをテンソルに変換します そのテンソルを使用して特徴を作成し 新しい特徴をディクショナリに入れます この例の最初の結果は 変更なしで渡します 入力テンソルも変更なしで結果に追加します 次に曜日が必要です 整数として必要です ただし入力は Thu（木曜）のような文字列です そこでTensorFlow変換を利用して 読み取ったThuなどの文字列を 3や5などの整数に変換します トレーニングデータセット内の
すべての曜日について TF変換によりボキャブラリを計算します これは分析フェーズ中に実行され その情報を基に予測フェーズで
文字列を整数にマッピングします 次はドロップフラットを
0から1の範囲にスケーリングします 分析フェーズで TF変換が列の最小値と最大値を計算し その値を基に入力をスケーリングします 別のTensorFlow関数も呼び出せます ここではJSONの整数である乗客数を
実数値にキャストします すべての特徴を作成/追加したら 結果を戻します 分析と変換のP変換は
トレーニングデータセットが対象です 評価データセットはどうなるのでしょうか 評価データセットについては トレーニングデータセットとほぼ同じ
Beamパイプラインを実行します 1つ大きな違いがあります 評価データセットの分析は行いません 値をスケーリングする場合 評価データセット内の値は トレーニングデータセットの最小値/最大値を
基にスケーリングされます 評価データセットでは 分析と変換を呼び出さず TransformDatasetのみを呼び出します これで前処理の内容がすべて自動的に
呼び出されます ただしTransformDatasetの入力として トレーニングデータセットで計算した
変換関数が必要です この部分が肝になります TransformDatasetさえあれば トレーニングデータセットの場合と同じように
評価データセットを書き出せます