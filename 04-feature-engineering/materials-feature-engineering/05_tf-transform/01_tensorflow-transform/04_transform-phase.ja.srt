1
00:00:00,000 --> 00:00:06,300
前処理関数は入力データを変換する関数です

2
00:00:06,300 --> 00:00:11,745
Beamではデータセット分析/変換の
一部としてこの関数を呼び出します

3
00:00:11,745 --> 00:00:16,010
TensorFlowの前処理で実行する内容は

4
00:00:16,010 --> 00:00:20,165
処理入力関数の一部として呼び出されます

5
00:00:20,165 --> 00:00:23,825
つまりTensorFlowグラフに追加され

6
00:00:23,825 --> 00:00:28,255
処理中にTensorFlowで実行できます

7
00:00:28,255 --> 00:00:32,330
TensorFlowグラフの一部として
実行されるため

8
00:00:32,330 --> 00:00:39,450
前処理関数は
TensorFlowで呼び出せるものに限られます

9
00:00:39,450 --> 00:00:42,860
通常のPython関数は呼び出せません

10
00:00:42,860 --> 00:00:47,160
前処理は
TensorFlowグラフの一部であるためです

11
00:00:47,160 --> 00:00:49,185
例を見てみましょう

12
00:00:49,185 --> 00:00:55,025
この例では一連の入力を前処理します

13
00:00:55,025 --> 00:00:58,965
入力のデータ型は何でしょうか

14
00:00:58,965 --> 00:01:04,239
テンソル値のディクショナリです

15
00:01:04,239 --> 00:01:08,620
これは処理入力関数からの戻り値であり

16
00:01:08,620 --> 00:01:13,780
読み取られた生データです

17
00:01:13,780 --> 00:01:17,230
入力関数は特徴を返します

18
00:01:17,230 --> 00:01:20,620
さらにラベルも返されます

19
00:01:20,620 --> 00:01:25,220
特徴はdict（ディクショナリ）です

20
00:01:25,220 --> 00:01:29,900
分析フェーズ中にTF変換が実行され

21
00:01:29,900 --> 00:01:34,200
P変換からのデータをテンソルに変換します

22
00:01:34,200 --> 00:01:38,510
そのテンソルを使用して特徴を作成し

23
00:01:38,510 --> 00:01:42,155
新しい特徴をディクショナリに入れます

24
00:01:42,165 --> 00:01:46,485
この例の最初の結果は

25
00:01:46,485 --> 00:01:48,570
変更なしで渡します

26
00:01:48,570 --> 00:01:52,995
入力テンソルも変更なしで結果に追加します

27
00:01:52,995 --> 00:01:56,430
次に曜日が必要です

28
00:01:56,430 --> 00:01:58,615
整数として必要です

29
00:01:58,615 --> 00:02:00,950
ただし入力は

30
00:02:00,950 --> 00:02:04,370
Thu（木曜）のような文字列です

31
00:02:04,370 --> 00:02:08,820
そこでTensorFlow変換を利用して

32
00:02:08,820 --> 00:02:13,020
読み取ったThuなどの文字列を

33
00:02:13,040 --> 00:02:17,795
3や5などの整数に変換します

34
00:02:17,795 --> 00:02:21,630
トレーニングデータセット内の
すべての曜日について

35
00:02:21,630 --> 00:02:27,165
TF変換によりボキャブラリを計算します

36
00:02:27,165 --> 00:02:30,270
これは分析フェーズ中に実行され

37
00:02:30,270 --> 00:02:37,380
その情報を基に予測フェーズで
文字列を整数にマッピングします

38
00:02:37,380 --> 00:02:45,815
次はドロップフラットを
0から1の範囲にスケーリングします

39
00:02:45,815 --> 00:02:48,095
分析フェーズで

40
00:02:48,095 --> 00:02:52,100
TF変換が列の最小値と最大値を計算し

41
00:02:52,100 --> 00:02:56,635
その値を基に入力をスケーリングします

42
00:02:56,635 --> 00:03:00,805
別のTensorFlow関数も呼び出せます

43
00:03:00,805 --> 00:03:11,870
ここではJSONの整数である乗客数を
実数値にキャストします

44
00:03:11,870 --> 00:03:16,660
すべての特徴を作成/追加したら

45
00:03:16,660 --> 00:03:18,935
結果を戻します

46
00:03:18,935 --> 00:03:24,445
分析と変換のP変換は
トレーニングデータセットが対象です

47
00:03:24,445 --> 00:03:28,645
評価データセットはどうなるのでしょうか

48
00:03:28,645 --> 00:03:31,749
評価データセットについては

49
00:03:31,749 --> 00:03:37,605
トレーニングデータセットとほぼ同じ
Beamパイプラインを実行します

50
00:03:37,605 --> 00:03:40,405
1つ大きな違いがあります

51
00:03:40,405 --> 00:03:44,625
評価データセットの分析は行いません

52
00:03:44,625 --> 00:03:46,945
値をスケーリングする場合

53
00:03:46,945 --> 00:03:49,600
評価データセット内の値は

54
00:03:49,600 --> 00:03:54,230
トレーニングデータセットの最小値/最大値を
基にスケーリングされます

55
00:03:54,230 --> 00:03:56,650
評価データセットでは

56
00:03:56,650 --> 00:03:59,380
分析と変換を呼び出さず

57
00:03:59,380 --> 00:04:02,405
TransformDatasetのみを呼び出します

58
00:04:02,405 --> 00:04:10,160
これで前処理の内容がすべて自動的に
呼び出されます

59
00:04:10,160 --> 00:04:14,280
ただしTransformDatasetの入力として

60
00:04:14,280 --> 00:04:19,959
トレーニングデータセットで計算した
変換関数が必要です

61
00:04:19,959 --> 00:04:23,090
この部分が肝になります

62
00:04:23,090 --> 00:04:26,075
TransformDatasetさえあれば

63
00:04:26,075 --> 00:04:32,422
トレーニングデータセットの場合と同じように
評価データセットを書き出せます