Dans cet atelier, nous verrons
comment utiliser TensorFlow Transform. Nous écrirons un pipeline Beam
pour analyser et transformer les données d'entraînement. Dans ce pipeline,
nous transformerons aussi les données d'évaluation et enregistrerons la fonction de transformation
pour l'utiliser lors de la prédiction. Nous modifierons les fonctions d'entrée d'entraînement et d'évaluation
pour lire les fichiers prétraités. Nous entraînerons ensuite
le modèle comme d'habitude. Comme nous aurons prétraité les données, nous pourrons effectuer
ce prétraitement à l'échelle sur de très grands ensembles de données
lors de l'entraînement avec Dataflow. Nous pourrons aussi effectuer
le prétraitement efficacement dans le cadre du graphique du modèle
dans TensorFlow lors de la diffusion. Il s'agit d'une manière
de tirer parti de l'échelle du cloud en effectuant un prétraitement sur de
multiples processeurs de façon distribuée et de profiter
de l'efficacité des processeurs, des GPU et des unités de traitement
TensorFlow lors de la prédiction. Je vous invite donc à lancer Qwiklabs
et à essayer cet atelier.