Googleのプログラムマネージャーの Carl Osipovです Google Cloudをご利用のお客様が スケーラブルで本番環境に対応した
MLシステムを導入するサポートしています ここではMLシステムの 特徴量セットを準備するための2つの手法 入力データの前処理と
特徴量の作成を取り上げます まず 前処置と特徴量作成の例を見ながら 特徴エンジニアリングの
一部であるこれらを適用する際の 課題について説明します 次に こうした課題の解決に役立つ Google Cloud Dataflowや
Cloud Dataprepなどの ツールについて説明します それでは 前処理と特徴量作成を行うのは
どのような場合なのか例を挙げて見ていきます 特徴量の一部の値は MLモデルに渡す前に 正規化しスケール変換する必要があります スケール変換とは 価格などの実数値の特徴量を 表示された式で0～1の範囲に変換することです スケール変換を行う理由はさまざまですが 通常は 勾配降下法の
パフォーマンス向上を目的としています この式でスケール変換するには 特徴量の最小値と最大値が必要です それらの値がわからなければ データセット全体を前処理して
値を求める必要があります 前処理は 画面のコードのように 都市名などのデータセットの
カテゴリ値にも有効です たとえば TensorFlowで ワンホットエンコーディングにより 各都市を2進値の特徴量で表すなら Layers APIのcategorical_column_
with_vocabulary_listメソッドを使用できます このメソッドを使用するには
都市名などの値のリストを渡す必要があります keyに入れるこの値の辞書がなければ データセット全体の前処理を行って作成します このモジュールでは3つの 前処理テクノロジーを紹介します BigQueryとApache Beamは トレーニング前に
入力データセット全体を処理します 一部のデータポイントの除外や基本統計量と
ボキャブラリの計算などを行います 特徴量によっては 一定期間内の 統計量が必要です たとえば あるサイトで 1時間に売り上げた製品数などには Beamのバッチおよびストリーム
データパイプラインを使用します その他の特徴量は TensorFlowに直接または
Beamを使って実装できます このため Apache Beamと 相補的なGoogle Cloudテクノロジー
Cloud Dataflowが重要です まず BigQueryとTensorFlowのみの 特徴エンジニアリングの制限について 次に Beamを使った対処法について
説明します BigQueryは Google Cloudサービスの一つで
高速でスケーラブルな フルマネージドのデータウェアハウスです 標準SQLで前処理を実装できるため 特徴量エンジニアリングに有効です たとえば NYのタクシー利用に関する 100億件のデータセットを前処理する場合 中には不正なデータが
含まれている場合があります この場合 不正なデータを排除する
SQLステートメントを書いて BigQueryで数秒で実行できます 標準SQLの数学関数やデータ処理関数を使った その他のステートメントも使用できます ソースデータの加算などの簡単な計算や タイムスタンプから時刻を抽出するなどの データ形式の解析に役立ちます SQLを使って前処理を行う場合 必ず TensorFlowでも まったく同じ前処理ロジックを実装します 次に TensorFlowで
前処理コードを書く方法を 2つ紹介します 実際には1つ目か2つ目の方法のどちらか または両方を使うこともあります 一般的な前処理であれば TensorFlowの特徴量カラムAPIの
既存メソッド使って書くことができます たとえば 実数値の特徴量を
離散値に変換するなら bucketized_columnメソッドを使用できます TensorFlowAPIで既存のものがない場合でも 学習、検証、テスト時に 入力パラメータに使用する関数を変更できます 詳しく説明していきます まず 独自の前処理コードを実装する場合です ここでは 前処理コードが add_engineeredメソッドで
パッケージ化されていて ソースデータセットの
グローバル統計量は必要ありません 緯度、経度による座標データから
ユークリッド距離を計算するため コードは元の特徴量辞書と 距離の式で求めた新しい特徴量を返します 学習、評価、供給段階に ユークリッド距離が含まれるよう 対応するinput-fn関数はすべて add_engineeredメソッドの呼び出しで
前処理された特徴量をラップしています 次に 既存の前処理ステップを使用する場合です 適当なヘルパーメソッドを呼び出して 特徴量カラムを定義できます ここではbucketized_columnメソッド使って ソースデータから緯度を求め 値を38～42の範囲内に収めています 次に 元の緯度の値は 相互排他的なバケットに配置され 範囲内のバケット数は最後のバケットの
パラメータで制御されます BigQueryのSQLとTensorFlowでの 前処理コードの管理は
複雑で困難な場合があります Apache Beamを利用した
前処理の利点の一つは モデルの学習と供給の両方で 同じコードを使用できることです ただし TensorFlowの 便利なヘルパーメソッドは使用できません つまり この例のように 独自のコードの実装が必要です このモジュールでは Apache Beamを使った
前処理の例を紹介しました