1
00:00:01,589 --> 00:00:02,940
Pour démarrer cet atelier,

2
00:00:02,940 --> 00:00:07,375
vérifiez que Google Cloud Platform
est ouvert dans votre navigateur.

3
00:00:07,375 --> 00:00:11,755
Cliquez d'abord
sur "Activer Google Cloud Shell".

4
00:00:11,755 --> 00:00:15,360
Il est essentiel de préparer
l'environnement Cloud Shell

5
00:00:15,360 --> 00:00:19,055
avec le code source et les packages
nécessaires pour l'exécuter.

6
00:00:19,055 --> 00:00:21,620
Si vous venez
de terminer l'atelier précédent,

7
00:00:21,620 --> 00:00:24,605
le code et les packages
devraient déjà être installés.

8
00:00:24,605 --> 00:00:26,930
Cependant,
si votre environnement Cloud Shell

9
00:00:26,930 --> 00:00:30,440
ne contient pas
le répertoire "training-data-analyst",

10
00:00:30,440 --> 00:00:35,090
arrêtez cet atelier et effectuez
le précédent avant d'aller plus loin.

11
00:00:35,090 --> 00:00:37,390
Si votre environnement
Cloud Shell est configuré,

12
00:00:37,390 --> 00:00:40,730
vous pouvez utiliser l'éditeur
de code Cloud Shell pour ouvrir

13
00:00:40,730 --> 00:00:44,650
le code source du pipeline
Apache Beam utilisé dans cet atelier.

14
00:00:44,650 --> 00:00:49,230
Vous le trouverez dans le répertoire
"training-data-analyst/courses/

15
00:00:49,230 --> 00:00:52,080
data_analysis/lab2/

16
00:00:52,080 --> 00:00:56,890
python", fichier "is_popular.py".

17
00:00:56,890 --> 00:01:01,045
Il y a plus de code dans ce fichier
que dans celui de l'atelier précédent.

18
00:01:01,045 --> 00:01:05,140
Vous verrez ensuite
le code plus en détail.

19
00:01:05,140 --> 00:01:08,430
Si vous faites défiler jusqu'au corps
de la méthode principale,

20
00:01:08,430 --> 00:01:11,330
vous pouvez voir
l'argument d'entrée du code.

21
00:01:11,330 --> 00:01:14,402
En entrée, le pipeline prend les fichiers

22
00:01:14,402 --> 00:01:17,475
de code source Java
du répertoire "javahelp".

23
00:01:17,475 --> 00:01:24,070
Notez que le résultat du pipeline
sera stocké dans le répertoire "/tmp",

24
00:01:24,070 --> 00:01:27,530
dans des fichiers
ayant par défaut le préfixe "output".

25
00:01:27,530 --> 00:01:30,060
Ce paramètre est bien sûr modifiable.

26
00:01:30,060 --> 00:01:32,660
Une fois les données lues
depuis Google Cloud Storage,

27
00:01:32,660 --> 00:01:35,690
l'étape suivante
du pipeline consiste à vérifier les lignes

28
00:01:35,690 --> 00:01:37,230
qui commencent par le terme clé.

29
00:01:37,230 --> 00:01:39,850
Comme vous l'avez vu
dans l'atelier précédent,

30
00:01:39,850 --> 00:01:43,745
le terme clé de ce pipeline est "import".

31
00:01:43,745 --> 00:01:49,245
Le pipeline traite ensuite
les noms des packages importés.

32
00:01:49,245 --> 00:01:54,480
Notez que ceci dépend
de la méthode "PackageUse",

33
00:01:54,480 --> 00:01:56,560
qui vérifie à son tour
les noms des packages

34
00:01:56,560 --> 00:02:00,480
dans l'instruction d'importation,
extrait le nom du package,

35
00:02:00,480 --> 00:02:02,280
et supprime le mot clé "import"

36
00:02:02,280 --> 00:02:04,335
ainsi que le point-virgule de fermeture.

37
00:02:04,335 --> 00:02:07,500
Enfin, une fois le nom du package obtenu,

38
00:02:07,500 --> 00:02:13,280
la fonction "splitPackageName" renvoie
les préfixes de chaque nom de package.

39
00:02:13,280 --> 00:02:17,790
Par exemple, pour un package
nommé "com.example.appname",

40
00:02:17,790 --> 00:02:24,980
la fonction renvoie les préfixes "com",
"com.example" et "com.example.appname".

41
00:02:24,980 --> 00:02:26,880
Pour chacun de ces packages,

42
00:02:26,880 --> 00:02:32,290
la méthode renvoie une paire : le préfixe
et le chiffre 1 pour chaque occurrence.

43
00:02:32,290 --> 00:02:34,900
Les occurrences sont ajoutées ensemble

44
00:02:34,900 --> 00:02:39,450
à l'aide de l'opération "CombinePerKey"
et la fonction "sum" en argument.

45
00:02:39,450 --> 00:02:45,290
Le combinateur du top cinq identifie
les cinq packages les plus importés.

46
00:02:45,290 --> 00:02:50,290
Vous pouvez ensuite exécuter
le fichier "is_popular.py".

47
00:02:50,290 --> 00:02:53,100
Une fois le pipeline exécuté,

48
00:02:53,100 --> 00:02:55,330
vous pouvez vérifier
le répertoire de sortie.

49
00:02:55,330 --> 00:02:57,780
Si vous répertoriez
les fichiers qu'il contient,

50
00:02:57,780 --> 00:03:01,090
vous pouvez voir
les packages les plus populaires :

51
00:03:01,090 --> 00:03:08,565
"org", "org.apache", "org.apache.beam"
et "org.apache.beam.sdk".

52
00:03:08,565 --> 00:03:12,520
Lors de la mise en œuvre de ce pipeline,

53
00:03:12,520 --> 00:03:15,775
il est possible de modifier
la destination du résultat.

54
00:03:15,775 --> 00:03:18,352
Par exemple,
si vous modifiez les paramètres par défaut

55
00:03:18,352 --> 00:03:20,410
pour demander au pipeline

56
00:03:20,410 --> 00:03:26,005
d'écrire les résultats dans le répertoire
"/tmp" avec le préfixe "myoutput",

57
00:03:26,005 --> 00:03:31,160
vous pouvez exécuter le pipeline à nouveau
et rechercher le nouveau résultat.

58
00:03:31,160 --> 00:03:36,070
Les nouvelles instances des fichiers
de sortie auront le préfixe "myoutput".

59
00:03:36,070 --> 00:03:38,730
Voilà. Cet atelier est terminé.