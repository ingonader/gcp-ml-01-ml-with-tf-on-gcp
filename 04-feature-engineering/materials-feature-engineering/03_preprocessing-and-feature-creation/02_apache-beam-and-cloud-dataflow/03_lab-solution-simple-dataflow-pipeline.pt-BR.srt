1
00:00:00,000 --> 00:00:02,360
Neste laboratório, você precisa
do código-fonte

2
00:00:02,360 --> 00:00:04,890
copiado do GitHub para
o ambiente do Cloud Shell.

3
00:00:04,890 --> 00:00:07,290
E você também precisará
executar um script

4
00:00:07,290 --> 00:00:10,925
de download das bibliotecas que terão
as dependências por meio do canal.

5
00:00:10,925 --> 00:00:13,585
Essas etapas levam alguns minutos
para serem concluídas.

6
00:00:13,585 --> 00:00:16,900
Agora, você pode ver o
avanço rápido do vídeo por essas

7
00:00:16,900 --> 00:00:22,155
etapas até o código-fonte ser instalado
e as bibliotecas baixadas.

8
00:00:22,155 --> 00:00:27,560
Do Cloud Shell, você pode usar diferentes
editores para ver o código-fonte do canal.

9
00:00:27,560 --> 00:00:30,695
Você pode usar um editor baseado
em texto, como o Nano.

10
00:00:30,695 --> 00:00:32,450
Mas aqui neste vídeo,

11
00:00:32,450 --> 00:00:36,165
você me verá usando um editor gráfico
integrado no Cloud Shell.

12
00:00:36,165 --> 00:00:37,860
Quando este editor carrega,

13
00:00:37,860 --> 00:00:40,060
veja que, no menu à esquerda,

14
00:00:40,060 --> 00:00:42,385
você pode abrir o training-data-analyst,

15
00:00:42,385 --> 00:00:46,810
courses, data_analysis, lab2, pasta python

16
00:00:46,810 --> 00:00:50,215
e acessar o código-fonte do canal
no arquivo grep.py.

17
00:00:50,215 --> 00:00:57,140
O código-fonte pega como entrada os vários
arquivos Java destacados na linha 26.

18
00:00:57,140 --> 00:01:02,045
Assim, você usará o arquivo Java
especificado como a instrução curinga.

19
00:01:02,045 --> 00:01:04,170
Para cada um dos arquivos,

20
00:01:04,170 --> 00:01:08,825
a transformação está procurando por linhas
de código-fonte Java com a palavra-chave.

21
00:01:08,825 --> 00:01:11,475
O termo de pesquisa é "import".

22
00:01:11,475 --> 00:01:17,555
Você pode ver os detalhes da implementação
do canal nas linhas 32 a 34.

23
00:01:17,555 --> 00:01:20,630
Observe que a etapa grep do canal

24
00:01:20,630 --> 00:01:24,335
está usando o método My_grep
definido na linha 20.

25
00:01:24,335 --> 00:01:27,950
O método My_grep procura pelo
termo de pesquisa "import".

26
00:01:27,950 --> 00:01:31,540
Para todas as linhas com
o termo de pesquisa,

27
00:01:31,540 --> 00:01:35,675
o resultado é gravado no
diretório /tmp/output.

28
00:01:35,675 --> 00:01:38,160
Para executar o canal no Cloud Shell,

29
00:01:38,160 --> 00:01:40,590
basta usar o comando Python e passar

30
00:01:40,590 --> 00:01:43,890
o nome do arquivo de código-fonte com
a implementação do canal.

31
00:01:43,890 --> 00:01:46,810
O canal foi concluído
com êxito e você pode

32
00:01:46,810 --> 00:01:50,395
confirmar isso examinando os arquivos de
saída que o canal criou.

33
00:01:50,395 --> 00:01:54,380
O canal identificou corretamente todas as
linhas de código-fonte Java

34
00:01:54,380 --> 00:01:57,095
com a palavra-chave "import".

35
00:01:57,095 --> 00:01:59,185
Na parte restante do laboratório,

36
00:01:59,185 --> 00:02:01,730
você pegará esse código-fonte do canal

37
00:02:01,730 --> 00:02:05,375
e o preparará para ser executado na
plataforma do Google Cloud Dataflow.

38
00:02:05,375 --> 00:02:07,110
Mas antes que você possa fazer isso,

39
00:02:07,110 --> 00:02:08,990
há algumas etapas de pré-requisitos.

40
00:02:08,990 --> 00:02:12,210
Primeiro, você precisa procurar por
APIs Dataflow

41
00:02:12,210 --> 00:02:17,070
no GCP e ativar as APIs usando o botão
de ativação exibido na tela.

42
00:02:17,070 --> 00:02:19,115
Isso levará alguns instantes,

43
00:02:19,115 --> 00:02:23,965
então o vídeo avançará rapidamente
até que as APIs sejam ativadas.

44
00:02:23,965 --> 00:02:28,490
Certo, para confirmar
se as APIs estão ativadas,

45
00:02:28,490 --> 00:02:32,555
veja se o botão "Desativar"
está na tela da API Dataflow.

46
00:02:32,555 --> 00:02:35,190
Em seguida, você precisa ter certeza

47
00:02:35,190 --> 00:02:38,175
de ter um intervalo do Cloud Storage
criado para o seu canal.

48
00:02:38,175 --> 00:02:39,810
Você pode criar esse intervalo

49
00:02:39,810 --> 00:02:41,940
e é importante atribuir a ele

50
00:02:41,940 --> 00:02:45,735
um nome exclusivo e verificar se está
configurado como original.

51
00:02:45,735 --> 00:02:50,750
Aqui, atribuí us-east4
para a região da Virgínia do Norte.

52
00:02:50,750 --> 00:02:53,565
Certo. Quando o intervalo estiver pronto,

53
00:02:53,565 --> 00:02:56,060
você copiará os arquivos
de código-fonte de entrada

54
00:02:56,060 --> 00:02:59,760
do canal do Cloud Shell para o intervalo
do Google Cloud Storage.

55
00:02:59,760 --> 00:03:02,360
Faça isso usando
o comando de cópia do GSU.

56
00:03:02,360 --> 00:03:04,250
Lembre-se de que você está copiando

57
00:03:04,250 --> 00:03:08,120
esses arquivos de código-fonte Java
para o canal porque ele

58
00:03:08,120 --> 00:03:10,950
não tem acesso ao sistema de arquivos

59
00:03:10,950 --> 00:03:14,375
do Cloud Shell, enquanto é executado
no Google Cloud Dataflow.

60
00:03:15,025 --> 00:03:18,535
Depois que o comando de cópia gsutil
terminar de copiar os arquivos,

61
00:03:18,535 --> 00:03:22,080
você pode voltar ao intervalo do Google
Cloud Storage em seu navegador,

62
00:03:22,080 --> 00:03:27,425
atualizar a página e confirmar que
os arquivos foram copiados com êxito.

63
00:03:27,865 --> 00:03:30,440
Aqui estão os quatro
arquivos Java que serão usados

64
00:03:30,440 --> 00:03:33,925
​​como entrada para seu canal em execução
no Google Cloud Dataflow.

65
00:03:34,525 --> 00:03:37,845
Em seguida, observe o código-fonte
da implementação do canal

66
00:03:37,845 --> 00:03:42,045
que foi modificado para ser executado
na plataforma do Google Cloud Dataflow.

67
00:03:42,045 --> 00:03:45,265
Está no arquivo grepc.py.

68
00:03:46,065 --> 00:03:50,195
Observe que este usa constance
para nomes de projetos e intervalos.

69
00:03:50,195 --> 00:03:55,430
No meu caso, usei o mesmo código exclusivo
para o projeto e o intervalo.

70
00:03:55,430 --> 00:03:57,800
Então eu vou colocar
o mesmo valor para ambos.

71
00:03:58,320 --> 00:03:59,860
O código também especifica

72
00:03:59,860 --> 00:04:03,860
alguns parâmetros que eu precisava para
executar este canal no Cloud Dataflow.

73
00:04:04,170 --> 00:04:08,090
Por exemplo, você precisa especificar o
nome do job que está executando o canal,

74
00:04:08,090 --> 00:04:12,520
e também o DataflowRunner,
para executar o canal no Dataflow.

75
00:04:13,070 --> 00:04:15,400
Aqui, a entrada e a saída

76
00:04:15,400 --> 00:04:19,329
são especificadas como caminhos para o
intervalo do Google Cloud Storage.

77
00:04:20,550 --> 00:04:23,535
O restante do código para o canal
permanece o mesmo.

78
00:04:23,535 --> 00:04:25,830
Para executar seu canal no Dataflow,

79
00:04:25,830 --> 00:04:29,160
você ainda usa o comando Python
e passa como argumentos

80
00:04:29,160 --> 00:04:32,520
o nome do arquivo e o código-fonte
da implementação do canal.

81
00:04:33,110 --> 00:04:36,710
Aqui, como o código-fonte usou
o DataflowRunner,

82
00:04:36,710 --> 00:04:40,850
seu código será empacotado como
bibliotecas Dataflow

83
00:04:40,850 --> 00:04:46,360
e enviado como job para executar um canal
na plataforma do Google Cloud Dataflow.

84
00:04:47,030 --> 00:04:49,380
Quando o comando Python
terminar de ser executado,

85
00:04:49,380 --> 00:04:52,470
você volta para o GCP e abre

86
00:04:52,470 --> 00:04:56,925
o Dataflow usando o menu de três traços
à esquerda ou usando a barra de pesquisa.

87
00:04:56,925 --> 00:04:58,980
E do painel do Dataflow,

88
00:04:58,980 --> 00:05:03,045
você pode monitorar o canal que acabou
de enviar como um dos jobs.

89
00:05:03,705 --> 00:05:06,245
Aqui, o job é chamado de example2,

90
00:05:06,245 --> 00:05:09,415
porque esse é o nome que usei
no arquivo grepc.py.

91
00:05:09,415 --> 00:05:12,970
Primeiro, você notará que o job ainda
não foi totalmente iniciado.

92
00:05:12,970 --> 00:05:15,910
Ele diz que é escalonamento
automático e mostra

93
00:05:15,910 --> 00:05:19,505
que está usando apenas um único
núcleo virtual para execução.

94
00:05:20,025 --> 00:05:21,800
No lado direito, você também pode ver

95
00:05:21,800 --> 00:05:25,145
opções de canais e outras
informações sobre o job.

96
00:05:25,535 --> 00:05:29,360
Na seção de registro, você pode descobrir
que o canal ainda não está em execução

97
00:05:29,360 --> 00:05:32,145
porque ele ainda está inicializando
um dos workers,

98
00:05:32,145 --> 00:05:36,395
e você pode confirmar isso pelo gráfico
na seção de escalonamento automático.

99
00:05:36,975 --> 00:05:41,455
Aqui, você notará que o job está esperando
usar um worker de destino.

100
00:05:41,455 --> 00:05:45,160
E, atualmente, o número de workers
passou de zero para um.

101
00:05:45,160 --> 00:05:48,055
Isso significa que exatamente
uma instância virtual

102
00:05:48,055 --> 00:05:50,835
foi provisionada para executar esse canal.

103
00:05:51,845 --> 00:05:54,770
Levará alguns minutos para esse canal
concluir a execução.

104
00:05:54,770 --> 00:05:56,930
Agora, você pode ver o vídeo avançar

105
00:05:56,930 --> 00:06:00,265
alguns minutos,
até que o job seja concluído.

106
00:06:00,265 --> 00:06:04,760
Se olhar mais atentamente o canal, poderá
dizer, pelas marcas de seleção verdes,

107
00:06:04,760 --> 00:06:06,720
que todas as etapas individuais para

108
00:06:06,720 --> 00:06:08,725
as transformações foram concluídas.

109
00:06:08,725 --> 00:06:11,430
E, analisando o gráfico
no canto inferior direito,

110
00:06:11,430 --> 00:06:13,500
você perceberá que todos os workers

111
00:06:13,500 --> 00:06:16,420
usados ​​para executar o canal
foram reduzidos.

112
00:06:17,000 --> 00:06:19,460
Você pode dar uma olhada
na saída desse canal

113
00:06:19,460 --> 00:06:24,195
copiando os arquivos de saída do
Google Cloud Storage para o Cloud Shell.

114
00:06:24,635 --> 00:06:26,540
E assim que os arquivos forem copiados,

115
00:06:26,540 --> 00:06:30,635
você poderá revisá-los diretamente
no Cloud Shell ou também abrir

116
00:06:30,635 --> 00:06:33,020
o Google Cloud Storage no navegador

117
00:06:33,020 --> 00:06:35,945
e encontrar os arquivos
no intervalo na pasta Java Help.

118
00:06:35,945 --> 00:06:39,230
Os arquivos terão um prefixo de saídas,

119
00:06:39,230 --> 00:06:41,600
então eles serão nomeados como 04,

120
00:06:41,600 --> 00:06:44,105
0104, 0204 e assim por diante.

121
00:06:44,105 --> 00:06:46,430
Para revisar o conteúdo dos arquivos,

122
00:06:46,430 --> 00:06:50,530
é importante que você use uma caixa
de seleção de link pública à direita.

123
00:06:50,530 --> 00:06:53,880
Aqui, você pode ver o conteúdo
do primeiro arquivo.