1
00:00:00,000 --> 00:00:01,530
En esta parte del módulo

2
00:00:01,530 --> 00:00:04,960
conocerán lo que se necesita
para implementar una canalización

3
00:00:04,960 --> 00:00:08,127
que se va escalando a medida
que crece el conjunto de datos.

4
00:00:08,127 --> 00:00:09,735
Veamos.

5
00:00:10,935 --> 00:00:13,930
Tal vez, algunos ya conocen MapReduce.

6
00:00:13,930 --> 00:00:17,760
Es un marco de trabajo de procesamiento
de datos distribuido y tolerante a fallas

7
00:00:17,760 --> 00:00:22,435
que fue descrito por Google en un artículo
de investigación muy influyente, en 2004.

8
00:00:22,595 --> 00:00:24,370
Se sigue usando con mucha frecuencia

9
00:00:24,370 --> 00:00:26,735
por ejemplo, en el proyecto Apache ParDo.

10
00:00:27,155 --> 00:00:30,770
Es importante conocer
los conceptos básicos de MapReduce

11
00:00:30,770 --> 00:00:35,160
porque Dataflow y Apache Beam
utilizan ideas de ese marco de trabajo.

12
00:00:35,450 --> 00:00:39,080
Aunque también incluyen innovaciones
desarrolladas por los investigadores

13
00:00:39,080 --> 00:00:41,795
e ingenieros de Google después de 2004.

14
00:00:42,705 --> 00:00:46,865
El diagrama que aparece en la pantalla
es una introducción rápida a MapReduce.

15
00:00:47,190 --> 00:00:52,939
Para procesar datos en MapReduce,
primero los "fragmentamos" o subdividimos.

16
00:00:53,415 --> 00:00:57,240
Los fragmentos de datos se distribuyen
en dispositivos de almacenamiento

17
00:00:57,240 --> 00:01:00,900
en múltiples nodos
de procesamiento de un clúster.

18
00:01:01,270 --> 00:01:06,060
En el diagrama, vemos que los datos
se reparten entre los nodos 1 a 3.

19
00:01:06,060 --> 00:01:08,090
en el clúster de procesamiento.

20
00:01:09,320 --> 00:01:12,850
Para ejecutar un trabajo de procesamiento
de datos en este marco de trabajo

21
00:01:12,850 --> 00:01:15,830
escribiremos código
para las funciones Map y Reduce.

22
00:01:15,830 --> 00:01:17,340
Primero, veamos a Map.

23
00:01:18,130 --> 00:01:21,850
Un Map debe ser una función
sin estado, para que se pueda programar

24
00:01:21,850 --> 00:01:25,040
su ejecución en paralelo
en todos los nodos del clúster.

25
00:01:25,340 --> 00:01:30,560
Cada Map lee los datos del almacenamiento
del nodo en el que se ejecuta

26
00:01:30,560 --> 00:01:33,980
los procesa y genera un resultado.

27
00:01:34,740 --> 00:01:38,040
La salida de las operaciones Map se mezcla

28
00:01:38,040 --> 00:01:42,515
con la de los otros nodos del clúster
para pasar a la siguiente etapa: Reduce.

29
00:01:42,515 --> 00:01:47,160
Las reducciones son como
operaciones de agregación con datos.

30
00:01:47,650 --> 00:01:51,320
Las agregaciones son procesos
como contar la cantidad elementos de datos

31
00:01:51,320 --> 00:01:52,805
o calcular sumas.

32
00:01:53,205 --> 00:01:55,790
Una vez que finalizan
las operaciones de reducción

33
00:01:55,790 --> 00:01:59,910
el resultado se transforma en la salida
del paso de MapReduce en una canalización.

34
00:02:01,820 --> 00:02:03,830
Si queremos tomar una transformación

35
00:02:03,830 --> 00:02:05,910
en la canalización
de procesamiento de datos

36
00:02:05,910 --> 00:02:08,402
y dejamos
que Dataflow la ejecute a escala

37
00:02:08,402 --> 00:02:11,615
con distribución automática
en varios nodos de un clúster

38
00:02:11,615 --> 00:02:15,490
debemos usar
la clase ParDo de Apache Beam.

39
00:02:15,490 --> 00:02:17,975
ParDo es una contracción de "parallel do".

40
00:02:17,975 --> 00:02:20,590
Los pasos de transformación
creados con ParDo

41
00:02:20,590 --> 00:02:23,435
son parecidos a los Map en MapReduce.

42
00:02:23,835 --> 00:02:26,060
Las transformaciones
realizadas con ParDo

43
00:02:26,060 --> 00:02:29,105
no deben tener estado,
para poder ejecutarlas en paralelo.

44
00:02:29,415 --> 00:02:32,600
Es un poco restrictivo,
pero útil para realizar muchas tareas.

45
00:02:32,880 --> 00:02:36,280
Por ejemplo, si creamos
una canalización de procesamiento de datos

46
00:02:36,280 --> 00:02:38,735
para analizar archivos
de registro de servidores web

47
00:02:38,735 --> 00:02:41,070
y necesitamos filtrar
las entradas de registro

48
00:02:41,070 --> 00:02:43,875
que tienen la dirección de IP
de un visitante del sitio web.

49
00:02:43,875 --> 00:02:46,220
Podemos hacerlo
con una transformación sin estado

50
00:02:46,220 --> 00:02:51,172
o, para extraer el valor de la dirección
de IP de la string de la entrada

51
00:02:51,185 --> 00:02:53,195
lo podemos hacer sin estado.

52
00:02:53,365 --> 00:02:55,710
Otras operaciones
de procesamiento sin estado

53
00:02:55,710 --> 00:02:57,752
como convertir strings en números enteros

54
00:02:57,752 --> 00:03:00,715
o cualquier cálculo que use
solo con parte de la entrada

55
00:03:00,715 --> 00:03:04,680
como una fila de datos,
también pueden hacerse con ParDo.

56
00:03:06,180 --> 00:03:09,800
Si usamos Python para implementar
la canalización de procesamiento de datos

57
00:03:09,800 --> 00:03:13,190
hay métodos de ayuda
para comenzar a usar ParDo.

58
00:03:13,640 --> 00:03:19,020
Beam.Map, que aparece en la pantalla,
se diseñó solo para relaciones uno a uno.

59
00:03:19,020 --> 00:03:22,385
Por ejemplo, si procesamos
las palabras de un documento

60
00:03:22,385 --> 00:03:28,270
y, por cada palabra, queremos mostrar
un par, con la palabra y su longitud

61
00:03:28,305 --> 00:03:32,260
existe una relación uno a uno,
ya que cada palabra puede corresponderse

62
00:03:32,260 --> 00:03:35,970
solo con una longitud, determinada
por la cantidad de caracteres que posee.

63
00:03:36,370 --> 00:03:40,980
Si usamos beam.Map para la transformación
en nuestra canalización, Dataflow manejará

64
00:03:40,980 --> 00:03:43,535
automáticamente la ejecución
durante la transformación

65
00:03:43,535 --> 00:03:46,660
como los cálculos de la longitud
de palabras en varios nodos

66
00:03:46,660 --> 00:03:48,779
de un clúster de Dataflow.

67
00:03:48,779 --> 00:03:53,389
A diferencia de Map, beam.FlatMap
admite transformaciones

68
00:03:53,389 --> 00:03:58,090
que pueden generar cualquier cantidad
de salidas para una entrada, incluso cero.

69
00:03:58,540 --> 00:04:02,130
Volvamos al ejemplo
de las palabras del documento

70
00:04:02,130 --> 00:04:06,140
y supongamos que, por cada palabra,
queremos obtener una lista de sus vocales.

71
00:04:06,140 --> 00:04:10,390
El resultado puede ser 0, 1, 2
o incluso más vocales por palabra.

72
00:04:10,925 --> 00:04:15,370
Las transformaciones de beam.FlatMap
también pueden ejecutarse en paralelo

73
00:04:15,370 --> 00:04:16,172
con Dataflow.

74
00:04:17,232 --> 00:04:20,055
Si usamos Java
para implementar la canalización

75
00:04:20,055 --> 00:04:23,080
simplemente llamamos
a ParDo.of seguido del método estático

76
00:04:23,080 --> 00:04:26,855
en la transformación y pasamos
el resultado al siguiente llamado apply

77
00:04:26,855 --> 00:04:27,857
de la canalización.

78
00:04:27,857 --> 00:04:33,100
Para usar la operación GroupByKey,
es muy fácil agregarla a la canalización.

79
00:04:33,690 --> 00:04:37,690
Por ejemplo, si tenemos una canalización
que procesa direcciones postales

80
00:04:37,690 --> 00:04:41,170
e intenta encontrar todos
los códigos postales de cada ciudad

81
00:04:41,170 --> 00:04:45,050
una vez que la canalización
tenga una PCollection de pares clave-valor

82
00:04:45,050 --> 00:04:49,170
como aquí, con el par
que incluye una clave y un código postal

83
00:04:49,170 --> 00:04:54,280
la salida creada por beam.GoupByKey
producirá una PCollection de pares

84
00:04:54,280 --> 00:04:57,555
cada uno de los cuales
incluye la ciudad como clave

85
00:04:57,555 --> 00:05:00,480
y una lista
de códigos postales como valor.

86
00:05:02,780 --> 00:05:06,485
Si bien GroupByKey es similar
al paso de mezcla de MapReduce

87
00:05:06,485 --> 00:05:09,960
la operación Combine.PerKey
es más general y además incluye

88
00:05:09,960 --> 00:05:11,852
tanto pasos de mezcla como de reducción

89
00:05:11,852 --> 00:05:15,525
para ayudarnos a implementar
agregaciones como sum o count.

90
00:05:15,845 --> 00:05:20,154
Podemos usar el método Combine.globally
para hacer cálculos con todos los datos.

91
00:05:20,505 --> 00:05:23,765
Por ejemplo, si procesamos
datos de transacciones financieras

92
00:05:23,765 --> 00:05:28,505
y cada fila de la PCollection
es el monto de venta de una transacción

93
00:05:28,505 --> 00:05:32,195
para calcular el total de ventas
de todas las transacciones

94
00:05:32,195 --> 00:05:36,450
podemos usar Combine.global
con la operación sum como argumento.

95
00:05:37,190 --> 00:05:40,755
Combine también es compatible
con agregaciones más detalladas.

96
00:05:40,935 --> 00:05:44,130
Por ejemplo, si sus registros
de transacciones financieras incluyen

97
00:05:44,130 --> 00:05:47,675
los nombres de los vendedores,
además de los montos de venta

98
00:05:47,675 --> 00:05:50,760
podemos pasar la operación Sum
a Combine.PerKey

99
00:05:50,760 --> 00:05:55,100
a fin de combinar
el total de ventas por vendedor.