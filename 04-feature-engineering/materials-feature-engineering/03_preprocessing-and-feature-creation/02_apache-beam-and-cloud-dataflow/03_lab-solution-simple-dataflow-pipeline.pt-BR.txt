Neste laboratório, você precisa
do código-fonte copiado do GitHub para
o ambiente do Cloud Shell. E você também precisará
executar um script de download das bibliotecas que terão
as dependências por meio do canal. Essas etapas levam alguns minutos
para serem concluídas. Agora, você pode ver o
avanço rápido do vídeo por essas etapas até o código-fonte ser instalado
e as bibliotecas baixadas. Do Cloud Shell, você pode usar diferentes
editores para ver o código-fonte do canal. Você pode usar um editor baseado
em texto, como o Nano. Mas aqui neste vídeo, você me verá usando um editor gráfico
integrado no Cloud Shell. Quando este editor carrega, veja que, no menu à esquerda, você pode abrir o training-data-analyst, courses, data_analysis, lab2, pasta python e acessar o código-fonte do canal
no arquivo grep.py. O código-fonte pega como entrada os vários
arquivos Java destacados na linha 26. Assim, você usará o arquivo Java
especificado como a instrução curinga. Para cada um dos arquivos, a transformação está procurando por linhas
de código-fonte Java com a palavra-chave. O termo de pesquisa é "import". Você pode ver os detalhes da implementação
do canal nas linhas 32 a 34. Observe que a etapa grep do canal está usando o método My_grep
definido na linha 20. O método My_grep procura pelo
termo de pesquisa "import". Para todas as linhas com
o termo de pesquisa, o resultado é gravado no
diretório /tmp/output. Para executar o canal no Cloud Shell, basta usar o comando Python e passar o nome do arquivo de código-fonte com
a implementação do canal. O canal foi concluído
com êxito e você pode confirmar isso examinando os arquivos de
saída que o canal criou. O canal identificou corretamente todas as
linhas de código-fonte Java com a palavra-chave "import". Na parte restante do laboratório, você pegará esse código-fonte do canal e o preparará para ser executado na
plataforma do Google Cloud Dataflow. Mas antes que você possa fazer isso, há algumas etapas de pré-requisitos. Primeiro, você precisa procurar por
APIs Dataflow no GCP e ativar as APIs usando o botão
de ativação exibido na tela. Isso levará alguns instantes, então o vídeo avançará rapidamente
até que as APIs sejam ativadas. Certo, para confirmar
se as APIs estão ativadas, veja se o botão "Desativar"
está na tela da API Dataflow. Em seguida, você precisa ter certeza de ter um intervalo do Cloud Storage
criado para o seu canal. Você pode criar esse intervalo e é importante atribuir a ele um nome exclusivo e verificar se está
configurado como original. Aqui, atribuí us-east4
para a região da Virgínia do Norte. Certo. Quando o intervalo estiver pronto, você copiará os arquivos
de código-fonte de entrada do canal do Cloud Shell para o intervalo
do Google Cloud Storage. Faça isso usando
o comando de cópia do GSU. Lembre-se de que você está copiando esses arquivos de código-fonte Java
para o canal porque ele não tem acesso ao sistema de arquivos do Cloud Shell, enquanto é executado
no Google Cloud Dataflow. Depois que o comando de cópia gsutil
terminar de copiar os arquivos, você pode voltar ao intervalo do Google
Cloud Storage em seu navegador, atualizar a página e confirmar que
os arquivos foram copiados com êxito. Aqui estão os quatro
arquivos Java que serão usados ​​como entrada para seu canal em execução
no Google Cloud Dataflow. Em seguida, observe o código-fonte
da implementação do canal que foi modificado para ser executado
na plataforma do Google Cloud Dataflow. Está no arquivo grepc.py. Observe que este usa constance
para nomes de projetos e intervalos. No meu caso, usei o mesmo código exclusivo
para o projeto e o intervalo. Então eu vou colocar
o mesmo valor para ambos. O código também especifica alguns parâmetros que eu precisava para
executar este canal no Cloud Dataflow. Por exemplo, você precisa especificar o
nome do job que está executando o canal, e também o DataflowRunner,
para executar o canal no Dataflow. Aqui, a entrada e a saída são especificadas como caminhos para o
intervalo do Google Cloud Storage. O restante do código para o canal
permanece o mesmo. Para executar seu canal no Dataflow, você ainda usa o comando Python
e passa como argumentos o nome do arquivo e o código-fonte
da implementação do canal. Aqui, como o código-fonte usou
o DataflowRunner, seu código será empacotado como
bibliotecas Dataflow e enviado como job para executar um canal
na plataforma do Google Cloud Dataflow. Quando o comando Python
terminar de ser executado, você volta para o GCP e abre o Dataflow usando o menu de três traços
à esquerda ou usando a barra de pesquisa. E do painel do Dataflow, você pode monitorar o canal que acabou
de enviar como um dos jobs. Aqui, o job é chamado de example2, porque esse é o nome que usei
no arquivo grepc.py. Primeiro, você notará que o job ainda
não foi totalmente iniciado. Ele diz que é escalonamento
automático e mostra que está usando apenas um único
núcleo virtual para execução. No lado direito, você também pode ver opções de canais e outras
informações sobre o job. Na seção de registro, você pode descobrir
que o canal ainda não está em execução porque ele ainda está inicializando
um dos workers, e você pode confirmar isso pelo gráfico
na seção de escalonamento automático. Aqui, você notará que o job está esperando
usar um worker de destino. E, atualmente, o número de workers
passou de zero para um. Isso significa que exatamente
uma instância virtual foi provisionada para executar esse canal. Levará alguns minutos para esse canal
concluir a execução. Agora, você pode ver o vídeo avançar alguns minutos,
até que o job seja concluído. Se olhar mais atentamente o canal, poderá
dizer, pelas marcas de seleção verdes, que todas as etapas individuais para as transformações foram concluídas. E, analisando o gráfico
no canto inferior direito, você perceberá que todos os workers usados ​​para executar o canal
foram reduzidos. Você pode dar uma olhada
na saída desse canal copiando os arquivos de saída do
Google Cloud Storage para o Cloud Shell. E assim que os arquivos forem copiados, você poderá revisá-los diretamente
no Cloud Shell ou também abrir o Google Cloud Storage no navegador e encontrar os arquivos
no intervalo na pasta Java Help. Os arquivos terão um prefixo de saídas, então eles serão nomeados como 04, 0104, 0204 e assim por diante. Para revisar o conteúdo dos arquivos, é importante que você use uma caixa
de seleção de link pública à direita. Aqui, você pode ver o conteúdo
do primeiro arquivo.