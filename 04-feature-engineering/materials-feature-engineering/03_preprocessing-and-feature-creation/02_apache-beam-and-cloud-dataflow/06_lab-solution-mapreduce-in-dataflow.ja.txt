それでは ブラウザでGCPダッシュボードを開いて [Google Cloud Shellを有効にする]
をクリックします Cloud Shell環境に 必要なソースコードとパッケージが
そろっていることが重要です training-data-analyst
ディレクトリが見当たらない場合は 一旦ここでストップし 前回のラボを実施してから進めてください 環境が整ったらコードエディタで これから使用するApache Beam
パイプラインのソースコードを開きます [training-data-analyst] > [コース] > 
[data_analysis] > [lab2] > [python]の 「is_popular.py」ファイルです 前回のラボよりコードが増えていますので 詳しく見ていきます mainメソッドの本体の
inputの引数を見ると パイプラインへの入力は javahelpディレクトリの
Javaソースコードファイルです また パイプラインからの出力は デフォルトで/tempディレクトリの outputで始まるファイルに保存されます データを読み込んだら 次はキーワードで始まる行を探します 前回のラボと同様に キーワードは「import」です 次にインポートされた
パッケージ名を処理します packageUseメソッドが import文のパッケージ名から キーワードと末尾のセミコロンを削除した パッケージ名を抽出し 最後にsplitPackageName関数が 各パッケージ名の
複数のプリフィックスを返します たとえば com.example.appnameなら com、com.example
com.example.appnameを返します メソッドは各パッケージの
各オカレンスについて プリフィックスと整数1のペアを返し オカレンスは sum関数を引数とする CombinePerKeyで合算されます Top_5コンバイナがインポート数が
多いパッケージを特定します 次に「is_popular.py」ファイルを実行します パイプラインが実行されたら outputディレクトリの出力ファイルの
内容をリストしてorg、org.apache org.apache.beam、org.apache.beam.sdk
などTop 5のパッケージを確認できます このパイプラインでは 出力先を変更できます たとえば /tmpディレクトリの
myoutputで始まるファイルに 結果を書き込むよう
デフォルトを上書きして パイプラインを実行すると myoutputで始まる新しい
出力インスタンスが作成されます 今回は以上です