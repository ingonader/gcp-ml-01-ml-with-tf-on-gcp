1
00:00:00,000 --> 00:00:03,270
このラボでは ソースコードを

2
00:00:03,270 --> 00:00:06,810
GitHubからCloud Shell環境にコピーし

3
00:00:06,810 --> 00:00:09,110
スクリプトを実行して

4
00:00:09,110 --> 00:00:12,665
ライブラリをダウンロードします

5
00:00:12,665 --> 00:00:15,665
作業に数分ほどかかるため

6
00:00:15,665 --> 00:00:18,800
ここではコピーとダウンロードが

7
00:00:18,800 --> 00:00:21,915
終わったところまで早送りします

8
00:00:21,915 --> 00:00:26,060
Cloud ShellではテキストベースのNanoなど

9
00:00:26,060 --> 00:00:30,695
各種エディタでパイプラインの
ソースコードを表示できます

10
00:00:30,695 --> 00:00:32,450
ここでは

11
00:00:32,450 --> 00:00:36,160
Cloud Shellのビルトイン
エディタを使用します

12
00:00:36,160 --> 00:00:39,060
エディタの左のメニューから

13
00:00:39,060 --> 00:00:42,385
[training-data-analyst]を展開して

14
00:00:42,385 --> 00:00:47,620
[courses] > [data_analysis] >
[lab2] > [python]フォルダを開き

15
00:00:47,620 --> 00:00:53,185
「grep.py」ファイルのパイプライン
ソースコードにアクセスします

16
00:00:53,185 --> 00:00:57,620
26行目にあるワイルドカードで指定された

17
00:00:57,620 --> 00:01:02,045
Javaファイルを入力として使用します

18
00:01:02,045 --> 00:01:04,300
変換で各ファイルの

19
00:01:04,300 --> 00:01:07,545
キーワードを含む行を検索します

20
00:01:07,545 --> 00:01:11,475
検索ワードは「import」です

21
00:01:11,475 --> 00:01:17,555
実装されたパイプラインの
詳細は32～34行目にあります

22
00:01:17,555 --> 00:01:20,642
パイプラインのGrepステップで

23
00:01:20,642 --> 00:01:24,335
20行目で定義した
my_grepメソッドを使用します

24
00:01:24,335 --> 00:01:28,160
このメソッドは検索ワード「import」と

25
00:01:28,160 --> 00:01:31,240
それを含むすべての行を検索し

26
00:01:31,240 --> 00:01:35,675
結果を/tmp/outputディレクトリに
書き込みます

27
00:01:35,675 --> 00:01:38,960
Cloud Shellでパイプラインを実行するには

28
00:01:38,960 --> 00:01:40,960
pythonコマンドで

29
00:01:40,960 --> 00:01:43,890
パイプラインのソースコード名を渡します

30
00:01:43,890 --> 00:01:46,810
パイプラインの処理が完了し

31
00:01:46,810 --> 00:01:48,985
出力ファイルを見ると

32
00:01:48,985 --> 00:01:53,660
Javaソースコードの
「import」を含むすべての行が

33
00:01:53,660 --> 00:01:57,095
正しく特定できたことが確認できます

34
00:01:57,095 --> 00:01:58,615
次に

35
00:01:58,615 --> 00:02:01,790
このパイプラインソースコードを

36
00:02:01,790 --> 00:02:05,635
Dataflowプラットフォームで実行します

37
00:02:05,635 --> 00:02:08,760
いくつか準備が必要です

38
00:02:08,760 --> 00:02:13,210
まず GCPでDataflow APIを検索し

39
00:02:13,210 --> 00:02:17,070
[有効にする]ボタンで有効化します

40
00:02:17,070 --> 00:02:19,385
少し時間かがかるので

41
00:02:19,385 --> 00:02:23,965
有効化が終わったところまで早送りします

42
00:02:23,965 --> 00:02:28,920
[無効にする]ボタンが表示されているので

43
00:02:28,920 --> 00:02:31,685
APIは有効です

44
00:02:31,685 --> 00:02:34,400
次に パイプライン用の

45
00:02:34,400 --> 00:02:38,175
Cloud Storageバケットを用意します

46
00:02:38,175 --> 00:02:41,770
バケットには固有の名前を付け

47
00:02:41,770 --> 00:02:45,735
必ず「Regional」を選択します

48
00:02:45,735 --> 00:02:50,750
ここではus-east4を割り当てました

49
00:02:50,750 --> 00:02:52,695
作成できたら

50
00:02:52,695 --> 00:02:55,360
gsutilのcpコマンドで

51
00:02:55,360 --> 00:02:57,960
ソースコードファイルを

52
00:02:57,960 --> 00:03:02,360
Cloud Shellからバケットにコピーします

53
00:03:02,360 --> 00:03:06,040
ソースコードファイルをコピーするのは

54
00:03:06,040 --> 00:03:08,730
パイプラインは

55
00:03:08,730 --> 00:03:14,375
Cloud Shellファイルシステムに
アクセスできないからです

56
00:03:14,375 --> 00:03:17,075
コピーが終わったら

57
00:03:17,075 --> 00:03:20,830
ブラウザのバケットのページに戻り

58
00:03:20,830 --> 00:03:26,545
ページを更新して正しく
コピーできたことを確認します

59
00:03:26,545 --> 00:03:31,180
Dataflowで実行するパイプラインに入力する

60
00:03:31,180 --> 00:03:33,925
4つのJavaファイルです

61
00:03:33,925 --> 00:03:38,735
次に Dataflowでの実行に合わせて修正した

62
00:03:38,735 --> 00:03:42,045
パイプラインのソースコードです

63
00:03:42,045 --> 00:03:45,265
「grepc.py」ファイルを見ます

64
00:03:45,265 --> 00:03:50,975
このコードではプロジェクト名と
バケット名に定数を使用します

65
00:03:50,975 --> 00:03:55,430
プロジェクトとバケットに
同じIDを使用したので

66
00:03:55,430 --> 00:03:57,810
同じ値を入力します

67
00:03:57,810 --> 00:04:00,170
このコードでは

68
00:04:00,170 --> 00:04:05,880
Dataflowでのパイプラインの実行に必要な

69
00:04:05,880 --> 00:04:09,060
ジョブ名やランナーなどの

70
00:04:09,060 --> 00:04:12,520
パラメータも指定しています

71
00:04:12,520 --> 00:04:15,060
また 入力と出力は

72
00:04:15,060 --> 00:04:20,689
Google Cloud Storageバケットの
パスで指定されています

73
00:04:20,689 --> 00:04:23,535
その他のコードは同じです

74
00:04:23,535 --> 00:04:25,430
実行するには

75
00:04:25,430 --> 00:04:28,240
同じくpythonコマンドを使って

76
00:04:28,240 --> 00:04:32,520
ソースコードのファイル名を
引数として渡します

77
00:04:32,520 --> 00:04:38,340
このソースコードは
Dataflowランナーを使用するため

78
00:04:38,340 --> 00:04:43,660
Dataflowライブラリとしてパッケージされ

79
00:04:43,660 --> 00:04:46,360
ジョブとして送信されます

80
00:04:46,360 --> 00:04:48,610
実行が完了したら

81
00:04:48,610 --> 00:04:54,270
GCPに戻って左のハンバーガー
メニューか検索バーから

82
00:04:54,270 --> 00:04:56,925
Dataflowを開きます

83
00:04:56,925 --> 00:04:59,330
ダッシュボードから

84
00:04:59,330 --> 00:05:03,045
パイプラインを確認できます

85
00:05:03,045 --> 00:05:06,825
ジョブ名は 「grepc.py」で指定した

86
00:05:06,825 --> 00:05:09,415
「examplejob2」です

87
00:05:09,415 --> 00:05:12,970
ジョブは完全に開始されていません

88
00:05:12,970 --> 00:05:16,110
オートスケール中と表示されていて

89
00:05:16,110 --> 00:05:19,505
1つの仮想コアのみで実行されています

90
00:05:19,505 --> 00:05:22,900
右側はパイプラインのオプションと

91
00:05:22,900 --> 00:05:25,145
ジョブに関する情報です

92
00:05:25,145 --> 00:05:27,450
[ログ]を開くと

93
00:05:27,450 --> 00:05:31,675
ワーカーを起動中であることがわかります

94
00:05:31,675 --> 00:05:36,395
[オートスケール]のグラフでも確認できます

95
00:05:36,395 --> 00:05:41,455
このジョブが使用する
ターゲットワーカーは1つです

96
00:05:41,455 --> 00:05:45,160
ワーカー数が0から1になったので

97
00:05:45,160 --> 00:05:48,955
このパイプラインを実行するために

98
00:05:48,955 --> 00:05:54,755
仮想インスタンスが1つ
プロビジョニングされました

99
00:05:54,770 --> 00:05:58,390
ジョブが完了したところまで

100
00:05:58,390 --> 00:06:00,265
早送りします

101
00:06:00,265 --> 00:06:03,300
パイプラインの各変換ステップに

102
00:06:03,300 --> 00:06:05,765
緑のチェックマークが付き

103
00:06:05,765 --> 00:06:08,412
完了したことを示しています

104
00:06:08,412 --> 00:06:10,251
右下のグラフは

105
00:06:10,251 --> 00:06:12,850
実行に使用したワーカーの

106
00:06:12,850 --> 00:06:15,900
スケールダウンを示しています

107
00:06:15,900 --> 00:06:20,910
Google Cloud Storageから
Cloud Shellに出力ファイルをコピーして

108
00:06:20,912 --> 00:06:24,422
パイプラインの出力を確認できます

109
00:06:24,422 --> 00:06:26,540
コピーできたら

110
00:06:26,540 --> 00:06:29,245
Cloud Shellで直接または

111
00:06:29,245 --> 00:06:33,020
ブラウザでGoogle Cloud Storageを開いて

112
00:06:33,020 --> 00:06:37,545
バケット内の「javahelp」フォルダから
探して確認できます

113
00:06:37,545 --> 00:06:40,980
ファイル名は「output」で始まり

114
00:06:40,980 --> 00:06:44,070
00000 of 00004、00001 of 00004
などが続きます

115
00:06:44,070 --> 00:06:47,330
ファイルの内容を確認するには

116
00:06:47,330 --> 00:06:51,460
[公開リンク]チェックボックスを使います

117
00:06:51,460 --> 00:06:55,070
こちらが最初のファイルの内容です