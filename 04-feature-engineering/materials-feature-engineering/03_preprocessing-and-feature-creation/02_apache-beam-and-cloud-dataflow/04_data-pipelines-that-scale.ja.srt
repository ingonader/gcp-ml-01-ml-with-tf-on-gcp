1
00:00:00,000 --> 00:00:01,530
ここでは

2
00:00:01,530 --> 00:00:05,730
データサイズの拡大に合わせてスケールする

3
00:00:05,730 --> 00:00:10,075
パイプラインの実装に必要なことを説明します

4
00:00:10,080 --> 00:00:16,030
MapReduceはGoogleが
2004年の研究論文で発表した

5
00:00:16,030 --> 00:00:21,275
耐障害性分散データ処理フレームワークで

6
00:00:21,275 --> 00:00:26,770
現在でもApache Hadoopなどで
幅広く利用されています

7
00:00:26,770 --> 00:00:30,960
DataflowとApache Beamは

8
00:00:30,960 --> 00:00:35,560
MapReduceの考え方を基盤としているため

9
00:00:35,560 --> 00:00:39,100
2004年以降の変革も踏まえた

10
00:00:39,100 --> 00:00:42,075
基本概念の理解が必要です

11
00:00:42,075 --> 00:00:46,225
画面の図を使って説明します

12
00:00:46,225 --> 00:00:47,909
MapReduceでは

13
00:00:47,909 --> 00:00:50,710
データをシャーディング

14
00:00:50,710 --> 00:00:52,905
つまり分割して

15
00:00:52,905 --> 00:00:57,270
それをクラスタ内の複数のノードの

16
00:00:57,270 --> 00:01:01,670
ストレージデバイスに分散させます

17
00:01:01,670 --> 00:01:05,710
図ではデータがコンピューティングクラスタの

18
00:01:05,710 --> 00:01:09,110
ノード1～3に分割されています

19
00:01:09,110 --> 00:01:12,850
データ処理のジョブを実行するには

20
00:01:12,850 --> 00:01:15,830
MapとReduce関数を使用します

21
00:01:15,830 --> 00:01:20,990
Mapはクラスタ内のノードで
並列実行できるよう

22
00:01:20,990 --> 00:01:25,040
ステートレス関数である必要があります

23
00:01:25,040 --> 00:01:30,810
各Mapが実行中のノードの
ストレージからデータを読み出し

24
00:01:30,810 --> 00:01:33,760
処理し 出力を生成します

25
00:01:33,760 --> 00:01:39,310
クラスタ内の各ノードの出力がシャッフルされ

26
00:01:39,310 --> 00:01:42,515
次のReduceに進みます

27
00:01:42,515 --> 00:01:47,700
Reduceはデータの集計と考えて構いません

28
00:01:47,700 --> 00:01:52,830
集計とはデータ要素のカウントや合算などです

29
00:01:52,830 --> 00:01:56,040
Reduce処理の結果が

30
00:01:56,040 --> 00:02:00,490
パイプラインのMapReduce
ステップの出力となります

31
00:02:00,490 --> 00:02:04,150
データ処理パイプラインの変換を

32
00:02:04,150 --> 00:02:08,925
スケールに応じてDataflowで実行するなら

33
00:02:08,925 --> 00:02:14,000
Apache BeamのParDoクラスを使用します

34
00:02:14,000 --> 00:02:17,695
ParDoは並列処理を意味します

35
00:02:17,695 --> 00:02:22,380
ParDoの変換ステップはMapと似ていて

36
00:02:22,380 --> 00:02:27,925
並列処理できるよう
ステートレスである必要があります

37
00:02:27,925 --> 00:02:32,600
多少制限がありますが
多くのタスクに有効です

38
00:02:32,600 --> 00:02:38,970
たとえば ウェブサーバーの
ログファイルを分析するパイプラインで

39
00:02:38,970 --> 00:02:44,755
サイト訪問者のIPアドレスを含む
エントリを除外する場合

40
00:02:44,755 --> 00:02:47,640
ステートレス変換を使用するか

41
00:02:47,640 --> 00:02:53,205
エントリからIPアドレスを
ステートレスに抽出できます

42
00:02:53,205 --> 00:02:56,600
その他のステートレス処理や

43
00:02:56,600 --> 00:03:01,175
入力データの一部のみを対象とした計算などは

44
00:03:01,175 --> 00:03:05,440
すべてParDoでの処理に適しています

45
00:03:05,470 --> 00:03:07,720
Python向けに

46
00:03:07,720 --> 00:03:13,190
ParDoを利用するための
ヘルパーメソッドがあります

47
00:03:13,190 --> 00:03:19,020
画面のbeam.Mapは
1対1の関係のみに使用できます

48
00:03:19,020 --> 00:03:23,070
たとえば 文書内の各単語について

49
00:03:23,070 --> 00:03:26,775
単語とその文字数を返す場合

50
00:03:26,775 --> 00:03:31,530
どの単語も文字数は1種類のみなので

51
00:03:31,530 --> 00:03:35,310
1対1の関係が成り立ちます

52
00:03:35,310 --> 00:03:39,190
このため beam.Mapを使用すると

53
00:03:39,190 --> 00:03:44,055
Dataflowは単語の長さの計算などの変換を

54
00:03:44,055 --> 00:03:48,750
自動的にクラスタ内の
複数のノードで処理します

55
00:03:48,750 --> 00:03:51,999
一方 beam.FlatMapは

56
00:03:51,999 --> 00:03:58,090
1つの入力に対してゼロを含む
あらゆる数の出力を生成できます

57
00:03:58,090 --> 00:04:02,580
同じく文書内の単語の処理の例を使うと

58
00:04:02,580 --> 00:04:06,760
各単語に含まれる母音を出力する場合

59
00:04:06,760 --> 00:04:10,500
単語あたりの母音の数はさまざまです

60
00:04:10,505 --> 00:04:15,890
beam.FlatMapによる変換も
Dataflowで並列実行できます

61
00:04:15,890 --> 00:04:18,465
Javaの場合は

62
00:04:18,465 --> 00:04:23,080
変換時にParDo off
静的メソッドを呼び出して

63
00:04:23,080 --> 00:04:27,645
パイプラインの次の適用コードに
結果を渡します

64
00:04:27,645 --> 00:04:33,070
GroupByKeyはパイプラインに加えるだけです

65
00:04:33,070 --> 00:04:35,910
たとえば 住所を処理して

66
00:04:35,910 --> 00:04:40,660
各都市の郵便番号を調べるパイプラインの場合

67
00:04:40,660 --> 00:04:42,320
画面にある

68
00:04:42,320 --> 00:04:48,850
Key-ValueペアのPCollectionを
パイプラインに入力すると

69
00:04:48,850 --> 00:04:56,450
beam.GroupByKeyは都市名をKey
郵便番号のリストをValueとする

70
00:04:56,450 --> 00:05:00,710
PCollectionを出力します

71
00:05:00,710 --> 00:05:06,485
GroupByKeyがMapReduceの
シャッフルステップに近いのに対し

72
00:05:06,485 --> 00:05:10,820
Combine.perKeyはより汎用的で

73
00:05:10,820 --> 00:05:15,525
集計に役立つシャッフルと
まとめのステップを含みます

74
00:05:15,525 --> 00:05:20,125
Combine.globallyメソッドは
データセット全体が対象です

75
00:05:20,125 --> 00:05:23,735
たとえば 金融取引データで

76
00:05:23,735 --> 00:05:28,265
各取引の売上金額のPCollectionから

77
00:05:28,265 --> 00:05:32,195
全取引の売上金額の合計を求める場合

78
00:05:32,195 --> 00:05:36,450
sumを引数とする
Combine.globallyを使用できます

79
00:05:36,450 --> 00:05:40,755
Combineはより細かい集計も可能です

80
00:05:40,755 --> 00:05:44,250
たとえば 先ほどの金融取引データに

81
00:05:44,250 --> 00:05:47,495
売上と担当者名が含まれている場合

82
00:05:47,495 --> 00:05:50,770
Combine.perKeyにsumを渡せば

83
00:05:50,770 --> 00:05:55,100
担当者ごとに売上金額の合計を求められます