ここでは データサイズの拡大に合わせてスケールする パイプラインの実装に必要なことを説明します MapReduceはGoogleが
2004年の研究論文で発表した 耐障害性分散データ処理フレームワークで 現在でもApache Hadoopなどで
幅広く利用されています DataflowとApache Beamは MapReduceの考え方を基盤としているため 2004年以降の変革も踏まえた 基本概念の理解が必要です 画面の図を使って説明します MapReduceでは データをシャーディング つまり分割して それをクラスタ内の複数のノードの ストレージデバイスに分散させます 図ではデータがコンピューティングクラスタの ノード1～3に分割されています データ処理のジョブを実行するには MapとReduce関数を使用します Mapはクラスタ内のノードで
並列実行できるよう ステートレス関数である必要があります 各Mapが実行中のノードの
ストレージからデータを読み出し 処理し 出力を生成します クラスタ内の各ノードの出力がシャッフルされ 次のReduceに進みます Reduceはデータの集計と考えて構いません 集計とはデータ要素のカウントや合算などです Reduce処理の結果が パイプラインのMapReduce
ステップの出力となります データ処理パイプラインの変換を スケールに応じてDataflowで実行するなら Apache BeamのParDoクラスを使用します ParDoは並列処理を意味します ParDoの変換ステップはMapと似ていて 並列処理できるよう
ステートレスである必要があります 多少制限がありますが
多くのタスクに有効です たとえば ウェブサーバーの
ログファイルを分析するパイプラインで サイト訪問者のIPアドレスを含む
エントリを除外する場合 ステートレス変換を使用するか エントリからIPアドレスを
ステートレスに抽出できます その他のステートレス処理や 入力データの一部のみを対象とした計算などは すべてParDoでの処理に適しています Python向けに ParDoを利用するための
ヘルパーメソッドがあります 画面のbeam.Mapは
1対1の関係のみに使用できます たとえば 文書内の各単語について 単語とその文字数を返す場合 どの単語も文字数は1種類のみなので 1対1の関係が成り立ちます このため beam.Mapを使用すると Dataflowは単語の長さの計算などの変換を 自動的にクラスタ内の
複数のノードで処理します 一方 beam.FlatMapは 1つの入力に対してゼロを含む
あらゆる数の出力を生成できます 同じく文書内の単語の処理の例を使うと 各単語に含まれる母音を出力する場合 単語あたりの母音の数はさまざまです beam.FlatMapによる変換も
Dataflowで並列実行できます Javaの場合は 変換時にParDo off
静的メソッドを呼び出して パイプラインの次の適用コードに
結果を渡します GroupByKeyはパイプラインに加えるだけです たとえば 住所を処理して 各都市の郵便番号を調べるパイプラインの場合 画面にある Key-ValueペアのPCollectionを
パイプラインに入力すると beam.GroupByKeyは都市名をKey
郵便番号のリストをValueとする PCollectionを出力します GroupByKeyがMapReduceの
シャッフルステップに近いのに対し Combine.perKeyはより汎用的で 集計に役立つシャッフルと
まとめのステップを含みます Combine.globallyメソッドは
データセット全体が対象です たとえば 金融取引データで 各取引の売上金額のPCollectionから 全取引の売上金額の合計を求める場合 sumを引数とする
Combine.globallyを使用できます Combineはより細かい集計も可能です たとえば 先ほどの金融取引データに 売上と担当者名が含まれている場合 Combine.perKeyにsumを渡せば 担当者ごとに売上金額の合計を求められます