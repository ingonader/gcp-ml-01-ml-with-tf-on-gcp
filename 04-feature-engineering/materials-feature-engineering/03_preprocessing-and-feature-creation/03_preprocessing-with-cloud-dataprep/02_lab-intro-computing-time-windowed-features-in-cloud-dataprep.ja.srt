1
00:00:00,000 --> 00:00:02,015
このラボでは

2
00:00:02,015 --> 00:00:05,500
BigQueryのタクシー料金のデータセットを

3
00:00:05,500 --> 00:00:08,445
Dataprepで前処理します

4
00:00:08,445 --> 00:00:11,270
データ値の分散を調査し

5
00:00:11,270 --> 00:00:13,940
ヒストグラムで可視化し

6
00:00:13,940 --> 00:00:16,410
Dataprepフローで

7
00:00:16,410 --> 00:00:20,400
1時間あたりの平均利用数に基づく

8
00:00:20,400 --> 00:00:24,555
移動時間枠による特徴量を作成します

9
00:00:24,555 --> 00:00:29,265
最後にフローをGCPにデプロイして実行し

10
00:00:29,265 --> 00:00:34,065
Dataflowでジョブの実行状況を
モニタリングします

11
00:00:34,065 --> 00:00:36,590
ラボを始める前の

12
00:00:36,590 --> 00:00:39,370
準備からです

13
00:00:39,370 --> 00:00:42,990
GCPダッシュボードを開きます

14
00:00:42,990 --> 00:00:49,370
まず Google Cloud Storageの
バケットを作成します

15
00:00:49,370 --> 00:00:52,430
ハンバーガーアイコンをクリックして

16
00:00:52,430 --> 00:00:56,165
[Storage] > [ブラウザ]をクリックして

17
00:00:56,165 --> 00:00:59,205
[バケットを作成]を選択します

18
00:00:59,205 --> 00:01:01,785
バケット名はグローバルに

19
00:01:01,785 --> 00:01:05,355
重複しない名前にする必要があります

20
00:01:05,355 --> 00:01:10,920
固有のバケット名を入力し
ロケーションはus-east4としました

21
00:01:10,920 --> 00:01:14,505
[作成]をクリックするとすぐに

22
00:01:14,505 --> 00:01:17,220
バケットの準備ができました

23
00:01:17,220 --> 00:01:22,285
次に BigQueryデータセットの準備です

24
00:01:22,285 --> 00:01:24,995
[Products & Services]メニューの

25
00:01:24,995 --> 00:01:27,560
[ビッグデータ]セクションの

26
00:01:27,560 --> 00:01:30,220
[BigQuery]をクリックします

27
00:01:30,220 --> 00:01:33,035
ブラウザで新しいタブが開きます

28
00:01:33,035 --> 00:01:35,330
プロジェクト名の右にある

29
00:01:35,330 --> 00:01:40,180
下向きの矢印をクリックして
[Create new dataset]を選択します

30
00:01:40,180 --> 00:01:46,350
データセットIDを「taxi_cab_reporting」として
[OK]をクリックして作成します

31
00:01:46,350 --> 00:01:48,990
データセットができたら

32
00:01:48,990 --> 00:01:52,195
GCPダッシュボードに戻って

33
00:01:52,195 --> 00:01:56,070
[Dataprep]をクリックします

34
00:01:56,070 --> 00:02:00,560
Dataprepはパートナーが
提供するサービスなので

35
00:02:00,560 --> 00:02:06,135
[ACCEPT]をクリックして
利用規約に同意する必要があります

36
00:02:06,135 --> 00:02:09,680
さらに [Allow]をクリックして

37
00:02:09,680 --> 00:02:14,900
Dataprepの提供元に
データアクセスを許可します

38
00:02:14,900 --> 00:02:19,980
Dataprepが有効になるまで
しばらくかかるため

39
00:02:19,980 --> 00:02:22,590
早送りで先に進めます

40
00:02:22,590 --> 00:02:26,900
次に Dataprepに使用する
アカウントを選択し

41
00:02:26,900 --> 00:02:29,680
[ALLOW]をクリックします

42
00:02:29,680 --> 00:02:33,430
プロジェクトに初めて
Dataprepを設定する場合

43
00:02:33,430 --> 00:02:36,775
データを保存するバケットを指定します

44
00:02:36,775 --> 00:02:39,965
ラボの初めに作成したバケットを選択し

45
00:02:39,965 --> 00:02:42,720
[Use this folder]をクリックします

46
00:02:42,720 --> 00:02:46,020
バケットを選択して
[Continue]をクリックします

47
00:02:46,020 --> 00:02:47,910
設定が完了したら

48
00:02:47,910 --> 00:02:52,805
[Don't show me any helpers]をクリックして
チュートリアルをスキップします

49
00:02:52,805 --> 00:02:56,940
次に Dataprepでフローを作成します

50
00:02:56,940 --> 00:03:00,290
名前は「NYCタクシーレポート」

51
00:03:00,290 --> 00:03:04,000
内容は「タクシー利用に関するデータの

52
00:03:04,000 --> 00:03:06,815
取り込み、変換、分析」です

53
00:03:06,815 --> 00:03:09,340
[Create]をクリックします

54
00:03:09,340 --> 00:03:12,240
まず フローが処理する

55
00:03:12,240 --> 00:03:15,480
データセットを追加します

56
00:03:15,480 --> 00:03:20,345
ここでは 事前にパブリッククラウド
ストレージに保存してある

57
00:03:20,345 --> 00:03:23,365
データセットを使用します

58
00:03:23,365 --> 00:03:29,710
asl-ml-immersion/nyctaxicab
ディレクトリにアクセスし

59
00:03:29,710 --> 00:03:32,090
ディレクトリ内の

60
00:03:32,090 --> 00:03:38,245
2015年と2016年のタクシー料金
データを使用します

61
00:03:38,245 --> 00:03:42,170
このカンマ区切りのCSVファイルを

62
00:03:42,170 --> 00:03:46,350
[Import & Add to Flow]で

63
00:03:46,350 --> 00:03:48,620
フローに追加します

64
00:03:48,620 --> 00:03:52,010
データセットの処理や操作を行うには

65
00:03:52,010 --> 00:03:54,880
[Add new Recipe]をクリックして

66
00:03:54,880 --> 00:03:57,930
レシピにステップを追加します

67
00:03:57,930 --> 00:04:01,480
データセットの読み込みが終わると

68
00:04:01,480 --> 00:04:04,040
プレビューが表示されます

69
00:04:04,040 --> 00:04:06,740
データセットにはタクシーの

70
00:04:06,740 --> 00:04:10,295
乗車日時、降車日時、乗客数などの

71
00:04:10,295 --> 00:04:13,855
情報が含まれているのがわかります

72
00:04:13,855 --> 00:04:17,240
乗車距離のヒストグラムからは

73
00:04:17,240 --> 00:04:21,089
ほとんどが8km未満だとわかります

74
00:04:21,089 --> 00:04:27,245
次に2015年と2016年の
データセットを結合します

75
00:04:27,245 --> 00:04:30,065
2016年分を選択し

76
00:04:30,065 --> 00:04:34,170
[Add and Align by Name]をクリックして

77
00:04:34,170 --> 00:04:37,110
各データセットの列見出しと

78
00:04:37,110 --> 00:04:40,425
結合後の見出しを一致させます

79
00:04:40,425 --> 00:04:44,205
[Add to Recipe]をクリックすると

80
00:04:44,205 --> 00:04:50,030
2015年と2016年のデータを含む
データセットのサンプルが表示されます

81
00:04:50,030 --> 00:04:54,645
乗車日と乗車時間は個別の列になっています

82
00:04:54,645 --> 00:04:59,870
このラボではタクシー料金の
移動平均を計算するので

83
00:04:59,870 --> 00:05:06,430
まず入力データをSQLの日付/時間
フォーマットに変換します

84
00:05:06,430 --> 00:05:09,920
レシピにMergeを追加して

85
00:05:09,920 --> 00:05:12,950
複数の列の値を連結します

86
00:05:12,950 --> 00:05:17,075
pickup_dayとpickup_timeの列を連結して

87
00:05:17,075 --> 00:05:20,905
pickup_datetimeという新しい列を作ります

88
00:05:20,905 --> 00:05:24,705
値の区切り文字はスペースにします

89
00:05:24,705 --> 00:05:26,350
画面左側に

90
00:05:26,350 --> 00:05:28,855
プレビューが表示されます

91
00:05:28,855 --> 00:05:34,490
次に乗車時間をSQLの日付/時間
フォーマットに変換して

92
00:05:34,490 --> 00:05:37,410
新しい列を作成します

93
00:05:37,410 --> 00:05:41,120
新しい列ができたら分と秒を除く

94
00:05:41,120 --> 00:05:44,870
年月日と時間の情報を抽出します

95
00:05:44,870 --> 00:05:50,345
hour_pickup_datetimeの列には
分と秒の値がないので

96
00:05:50,345 --> 00:05:55,960
SQLの日付/時間
フォーマットに変換できません

97
00:05:55,960 --> 00:05:59,140
変換を可能にするためには

98
00:05:59,140 --> 00:06:02,210
新しいステップを追加し

99
00:06:02,210 --> 00:06:05,530
再びMergeを使って

100
00:06:05,530 --> 00:06:10,700
hour_pickup_datetimeの列の値と

101
00:06:10,700 --> 00:06:15,120
分と秒の値「0000」を連結します

102
00:06:15,130 --> 00:06:17,300
新しい列には

103
00:06:17,300 --> 00:06:20,775
自動的に名前が付けられますが

104
00:06:20,775 --> 00:06:23,040
簡単に変更できます

105
00:06:23,040 --> 00:06:27,510
ここでは「pickup_hour」に変更します

106
00:06:27,510 --> 00:06:32,450
次に 乗車時間ごとの統計情報を計算します

107
00:06:32,450 --> 00:06:38,255
sumやaverageなど
標準SQLの集計関数を使用できます

108
00:06:38,255 --> 00:06:41,010
このWranglerで

109
00:06:41,010 --> 00:06:45,220
乗車人数、乗車距離、料金それぞれの

110
00:06:45,220 --> 00:06:48,400
合計と平均を計算します

111
00:06:48,400 --> 00:06:53,640
最後に乗車時間ごとの最大料金を計算します

112
00:06:54,590 --> 00:06:57,100
ここでも画面左側に

113
00:06:57,100 --> 00:07:03,165
統計情報とヒストグラムの
プレビューが表示されます

114
00:07:03,165 --> 00:07:06,815
平均料金のヒストグラムを見ると

115
00:07:06,815 --> 00:07:12,490
ほとんどが乗車1回あたり
18～19ドルだとわかります

116
00:07:12,490 --> 00:07:18,470
次に乗車時間ごとに
過去3時間分のデータに基づく

117
00:07:18,470 --> 00:07:21,715
料金の移動平均を計算します

118
00:07:21,715 --> 00:07:26,930
Dataprepの
ROLLINGAVERAGE関数を使います

119
00:07:26,930 --> 00:07:31,315
移動平均の値を入力し
乗車時間で分類します

120
00:07:31,315 --> 00:07:36,440
最後に列の名前を
「average_3hr_rolling_fare」とします

121
00:07:36,440 --> 00:07:38,970
レシピができたら

122
00:07:38,970 --> 00:07:43,395
Dataflowのジョブとしてデプロイします

123
00:07:43,395 --> 00:07:47,355
[Run Job]をクリックして

124
00:07:47,355 --> 00:07:52,035
ジョブの結果を保存する場所を指定します

125
00:07:52,035 --> 00:07:57,765
デフォルトはGoogle Cloud Storageの
CSVファイルですが

126
00:07:57,765 --> 00:08:01,080
保存先をBigQueryにして

127
00:08:01,080 --> 00:08:06,640
ジョブが実行されるたびに
新しいテーブルを作成できます

128
00:08:06,640 --> 00:08:11,635
画面右側で 
[Create new table every run]を選択し

129
00:08:11,635 --> 00:08:16,300
名前を「tlc_yellow_trips_reporting」
に変更すると

130
00:08:16,300 --> 00:08:20,795
このラボの初めに作成したデータセットに

131
00:08:20,795 --> 00:08:24,275
新しいテーブルが作成されます

132
00:08:24,275 --> 00:08:27,570
[Run Job]をクリックすると

133
00:08:27,570 --> 00:08:30,585
ジョブが変換中と表示され

134
00:08:30,585 --> 00:08:35,769
DataprepからDataflowにデプロイされます

135
00:08:35,769 --> 00:08:40,624
メニューの [JOBS]で進捗を確認できます

136
00:08:40,624 --> 00:08:44,150
右側の省略記号をクリックすると

137
00:08:44,150 --> 00:08:48,990
ジョブをデプロイした直後には
表示されませんが

138
00:08:48,990 --> 00:08:52,389
しばらく待ってページを更新すると

139
00:08:52,389 --> 00:08:58,825
Dataflowジョブにアクセスする
ためのリンクが表示されます

140
00:08:58,825 --> 00:09:03,185
クリックするとDataflow UIが開き

141
00:09:03,185 --> 00:09:07,660
変換ステップをDataflowで確認できます

142
00:09:07,660 --> 00:09:10,895
Dataflow UIの右側には

143
00:09:10,895 --> 00:09:14,155
ジョブの詳細が表示されます

144
00:09:14,155 --> 00:09:16,690
開始したばかりで

145
00:09:16,690 --> 00:09:21,080
ジョブを実行するクラスタのスケール中ですが

146
00:09:21,080 --> 00:09:25,225
すでにジョブ構成の結果を確認できます

147
00:09:25,225 --> 00:09:29,520
ほとんどの変換ステップは開始前ですが

148
00:09:29,520 --> 00:09:32,670
BigQueryのテーブルの準備と

149
00:09:32,670 --> 00:09:38,370
CSV入力ファイルのデータの
取り込みは始まっています

150
00:09:38,370 --> 00:09:42,060
Dataflowでのジョブの確認に加えて

151
00:09:42,060 --> 00:09:44,140
BigQueryでは

152
00:09:44,140 --> 00:09:48,105
データセットのジョブの出力を確認できます

153
00:09:48,105 --> 00:09:51,025
ジョブを実行すると

154
00:09:51,025 --> 00:09:55,135
tlc_yellow_trips_reportingに
値が挿入されます

155
00:09:55,135 --> 00:09:58,420
テーブルの作成にしばらくかかるので

156
00:09:58,420 --> 00:10:01,545
少し待ってからページを更新します

157
00:10:01,545 --> 00:10:03,710
テーブルができたら

158
00:10:03,710 --> 00:10:08,435
SQL文を入力して
結果を取り出します

159
00:10:08,435 --> 00:10:14,315
実行前に必ずSQL Dialectの
構成を確認してください

160
00:10:14,315 --> 00:10:17,030
ジョブを実行すると

161
00:10:17,030 --> 00:10:21,700
乗車時間、平均乗車距離、平均料金など

162
00:10:21,700 --> 00:10:26,120
約192KBのデータが生成されます

163
00:10:26,120 --> 00:10:29,030
今回のラボは以上です