Bei Statistiken würden Sie es
wahrscheinlich sehen, wenn Werte fehlen. Sie würden den durchschnittlichen
Wert einer Spalte einfach imputieren. An dieser Stelle gehen ML und
Statistiken vom Ansatz her auseinander. Die Idee von ML ist,
dass Sie ein eigenständiges Modell dafür entwickeln, ob
die Daten vorhanden sind oder nicht. ML bietet uns die Möglichkeit, über Szenarien mit
und ohne Daten nachzudenken, da wir in ML genügend Daten haben, um möglichst präzise Modelle zu erstellen. Bei Statistiken geht es jedoch darum, aus den vorhandenen Daten
die besten Ergebnisse zu erzielen. Die unterschiedlichen Ansätze wirken
sich auf den Umgang mit Abweichungen aus. Bei ML finden Sie genügend Abweichungen, zum Trainieren eines Modells. Erinnern Sie sich
an die Regel der fünf Proben? Bei Statistiken sagen Sie "Ich habe alle Daten,
die ich erfassen kann." Abweichungen werden ausgeschlossen. Die Ansätze unterscheiden sich aufgrund der Situationen,
in denen ML und Statistiken genutzt werden. Statistiken werden für begrenzte Daten
genutzt, ML für riesige Datenmengen. Eine Extraspalte
zur Kennzeichnung fehlender oder nicht fehlender Daten
würden Sie bei ML verwenden. Haben Sie zu wenig Daten, imputieren oder
ersetzen Sie sie durch einen Mittelwert. In diesem Beispiel soll
ein Immobilienwert berechnet werden. Das Dataset enthält Breitengrade
und die zwei abgebildeten Höchstwerte, einen für SFO und einen für LAS. San Francisco und Los Angeles. Es hat keinen Sinn, die Breite in unserem
Modell als Fließkommawert darzustellen. Denn es besteht keine lineare Beziehung zwischen Breitengrad und Immobilienwert. Häuser am Breitengrad 35 sind nicht 35-mal oder 34-mal teurer
als Häuser am Breitengrad 34. Trotzdem sind einzelne Breitengrade
wahrscheinlich ein guter Wertindikator. Was machen wir mit der Bezugsgröße? Eine Möglichkeit wäre Folgendes. Statt einer einzigen Fließkommafunktion könnten wir 11 individuelle
boolesche Funktionen anwenden. Yes-no latitudeBin1, latitudeBin2 bis latitudeBin11
mit booleschen Ja-Nein-Werten. Dabei kommen
feste Bin-Grenzwerte zum Einsatz. Andere Optionen,
die Data Scientists häufig verwenden, sind Quantilgrenzwerte, damit die Anzahl
der Werte in jedem Bin einheitlich ist. Dieses Problem taucht
häufig bei der Regression auf. Es kann mehrere Trainingsdurchläufe
erfordern, die Ausreißer zu korrigieren. Sie brechen also
die langen Werte in ML herunter, statt sie bei normalen
Statistiken aus ihrem Satz zu entfernen. Wenn das Haus 50 Zimmer hat, stellen
wir 4 Zimmer ein – unseren Höchstwert. Die Idee ist, dass der Preis
einer Immobilie sechsstellig ist, während die Anzahl
der Zimmer einstellig ist. Das ist ein typisches
Problem für Optimierungstools. Am Ende wird
der Gradient durch den Preis dominiert. Moderne Architekturen für ML
berücksichtigen viele Bezugsgrößen aufgrund eines Vorgangs,
der sich Batch-Normalisierung nennt. Sie werden allerdings Probleme haben, wenn ein Beispiel-Batch
nur ungewöhnliche Werte enthält. Es ist also nicht so wichtig,
wie es früher einmal war.