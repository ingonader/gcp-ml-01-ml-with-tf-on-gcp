1
00:00:00,000 --> 00:00:04,050
統計を取って
欠損値があることに気づいた場合

2
00:00:04,050 --> 00:00:07,440
通常は列の平均値などを
仮に使います

3
00:00:07,440 --> 00:00:12,150
ここがMLと統計学の分かれ道です

4
00:00:12,150 --> 00:00:13,790
MLでは

5
00:00:13,790 --> 00:00:18,900
データがある場合とない場合で
別々のモデルを作ります

6
00:00:18,900 --> 00:00:23,050
データがある場合とない場合で
別の処理ができます

7
00:00:23,050 --> 00:00:25,490
なぜならMLでは十分なデータがあり

8
00:00:25,490 --> 00:00:28,505
できる限り細かい粒度で
構築したいからです

9
00:00:28,505 --> 00:00:30,310
一方 統計学では

10
00:00:30,310 --> 00:00:34,780
手元のデータから最善の結果を
得られるようにデータを保持します

11
00:00:34,780 --> 00:00:36,710
両者の考え方が異なるので

12
00:00:36,710 --> 00:00:38,260
異常値の扱い異なり

13
00:00:38,260 --> 00:00:40,520
MLでは十分な数の異常値を見つけて

14
00:00:40,520 --> 00:00:42,210
トレーニングに使います

15
00:00:42,210 --> 00:00:45,050
「5個のサンプル」ルールを
覚えていますね

16
00:00:45,050 --> 00:00:46,520
統計学では

17
00:00:46,520 --> 00:00:48,935
収集できる全データが集まったら

18
00:00:48,935 --> 00:00:50,865
異常値をすべて取り除きます

19
00:00:50,865 --> 00:00:55,175
MLと統計学ではシナリオが異なるので
考え方も異なります

20
00:00:55,180 --> 00:00:58,035
統計学はしばしば限定的な
データ領域で使われ

21
00:00:58,035 --> 00:01:00,465
MLは大量のデータで運用されます

22
00:01:00,465 --> 00:01:03,690
欠損データの有無を示す列を
追加することは

23
00:01:03,690 --> 00:01:05,659
MLでは標準的な作業です

24
00:01:05,659 --> 00:01:09,750
データが不十分な場合は
平均値を代わりに使います

25
00:01:09,750 --> 00:01:13,410
この例では
家の価値を予測します

26
00:01:13,410 --> 00:01:17,860
データセットには緯度と
このような2つのピークがあり

27
00:01:17,860 --> 00:01:20,030
1つはSFO、もう1つはLAS

28
00:01:20,030 --> 00:01:22,775
サンフランシスコと
ロサンゼルスです

29
00:01:22,775 --> 00:01:24,260
このモデルでは

30
00:01:24,260 --> 00:01:28,380
緯度を浮動小数点の特徴として
表しても意味がありません

31
00:01:28,380 --> 00:01:31,900
緯度と家の価値の間に
線形関係がないからです

32
00:01:31,900 --> 00:01:36,250
たとえば緯度35度の家は
34度の家より

33
00:01:36,250 --> 00:01:41,590
35/34倍の値段ではありません

34
00:01:41,590 --> 00:01:46,615
とはいえ緯度は家の価格の
良い指標になるでしょう

35
00:01:46,615 --> 00:01:48,510
大小のある値を

36
00:01:48,510 --> 00:01:51,440
たとえばこのように扱えます

37
00:01:51,440 --> 00:01:54,465
浮動小数点の1つの特徴の代わりに

38
00:01:54,465 --> 00:01:58,080
11個の異なるブール値の特徴つまり

39
00:01:58,080 --> 00:02:03,145
yes-no latitudeBin1、latitudeBin2 ...
latitudeBin11までの

40
00:02:03,145 --> 00:02:05,435
yes-noブール値にして

41
00:02:05,435 --> 00:02:08,425
固定値のビン境界を使います

42
00:02:08,425 --> 00:02:12,980
データサイエンティストが
よく使うのは四分位の境界で

43
00:02:12,980 --> 00:02:16,690
各ビン内の
値の数が一定になります

44
00:02:16,690 --> 00:02:19,405
他の回帰の問題で
よく見かけるでしょう

45
00:02:19,405 --> 00:02:22,100
トレーニングサイクルの大半は

46
00:02:22,100 --> 00:02:25,650
異常なインスタンスの修正に費やされます

47
00:02:25,650 --> 00:02:32,210
MLではロングテールを分解しますが
通常の統計では取り除きます

48
00:02:32,210 --> 00:02:38,735
ある家に50部屋もある場合
範囲の上限である「4部屋」に設定します

49
00:02:38,735 --> 00:02:42,660
家の価格が
数十万ドルするのに比べて

50
00:02:42,660 --> 00:02:45,935
部屋数などは小さな数値です

51
00:02:45,935 --> 00:02:49,150
オプティマイザは従来
これをうまく扱うことができず

52
00:02:49,150 --> 00:02:51,850
価格が勾配を支配します

53
00:02:51,850 --> 00:02:54,870
さて最近のMLアーキテクチャでは

54
00:02:54,870 --> 00:02:58,975
変数の大小をいわゆる
バッチ正規化によって考慮します

55
00:02:58,975 --> 00:03:02,890
サンプルからなる1つのバッチに
すべて異常値が含まれる場合は

56
00:03:02,890 --> 00:03:05,440
問題が発生するかもしれませんが

57
00:03:05,440 --> 00:03:08,470
以前ほど重要ではありません