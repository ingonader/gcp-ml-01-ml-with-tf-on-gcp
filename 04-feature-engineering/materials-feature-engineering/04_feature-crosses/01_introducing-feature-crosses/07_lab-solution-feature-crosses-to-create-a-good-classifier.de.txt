Wir sind jetzt in TensorFlow Playground. Unser Dataset scheint blaue Punkte
unten links und oben rechts zu haben. Es scheint gelbe Punkte
oben links und unten rechts zu haben. Nehmen wir an,
wir haben zwei Roheingaben x1 und x2. Wir möchten nun x1 und x2
zum Trainieren des Modells verwenden. Fahren wir fort und trainieren das Modell mit x1 und x2
als Eingabe aus diesem Dataset. Wie Sie sehen, läuft das Training, aber das Hintergrundbild
ändert sich nicht merklich. Es ist ganz verwaschen, da ein lineares Modell für x1
und x2 keine gute Lernfähigkeit bietet. Das Modell lernt nicht viel. Beenden wir das
und sehen es uns noch einmal an. Es stellt sich heraus, dass eine Kombination
aus x1 und x2 ausschlaggebend ist. Wenn x1 negativ
und x2 negativ ist, erhalten wir Blau. Wenn x1 positiv
und x2 positiv ist, erhalten wir Blau. Wenn x1 und x2
unterschiedliche Vorzeichen haben, erhalten wir Gelb. An was erinnert Sie das? An eine Merkmalkreuzung zwischen x1 und x2. Fügen wir nun eine Merkmalkreuzung
aus x1 mal x2 als weitere Eingabe hinzu. Wenn wir wieder
trainieren, sehen wir fast sofort, dass wir im Grunde ein gutes Modell
zum Trennen von Blau und Gelb haben. Der Hintergrund
der blauen Punkte ist eher blau und der Hintergrund
der gelben Punkte ist eher gelb. Wir erhalten natürlich Rauschen
aufgrund von Fehlklassifizierungen, was wir aber erwartet haben,
da im Dataset Rauschen enthalten ist. Die wichtige Idee hierbei ist, dass wir
durch diese menschliche Erkenntnis, dass wir
mit einer Kombination aus x1 und x2 dieses Dataset
besser klassifizieren können, x1 mal x2 hinzufügen konnten. Das ist keine neue Eingabe, sondern eigentlich 
ein Feature Engineering, das wir auf die Originaleingaben x1
und x2 angewendet haben. Damit können wir
Blau und Gelb sehr gut trennen. Wenden wir uns einem anderen Fall zu. In diesem Fall
sind die blauen Punkte in der Mitte und die gelben Punkte außen herum. Wenn wir wieder mit x1 und x2 trainieren, ist der Hintergrund verwaschen, da dieses Modell
hier nicht viel lernen kann. Wir sollten uns ansehen, welche Art von Feature Engineering
wir hier vielleicht anwenden können. Ich beende dies nun. Mit was für einem Feature Engineering
können wir hier eine Trennung erreichen? Die Intuition sagt uns hier, wenn x1 und x2
beide klein sind, erhalten wir Blau. Wenn x1 und x2 groß sind, erhalten wir eher Gelb. Aber x1 und x2 sind nicht beide groß. Wenn wir uns diesen Punkt ansehen, ist x1 sehr klein, aber x2 ist groß. Wir können es folgendermaßen betrachten: Stellen wir uns dies
als Mitte des Bilds vor. Punkte nahe der Mitte sind eher blau, weiter von der Mitte
entfernte Punkte sind eher gelb. Erinnert Sie das an etwas? Bei nahen und entfernten Punkten
geht es um eine Entfernung. Wie lautet
die Gleichung für eine Entfernung? Wurzel aus
x zum Quadrat plus y zum Quadrat. Wir benötigen die Wurzel nicht, da wir hier nur Eingabemerkmale
für ein neurales Netzwerk verwenden. Wir benötigen also 
x Quadrat und y Quadrat. Nehmen wir daher nun x1 zum Quadrat
und x2 zum Quadrat als einzelne Eingaben. Fahren wir fort und trainieren. Sie sehen fast sofort, dass Sie eine gute Trennung
der blauen und gelben Punkte erhalten. Beenden wir dies. Sehen wir uns die beiden Grafiken an. Ist bei beiden die Trennungsgrenze linear? In diesem Fall ist offensichtlich, dass es keine lineare Grenze ist. Wir verwenden hier ein lineares Modell. Es gibt keine versteckten Ebenen. Es gibt kein neurales Netzwerk. Wir haben im Wesentlichen
eine lineare Kombination der Eingaben. Trotzdem können wir
eine nicht lineare Grenze erhalten. Das müssen Sie sich bewusst machen. Wenn Sie Merkmalkreuzungen verwenden, können Sie, auch wenn
Sie ein lineares Modell verwenden, ein nicht lineares Modell erhalten,
da die Merkmalkreuzung nicht linear ist. Ein Grund, warum
Merkmalkreuzungen funktionieren, ist, dass sie Nichtlinearität
in dieses Problem einbringen können. Sie bringen sie in dieses Problem ein und wir müssen trotzdem nicht
den Preis für Nichtlinearität zahlen. Wir müssen uns nicht sorgen, dass Modelle zu tief gehen,
viele Trainingsprobleme auftreten usw. Es ist ein lineares Modell und das Gute dabei ist, dass die Fehleroberfläche konvex ist. Das bedeutet, Sie haben
ein eindeutiges globales Minimum, das relativ einfach zu finden ist. Sie erhalten also
die Vorteile eines linearen Modells, aber die Leistung von Nichtlinearität. Das ist so toll an Merkmalkreuzungen. Auch in dem anderem Fall haben wir eine nicht lineare Grenze,
da wir zwei Linien erhalten. Es ist keine einzelne Linie, aber nicht
so offensichtlich wie in diesem Fall, wo wir eine Ellipse
und ganz klar keine Linie haben. Wir sollten uns daher eines merken: Auch wenn wir
die Leistung neuraler Netzwerke haben und diese verwenden möchten, sollten Sie die Verwendung von
Merkmalkreuzungen berücksichtigen, da sie mit diesen
ein einfaches Modell erstellen, aber trotzdem
Nichtlinearität erhalten können.