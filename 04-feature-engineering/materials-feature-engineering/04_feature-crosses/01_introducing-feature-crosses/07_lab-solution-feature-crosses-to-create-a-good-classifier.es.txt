Estamos en TensorFlow Playground
y el conjunto de datos que tenemos básicamente parece tener puntos azules en la esquina inferior izquierda
y en la esquina superior derecha. Parece tener puntos naranjas
en la parte superior izquierda y en la inferior derecha. Supongamos que tenemos dos entradas
sin procesar: x1 y x2. Y queremos usar x1 y x2
para entrenar el modelo. Hagámoslo.
Entrenemos el modelo que toma x1 y x2 como entradas
en este conjunto de datos en particular. Como pueden ver,
puede seguir entrenando pero la imagen de fondo
no cambia mucho. Está difuminada
porque x1 y x2, un modelo lineal no funciona bien en términos
de buena capacidad para aprender. Por lo que el modelo no aprende mucho. Paremos esto
y veamos de nuevo. Resulta que…
es la combinación de x1 y x2 lo que realmente importa. Si x1 y x2 son negativos, es azul. Si x1 y x2 son positivos, es azul. Si x1 y x2 tienen signos diferentes parece que es naranja. ¿A qué les recuerda? Es una combinación de atributos
entre x1 y x2. Agreguemos la combinación de x1 y x2
como otra entrada. Ahora, entrenemos
y veremos casi de inmediato que tenemos un modelo bastante bueno
que separa el azul del amarillo el fondo de los puntos azules
tiende al azul y el de los puntos amarillos
tiende al amarillo. Por supuesto, hay ruido
cuando existe una mala clasificación pero eso es de esperarse
porque es un conjunto de datos con ruido. La idea clave es que cuando se toma la intuición humana que nos dice que la combinación
de x1 y x2 nos permitirá clasificar mejor
con este conjunto de datos podemos agregar x1 y x2 que no es en realidad una nueva entrada sino una ingeniería de atributos
que hicimos con las entradas originales de x1 y x2 lo que nos permite separar el azul
del amarillo bastante bien. Veamos un caso diferente. En este caso, básicamente
tenemos los puntos azules en el centro y los amarillos hacia las esquinas. De nuevo, si usamos x1 y x2,
y entrenamos la imagen de fondo está difuminada
porque no hay mucho que este modelo pueda aprender. Podríamos decir
que probablemente debemos ver qué tipo de ingeniería de atributos
podemos hacer… detendré esto un momento. ¿Qué tipo de ingeniería de atributos
podemos realizar para la separación? La intuición aquí es que si x1 y x2 son pequeños, es azul y si son grandes,
tiende a ser amarillo. Pero no es que x1 y x2 sean ambos grandes. Si miran este punto aquí x1 es muy pequeño, pero x2 es grande. Otra forma de verlo si piensan en esto
como el centro de la imagen los puntos que están más cerca del centro
tienden a ser azules y los que están más alejados,
tienden a ser amarillos. ¿A qué les recuerda? Puntos cercanos y alejados…
¿es una distancia? ¿Cuál es la ecuación de una distancia? La raíz cuadrada de x² + y². No necesitamos la raíz cuadrada
porque todo lo que estamos haciendo es usar los atributos de entrada
en una red neuronal por lo que necesitamos x² y y². Entonces, tomemos x1² y x2²
como entradas. Ahora, entrenemos. Verán que casi de inmediato obtienen una buena separación
entre los puntos azules y los naranjas. Paremos esto. Observemos ambos. El límite de separación, ¿es lineal? En este caso, es bastante obvio. No es un límite lineal. A pesar de que usamos un modelo lineal no hay capas ocultas no hay una red neuronal. Es básicamente gracias
a la combinación lineal de las entradas que podemos obtener un límite no lineal. Debemos tener eso en cuenta. Si tienen combinaciones de atributos aunque usen un modelo lineal debido a que la combinación
de atributos es no lineal entonces, tendrán un modelo no lineal. Una de las razones por las que
las combinaciones de atributos funcionan es porque traen el poder
de la no linealidad al problema. La traen al problema sin que tengamos que pagar el precio
de la no linealidad. No tenemos que preocuparnos
de que el modelo sea muy profundo
y de otros problemas de entrenamiento. Es un modelo lineal. Y lo bueno de eso es que la superficie del área es convexa. Lo que significa
que tendrán un mínimo global único que es fácil de encontrar. Entonces, tendrán las ventajas
de un modelo lineal pero con el poder de la no linealidad. Eso es lo genial
de las combinaciones de atributos. Incluso en el otro caso también es un límite no lineal
porque son dos líneas. No es una sola línea. Pero no es tan obvio como en este caso en el que es una elipsis,
que obviamente no es una línea. Es algo que debemos recordar que,
aunque tengamos el poder de las redes neuronales,
si queremos usarlas debemos considerar el uso
de combinaciones de atributos porque nos permiten tener un modelo simple
con el beneficio de la no linealidad.