1
00:00:00,000 --> 00:00:03,360
今機械学習モデルを作っているとします

2
00:00:03,360 --> 00:00:07,310
車を見てタクシーかどうか
判断するものです

3
00:00:07,310 --> 00:00:10,960
ローマの白い車と
ニューヨークの黄色い車は

4
00:00:10,960 --> 00:00:13,950
通常タクシーだと
私たちは知っています

5
00:00:13,950 --> 00:00:20,760
しかし車両登録のデータセットから
MLモデルにこれを学習させたいのです

6
00:00:20,760 --> 00:00:24,005
入力データはこんな風になります

7
00:00:24,005 --> 00:00:27,085
[赤, ローマ] [白, ローマ]

8
00:00:27,085 --> 00:00:30,690
そしてラベルはタクシーかどうかを示します

9
00:00:30,690 --> 00:00:35,250
車の色と都市が
2つの入力特徴（feature）です

10
00:00:35,250 --> 00:00:39,230
これらの特徴を線形モデルで使い

11
00:00:39,230 --> 00:00:42,490
車がタクシーかどうかを予測します

12
00:00:42,490 --> 00:00:45,350
どうすればいいでしょう？

13
00:00:45,350 --> 00:00:50,020
最初の入力 つまり車の色を
ワンホッドエンコーディングし

14
00:00:50,020 --> 00:00:52,430
2つ目の入力 つまり都市名も

15
00:00:52,430 --> 00:00:55,040
ワンホッドエンコーディングして

16
00:00:55,040 --> 00:01:00,150
これらをそのまま線形モデルに送ります

17
00:01:00,150 --> 00:01:05,499
さて黄色の車に重み0.8を指定するとします

18
00:01:05,499 --> 00:01:10,035
トレーニングデータセットの黄色い車の
80%はタクシーだからです

19
00:01:10,035 --> 00:01:12,840
ですからw3=0.8です

20
00:01:12,840 --> 00:01:16,315
もちろん私たちは
重み0.8を指定しません

21
00:01:16,315 --> 00:01:18,910
最急降下法で重みが学習されます

22
00:01:18,910 --> 00:01:21,515
それが最急降下法の役割です

23
00:01:21,515 --> 00:01:26,785
残念ながらこの重み0.8は
ニューヨークだけでなく

24
00:01:26,785 --> 00:01:29,810
全都市の黄色の車に適用されます

25
00:01:29,810 --> 00:01:31,920
どう修正しますか？

26
00:01:31,920 --> 00:01:35,145
高い重みをニューヨークに指定しますか？

27
00:01:35,145 --> 00:01:37,275
それはうまくいきません

28
00:01:37,275 --> 00:01:42,530
ニューヨークのすべての車に
高い重みを指定した場合の

29
00:01:42,530 --> 00:01:45,090
問題点がわかりますか？

30
00:01:46,640 --> 00:01:50,225
特徴クロスを加えると
どうなりますか？

31
00:01:50,225 --> 00:01:55,550
まずニューヨークの赤い車に対応する
入力ノードがあります

32
00:01:55,550 --> 00:01:58,119
2番目がニューヨークの黄色い車

33
00:01:58,119 --> 00:02:00,590
3番目がニューヨークの白い車

34
00:02:00,590 --> 00:02:03,510
4番目がニューヨークの緑の車です

35
00:02:03,510 --> 00:02:05,455
ローマの車も同様です

36
00:02:05,455 --> 00:02:13,540
モデルはニューヨークの黄色い車と
ローマの白い車がタクシーだとすぐに学習し

37
00:02:13,540 --> 00:02:17,975
2つのノードに高い重みを与えます

38
00:02:17,975 --> 00:02:20,310
他はすべて重み0です

39
00:02:20,310 --> 00:02:21,975
問題が解決しました

40
00:02:21,975 --> 00:02:26,480
このように特徴クロスはとても強力です

41
00:02:29,240 --> 00:02:33,440
特徴クロスは線形モデルに
大きなパワーをもたらします

42
00:02:33,440 --> 00:02:38,280
特徴クロスおよび
大量のデータを使うことは

43
00:02:38,280 --> 00:02:43,835
高度に複雑な空間学習において
とても効率的な戦略です

44
00:02:43,835 --> 00:02:49,620
複雑な空間を学習する別の方法に
ニューラルネットワークがあります

45
00:02:49,620 --> 00:02:54,745
でも 特徴クロスなら
線形モデルを使い続けることができます

46
00:02:54,745 --> 00:03:00,535
特徴クロスがなければ
線形モデルの表現度はかなり制限されます

47
00:03:00,535 --> 00:03:04,879
特徴クロスの場合
大規模なデータセットが存在すれば

48
00:03:04,879 --> 00:03:08,910
線形モデルで入力空間を
隅々まで学習できます

49
00:03:08,910 --> 00:03:14,785
特徴クロスにより線形モデルは
大きなデータセットを記憶できます

50
00:03:14,785 --> 00:03:19,269
それぞれの特徴クロスに
1つの重みを割り当てると

51
00:03:19,269 --> 00:03:23,780
この方法でモデルは
特徴の組み合わせを学習します

52
00:03:23,780 --> 00:03:26,525
たとえ線形モデルであっても

53
00:03:26,525 --> 00:03:32,850
基盤となる入力/出力間の関係は
線形ではありません

54
00:03:34,440 --> 00:03:38,985
線形モデルを使えるかどうか
なぜこんなに気にするのでしょう？

55
00:03:38,985 --> 00:03:42,215
前のコースを思い出してください

56
00:03:42,215 --> 00:03:47,005
凸状の問題と
凸状でない問題を説明しました

57
00:03:47,005 --> 00:03:52,445
多数の層を持つニューラルネットワークは
凸状ではありません

58
00:03:52,445 --> 00:03:57,665
しかし線形モデルの最適化は
凸状の問題です

59
00:03:57,665 --> 00:04:00,405
そして凸状の問題は

60
00:04:00,405 --> 00:04:04,645
凸状でない問題より
はるかに簡単です

61
00:04:04,645 --> 00:04:08,905
長い間にわたり
疎（sparse）線形モデルは

62
00:04:08,905 --> 00:04:15,510
何十億ものトレーニングサンプルや
入力特徴にスケーリングできる

63
00:04:15,510 --> 00:04:18,010
唯一のアルゴリズムでした

64
00:04:18,010 --> 00:04:23,550
Google TensorFlowより前の
SETI、SmartAss、Siebelは

65
00:04:23,550 --> 00:04:26,710
大規模データを
スケーリングに学習しました

66
00:04:26,710 --> 00:04:28,960
ここ数年でそれが変化し

67
00:04:28,960 --> 00:04:34,840
ニューラルネットワークも大規模データを
処理できるようになり

68
00:04:34,840 --> 00:04:38,580
しばしばGPUやTPUの助けを借ります

69
00:04:38,580 --> 00:04:43,775
しかし疎な線形モデルは
今でも高速で低コストな選択肢です

70
00:04:43,775 --> 00:04:49,600
疎な線形モデルを
特徴の事前処理に使うと 多くの場合

71
00:04:49,600 --> 00:04:54,220
ニューラルネットワークの収束が
ずっと速くなります