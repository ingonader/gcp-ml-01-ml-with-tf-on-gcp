今機械学習モデルを作っているとします 車を見てタクシーかどうか
判断するものです ローマの白い車と
ニューヨークの黄色い車は 通常タクシーだと
私たちは知っています しかし車両登録のデータセットから
MLモデルにこれを学習させたいのです 入力データはこんな風になります [赤, ローマ] [白, ローマ] そしてラベルはタクシーかどうかを示します 車の色と都市が
2つの入力特徴（feature）です これらの特徴を線形モデルで使い 車がタクシーかどうかを予測します どうすればいいでしょう？ 最初の入力 つまり車の色を
ワンホッドエンコーディングし 2つ目の入力 つまり都市名も ワンホッドエンコーディングして これらをそのまま線形モデルに送ります さて黄色の車に重み0.8を指定するとします トレーニングデータセットの黄色い車の
80%はタクシーだからです ですからw3=0.8です もちろん私たちは
重み0.8を指定しません 最急降下法で重みが学習されます それが最急降下法の役割です 残念ながらこの重み0.8は
ニューヨークだけでなく 全都市の黄色の車に適用されます どう修正しますか？ 高い重みをニューヨークに指定しますか？ それはうまくいきません ニューヨークのすべての車に
高い重みを指定した場合の 問題点がわかりますか？ 特徴クロスを加えると
どうなりますか？ まずニューヨークの赤い車に対応する
入力ノードがあります 2番目がニューヨークの黄色い車 3番目がニューヨークの白い車 4番目がニューヨークの緑の車です ローマの車も同様です モデルはニューヨークの黄色い車と
ローマの白い車がタクシーだとすぐに学習し 2つのノードに高い重みを与えます 他はすべて重み0です 問題が解決しました このように特徴クロスはとても強力です 特徴クロスは線形モデルに
大きなパワーをもたらします 特徴クロスおよび
大量のデータを使うことは 高度に複雑な空間学習において
とても効率的な戦略です 複雑な空間を学習する別の方法に
ニューラルネットワークがあります でも 特徴クロスなら
線形モデルを使い続けることができます 特徴クロスがなければ
線形モデルの表現度はかなり制限されます 特徴クロスの場合
大規模なデータセットが存在すれば 線形モデルで入力空間を
隅々まで学習できます 特徴クロスにより線形モデルは
大きなデータセットを記憶できます それぞれの特徴クロスに
1つの重みを割り当てると この方法でモデルは
特徴の組み合わせを学習します たとえ線形モデルであっても 基盤となる入力/出力間の関係は
線形ではありません 線形モデルを使えるかどうか
なぜこんなに気にするのでしょう？ 前のコースを思い出してください 凸状の問題と
凸状でない問題を説明しました 多数の層を持つニューラルネットワークは
凸状ではありません しかし線形モデルの最適化は
凸状の問題です そして凸状の問題は 凸状でない問題より
はるかに簡単です 長い間にわたり
疎（sparse）線形モデルは 何十億ものトレーニングサンプルや
入力特徴にスケーリングできる 唯一のアルゴリズムでした Google TensorFlowより前の
SETI、SmartAss、Siebelは 大規模データを
スケーリングに学習しました ここ数年でそれが変化し ニューラルネットワークも大規模データを
処理できるようになり しばしばGPUやTPUの助けを借ります しかし疎な線形モデルは
今でも高速で低コストな選択肢です 疎な線形モデルを
特徴の事前処理に使うと 多くの場合 ニューラルネットワークの収束が
ずっと速くなります