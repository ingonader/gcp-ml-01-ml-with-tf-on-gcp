1
00:00:00,310 --> 00:00:03,380
¿Se acuerdan de estos diagramas
que usamos para explicar

2
00:00:03,380 --> 00:00:05,320
qué son las redes neuronales?

3
00:00:05,320 --> 00:00:08,800
Pueden pensar
en los puntos azules como clientes

4
00:00:08,800 --> 00:00:10,890
que compraron un teléfono en particular

5
00:00:10,890 --> 00:00:15,085
y en los puntos amarillos
como clientes que no lo compraron.

6
00:00:16,035 --> 00:00:19,160
Tal vez el eje x es el tiempo
que pasó desde la última vez

7
00:00:19,160 --> 00:00:21,530
que este cliente compró un teléfono

8
00:00:21,530 --> 00:00:26,765
y tal vez el eje y
es su nivel de ingresos.

9
00:00:26,765 --> 00:00:29,695
Básicamente, las personas
que compran el producto

10
00:00:29,695 --> 00:00:34,320
si ha pasado mucho tiempo
desde que lo compraron y si tienen dinero.

11
00:00:35,040 --> 00:00:36,870
Vean estos datos.

12
00:00:37,460 --> 00:00:42,380
¿Pueden imaginar una línea
que más o menos separe estas dos clases?

13
00:00:43,300 --> 00:00:44,790
Claro que sí.

14
00:00:45,180 --> 00:00:46,980
Es posible que tenga un poco de error

15
00:00:46,980 --> 00:00:49,250
no es perfectamente separable

16
00:00:49,250 --> 00:00:52,890
pero un modelo lineal
es probablemente una buena idea aquí.

17
00:00:52,890 --> 00:00:55,440
Entonces, este es un problema lineal.

18
00:00:55,440 --> 00:01:00,300
Los puntos azules y los amarillos
se pueden separar con la línea verde.

19
00:01:00,970 --> 00:01:02,065
Excelente.

20
00:01:03,875 --> 00:01:06,945
Pero ¿y si nuestros datos se ven así?

21
00:01:06,945 --> 00:01:09,180
¿Podemos usar el modelo lineal?

22
00:01:10,930 --> 00:01:13,640
Parece que no puedo trazar una línea

23
00:01:13,640 --> 00:01:18,490
que logre separar los puntos azules
de los amarillos.

24
00:01:19,240 --> 00:01:22,460
No. Donde sea que trace la línea

25
00:01:22,460 --> 00:01:25,430
hay puntos azules
en ambos lados de la línea.

26
00:01:26,100 --> 00:01:29,755
Estos datos
no se pueden separar linealmente.

27
00:01:30,305 --> 00:01:32,270
No puedo usar un modelo lineal.

28
00:01:33,150 --> 00:01:37,720
¿Podemos especificar un poco más
lo que queremos decir con modelo lineal?

29
00:01:37,720 --> 00:01:40,510
Veamos.

30
00:01:40,510 --> 00:01:43,500
x1 es una de las variables de entrada

31
00:01:43,500 --> 00:01:46,515
x2 es la otra variable de entrada.

32
00:01:46,975 --> 00:01:51,180
Cuando decimos
que no se puede usar un modelo lineal

33
00:01:51,180 --> 00:01:55,570
queremos decir que no hay forma
de combinar linealmente x1 y x2

34
00:01:55,570 --> 00:02:00,065
para obtener un único límite de decisión
que acomodaría bien los datos.

35
00:02:00,685 --> 00:02:04,525
En terminología de aprendizaje automático
y es el objetivo (la etiqueta).

36
00:02:04,525 --> 00:02:07,905
Tal vez azul es igual a uno
y amarillo es igual a cero

37
00:02:07,905 --> 00:02:09,415
esas son las etiquetas

38
00:02:09,415 --> 00:02:12,190
y las w y las b son los pesos

39
00:02:12,190 --> 00:02:14,845
y la ordenada al origen
que intentamos aprender.

40
00:02:15,465 --> 00:02:22,705
No hay forma de modificar las w y las b
para hacer entrar este límite de decisión.

41
00:02:23,545 --> 00:02:27,950
Pero ¿habrá otra forma
de seguir usando un modelo lineal?

42
00:02:29,900 --> 00:02:34,780
Por simplicidad, coloquemos los dos ejes
en el centro del diagrama

43
00:02:34,780 --> 00:02:39,465
de modo que el origen (0,0)
esté en el centro.

44
00:02:40,005 --> 00:02:43,075
Por supuesto, pueden obtener
los x1 y x2 actuales

45
00:02:43,075 --> 00:02:44,815
a partir de los anteriores

46
00:02:44,815 --> 00:02:47,520
mediante la simple sustracción
de una constante.

47
00:02:47,520 --> 00:02:49,640
Entonces, este modelo lineal

48
00:02:49,640 --> 00:02:53,325
seguirá siendo un modelo lineal
en el antiguo sistema de coordenadas

49
00:02:53,325 --> 00:02:55,455
pero ahora en este espacio

50
00:02:55,455 --> 00:02:58,955
definamos un nuevo atributo: x3.

51
00:02:58,955 --> 00:03:04,045
x3 será una combinación de atributos,
¿listos?

52
00:03:05,005 --> 00:03:10,050
Definamos el nuevo atributo x3
como el producto de x1 y x2.

53
00:03:10,050 --> 00:03:12,245
¿De qué forma ayuda esto?

54
00:03:12,245 --> 00:03:15,315
Tomen x3, el producto de x1 y x2

55
00:03:15,315 --> 00:03:17,580
¿cuándo es positivo?

56
00:03:18,150 --> 00:03:22,800
Exactamente, cuando x1 y x2
son ambos positivos

57
00:03:22,800 --> 00:03:26,880
o cuando ambos son negativos.

58
00:03:27,545 --> 00:03:30,480
Y ¿cuándo es x3 negativo?

59
00:03:31,000 --> 00:03:36,235
Exactamente, cuando x1 o x2
es negativo y el otro es positivo.

60
00:03:36,775 --> 00:03:38,605
Ahora tenemos x3.

61
00:03:39,085 --> 00:03:43,530
¿Se dan cuenta cómo agregar x3
hace esto solucionable

62
00:03:43,530 --> 00:03:46,010
mediante un modelo lineal?

63
00:03:47,140 --> 00:03:53,415
Ahora, podemos encontrar una regla
mediante la que el signo de x3 nos dé y.

64
00:03:54,385 --> 00:03:56,440
Por supuesto, es lo que acabamos de hacer.

65
00:03:56,440 --> 00:03:59,070
w1 es 0, w2 es 0

66
00:03:59,070 --> 00:04:00,650
y w3 es 1.

67
00:04:01,370 --> 00:04:05,055
Básicamente, y es un signo de x3.

68
00:04:05,055 --> 00:04:09,865
La combinación de atributos hizo
que se convierta en un problema lineal.

69
00:04:10,695 --> 00:04:12,680
Genial, ¿no creen?

70
00:04:13,300 --> 00:04:14,925
Entonces, en el AA tradicional

71
00:04:14,925 --> 00:04:17,824
la combinación de atributos
no juega un papel muy importante

72
00:04:17,824 --> 00:04:21,250
porque los métodos tradicionales
se desarrollaron para conjuntos de datos

73
00:04:21,250 --> 00:04:24,345
relativamente pequeños.

74
00:04:24,345 --> 00:04:29,105
Una vez que se tienen conjuntos
con miles de millones de ejemplos

75
00:04:29,105 --> 00:04:33,570
la combinación de atributos se convierte
en una herramienta extremadamente útil.

76
00:04:34,190 --> 00:04:37,980
Recuerden que dijimos
que las capas de una red neuronal

77
00:04:37,980 --> 00:04:40,840
les permiten combinar las entradas

78
00:04:40,840 --> 00:04:45,145
y eso es lo que hace que las redes
neuronales sean tan poderosas.

79
00:04:45,145 --> 00:04:48,655
Las redes neuronales profundas (DNN)
les permiten tener muchas capas

80
00:04:48,655 --> 00:04:52,050
y dado que cada capa
combina las capas anteriores

81
00:04:52,050 --> 00:04:56,880
las DNN pueden modelar
espacios multidimensionales complejos.

82
00:04:58,200 --> 00:05:02,280
Las combinaciones de atributos
también les permiten combinar atributos.

83
00:05:02,280 --> 00:05:03,940
Lo bueno es que

84
00:05:03,940 --> 00:05:06,320
pueden usar un modelo más simple

85
00:05:06,320 --> 00:05:08,870
un modelo lineal, y eso es bueno

86
00:05:08,870 --> 00:05:11,380
los modelos más simples
son una buena idea.

87
00:05:11,380 --> 00:05:14,630
Entonces, las combinaciones de atributos
son una forma de traer

88
00:05:14,630 --> 00:05:19,585
entradas no lineales a un clasificador
lineal: un modelo lineal.

89
00:05:20,165 --> 00:05:23,650
Pero hay un pequeño detalle.

90
00:05:23,650 --> 00:05:26,650
Les explicaré de una forma intuitiva.

91
00:05:27,230 --> 00:05:32,210
¿Recuerdan que comencé esta sección
moviendo el eje al medio del diagrama?

92
00:05:33,540 --> 00:05:35,490
¿Por qué lo hice?