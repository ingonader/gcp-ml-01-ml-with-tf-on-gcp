1
00:00:00,000 --> 00:00:04,950
Você se lembra desses diagramas usados
para explicar o que eram redes neurais?

2
00:00:04,950 --> 00:00:10,760
Você poderia pensar nos pontos azuis como
clientes que compram um telefone,

3
00:00:10,760 --> 00:00:15,285
e nos pontos amarelos como clientes
que não compram o telefone.

4
00:00:15,285 --> 00:00:21,240
Talvez o eixo x seja o tempo desde que o
cliente comprou pela última vez,

5
00:00:21,240 --> 00:00:26,625
e talvez o eixo y seja o nível
de renda do cliente.

6
00:00:26,625 --> 00:00:29,695
Basicamente, as pessoas que
compram o produto,

7
00:00:29,695 --> 00:00:34,320
se faz tempo que compraram o telefone
e se têm relativamente boa renda.

8
00:00:34,320 --> 00:00:36,870
Então, olhe para estes dados.

9
00:00:36,870 --> 00:00:42,960
Você consegue criar uma linha que mais ou
menos separa essas duas classes?

10
00:00:42,960 --> 00:00:44,930
Claro que podemos.

11
00:00:44,930 --> 00:00:46,980
Pode ter um pouco de erro,

12
00:00:46,980 --> 00:00:49,020
não é perfeitamente separável,

13
00:00:49,020 --> 00:00:52,530
mas um modelo linear é provavelmente
muito bom aqui.

14
00:00:52,530 --> 00:00:54,780
Então este é um problema linear.

15
00:00:54,780 --> 00:01:00,510
Os pontos azuis e os amarelos são
linearmente separáveis ​​pela linha verde.

16
00:01:00,510 --> 00:01:06,495
Ótimo. Mas e se os nossos
dados forem parecidos com isso?

17
00:01:06,495 --> 00:01:09,700
Ainda podemos usar um modelo linear?

18
00:01:09,700 --> 00:01:13,000
Bem, parece que não consigo desenhar

19
00:01:13,000 --> 00:01:18,490
uma linha que consiga separar os
pontos azuis dos pontos amarelos.

20
00:01:18,490 --> 00:01:22,460
Não, onde quer que eu desenhe minha linha,

21
00:01:22,460 --> 00:01:25,330
há pontos azuis em ambos os lados dela.

22
00:01:25,330 --> 00:01:29,755
Esses dados não são
linearmente separáveis.

23
00:01:29,755 --> 00:01:33,010
Então eu não posso usar um modelo linear.

24
00:01:33,010 --> 00:01:37,720
Podemos ser um pouco mais específicos
sobre o que entendemos por modelo linear?

25
00:01:37,720 --> 00:01:40,510
Vamos deixar o eixo Aksum aqui,

26
00:01:40,510 --> 00:01:43,500
x1 é uma das nossas variáveis
​​de entrada,

27
00:01:43,500 --> 00:01:46,955
x2 é a outra variável de entrada.

28
00:01:46,955 --> 00:01:51,530
E o que queremos dizer quando dizemos que
não podemos usar um modelo linear é que

29
00:01:51,530 --> 00:01:55,750
não é possível combinar linearmente
x1 e x2 para conseguir

30
00:01:55,750 --> 00:02:00,065
uma única fronteira de decisão que
se ajuste bem aos dados.

31
00:02:00,065 --> 00:02:02,505
Na terminologia de aprendizado
de máquina,

32
00:02:02,505 --> 00:02:04,485
y é o destino.

33
00:02:04,485 --> 00:02:07,905
Talvez azul seja igual a um e
amarelo seja igual a zero,

34
00:02:07,905 --> 00:02:09,285
esses são os rótulos.

35
00:02:09,285 --> 00:02:11,440
E os "w"s e o "b"

36
00:02:11,440 --> 00:02:15,255
são os pesos e as compensações que
estamos tentando aprender.

37
00:02:15,255 --> 00:02:22,975
Não há como modificar os "w"s e/ou o "b"
para encaixar nesta fronteira de decisão.

38
00:02:22,975 --> 00:02:27,950
Mas existe alguma outra maneira de
continuarmos a usar um modelo linear?

39
00:02:29,030 --> 00:02:34,460
Para simplificar, vamos colocar
dois eixos no centro do diagrama

40
00:02:34,460 --> 00:02:39,465
para que a origem (0,0)
esteja no centro do diagrama.

41
00:02:39,465 --> 00:02:44,805
Obviamente, você pode conseguir as
x1 e x2 atuais das x1 e x2 anteriores

42
00:02:44,805 --> 00:02:47,010
subtraindo uma constante.

43
00:02:47,010 --> 00:02:49,200
Então, um modelo linear agora

44
00:02:49,200 --> 00:02:52,935
ainda será um modelo linear no antigo
sistema de coordenadas.

45
00:02:52,935 --> 00:02:55,215
Mas agora para este espaço,

46
00:02:55,215 --> 00:02:58,725
vamos definir um novo atributo, x3.

47
00:02:58,725 --> 00:03:02,545
X3 vai ser um cruzamento de atributos.

48
00:03:02,545 --> 00:03:03,660
Pronto?

49
00:03:04,795 --> 00:03:10,050
Defina um novo atributo x3 como um
produto de x1 e x2.

50
00:03:10,050 --> 00:03:11,865
Como isso ajuda?

51
00:03:11,865 --> 00:03:15,315
Pegue x3, o produto de x1 e x2.

52
00:03:15,315 --> 00:03:18,120
Onde é positivo?

53
00:03:18,120 --> 00:03:22,800
Exatamente. Quando x1 e x2 forem
ambos positivos,

54
00:03:22,800 --> 00:03:26,880
ou quando x1 e x2 forem ambos negativos.

55
00:03:26,880 --> 00:03:28,575
E onde está negativo?

56
00:03:28,575 --> 00:03:30,480
Onde está x3 negativo?

57
00:03:30,480 --> 00:03:36,235
Exatamente, quando x1 ou x2 for
negativo e o outro positivo.

58
00:03:36,235 --> 00:03:38,605
Então, agora temos x3.

59
00:03:38,605 --> 00:03:45,910
Você pode ver como essa adição torna isso
solucionável por meio de um modelo linear?

60
00:03:46,010 --> 00:03:53,855
Agora podemos encontrar uma regra
tal que o seno de x3 nos dê y.

61
00:03:53,855 --> 00:03:56,440
Claro, isso é exatamente o que fizemos.

62
00:03:56,440 --> 00:03:59,070
W1 é zero, w2 é zero,

63
00:03:59,070 --> 00:04:00,990
e w3 é um.

64
00:04:00,990 --> 00:04:05,055
Basicamente, y é um seno de x3.

65
00:04:05,055 --> 00:04:10,375
O cruzamento de atributos fez disso
um problema linear.

66
00:04:10,375 --> 00:04:12,680
Muito legal, você não acha?

67
00:04:12,680 --> 00:04:14,865
Assim, no aprendizado de
máquina tradicional,

68
00:04:14,865 --> 00:04:17,474
cruzamentos de atributos não têm
um papel importante,

69
00:04:17,474 --> 00:04:22,470
porque os métodos tradicionais de ML foram
criados para conjuntos de dados pequenos.

70
00:04:22,470 --> 00:04:24,345
E, depois de ter conjuntos de dados

71
00:04:24,345 --> 00:04:28,875
com centenas de milhares a milhões
e bilhões de exemplos,

72
00:04:28,875 --> 00:04:33,570
o cruzamento de atributos torna-se algo
útil para ter na caixa de ferramentas.

73
00:04:33,570 --> 00:04:37,980
Lembre-se que dissemos que as camadas
de uma rede neural

74
00:04:37,980 --> 00:04:41,190
permitem combinar as entradas

75
00:04:41,190 --> 00:04:44,895
e isso faz parte do que torna as redes
neurais tão poderosas.

76
00:04:44,895 --> 00:04:48,295
As redes neurais profundas permitem que
você tenha muitas camadas

77
00:04:48,295 --> 00:04:52,050
e, como cada camada combina
as camadas anteriores,

78
00:04:52,050 --> 00:04:57,200
as DNNs podem modelar espaços
multidimensionais complexos.

79
00:04:57,250 --> 00:05:02,280
Cruzamentos de atributos também
permitem combinar atributos.

80
00:05:02,280 --> 00:05:03,720
E o bom é que você

81
00:05:03,720 --> 00:05:06,320
pode conseguir um caminho com
o modelo mais simples,

82
00:05:06,320 --> 00:05:08,870
um modelo linear, e isso é positivo,

83
00:05:08,870 --> 00:05:11,120
modelos mais simples são bons.

84
00:05:11,120 --> 00:05:14,270
Cruzamentos de atributos são
uma maneira de trazer

85
00:05:14,270 --> 00:05:19,585
entradas não lineares para um
aprendiz linear, um modelo linear.

86
00:05:19,585 --> 00:05:23,380
Mas há uma pequena ressalva.

87
00:05:23,380 --> 00:05:26,650
Deixe-me explicar de uma
maneira intuitiva.

88
00:05:26,650 --> 00:05:32,210
Lembre-se de que comecei esta sessão
movendo o eixo para o meio do diagrama.

89
00:05:33,300 --> 00:05:35,670
Por que eu fiz isso?