1
00:00:00,350 --> 00:00:05,610
Estamos en TensorFlow Playground
y el conjunto de datos que tenemos

2
00:00:05,610 --> 00:00:09,060
básicamente parece tener puntos azules

3
00:00:09,060 --> 00:00:12,660
en la esquina inferior izquierda
y en la esquina superior derecha.

4
00:00:12,660 --> 00:00:16,995
Parece tener puntos naranjas
en la parte superior izquierda

5
00:00:16,995 --> 00:00:18,635
y en la inferior derecha.

6
00:00:18,635 --> 00:00:22,965
Supongamos que tenemos dos entradas
sin procesar: x1 y x2.

7
00:00:22,965 --> 00:00:28,060
Y queremos usar x1 y x2
para entrenar el modelo.

8
00:00:28,060 --> 00:00:30,240
Hagámoslo.
Entrenemos el modelo

9
00:00:30,240 --> 00:00:33,925
que toma x1 y x2 como entradas
en este conjunto de datos en particular.

10
00:00:33,925 --> 00:00:36,690
Como pueden ver,
puede seguir entrenando

11
00:00:36,690 --> 00:00:40,620
pero la imagen de fondo
no cambia mucho.

12
00:00:40,620 --> 00:00:45,430
Está difuminada
porque x1 y x2, un modelo lineal

13
00:00:45,430 --> 00:00:50,505
no funciona bien en términos
de buena capacidad para aprender.

14
00:00:50,505 --> 00:00:53,055
Por lo que el modelo no aprende mucho.

15
00:00:53,055 --> 00:00:56,745
Paremos esto
y veamos de nuevo.

16
00:00:57,325 --> 00:01:01,960
Resulta que…
es la combinación de x1 y x2

17
00:01:01,960 --> 00:01:04,075
lo que realmente importa.

18
00:01:04,075 --> 00:01:09,900
Si x1 y x2 son negativos, es azul.

19
00:01:09,900 --> 00:01:15,430
Si x1 y x2 son positivos, es azul.

20
00:01:15,430 --> 00:01:18,795
Si x1 y x2 tienen signos diferentes

21
00:01:18,795 --> 00:01:21,570
parece que es naranja.

22
00:01:21,570 --> 00:01:23,920
¿A qué les recuerda?

23
00:01:23,920 --> 00:01:27,030
Es una combinación de atributos
entre x1 y x2.

24
00:01:27,030 --> 00:01:32,485
Agreguemos la combinación de x1 y x2
como otra entrada.

25
00:01:32,485 --> 00:01:37,365
Ahora, entrenemos
y veremos casi de inmediato

26
00:01:37,365 --> 00:01:43,230
que tenemos un modelo bastante bueno
que separa el azul del amarillo

27
00:01:43,230 --> 00:01:45,870
el fondo de los puntos azules
tiende al azul

28
00:01:45,870 --> 00:01:48,975
y el de los puntos amarillos
tiende al amarillo.

29
00:01:48,975 --> 00:01:54,010
Por supuesto, hay ruido
cuando existe una mala clasificación

30
00:01:54,010 --> 00:01:58,115
pero eso es de esperarse
porque es un conjunto de datos con ruido.

31
00:01:58,115 --> 00:02:00,095
La idea clave

32
00:02:01,005 --> 00:02:04,260
es que cuando se toma la intuición humana

33
00:02:04,260 --> 00:02:08,620
que nos dice que la combinación
de x1 y x2 nos permitirá

34
00:02:08,620 --> 00:02:12,575
clasificar mejor
con este conjunto de datos

35
00:02:12,575 --> 00:02:14,340
podemos agregar x1 y x2

36
00:02:14,340 --> 00:02:16,475
que no es en realidad una nueva entrada

37
00:02:16,475 --> 00:02:20,000
sino una ingeniería de atributos
que hicimos

38
00:02:20,000 --> 00:02:22,530
con las entradas originales de x1 y x2

39
00:02:22,530 --> 00:02:27,510
lo que nos permite separar el azul
del amarillo bastante bien.

40
00:02:28,020 --> 00:02:31,800
Veamos un caso diferente.

41
00:02:31,800 --> 00:02:37,005
En este caso, básicamente
tenemos los puntos azules en el centro

42
00:02:37,005 --> 00:02:41,055
y los amarillos hacia las esquinas.

43
00:02:41,055 --> 00:02:45,657
De nuevo, si usamos x1 y x2,
y entrenamos

44
00:02:45,657 --> 00:02:49,200
la imagen de fondo está difuminada
porque no hay mucho

45
00:02:49,200 --> 00:02:52,190
que este modelo pueda aprender.

46
00:02:52,190 --> 00:02:55,415
Podríamos decir
que probablemente debemos ver

47
00:02:55,415 --> 00:02:57,810
qué tipo de ingeniería de atributos
podemos hacer…

48
00:02:57,810 --> 00:02:59,460
detendré esto un momento.

49
00:02:59,460 --> 00:03:03,770
¿Qué tipo de ingeniería de atributos
podemos realizar para la separación?

50
00:03:03,770 --> 00:03:06,540
La intuición aquí es que

51
00:03:06,540 --> 00:03:11,040
si x1 y x2 son pequeños, es azul

52
00:03:11,040 --> 00:03:15,475
y si son grandes,
tiende a ser amarillo.

53
00:03:15,475 --> 00:03:17,830
Pero no es que x1 y x2 sean ambos grandes.

54
00:03:17,830 --> 00:03:20,170
Si miran este punto aquí

55
00:03:20,170 --> 00:03:23,690
x1 es muy pequeño, pero x2 es grande.

56
00:03:24,250 --> 00:03:26,740
Otra forma de verlo

57
00:03:26,740 --> 00:03:31,120
si piensan en esto
como el centro de la imagen

58
00:03:31,120 --> 00:03:34,380
los puntos que están más cerca del centro
tienden a ser azules

59
00:03:34,380 --> 00:03:37,800
y los que están más alejados,
tienden a ser amarillos.

60
00:03:38,700 --> 00:03:40,490
¿A qué les recuerda?

61
00:03:40,490 --> 00:03:43,480
Puntos cercanos y alejados…
¿es una distancia?

62
00:03:43,480 --> 00:03:46,060
¿Cuál es la ecuación de una distancia?

63
00:03:46,060 --> 00:03:48,720
La raíz cuadrada de x² + y².

64
00:03:48,720 --> 00:03:52,040
No necesitamos la raíz cuadrada
porque todo lo que estamos haciendo

65
00:03:52,040 --> 00:03:55,440
es usar los atributos de entrada
en una red neuronal

66
00:03:55,440 --> 00:03:57,790
por lo que necesitamos x² y y².

67
00:03:57,790 --> 00:04:02,535
Entonces, tomemos x1² y x2²
como entradas.

68
00:04:02,535 --> 00:04:05,105
Ahora, entrenemos.

69
00:04:05,105 --> 00:04:07,575
Verán que casi de inmediato

70
00:04:07,575 --> 00:04:14,545
obtienen una buena separación
entre los puntos azules y los naranjas.

71
00:04:15,255 --> 00:04:16,840
Paremos esto.

72
00:04:16,840 --> 00:04:19,145
Observemos ambos.

73
00:04:21,885 --> 00:04:25,950
El límite de separación, ¿es lineal?

74
00:04:26,580 --> 00:04:28,295
En este caso, es bastante obvio.

75
00:04:28,295 --> 00:04:30,060
No es un límite lineal.

76
00:04:30,060 --> 00:04:33,125
A pesar de que usamos un modelo lineal

77
00:04:33,125 --> 00:04:34,920
no hay capas ocultas

78
00:04:34,920 --> 00:04:36,980
no hay una red neuronal.

79
00:04:36,980 --> 00:04:40,855
Es básicamente gracias
a la combinación lineal de las entradas

80
00:04:40,855 --> 00:04:44,280
que podemos obtener un límite no lineal.

81
00:04:44,280 --> 00:04:45,960
Debemos tener eso en cuenta.

82
00:04:45,960 --> 00:04:48,765
Si tienen combinaciones de atributos

83
00:04:48,765 --> 00:04:51,210
aunque usen un modelo lineal

84
00:04:51,210 --> 00:04:54,535
debido a que la combinación
de atributos es no lineal

85
00:04:54,535 --> 00:04:56,805
entonces, tendrán un modelo no lineal.

86
00:04:56,805 --> 00:05:00,165
Una de las razones por las que
las combinaciones de atributos funcionan

87
00:05:00,165 --> 00:05:05,590
es porque traen el poder
de la no linealidad al problema.

88
00:05:06,820 --> 00:05:08,625
La traen al problema

89
00:05:08,625 --> 00:05:13,210
sin que tengamos que pagar el precio
de la no linealidad.

90
00:05:13,210 --> 00:05:16,120
No tenemos que preocuparnos
de que el modelo

91
00:05:16,120 --> 00:05:19,440
sea muy profundo
y de otros problemas de entrenamiento.

92
00:05:19,440 --> 00:05:21,135
Es un modelo lineal.

93
00:05:21,135 --> 00:05:23,120
Y lo bueno de eso

94
00:05:23,120 --> 00:05:26,770
es que la superficie del área es convexa.

95
00:05:26,770 --> 00:05:30,075
Lo que significa
que tendrán un mínimo global único

96
00:05:30,075 --> 00:05:32,775
que es fácil de encontrar.

97
00:05:32,775 --> 00:05:35,880
Entonces, tendrán las ventajas
de un modelo lineal

98
00:05:35,880 --> 00:05:39,165
pero con el poder de la no linealidad.

99
00:05:39,165 --> 00:05:42,670
Eso es lo genial
de las combinaciones de atributos.

100
00:05:43,620 --> 00:05:45,465
Incluso en el otro caso

101
00:05:45,465 --> 00:05:48,820
también es un límite no lineal
porque son dos líneas.

102
00:05:48,820 --> 00:05:50,420
No es una sola línea.

103
00:05:50,420 --> 00:05:54,010
Pero no es tan obvio como en este caso

104
00:05:54,010 --> 00:05:57,450
en el que es una elipsis,
que obviamente no es una línea.

105
00:05:57,450 --> 00:06:01,675
Es algo que debemos recordar que,
aunque tengamos el poder

106
00:06:01,675 --> 00:06:05,025
de las redes neuronales,
si queremos usarlas

107
00:06:05,025 --> 00:06:10,460
debemos considerar el uso
de combinaciones de atributos

108
00:06:10,460 --> 00:06:17,845
porque nos permiten tener un modelo simple
con el beneficio de la no linealidad.