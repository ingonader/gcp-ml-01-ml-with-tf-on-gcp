1
00:00:00,000 --> 00:00:03,160
Was wäre, wenn wir
die x1-Achse diskretisieren,

2
00:00:03,160 --> 00:00:07,845
indem wir nicht nur eine weiße,
sondern viele schwarze Linien zeichnen?

3
00:00:07,845 --> 00:00:13,245
Und wir auch für die x2-Achse 
viele schwarze Linien zeichnen.

4
00:00:13,245 --> 00:00:18,810
Jetzt haben wir die x1-Achse
und die x2-Achse diskretisiert.

5
00:00:18,810 --> 00:00:21,180
Mit den zwei weißen Linien

6
00:00:21,180 --> 00:00:23,265
erhielten wir vier Quadranten.

7
00:00:23,265 --> 00:00:24,885
Wie sieht es jetzt aus?

8
00:00:24,885 --> 00:00:28,845
Wenn wir m vertikale
und n horizontale Linien haben,

9
00:00:28,845 --> 00:00:34,185
erhalten wir m + 1 mal n + 1 Rasterzellen.

10
00:00:34,185 --> 00:00:42,165
Diskretisieren wir nun x1 und x2
und multiplizieren wir anschließend.

11
00:00:42,165 --> 00:00:48,387
Denken Sie an das Diagramm mit dem
in Quadranten aufgeteilten Eingaberaum.

12
00:00:48,390 --> 00:00:53,895
Im Grunde haben wir für jeden Quadranten
eine andere Vorhersage getroffen.

13
00:00:53,895 --> 00:00:56,400
Was ist nun mit diesem grünen Bereich?

14
00:00:56,400 --> 00:00:59,430
Was ist Ihre Vorhersage 
für diesen Bereich?

15
00:00:59,430 --> 00:01:01,510
Gelb, oder?

16
00:01:01,510 --> 00:01:04,280
Und jetzt?

17
00:01:04,280 --> 00:01:07,425
Blau, aber auch ein wenig gelb.

18
00:01:07,425 --> 00:01:10,500
Zählen wir
die blauen Punkte und die gelben Punkte.

19
00:01:10,500 --> 00:01:14,685
Sagen wir, 85 % blau.

20
00:01:14,685 --> 00:01:18,795
Sie sehen jetzt,
wie Wahrscheinlichkeiten ins Spiel kommen.

21
00:01:18,795 --> 00:01:22,470
Was ist jetzt?

22
00:01:22,470 --> 00:01:26,925
Nun gut, sehen wir uns an, warum dies
als lineares Modell gut funktioniert.

23
00:01:26,925 --> 00:01:30,869
Wenn Sie
den ersten Wertesatz One-Hot-codieren,

24
00:01:30,869 --> 00:01:34,924
dann
den zweiten Wertesatz One-Hot-codieren

25
00:01:34,924 --> 00:01:37,200
und eine Merkmalkreuzung durchführen,

26
00:01:37,200 --> 00:01:46,050
bleibt nur ein Knoten, der für Punkte
auslöst, die in diesen Bucket fallen.

27
00:01:46,050 --> 00:01:55,335
x3 wird nur 1, 
wenn x1 = 1 und x2 = 1 ist.

28
00:01:55,335 --> 00:01:58,750
Für jeden Punkt im Eingaberaum

29
00:01:58,750 --> 00:02:02,180
wird nur ein Bucket ausgelöst.

30
00:02:02,180 --> 00:02:08,940
Wenn Sie diese Werte der Merkmalkreuzung
nun in eine lineare Regression geben,

31
00:02:08,940 --> 00:02:12,315
was muss dann die Gewichtung w3 sein?

32
00:02:12,315 --> 00:02:19,805
Das Verhältnis von blauen zu gelben Punkten
in der Rasterzelle für x1 und x2.

33
00:02:19,805 --> 00:02:23,970
Das ist der Grund, warum
Merkmalkreuzungen so mächtig sind.

34
00:02:23,970 --> 00:02:30,830
Sie diskretisieren den Eingaberaum
und memorieren das Trainings-Dataset.

35
00:02:30,830 --> 00:02:33,560
Können Sie hier
ein mögliches Problem erkennen?

36
00:02:33,560 --> 00:02:37,245
Was ist, wenn Sie nicht genug Daten haben?

37
00:02:37,245 --> 00:02:39,300
Was lernt das Modell dann?

38
00:02:39,300 --> 00:02:44,460
Es lernt, dass
die Vorhersage Blau sein muss. Stimmt das?

39
00:02:44,460 --> 00:02:47,655
Dafür gibt es Lösungen.

40
00:02:47,655 --> 00:02:51,330
Sie müssen den Eingaberaum
nicht gleichmäßig diskretisieren.

41
00:02:51,330 --> 00:02:54,720
Sie können stattdessen
unterschiedlich große Felder verwenden.

42
00:02:54,720 --> 00:03:01,110
Nutzen Sie dann Feldgrößen, die einen Bezug
zum Informationsinhalt im Feld haben.

43
00:03:01,110 --> 00:03:04,860
Sie können Felder
auch gruppieren oder clustern.

44
00:03:04,860 --> 00:03:06,480
Es gibt also Lösungen.

45
00:03:06,480 --> 00:03:12,765
Sie sollten sich trotzdem eins merken: Bei
Merkmalkreuzungen geht es um Memorieren

46
00:03:12,765 --> 00:03:16,870
und Memorieren
ist das Gegenteil von Generalisieren,

47
00:03:16,870 --> 00:03:19,575
was wiederum
das Ziel von maschinellem Lernen ist.

48
00:03:19,575 --> 00:03:22,440
Sollten Sie es dann tun?

49
00:03:22,440 --> 00:03:26,980
In realen Systemen mit maschinellem Lernen
gibt es Platz für beides.

50
00:03:26,985 --> 00:03:31,180
Memorieren funktioniert,
wenn Sie so viele Daten haben,

51
00:03:31,180 --> 00:03:36,400
dass die Datenverteilung
für jede Rasterzelle Ihres Eingaberaums

52
00:03:36,400 --> 00:03:38,242
statistisch signifikant ist.

53
00:03:38,242 --> 00:03:41,460
Ist dies der Fall, können Sie memorieren.

54
00:03:41,460 --> 00:03:47,130
Das Modell lernt im Grunde
nur den Mittelwert für jede Rasterzelle.

55
00:03:47,130 --> 00:03:50,980
Natürlich benötigt
auch Deep Learning eine Menge Daten.

56
00:03:50,980 --> 00:03:56,670
Unabhängig davon, ob Sie Merkmale kreuzen
oder viele Ebenen verwenden,

57
00:03:56,670 --> 00:03:58,755
brauchen Sie 
in diesem Bereich viele Daten.

58
00:03:58,755 --> 00:04:02,880
Wenn sie mit herkömmlichem
maschinellen Lernen vertraut sind,

59
00:04:02,880 --> 00:04:05,415
kennen Sie Merkmalkreuzungen
möglicherweise nicht.

60
00:04:05,415 --> 00:04:10,730
Merkmalkreuzungen memorieren,
und funktionieren nur bei großen Datasets.

61
00:04:10,730 --> 00:04:14,520
Das ist ein Grund, warum Sie vielleicht
noch nicht viel darüber gehört haben.

62
00:04:14,520 --> 00:04:21,000
Für reale Datasets werden Sie aber
Merkmalkreuzungen äußerst nützlich finden.

63
00:04:21,000 --> 00:04:22,950
Je mehr Daten Sie haben,

64
00:04:22,950 --> 00:04:25,345
desto kleiner
können Sie die Felder auslegen

65
00:04:25,345 --> 00:04:28,115
und desto feiner können Sie memorieren.

66
00:04:28,115 --> 00:04:34,697
Merkmalkreuzungen sind bei großen Datasets
eine mächtige Vorverarbeitungstechnik.