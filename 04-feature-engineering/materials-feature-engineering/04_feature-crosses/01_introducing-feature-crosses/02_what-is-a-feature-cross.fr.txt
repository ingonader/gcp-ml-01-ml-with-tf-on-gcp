Vous vous souvenez des schémas servant
à expliquer les réseaux de neurones ? Imaginons que les points bleus sont
les clients qui achètent un téléphone d'un certain modèle, et les points orange
les clients qui ne l'achètent pas. L'axe X correspondrait au temps écoulé
depuis que le client a acheté ce téléphone et l'axe Y à son niveau de revenus. En bref, les personnes
qui achètent le produit, si elles ont acheté le téléphone il y a
longtemps et si elles sont plutôt riches. Regardez ces données. Pouvez-vous imaginer une ligne
qui sépare à peu près ces deux classes ? Sans problème. Il peut y avoir un peu d'erreurs, car elles ne sont pas
parfaitement séparables, mais un modèle linéaire fonctionnerait
probablement bien ici. Il s'agit donc d'un problème linéaire. Les points peuvent être séparés
de manière linéaire par la ligne verte. Parfait. Et si nos données
se présentaient comme ceci ? Pouvons-nous toujours
utiliser un modèle linéaire ? Apparemment,
je ne peux pas tracer de ligne qui sépare les points bleus
des points orange. Peu importe où je trace ma ligne, il reste des points bleus des deux côtés. Les données ne peuvent pas
être séparées de manière linéaire. Je ne peux donc pas
utiliser un modèle linéaire. Expliquons plus en détail
ce qu'est un modèle linéaire. Voyons les axes. x1 est l'une de nos variables d'entrée, x2 est l'autre. Quand nous disons que nous ne pouvons pas
utiliser un modèle linéaire, nous voulons dire qu'il est impossible
d'associer x1 et x2 de manière linéaire pour obtenir une frontière de décision
unique correspondant aux données. Dans la terminologie du machine learning, "y" est la cible. Le bleu peut être égal à 1, l'orange à 0. Ce sont les libellés. Les "w" et le "b" désignent respectivement les pondérations
et le biais que nous voulons apprendre. Nous ne pouvons pas modifier les "w" et/ou le "b"
pour obtenir cette frontière de décision. Existe-t-il un autre moyen de continuer
à utiliser un modèle linéaire ? Pour faire simple, déplaçons les deux axes
au centre du schéma pour que l'origine (0,0) soit
au centre du schéma. Vous pouvez facilement obtenir
les valeurs x1 et x2 actuelles à partir des précédentes
en soustrayant une constante. Un modèle linéaire
dans le nouveau système de coordonnées en resterait un dans l'ancien. Définissons dans cet espace une nouvelle caractéristique, x3. x3 sera un croisement de caractéristiques. Vous êtes prêt ? Définissez une nouvelle caractéristique x3
comme le produit de x1 et x2. En quoi est-ce utile ? Prenez x3, le produit de x1 et x2. Quand est-il positif ? Exactement, quand x1 et x2 sont
tous les deux positifs ou tous les deux négatifs. Et quand x3 est-il négatif ? Exactement, quand x1 ou x2 est
négatif et l'autre positif. Nous avons maintenant x3. Voyez-vous comment l'ajout de x3
permet de résoudre ce problème avec un modèle linéaire ? Nous pouvons maintenant chercher une règle
qui donne "y" en fonction du signe de x3. C'est ce que nous venons de faire. "w1" est zéro, "w2" est zéro et "w3" est un. "y" est le signe de x3. Le croisement de caractéristiques a permis
de rendre ce problème linéaire. Pratique, n'est-ce pas ? Dans le machine learning conventionnel, les croisements de caractéristiques
ont peu d'importance. En effet, les méthodes de ML
classiques ont été développées pour des ensembles
de données relativement petits. Pour des ensembles de données comportant des centaines de milliers, voire
des millions ou des milliards d'exemples, les croisements de caractéristiques
s'avèrent extrêmement utiles. Souvenez-vous que les couches
d'un réseau de neurones permettent de combiner
des données d'entrée, ce qui explique en partie leur puissance. Les réseaux de neurones profonds peuvent
inclure de nombreuses couches. Comme chaque couche
combine les précédentes, les DNN peuvent modéliser
des espaces multidimensionnels complexes. Les croisements
de caractéristiques permettent également de combiner des caractéristiques. L'avantage est que vous pouvez vous contenter
d'un modèle simple, un modèle linéaire. Les modèles simples sont une bonne chose. Les croisements de caractéristiques
permettent donc d'adapter des données d'entrée
non linéaires à un modèle linéaire. Un avertissement est cependant de mise. Laissez-moi l'expliquer
de façon intuitive. J'ai démarré cette section
en déplaçant l'axe au centre du schéma. Pourquoi ?