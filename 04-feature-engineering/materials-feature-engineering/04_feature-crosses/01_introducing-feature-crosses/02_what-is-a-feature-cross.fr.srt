1
00:00:00,000 --> 00:00:04,950
Vous vous souvenez des schémas servant
à expliquer les réseaux de neurones ?

2
00:00:04,950 --> 00:00:09,830
Imaginons que les points bleus sont
les clients qui achètent un téléphone

3
00:00:09,830 --> 00:00:15,285
d'un certain modèle, et les points orange
les clients qui ne l'achètent pas.

4
00:00:15,285 --> 00:00:21,240
L'axe X correspondrait au temps écoulé
depuis que le client a acheté ce téléphone

5
00:00:21,240 --> 00:00:26,625
et l'axe Y à son niveau de revenus.

6
00:00:26,625 --> 00:00:29,695
En bref, les personnes
qui achètent le produit,

7
00:00:29,695 --> 00:00:34,320
si elles ont acheté le téléphone il y a
longtemps et si elles sont plutôt riches.

8
00:00:34,320 --> 00:00:36,870
Regardez ces données.

9
00:00:36,870 --> 00:00:42,960
Pouvez-vous imaginer une ligne
qui sépare à peu près ces deux classes ?

10
00:00:42,960 --> 00:00:44,930
Sans problème.

11
00:00:44,930 --> 00:00:46,980
Il peut y avoir un peu d'erreurs,

12
00:00:46,980 --> 00:00:49,120
car elles ne sont pas
parfaitement séparables,

13
00:00:49,120 --> 00:00:52,530
mais un modèle linéaire fonctionnerait
probablement bien ici.

14
00:00:52,530 --> 00:00:54,780
Il s'agit donc d'un problème linéaire.

15
00:00:54,780 --> 00:01:00,510
Les points peuvent être séparés
de manière linéaire par la ligne verte.

16
00:01:00,510 --> 00:01:03,502
Parfait.

17
00:01:03,502 --> 00:01:06,315
Et si nos données
se présentaient comme ceci ?

18
00:01:06,315 --> 00:01:09,590
Pouvons-nous toujours
utiliser un modèle linéaire ?

19
00:01:09,590 --> 00:01:13,530
Apparemment,
je ne peux pas tracer de ligne

20
00:01:13,530 --> 00:01:18,490
qui sépare les points bleus
des points orange.

21
00:01:18,490 --> 00:01:22,460
Peu importe où je trace ma ligne,

22
00:01:22,460 --> 00:01:25,330
il reste des points bleus des deux côtés.

23
00:01:25,330 --> 00:01:29,755
Les données ne peuvent pas
être séparées de manière linéaire.

24
00:01:29,755 --> 00:01:32,270
Je ne peux donc pas
utiliser un modèle linéaire.

25
00:01:32,270 --> 00:01:37,720
Expliquons plus en détail
ce qu'est un modèle linéaire.

26
00:01:37,720 --> 00:01:40,510
Voyons les axes.

27
00:01:40,510 --> 00:01:43,500
x1 est l'une de nos variables d'entrée,

28
00:01:43,500 --> 00:01:46,515
x2 est l'autre.

29
00:01:46,515 --> 00:01:51,320
Quand nous disons que nous ne pouvons pas
utiliser un modèle linéaire,

30
00:01:51,320 --> 00:01:55,750
nous voulons dire qu'il est impossible
d'associer x1 et x2 de manière linéaire

31
00:01:55,750 --> 00:02:00,065
pour obtenir une frontière de décision
unique correspondant aux données.

32
00:02:00,065 --> 00:02:02,505
Dans la terminologie du machine learning,

33
00:02:02,505 --> 00:02:04,485
"y" est la cible.

34
00:02:04,485 --> 00:02:07,465
Le bleu peut être égal à 1, l'orange à 0.

35
00:02:07,465 --> 00:02:09,215
Ce sont les libellés.

36
00:02:09,215 --> 00:02:11,310
Les "w" et le "b" désignent

37
00:02:11,310 --> 00:02:15,405
respectivement les pondérations
et le biais que nous voulons apprendre.

38
00:02:15,405 --> 00:02:18,370
Nous ne pouvons pas modifier

39
00:02:18,370 --> 00:02:22,975
les "w" et/ou le "b"
pour obtenir cette frontière de décision.

40
00:02:22,975 --> 00:02:30,270
Existe-t-il un autre moyen de continuer
à utiliser un modèle linéaire ?

41
00:02:30,270 --> 00:02:34,460
Pour faire simple, déplaçons les deux axes
au centre du schéma

42
00:02:34,460 --> 00:02:39,465
pour que l'origine (0,0) soit
au centre du schéma.

43
00:02:39,465 --> 00:02:42,705
Vous pouvez facilement obtenir
les valeurs x1 et x2 actuelles

44
00:02:42,705 --> 00:02:46,860
à partir des précédentes
en soustrayant une constante.

45
00:02:46,860 --> 00:02:49,770
Un modèle linéaire
dans le nouveau système de coordonnées

46
00:02:49,770 --> 00:02:52,935
en resterait un dans l'ancien.

47
00:02:52,935 --> 00:02:55,215
Définissons dans cet espace

48
00:02:55,215 --> 00:02:58,725
une nouvelle caractéristique, x3.

49
00:02:58,725 --> 00:03:02,805
x3 sera un croisement de caractéristiques.

50
00:03:02,805 --> 00:03:04,045
Vous êtes prêt ?

51
00:03:04,045 --> 00:03:10,050
Définissez une nouvelle caractéristique x3
comme le produit de x1 et x2.

52
00:03:10,050 --> 00:03:11,865
En quoi est-ce utile ?

53
00:03:11,865 --> 00:03:15,315
Prenez x3, le produit de x1 et x2.

54
00:03:15,315 --> 00:03:17,580
Quand est-il positif ?

55
00:03:17,580 --> 00:03:22,800
Exactement, quand x1 et x2 sont
tous les deux positifs

56
00:03:22,800 --> 00:03:26,880
ou tous les deux négatifs.

57
00:03:26,880 --> 00:03:30,485
Et quand x3 est-il négatif ?

58
00:03:30,485 --> 00:03:36,235
Exactement, quand x1 ou x2 est
négatif et l'autre positif.

59
00:03:36,235 --> 00:03:38,605
Nous avons maintenant x3.

60
00:03:38,605 --> 00:03:43,600
Voyez-vous comment l'ajout de x3
permet de résoudre ce problème

61
00:03:43,600 --> 00:03:46,010
avec un modèle linéaire ?

62
00:03:46,010 --> 00:03:53,855
Nous pouvons maintenant chercher une règle
qui donne "y" en fonction du signe de x3.

63
00:03:53,855 --> 00:03:56,440
C'est ce que nous venons de faire.

64
00:03:56,440 --> 00:03:59,070
"w1" est zéro, "w2" est zéro

65
00:03:59,070 --> 00:04:00,990
et "w3" est un.

66
00:04:00,990 --> 00:04:05,055
"y" est le signe de x3.

67
00:04:05,055 --> 00:04:10,375
Le croisement de caractéristiques a permis
de rendre ce problème linéaire.

68
00:04:10,375 --> 00:04:12,680
Pratique, n'est-ce pas ?

69
00:04:12,680 --> 00:04:14,865
Dans le machine learning conventionnel,

70
00:04:14,865 --> 00:04:17,534
les croisements de caractéristiques
ont peu d'importance.

71
00:04:17,534 --> 00:04:20,350
En effet, les méthodes de ML
classiques ont été développées

72
00:04:20,350 --> 00:04:22,720
pour des ensembles
de données relativement petits.

73
00:04:22,720 --> 00:04:24,665
Pour des ensembles de données comportant

74
00:04:24,665 --> 00:04:28,875
des centaines de milliers, voire
des millions ou des milliards d'exemples,

75
00:04:28,875 --> 00:04:33,900
les croisements de caractéristiques
s'avèrent extrêmement utiles.

76
00:04:33,900 --> 00:04:37,980
Souvenez-vous que les couches
d'un réseau de neurones

77
00:04:37,980 --> 00:04:40,980
permettent de combiner
des données d'entrée,

78
00:04:40,980 --> 00:04:44,895
ce qui explique en partie leur puissance.

79
00:04:44,895 --> 00:04:48,295
Les réseaux de neurones profonds peuvent
inclure de nombreuses couches.

80
00:04:48,295 --> 00:04:52,050
Comme chaque couche
combine les précédentes,

81
00:04:52,050 --> 00:04:57,260
les DNN peuvent modéliser
des espaces multidimensionnels complexes.

82
00:04:57,260 --> 00:05:00,740
Les croisements
de caractéristiques permettent également

83
00:05:00,740 --> 00:05:02,350
de combiner des caractéristiques.

84
00:05:02,350 --> 00:05:04,020
L'avantage est que

85
00:05:04,020 --> 00:05:06,320
vous pouvez vous contenter
d'un modèle simple,

86
00:05:06,320 --> 00:05:08,440
un modèle linéaire.

87
00:05:08,440 --> 00:05:10,400
Les modèles simples sont une bonne chose.

88
00:05:10,400 --> 00:05:14,270
Les croisements de caractéristiques
permettent donc

89
00:05:14,270 --> 00:05:19,585
d'adapter des données d'entrée
non linéaires à un modèle linéaire.

90
00:05:19,585 --> 00:05:23,380
Un avertissement est cependant de mise.

91
00:05:23,380 --> 00:05:26,650
Laissez-moi l'expliquer
de façon intuitive.

92
00:05:26,650 --> 00:05:32,210
J'ai démarré cette section
en déplaçant l'axe au centre du schéma.

93
00:05:32,210 --> 00:05:35,670
Pourquoi ?