1
00:00:00,000 --> 00:00:01,010
So here we are.

2
00:00:01,010 --> 00:00:05,610
We're intensively playground and the data set that we have,

3
00:00:05,610 --> 00:00:09,060
essentially seems to have blue dots in

4
00:00:09,060 --> 00:00:12,660
the lower left hand corner and in the upper right hand corner,

5
00:00:12,660 --> 00:00:18,315
it seems to have orange dots in the top left and on the bottom right.

6
00:00:18,315 --> 00:00:22,605
And let's say we have two raw inputs x1 and x2.

7
00:00:22,605 --> 00:00:27,720
And what you want is to basically use the x1 and x2 to train the model.

8
00:00:27,720 --> 00:00:30,420
So let's go ahead and train the model that takes

9
00:00:30,420 --> 00:00:33,725
x1 and x2 as input in this particular data set.

10
00:00:33,725 --> 00:00:35,080
And as you can see,

11
00:00:35,080 --> 00:00:36,690
it can keep training,

12
00:00:36,690 --> 00:00:40,620
but the background image doesn't actually change much, right?

13
00:00:40,620 --> 00:00:45,060
It's all washed out because x1 and x 2 and linear model,

14
00:00:45,060 --> 00:00:50,505
it doesn't really work in terms of a good learning capability.

15
00:00:50,505 --> 00:00:52,605
So the model doesn't actually learn much.

16
00:00:52,605 --> 00:00:56,745
So let's go and stop this and let's look at this again.

17
00:00:56,745 --> 00:00:58,140
It turns out that,

18
00:00:58,140 --> 00:01:03,495
it's a combination of x1 and x2 that actually matters.

19
00:01:03,495 --> 00:01:09,900
If x1 is negative and x2 is negative, it's blue.

20
00:01:09,900 --> 00:01:14,790
If x1 is positive and x2 is positive, it is blue.

21
00:01:14,790 --> 00:01:18,795
And if the x1 and x2 have different signs,

22
00:01:18,795 --> 00:01:21,000
then it seems to be orange.

23
00:01:21,000 --> 00:01:23,430
So what does that remind you of?

24
00:01:23,430 --> 00:01:26,790
That is a feature cross between x1 and x2.

25
00:01:26,790 --> 00:01:31,965
So let's go ahead and add x1 and x2's feature cross as another input.

26
00:01:31,965 --> 00:01:37,365
And now, let's go ahead and train and we can see almost immediately

27
00:01:37,365 --> 00:01:43,230
that we basically have a pretty good model that separates the blue from the yellow,

28
00:01:43,230 --> 00:01:45,870
and the background for the blue dots tends to be blue and

29
00:01:45,870 --> 00:01:48,975
the background of the yellow dots tends to be yellow,

30
00:01:48,975 --> 00:01:53,790
and there is of course noise where you have misclassification,

31
00:01:53,790 --> 00:01:57,675
but that's to be expected because it's a noisy data set.

32
00:01:57,675 --> 00:02:00,345
So the key idea is,

33
00:02:00,345 --> 00:02:04,260
by taking this human insight, this insight that,

34
00:02:04,260 --> 00:02:07,980
it's a combination of x1 and x2 that actually will allow

35
00:02:07,980 --> 00:02:12,575
us to better classify on this data set,

36
00:02:12,575 --> 00:02:14,340
we are able to add x1 and x2.

37
00:02:14,340 --> 00:02:16,145
Which is not actually a new input.

38
00:02:16,145 --> 00:02:19,260
It is essentially a feature engineering that we've

39
00:02:19,260 --> 00:02:22,530
carried out on the original inputs in x1 and x2,

40
00:02:22,530 --> 00:02:27,510
it allows us to separate the blue and the yellow pretty well.

41
00:02:27,510 --> 00:02:31,800
So let's take now a different case.

42
00:02:31,800 --> 00:02:37,005
In this case, you basically have the blue dots in the center,

43
00:02:37,005 --> 00:02:41,055
and the yellow dots out towards the edges.

44
00:02:41,055 --> 00:02:45,660
And again, if I just use x1 and x2 and I train it,

45
00:02:45,660 --> 00:02:48,270
the background image is all washed out because there isn't

46
00:02:48,270 --> 00:02:51,345
much that can be learned for this model.

47
00:02:51,345 --> 00:02:53,430
So we can say,

48
00:02:53,430 --> 00:02:57,230
well we should probably look at what kind of future engineering we can do,

49
00:02:57,230 --> 00:02:58,870
so let me go and stop this.

50
00:02:58,870 --> 00:03:03,270
What kind of future engineering can we do to basically do the separation?

51
00:03:03,270 --> 00:03:06,690
And again the intuition here is that,

52
00:03:06,690 --> 00:03:10,845
if x1 and x2 are both small, it is blue.

53
00:03:10,845 --> 00:03:13,200
If x1 and x2 are large,

54
00:03:13,200 --> 00:03:15,420
it tends to be yellow.

55
00:03:15,420 --> 00:03:17,760
But it's not x1 and x2 are both large.

56
00:03:17,760 --> 00:03:19,830
If you look at a point here,

57
00:03:19,830 --> 00:03:23,940
it is x1 is very small but x2 is large.

58
00:03:23,940 --> 00:03:26,610
So another way to think about this is,

59
00:03:26,610 --> 00:03:30,660
if you have to think of this as the center of the image,

60
00:03:30,660 --> 00:03:34,080
points that are close to the center tend to be blue,

61
00:03:34,080 --> 00:03:37,410
points that are far away from the center tend to be yellow.

62
00:03:37,410 --> 00:03:40,350
And what does that remind you of?

63
00:03:40,350 --> 00:03:43,340
Point close and far away, that's a distance.

64
00:03:43,340 --> 00:03:45,600
And what is equation of a distance?

65
00:03:45,600 --> 00:03:48,300
Square root of x squared plus y squared.

66
00:03:48,300 --> 00:03:52,230
Well, you don't need a square root because all we're doing here is that,

67
00:03:52,230 --> 00:03:55,140
we're using input features into a neural network,

68
00:03:55,140 --> 00:03:57,395
so we need x squared and y squared.

69
00:03:57,395 --> 00:04:02,345
So let's go ahead and take x1 squared and x2 squared both of them as inputs.

70
00:04:02,345 --> 00:04:04,575
And now let's go ahead and train,

71
00:04:04,575 --> 00:04:07,215
and you see that almost immediately,

72
00:04:07,215 --> 00:04:14,940
you basically have a good separation between the blue dots and the orange dots.

73
00:04:14,940 --> 00:04:16,445
So let's stop this.

74
00:04:16,445 --> 00:04:19,320
Let's go in and look at both of these.

75
00:04:19,320 --> 00:04:25,665
Both of these, the separation boundary is a linear boundary.

76
00:04:25,665 --> 00:04:28,140
Well, in this case it's pretty obvious.

77
00:04:28,140 --> 00:04:29,745
It's not a linear boundary.

78
00:04:29,745 --> 00:04:32,550
Even though we are using a linear model here,

79
00:04:32,550 --> 00:04:34,740
there is no hidden layers,

80
00:04:34,740 --> 00:04:36,525
there is no neural network.

81
00:04:36,525 --> 00:04:40,290
It's essentially a linear combination of the inputs.

82
00:04:40,290 --> 00:04:43,850
We are able to get a non-linear boundary.

83
00:04:43,850 --> 00:04:45,655
So that's something to realize.

84
00:04:45,655 --> 00:04:48,210
If you have feature crosses,

85
00:04:48,210 --> 00:04:50,855
even though you're using a linear model,

86
00:04:50,855 --> 00:04:54,085
because the feature cross is non-linear,

87
00:04:54,085 --> 00:04:56,415
you actually have a non-linear model.

88
00:04:56,415 --> 00:05:00,000
So feature crosses, one of the reasons why they work,

89
00:05:00,000 --> 00:05:05,625
is that they bring the power of non-linearity to bring on this problem.

90
00:05:05,625 --> 00:05:09,090
They bring them to bear on this problem while

91
00:05:09,090 --> 00:05:12,850
we don't actually have to pay the price of non-linearity.

92
00:05:12,850 --> 00:05:16,110
We don't have to worry about the models being

93
00:05:16,110 --> 00:05:19,335
too deep and lots of training problems, etc.

94
00:05:19,335 --> 00:05:20,550
There's a linear model.

95
00:05:20,550 --> 00:05:23,310
And the good thing about a linear model is that,

96
00:05:23,310 --> 00:05:26,565
the area surface is convex.

97
00:05:26,565 --> 00:05:29,775
Which means that you have a unique global minimum,

98
00:05:29,775 --> 00:05:32,570
it's relatively easy to find and you can find it.

99
00:05:32,570 --> 00:05:36,495
So you have the advantages of a linear model but,

100
00:05:36,495 --> 00:05:38,430
the power of non-linearity.

101
00:05:38,430 --> 00:05:43,005
And that's the cool thing about a feature cross.

102
00:05:43,005 --> 00:05:45,240
Even on the other case,

103
00:05:45,240 --> 00:05:48,810
this is also a non-linear boundary because it's two lines, right?

104
00:05:48,810 --> 00:05:50,010
It's not a single line,

105
00:05:50,010 --> 00:05:53,070
but it's not as obvious to see as it is

106
00:05:53,070 --> 00:05:56,395
in this case where it is an ellipse and an ellipse is obviously not a line.

107
00:05:56,395 --> 00:05:59,775
So, that's something to remember that,

108
00:05:59,775 --> 00:06:04,860
even when we have the power of neural networks and we want to use neural networks,

109
00:06:04,860 --> 00:06:10,455
you might want to consider including feature crosses as part of your toolkit,

110
00:06:10,455 --> 00:06:18,340
because feature crosses allow you to have a simple model but still get non-linearity.