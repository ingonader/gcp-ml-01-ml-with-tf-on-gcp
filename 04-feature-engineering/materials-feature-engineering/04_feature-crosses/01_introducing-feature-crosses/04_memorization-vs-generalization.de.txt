Was wäre, wenn wir
die x1-Achse diskretisieren, indem wir nicht nur eine weiße,
sondern viele schwarze Linien zeichnen? Und wir auch für die x2-Achse 
viele schwarze Linien zeichnen. Jetzt haben wir die x1-Achse
und die x2-Achse diskretisiert. Mit den zwei weißen Linien erhielten wir vier Quadranten. Wie sieht es jetzt aus? Wenn wir m vertikale
und n horizontale Linien haben, erhalten wir m + 1 mal n + 1 Rasterzellen. Diskretisieren wir nun x1 und x2
und multiplizieren wir anschließend. Denken Sie an das Diagramm mit dem
in Quadranten aufgeteilten Eingaberaum. Im Grunde haben wir für jeden Quadranten
eine andere Vorhersage getroffen. Was ist nun mit diesem grünen Bereich? Was ist Ihre Vorhersage 
für diesen Bereich? Gelb, oder? Und jetzt? Blau, aber auch ein wenig gelb. Zählen wir
die blauen Punkte und die gelben Punkte. Sagen wir, 85 % blau. Sie sehen jetzt,
wie Wahrscheinlichkeiten ins Spiel kommen. Was ist jetzt? Nun gut, sehen wir uns an, warum dies
als lineares Modell gut funktioniert. Wenn Sie
den ersten Wertesatz One-Hot-codieren, dann
den zweiten Wertesatz One-Hot-codieren und eine Merkmalkreuzung durchführen, bleibt nur ein Knoten, der für Punkte
auslöst, die in diesen Bucket fallen. x3 wird nur 1, 
wenn x1 = 1 und x2 = 1 ist. Für jeden Punkt im Eingaberaum wird nur ein Bucket ausgelöst. Wenn Sie diese Werte der Merkmalkreuzung
nun in eine lineare Regression geben, was muss dann die Gewichtung w3 sein? Das Verhältnis von blauen zu gelben Punkten
in der Rasterzelle für x1 und x2. Das ist der Grund, warum
Merkmalkreuzungen so mächtig sind. Sie diskretisieren den Eingaberaum
und memorieren das Trainings-Dataset. Können Sie hier
ein mögliches Problem erkennen? Was ist, wenn Sie nicht genug Daten haben? Was lernt das Modell dann? Es lernt, dass
die Vorhersage Blau sein muss. Stimmt das? Dafür gibt es Lösungen. Sie müssen den Eingaberaum
nicht gleichmäßig diskretisieren. Sie können stattdessen
unterschiedlich große Felder verwenden. Nutzen Sie dann Feldgrößen, die einen Bezug
zum Informationsinhalt im Feld haben. Sie können Felder
auch gruppieren oder clustern. Es gibt also Lösungen. Sie sollten sich trotzdem eins merken: Bei
Merkmalkreuzungen geht es um Memorieren und Memorieren
ist das Gegenteil von Generalisieren, was wiederum
das Ziel von maschinellem Lernen ist. Sollten Sie es dann tun? In realen Systemen mit maschinellem Lernen
gibt es Platz für beides. Memorieren funktioniert,
wenn Sie so viele Daten haben, dass die Datenverteilung
für jede Rasterzelle Ihres Eingaberaums statistisch signifikant ist. Ist dies der Fall, können Sie memorieren. Das Modell lernt im Grunde
nur den Mittelwert für jede Rasterzelle. Natürlich benötigt
auch Deep Learning eine Menge Daten. Unabhängig davon, ob Sie Merkmale kreuzen
oder viele Ebenen verwenden, brauchen Sie 
in diesem Bereich viele Daten. Wenn sie mit herkömmlichem
maschinellen Lernen vertraut sind, kennen Sie Merkmalkreuzungen
möglicherweise nicht. Merkmalkreuzungen memorieren,
und funktionieren nur bei großen Datasets. Das ist ein Grund, warum Sie vielleicht
noch nicht viel darüber gehört haben. Für reale Datasets werden Sie aber
Merkmalkreuzungen äußerst nützlich finden. Je mehr Daten Sie haben, desto kleiner
können Sie die Felder auslegen und desto feiner können Sie memorieren. Merkmalkreuzungen sind bei großen Datasets
eine mächtige Vorverarbeitungstechnik.