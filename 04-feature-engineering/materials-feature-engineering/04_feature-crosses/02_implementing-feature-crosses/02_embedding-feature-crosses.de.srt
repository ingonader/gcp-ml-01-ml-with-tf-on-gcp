1
00:00:00,000 --> 00:00:01,069
Sie erinnern sich,

2
00:00:01,069 --> 00:00:07,085
dass ein großer Wert für Hash-Buckets
zu einer sehr dünnen Präsentation führt.

3
00:00:07,085 --> 00:00:11,065
Was ist aber,
wenn wir etwas zusätzlich machen?

4
00:00:11,065 --> 00:00:16,030
Verwenden wir nach der One-Hot-Codierung
die Merkmalkreuzung nicht unverändert,

5
00:00:16,030 --> 00:00:18,835
sondern senden sie durch eine Dichteebene.

6
00:00:18,835 --> 00:00:23,270
Wir können das Modell trainieren,
den Verkehr vorherzusagen, wie zuvor.

7
00:00:23,270 --> 00:00:27,620
Diese Dichteebene wird durch den grünen
und den gelben Knoten dargestellt.

8
00:00:27,620 --> 00:00:32,189
Die Dichteebene erstellt hier
eine sogenannte Einbettung.

9
00:00:32,189 --> 00:00:38,340
Die grauen
und blauen Felder sind Nullen und Einsen.

10
00:00:38,340 --> 00:00:41,220
In jeder Zeile des Eingabe-Datasets,

11
00:00:41,220 --> 00:00:43,590
in jedem Trainingsbeispiel,

12
00:00:43,590 --> 00:00:46,230
ist nur eines der Felder hervorgehoben.

13
00:00:46,230 --> 00:00:49,895
Dieses blaue Feld ist eins,

14
00:00:49,895 --> 00:00:54,185
die grauen Felder
in diesem Beispiel sind null.

15
00:00:54,185 --> 00:00:59,040
Ein anderes Trainingsbeispiel
entspricht einer anderen Tageszeit,

16
00:00:59,040 --> 00:01:01,460
daher wird
ein anderes Feld hervorgehoben.

17
00:01:01,460 --> 00:01:06,175
Dieses Feld ist dann eins,
die anderen Felder sind null.

18
00:01:06,175 --> 00:01:10,100
Jedoch ist das beim gelben
und beim grünen Feld anders.

19
00:01:10,100 --> 00:01:11,980
Diese sind nicht One-Hot-codiert.

20
00:01:11,980 --> 00:01:16,270
Es sind reellwertige Zahlen,
also Gleitkommawerte.

21
00:01:16,270 --> 00:01:21,405
Sie stellen nämlich eine gewichtete Summe
der Werte der Merkmalkreuzung dar.

22
00:01:21,405 --> 00:01:25,965
Was also passiert
in dem gelben und dem grünen Knoten?

23
00:01:25,965 --> 00:01:31,200
Die Gewichtungen,
die in die Einbettungsebene eingehen,

24
00:01:31,200 --> 00:01:35,390
die Gewichtungen, die in den gelben
und den grünen Knoten eingehen,

25
00:01:35,390 --> 00:01:38,275
werden aus den Daten gelernt.

26
00:01:38,275 --> 00:01:42,885
Stellen Sie sich vor,
wir haben eine Menge Verkehr beobachtet.

27
00:01:42,885 --> 00:01:48,850
Jedes Fahrzeug – Auto, Fahrrad, LKW –,
das eine bestimmte Ampel passiert,

28
00:01:48,850 --> 00:01:51,055
ist eine Verkehrsbeobachtung.

29
00:01:51,055 --> 00:01:55,295
Wir haben also die Daten
für eine ganze Stadt, für alle Ampeln,

30
00:01:55,295 --> 00:01:57,985
und damit
Millionen von Trainingsbeispielen.

31
00:01:57,985 --> 00:02:01,960
Moment, habe ich das gerade so gesagt?

32
00:02:01,960 --> 00:02:05,475
Dass mein Dataset
aus Verkehrsbeobachtungen besteht?

33
00:02:05,475 --> 00:02:10,229
Ein Trainingsbeispiel
für jedes Fahrzeug an einer Ampel?

34
00:02:10,229 --> 00:02:14,770
Wenn maschinelles Lernen
neu für Sie ist, wette ich, Sie dachten,

35
00:02:14,770 --> 00:02:20,190
unser Trainings-Dataset würde
aus aggregierten Verkehrszahlen bestehen,

36
00:02:20,190 --> 00:02:25,385
vielleicht aus der Gesamtzahl
an Fahrzeugen zu jeder Stunde an jedem Tag.

37
00:02:25,385 --> 00:02:29,790
Das ist jedoch nur ein kleines Dataset,
nur ein einfaches Problem.

38
00:02:29,790 --> 00:02:33,495
Damit lernen Sie nur Mittelwerte.

39
00:02:33,495 --> 00:02:36,360
Das ist im Prinzip uninteressant

40
00:02:36,360 --> 00:02:40,065
und eignet sich
nur für Nachrichtenartikel wie

41
00:02:40,065 --> 00:02:44,400
"Modellen zufolge steigt im nächsten Jahr
das Verkehrsaufkommen um 10 %."

42
00:02:44,400 --> 00:02:46,500
Aber was haben wir gesagt?

43
00:02:46,500 --> 00:02:50,890
Bei maschinellem Lernen
geht es darum, viele Daten zu lernen,

44
00:02:50,890 --> 00:02:58,240
um detailliertere Vorhersagen
als nur Mittelwerte treffen zu können.

45
00:02:58,240 --> 00:03:01,395
Nun, so sieht das dann in der Praxis aus.

46
00:03:01,395 --> 00:03:06,735
Anstatt mit wenigen hundert Zeilen
eines aggregierten Datasets zu arbeiten,

47
00:03:06,735 --> 00:03:13,620
haben wir minütliche Beobachtungen
von Fahrzeugen an jeder Ampel.

48
00:03:13,620 --> 00:03:17,335
Das sind die Verkehrsdaten,
die wir verwenden werden.

49
00:03:17,335 --> 00:03:22,820
Unsere Vorhersagen werden
Anzahlen von Autos, LKWs und Fahrrädern

50
00:03:22,820 --> 00:03:27,435
zu jedem Zeitpunkt
an jedem Ort in der Stadt sein.

51
00:03:27,435 --> 00:03:32,545
Beim maschinellen Lernen
geht es um detaillierte Vorhersagen.

52
00:03:32,545 --> 00:03:36,280
Nun zurück zu unserer Lektion.

53
00:03:36,280 --> 00:03:38,900
Wir haben also Fahrzeugbeobachtungen.

54
00:03:38,900 --> 00:03:42,595
Das Dataset 
kann den Fahrzeugtyp enthalten,

55
00:03:42,595 --> 00:03:45,690
Auto, Fahrrad, Bus, LKW,

56
00:03:45,690 --> 00:03:50,020
die Fahrtrichtung, Position usw.

57
00:03:50,020 --> 00:03:57,015
Das Dataset enthält einen Zeitstempel,
aus dem wir Tag und Stunde extrahieren.

58
00:03:57,015 --> 00:04:01,460
Dann kreuzen wir die Merkmale,
um im Diagramm x3 zu erhalten.

59
00:04:01,460 --> 00:04:10,695
Wie besprochen, ist x3
in mehrere Hash-Buckets One-Hot-codiert.

60
00:04:10,695 --> 00:04:15,270
Das nehmen wir
und senden es durch eine Dichteebene,

61
00:04:15,270 --> 00:04:20,483
deren Gewichtungen trainiert sind,
einige Dinge zum Verkehr vorherzusagen.

62
00:04:20,483 --> 00:04:26,205
Vielleicht sagen wir die Zeit vorher, bis
das nächste Fahrzeug die Kreuzung erreicht,

63
00:04:26,205 --> 00:04:29,470
damit wir
die Dauer des Ampelsignals steuern können.

64
00:04:29,470 --> 00:04:37,320
Diese Gewichtungen für dieses Dataset
zu trainieren, erweist sich als nützlich.

65
00:04:37,320 --> 00:04:43,085
Die Merkmalkreuzung
von Tag/Stunde hat 168 eindeutige Werte,

66
00:04:43,085 --> 00:04:49,420
doch erzwingen wir eine Darstellung
durch nur zwei reellwertige Zahlen.

67
00:04:49,420 --> 00:04:53,125
So lernt das Modell,

68
00:04:53,125 --> 00:04:58,270
wie es die Merkmalkreuzung in einen Raum
mit weniger Dimensionen einbettet.

69
00:04:58,270 --> 00:05:05,195
Vielleicht werden im grünen Feld
eher Fußgänger und Radfahrer erfasst,

70
00:05:05,195 --> 00:05:09,400
während im gelben
eher Kraftfahrzeuge erfasst werden.

71
00:05:09,400 --> 00:05:14,830
Dienstag 8:00 Uhr und Mittwoch 9:00 Uhr
können in der Merkmalkreuzung

72
00:05:14,830 --> 00:05:18,385
unterschiedlichen Feldern entsprechen.

73
00:05:18,385 --> 00:05:23,480
Wenn aber die Verkehrsmuster
an den meisten Kreuzungen in der Stadt

74
00:05:23,480 --> 00:05:26,370
sich zu diesen beiden Zeiten ähneln,

75
00:05:26,370 --> 00:05:32,010
sind auch die reellwertigen Darstellungen
dieser beiden Tag/Stunde-Kombinationen

76
00:05:32,010 --> 00:05:34,945
am Ende ziemlich ähnlich.

77
00:05:34,945 --> 00:05:38,410
Vielleicht sind
viele Fahrradfahrer und Fußgänger

78
00:05:38,410 --> 00:05:41,930
und auch viele Autos
zu diesen Zeiten unterwegs.

79
00:05:41,930 --> 00:05:46,600
Die Gewichtungen für 8:00 Uhr
und 9:00 Uhr werden so angepasst,

80
00:05:46,600 --> 00:05:52,195
dass sich die reellwertigen Zahlen
für Gelb und Grün zu diesen Zeiten ähneln.

81
00:05:52,195 --> 00:05:56,865
Dienstag 11:00 Uhr und Mittwoch 14:00 Uhr

82
00:05:56,865 --> 00:05:59,610
sind aber nicht viele Fußgänger unterwegs,

83
00:05:59,610 --> 00:06:02,800
jedoch eine mittlere Anzahl an Autos.

84
00:06:02,800 --> 00:06:05,305
Die Zahlen liegen dicht beieinander.

85
00:06:05,305 --> 00:06:12,045
Ähnlich gleichen sich die Zahlen für
Dienstag 2:00 Uhr und Mittwoch 3:00 Uhr,

86
00:06:12,045 --> 00:06:14,575
wo kaum Verkehr angezeigt wird.

87
00:06:14,575 --> 00:06:20,160
Wichtig ist, dass bezüglich Verkehr
ähnliche Tag/Stunde-Kombinationen

88
00:06:20,160 --> 00:06:21,729
eher ähnliche Werte haben,

89
00:06:21,729 --> 00:06:25,890
und Werte für Tag/Stunde-Kombinationen
mit unterschiedlichem Verkehrsaufkommen

90
00:06:25,890 --> 00:06:29,560
im zweidimensionalen Raum
eher weiter auseinander liegen.

91
00:06:29,560 --> 00:06:33,985
Genau das meinen wir,
wenn wir sagen, das Modell lernt,

92
00:06:33,985 --> 00:06:39,100
die Modellkreuzung in einem
niedrigerdimensionalen Raum einzubetten.

93
00:06:39,100 --> 00:06:43,310
Wie implementieren Sie
dies nun in TensorFlow?

94
00:06:43,310 --> 00:06:46,035
Nutzen Sie für eine Einbettung

95
00:06:46,035 --> 00:06:50,920
die Methode "embedding_column"
in "tf.feature_column".

96
00:06:50,920 --> 00:06:54,985
Übergeben Sie
die einzubettende kategorische Spalte,

97
00:06:54,985 --> 00:06:57,725
hier übergeben wir die Merkmalkreuzung,

98
00:06:57,725 --> 00:07:02,480
und geben Sie dann
die Anzahl der Einbettungsdimensionen an.

99
00:07:02,480 --> 00:07:04,235
Das war es dann schon.

100
00:07:04,235 --> 00:07:09,325
Für so eine wirkungsvolle Idee
ist das sehr einfach.

101
00:07:09,325 --> 00:07:12,590
Warum nenne ich die Idee wirkungsvoll?

102
00:07:12,590 --> 00:07:15,540
Eine tolle Sache bei der Einbettung ist,

103
00:07:15,540 --> 00:07:18,755
dass die Einbettung,
die Sie für ein Problem angelernt haben,

104
00:07:18,755 --> 00:07:23,970
oft auch auf andere ähnliche Probleme
für maschinelles Lernen anwendbar ist.

105
00:07:23,970 --> 00:07:26,549
Vielleicht haben Sie gelernt,

106
00:07:26,549 --> 00:07:31,800
auf Basis von Verkehrsdaten aus London
Tag/Stunde-Kombinationen darzustellen.

107
00:07:31,800 --> 00:07:35,980
Nun möchten Sie
neue Ampeln in Frankfurt aufstellen,

108
00:07:35,980 --> 00:07:39,245
Ihnen liegen aber
keine Daten für Frankfurt vor.

109
00:07:39,245 --> 00:07:41,440
Sie könnten eine Abkürzung nehmen.

110
00:07:41,440 --> 00:07:45,990
Sie könnten eine aus London
erlernte Einbettung in Frankfurt verwenden.

111
00:07:45,990 --> 00:07:52,500
Sie suchen ja nur eine Darstellungsweise
für Tag/Stunde-Kombinationen.

112
00:07:52,500 --> 00:07:56,150
Die über Daten aus London
trainierte Einbettung ist besser

113
00:07:56,150 --> 00:07:58,785
als über Heuristik erstellte Daten,

114
00:07:58,785 --> 00:08:01,165
wie für Morgenstunden oder für Stoßzeiten.

115
00:08:01,165 --> 00:08:03,090
Wie machen Sie das also?

116
00:08:03,090 --> 00:08:06,785
Sie laden sie einfach
aus dem für London gespeicherten Modell

117
00:08:06,785 --> 00:08:11,100
und weisen das Modell an,
diese Ebene nicht zu trainieren.

118
00:08:11,100 --> 00:08:15,155
Sie könnten
die Einbettung von London auch laden

119
00:08:15,155 --> 00:08:18,540
und sie einfach
als Startpunkt für Frankfurt verwenden.

120
00:08:18,545 --> 00:08:25,740
Für diese Option
setzen Sie in der Ebene "trainable=True".

121
00:08:25,740 --> 00:08:30,445
Einbettungen sind
ein äußerst leistungsstarkes Konzept.

122
00:08:30,445 --> 00:08:35,554
Das Übertragen von aus Einbettungen
Erlerntem macht sie noch leistungsstärker.

123
00:08:35,554 --> 00:08:39,755
Sie sind insbesondere nützlich
bei Spalten mit sehr geringer Dichte.

124
00:08:39,755 --> 00:08:44,054
Bei Tag/Stunde
mit nur 168 eindeutigen Kombinationen

125
00:08:44,054 --> 00:08:45,845
ist das weniger spürbar.

126
00:08:45,845 --> 00:08:49,895
Einbettungen werden uns aber oft begegnen,
wenn wir zu Sprachmodellen kommen.

127
00:08:49,895 --> 00:08:53,705
Dort haben Sie
vielleicht 100.000 eindeutige Wörter,

128
00:08:53,705 --> 00:09:01,335
die Sie einbetten und in 30
oder 50 Dimensionen darstellen möchten.

129
00:09:01,335 --> 00:09:04,497
Merkmalkreuzungen und Einbettungen

130
00:09:04,497 --> 00:09:09,340
sind bei realen Modellen
für maschinelles Lernen sehr nützlich.

131
00:09:09,337 --> 00:09:15,247
Wiederholen Sie daher bei Bedarf
diese zwei Lektionen, bevor Sie fortfahren.