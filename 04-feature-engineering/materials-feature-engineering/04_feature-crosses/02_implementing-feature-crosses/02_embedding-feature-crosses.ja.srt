1
00:00:00,000 --> 00:00:03,789
ハッシュバケット数に大きな値を使うと

2
00:00:03,789 --> 00:00:07,055
疎表現になると説明しましたが

3
00:00:07,055 --> 00:00:09,955
もう1つの方法を試せます

4
00:00:09,955 --> 00:00:15,780
たとえば 特徴クロスをワンホット
エンコーディングしてそのまま使う代わりに

5
00:00:15,780 --> 00:00:18,895
全結合層（密層）に
渡せます その後

6
00:00:18,895 --> 00:00:23,900
以前のようにトラフィックの
予測モデルをトレーニングできます

7
00:00:23,900 --> 00:00:28,280
この全結合層は 黄色と緑色の
ノードで示されていますが

8
00:00:28,280 --> 00:00:34,589
全結合層は
いわゆる「埋め込み」を作成します

9
00:00:34,589 --> 00:00:38,340
灰色と青の四角形は
それぞれ0と1を表します

10
00:00:38,340 --> 00:00:41,020
入力データセットのどの行でも

11
00:00:41,020 --> 00:00:43,590
どのトレーニングサンプルに対しても

12
00:00:43,590 --> 00:00:46,230
1つの四角形だけがヒットします

13
00:00:46,230 --> 00:00:50,265
青で示されている四角形がそれです

14
00:00:50,265 --> 00:00:54,005
この例の灰色の四角形は0です

15
00:00:54,005 --> 00:00:59,040
別の1つのトレーニングサンプルは
別の時刻に相当するので

16
00:00:59,040 --> 00:01:01,460
別の四角形が青になります

17
00:01:01,460 --> 00:01:06,175
その四角形が1で
他の四角形は0です

18
00:01:06,175 --> 00:01:12,050
しかし黄色と緑色の四角形は違います
ワンホットエンコーディングではありません

19
00:01:12,050 --> 00:01:17,190
これらは実数値、浮動小数点値です
なぜでしょう？

20
00:01:17,190 --> 00:01:21,465
特徴クロスの適用後の値を
加重合計しているからです

21
00:01:21,465 --> 00:01:25,965
黄色と緑色のノードでは
何が起きているのでしょう？

22
00:01:25,965 --> 00:01:31,410
注意すべき点ですが
埋め込み層に入ってくる重み

23
00:01:31,410 --> 00:01:35,690
つまり 黄色と緑色のノードに入る重みは

24
00:01:35,690 --> 00:01:38,465
データから学習されます

25
00:01:38,465 --> 00:01:43,255
膨大な交通量が観測されている場面を
想像してください

26
00:01:43,255 --> 00:01:48,500
車や自転車などが
特定の信号を通過するたびに

27
00:01:48,500 --> 00:01:51,055
交通量が観測されます

28
00:01:51,055 --> 00:01:53,965
街中のすべての信号のデータがあり

29
00:01:53,965 --> 00:01:57,985
数百万件のトレーニングサンプルができます

30
00:01:57,985 --> 00:02:01,960
ちょっと待って
私は今なんて言った？

31
00:02:01,960 --> 00:02:07,445
信号を通る車両ごとに1つの
トレーニングサンプルを観測して

32
00:02:07,445 --> 00:02:10,389
交通量のデータセットを作るんですか？

33
00:02:10,389 --> 00:02:14,770
機械学習が初めての方は
たぶんこう思うでしょう

34
00:02:14,770 --> 00:02:20,190
「トレーニングデータセットは
交通量の集計値だろう

35
00:02:20,190 --> 00:02:25,495
たとえば1日の
毎時の交通量の合計だろう」

36
00:02:25,495 --> 00:02:30,110
でも それは小さなデータセットです
おもちゃのようなものです

37
00:02:30,110 --> 00:02:33,735
そのようなデータでは
平均しか学習できず

38
00:02:33,735 --> 00:02:36,360
根本的に面白くありません

39
00:02:36,360 --> 00:02:39,865
単にこんな新聞記事が
書ける程度です

40
00:02:39,865 --> 00:02:44,710
「モデルの予測によると
来年の交通量は10%上昇」

41
00:02:44,710 --> 00:02:48,330
すでにご説明したとおり
機械学習とは

42
00:02:48,330 --> 00:02:53,510
ロングテールを学習し
詳細な予測を行い

43
00:02:53,510 --> 00:02:58,500
単なる全体平均を超えた
分析情報を得るための手法です

44
00:02:58,500 --> 00:03:01,705
そして 実際に
このように使われています

45
00:03:01,705 --> 00:03:06,735
単に数百行の
集約データセットを扱うのではなく

46
00:03:06,735 --> 00:03:10,670
きめ細かな観測によって

47
00:03:10,670 --> 00:03:17,335
すべての信号を通る車両の
交通データを集めるのです

48
00:03:17,335 --> 00:03:19,630
私たちが予測する際には

49
00:03:19,630 --> 00:03:23,360
車の数、トラックの数、自転車の数を

50
00:03:23,360 --> 00:03:27,685
任意の時刻、任意の地点について予測します

51
00:03:27,685 --> 00:03:32,545
機械学習は
きめ細かな予測を生成するのです

52
00:03:32,545 --> 00:03:36,280
さてレッスンに戻りましょう

53
00:03:36,280 --> 00:03:38,900
車両の観測データがあり

54
00:03:38,900 --> 00:03:42,595
データセットの中には
車両のタイプ つまり

55
00:03:42,595 --> 00:03:45,690
車、自転車、バス、トラック

56
00:03:45,690 --> 00:03:50,020
そして進行方向、
観測地点などが含まれます

57
00:03:50,020 --> 00:03:57,175
データセットに含まれる
タイムスタンプから曜日と時刻を抽出し

58
00:03:57,175 --> 00:04:01,740
特徴クロスを適用すると
図のx3が得られます

59
00:04:01,740 --> 00:04:03,720
すでに述べたとおり

60
00:04:03,720 --> 00:04:11,335
x3はワンホットエンコードされ
多数のハッシュバケットになります

61
00:04:11,335 --> 00:04:15,270
これを全結合層に渡すと

62
00:04:15,270 --> 00:04:20,483
重みがトレーニングされ
さまざまな交通状況を予測できます

63
00:04:20,483 --> 00:04:26,205
たとえば次の車両が交差点に来る
時刻を予測することで

64
00:04:26,205 --> 00:04:29,660
信号の長さを制御できるでしょう

65
00:04:29,660 --> 00:04:37,320
つまりデータセットによって
重みをトレーニングすると便利です

66
00:04:37,320 --> 00:04:43,085
曜日/時刻の特徴クロスには
168個の固有値がありますが

67
00:04:43,085 --> 00:04:49,420
ここではそれを変換して
単に2つの実数値で表します

68
00:04:49,420 --> 00:04:52,290
するとモデルは

69
00:04:52,290 --> 00:04:58,270
特徴クロスを低次元空間に埋め込む
方法を学習します

70
00:04:58,270 --> 00:05:05,195
緑色の四角形はおそらく
歩行者と自転車の交通をとらえ

71
00:05:05,195 --> 00:05:09,480
黄色はバイクをとらえています

72
00:05:09,480 --> 00:05:13,620
おそらく火曜日の午前8時と
水曜日の午前9時は

73
00:05:13,620 --> 00:05:18,385
特徴クロス内のまったく別の
四角形に相当するでしょう

74
00:05:18,385 --> 00:05:23,450
でも 仮に市内のほとんどの
交差点の交通パターンが

75
00:05:23,450 --> 00:05:26,370
この2つの時点で似ている場合は

76
00:05:26,370 --> 00:05:34,950
この2つの曜日/時刻ペアの
実数値表現がよく似たものになります

77
00:05:34,950 --> 00:05:39,660
この時間帯は自転車や徒歩の人が
多いでしょうし

78
00:05:39,660 --> 00:05:41,930
車も多いでしょう

79
00:05:41,930 --> 00:05:46,150
午前8時と午前9時の重みが調整されて

80
00:05:46,150 --> 00:05:52,195
緑色と黄色の実数値が
その時刻で類似するようになります

81
00:05:52,195 --> 00:05:55,015
しかし火曜日の午前11時と

82
00:05:55,015 --> 00:05:57,940
水曜日の午後2時には

83
00:05:57,940 --> 00:06:02,800
歩行者が少ないですが
車はほどほどに多いでしょう

84
00:06:02,800 --> 00:06:05,305
ですから数値が類似します

85
00:06:05,305 --> 00:06:10,745
同様に火曜日の午前2時と
水曜日の午前3時も似た数値になり

86
00:06:10,745 --> 00:06:15,155
交通量がまったくない状態を
反映するでしょう

87
00:06:15,155 --> 00:06:16,350
要するに

88
00:06:16,350 --> 00:06:21,729
交通状況が類似する曜日/時刻の
組み合わせは互いに近似し

89
00:06:21,729 --> 00:06:26,340
交通状況がまったく異なる
曜日/時刻の組み合わせは

90
00:06:26,340 --> 00:06:30,120
2次元空間で互いに離れる
傾向があります

91
00:06:30,120 --> 00:06:34,225
このようにしてモデルが学習し

92
00:06:34,225 --> 00:06:39,100
特徴クロスを低次元空間に
埋め込むのです

93
00:06:39,100 --> 00:06:44,150
では これをTensorFlowに
どのように実装しますか？

94
00:06:44,150 --> 00:06:46,515
埋め込みを作成するには

95
00:06:46,515 --> 00:06:50,920
TFF特徴列で
埋め込み列メソッドを使います

96
00:06:50,920 --> 00:06:54,765
埋め込みたいカテゴリの列を渡します

97
00:06:54,765 --> 00:06:57,865
たとえば ここでは特徴クロスを渡し

98
00:06:57,865 --> 00:07:02,480
次に 埋め込む次元の数を指定します

99
00:07:02,480 --> 00:07:06,825
こうするだけで
とても強力な概念を

100
00:07:06,825 --> 00:07:09,325
とても簡単に実装できます

101
00:07:09,325 --> 00:07:12,590
なぜ強力な概念と言えるのですか？

102
00:07:12,590 --> 00:07:18,230
埋め込みが優れている点は
1つの問題で学習した埋め込みを

103
00:07:18,230 --> 00:07:23,970
多くの場合他のよく似た
MLモデルにも適用できることです

104
00:07:23,970 --> 00:07:28,029
たとえば曜日/時刻の
組み合わせを表現する方法を

105
00:07:28,029 --> 00:07:32,390
ロンドンの詳細な交通データに
基づいて学習したとします

106
00:07:32,390 --> 00:07:36,060
フランクフルトで今
新しい信号機を設置する予定ですが

107
00:07:36,060 --> 00:07:39,245
フランクフルトのデータを
まだ収集していません

108
00:07:39,245 --> 00:07:40,940
手早い方法として

109
00:07:40,940 --> 00:07:45,990
ロンドンでの学習の埋め込みを
フランクフルトで利用できます

110
00:07:45,990 --> 00:07:51,600
結局のところ 曜日/時刻の組み合わせを
適切な方法で表現し

111
00:07:51,600 --> 00:07:55,530
ロンドンのデータで
トレーニングされた埋め込みは

112
00:07:55,530 --> 00:07:57,525
早朝やラッシュアワーなど

113
00:07:57,525 --> 00:08:01,165
ヒューリスティック法を使った
データ構築よりも優れています

114
00:08:01,165 --> 00:08:03,090
ではどうやって使いますか？

115
00:08:03,090 --> 00:08:06,785
保存済みのロンドンのモデルを
単に読み込んで

116
00:08:06,785 --> 00:08:11,100
「この層を学習するな」と
モデルに指示するだけです

117
00:08:11,100 --> 00:08:15,925
あるいは ロンドンから得られた
埋め込みを読み込んで

118
00:08:15,925 --> 00:08:18,930
フランクフルトの開始点として
使うこともできます

119
00:08:18,930 --> 00:08:21,575
そうするには

120
00:08:21,575 --> 00:08:26,782
層の中でtrainable=true
を設定します

121
00:08:26,782 --> 00:08:30,445
埋め込みはとてもパワフルな概念です

122
00:08:30,445 --> 00:08:35,554
埋め込みの学習を転用することで
さらにパワフルになります

123
00:08:35,554 --> 00:08:39,755
かなり疎（スパース）な列を扱うときに
これが特に役立ちます

124
00:08:39,755 --> 00:08:43,944
一意の168個の曜日/時刻の
組み合わせ程度であれば

125
00:08:43,944 --> 00:08:45,955
たいしたことは
ありませんが

126
00:08:45,955 --> 00:08:49,895
埋め込みは
言語モデルなどで多く使われます

127
00:08:49,895 --> 00:08:55,965
100,000個の固有の単語があり
それらを埋め込んで

128
00:08:55,965 --> 00:09:01,645
30次元、50次元などの低次元空間で
表現したい場合があります

129
00:09:01,645 --> 00:09:09,050
特徴クロスと埋め込みは 現実世界の
機械学習モデルでとても役立ちます

130
00:09:09,050 --> 00:09:15,260
必要に応じてこの2つのレッスンを
復習してから 次に進んでください