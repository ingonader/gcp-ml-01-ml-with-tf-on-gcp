ハッシュバケット数に大きな値を使うと 疎表現になると説明しましたが もう1つの方法を試せます たとえば 特徴クロスをワンホット
エンコーディングしてそのまま使う代わりに 全結合層（密層）に
渡せます その後 以前のようにトラフィックの
予測モデルをトレーニングできます この全結合層は 黄色と緑色の
ノードで示されていますが 全結合層は
いわゆる「埋め込み」を作成します 灰色と青の四角形は
それぞれ0と1を表します 入力データセットのどの行でも どのトレーニングサンプルに対しても 1つの四角形だけがヒットします 青で示されている四角形がそれです この例の灰色の四角形は0です 別の1つのトレーニングサンプルは
別の時刻に相当するので 別の四角形が青になります その四角形が1で
他の四角形は0です しかし黄色と緑色の四角形は違います
ワンホットエンコーディングではありません これらは実数値、浮動小数点値です
なぜでしょう？ 特徴クロスの適用後の値を
加重合計しているからです 黄色と緑色のノードでは
何が起きているのでしょう？ 注意すべき点ですが
埋め込み層に入ってくる重み つまり 黄色と緑色のノードに入る重みは データから学習されます 膨大な交通量が観測されている場面を
想像してください 車や自転車などが
特定の信号を通過するたびに 交通量が観測されます 街中のすべての信号のデータがあり 数百万件のトレーニングサンプルができます ちょっと待って
私は今なんて言った？ 信号を通る車両ごとに1つの
トレーニングサンプルを観測して 交通量のデータセットを作るんですか？ 機械学習が初めての方は
たぶんこう思うでしょう 「トレーニングデータセットは
交通量の集計値だろう たとえば1日の
毎時の交通量の合計だろう」 でも それは小さなデータセットです
おもちゃのようなものです そのようなデータでは
平均しか学習できず 根本的に面白くありません 単にこんな新聞記事が
書ける程度です 「モデルの予測によると
来年の交通量は10%上昇」 すでにご説明したとおり
機械学習とは ロングテールを学習し
詳細な予測を行い 単なる全体平均を超えた
分析情報を得るための手法です そして 実際に
このように使われています 単に数百行の
集約データセットを扱うのではなく きめ細かな観測によって すべての信号を通る車両の
交通データを集めるのです 私たちが予測する際には 車の数、トラックの数、自転車の数を 任意の時刻、任意の地点について予測します 機械学習は
きめ細かな予測を生成するのです さてレッスンに戻りましょう 車両の観測データがあり データセットの中には
車両のタイプ つまり 車、自転車、バス、トラック そして進行方向、
観測地点などが含まれます データセットに含まれる
タイムスタンプから曜日と時刻を抽出し 特徴クロスを適用すると
図のx3が得られます すでに述べたとおり x3はワンホットエンコードされ
多数のハッシュバケットになります これを全結合層に渡すと 重みがトレーニングされ
さまざまな交通状況を予測できます たとえば次の車両が交差点に来る
時刻を予測することで 信号の長さを制御できるでしょう つまりデータセットによって
重みをトレーニングすると便利です 曜日/時刻の特徴クロスには
168個の固有値がありますが ここではそれを変換して
単に2つの実数値で表します するとモデルは 特徴クロスを低次元空間に埋め込む
方法を学習します 緑色の四角形はおそらく
歩行者と自転車の交通をとらえ 黄色はバイクをとらえています おそらく火曜日の午前8時と
水曜日の午前9時は 特徴クロス内のまったく別の
四角形に相当するでしょう でも 仮に市内のほとんどの
交差点の交通パターンが この2つの時点で似ている場合は この2つの曜日/時刻ペアの
実数値表現がよく似たものになります この時間帯は自転車や徒歩の人が
多いでしょうし 車も多いでしょう 午前8時と午前9時の重みが調整されて 緑色と黄色の実数値が
その時刻で類似するようになります しかし火曜日の午前11時と 水曜日の午後2時には 歩行者が少ないですが
車はほどほどに多いでしょう ですから数値が類似します 同様に火曜日の午前2時と
水曜日の午前3時も似た数値になり 交通量がまったくない状態を
反映するでしょう 要するに 交通状況が類似する曜日/時刻の
組み合わせは互いに近似し 交通状況がまったく異なる
曜日/時刻の組み合わせは 2次元空間で互いに離れる
傾向があります このようにしてモデルが学習し 特徴クロスを低次元空間に
埋め込むのです では これをTensorFlowに
どのように実装しますか？ 埋め込みを作成するには TFF特徴列で
埋め込み列メソッドを使います 埋め込みたいカテゴリの列を渡します たとえば ここでは特徴クロスを渡し 次に 埋め込む次元の数を指定します こうするだけで
とても強力な概念を とても簡単に実装できます なぜ強力な概念と言えるのですか？ 埋め込みが優れている点は
1つの問題で学習した埋め込みを 多くの場合他のよく似た
MLモデルにも適用できることです たとえば曜日/時刻の
組み合わせを表現する方法を ロンドンの詳細な交通データに
基づいて学習したとします フランクフルトで今
新しい信号機を設置する予定ですが フランクフルトのデータを
まだ収集していません 手早い方法として ロンドンでの学習の埋め込みを
フランクフルトで利用できます 結局のところ 曜日/時刻の組み合わせを
適切な方法で表現し ロンドンのデータで
トレーニングされた埋め込みは 早朝やラッシュアワーなど ヒューリスティック法を使った
データ構築よりも優れています ではどうやって使いますか？ 保存済みのロンドンのモデルを
単に読み込んで 「この層を学習するな」と
モデルに指示するだけです あるいは ロンドンから得られた
埋め込みを読み込んで フランクフルトの開始点として
使うこともできます そうするには 層の中でtrainable=true
を設定します 埋め込みはとてもパワフルな概念です 埋め込みの学習を転用することで
さらにパワフルになります かなり疎（スパース）な列を扱うときに
これが特に役立ちます 一意の168個の曜日/時刻の
組み合わせ程度であれば たいしたことは
ありませんが 埋め込みは
言語モデルなどで多く使われます 100,000個の固有の単語があり
それらを埋め込んで 30次元、50次元などの低次元空間で
表現したい場合があります 特徴クロスと埋め込みは 現実世界の
機械学習モデルでとても役立ちます 必要に応じてこの2つのレッスンを
復習してから 次に進んでください