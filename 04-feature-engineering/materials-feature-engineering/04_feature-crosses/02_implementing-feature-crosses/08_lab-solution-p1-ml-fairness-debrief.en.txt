In the first course in
this specialization, we talked about ML Fairness. Now that we have a real world
model to predict taxi fares, let's take a look at whether
questions of ML fairness arise. Our model uses features crosses. Is it fair to do so? Is there a potential problem? Can the resolution of the feature cross,
the feature cross of latitude and longitude, can the resolution of that
feature cross amplify injustice? It all depends on how the ML
model is going to be used. A pure taxi fare model appears innocent. But you have to realize that machine
learning models will be used to make decisions. And if the model's estimated
fare is used to advertize a potential passenger to
a bunch of taxi drivers, then the idiosyncracies of this
machine learning model will start to determine whether or
not a passenger gets picked up. Imagine a neighborhood that's right
below the Queen's Borough Bridge. To get there, a taxi needs to drive
a long way on the bridge, and then below the bridge, and
then repeat this on the way back. The accuracy of fair estimates for such a neighbourhood relies heavily on
the resolution of the feature cross. Yet the more fine grain the feature cross,
the more likely it is that one of behaviours
start to play a larger impact. For example, asingle passenger
who lives in that neighborhood who always makes a taxi wait with
meter running, or asks the taxi to take a roundabout route just because
he wants to go through Central Park. A single passenger can completely throw
off the system because a feature cross is so fine grained. So it appears that using the feature
cross can make the system more adjust. Maybe we should use it. But what's the alternative? Remember that if we don't
use the feature cross, then we are at the mercy
of our raw features. And although we didn't look at
feature importance, it turns out that the Euclidean distance is a most important
feature once you remove feature crosses. So if we don't use feature crosses, we'll be extremely reliant
on the Euclidean distance. This seems pretty straightforward. There shouldn't be any fairness
problem with Euclidean distance right? However, what if I told you
that richer neighborhoods tend to have better access to highways so that the straight line distance tends to
be quite accurate for such neighborhoods. So a low res feature cross will
tend to have bad fare estimates for poorer neighborhoods. And so it's poorer neighborhoods that
start to pop up with weirdly high fair estimates if you have high resolution,
are always incorrect fair estimates, if we have very low
resolution feature process. There are no easy answers, there is no shortcut to actually
knowing the data and the domain. So the way to check would be
to look at the final impact, the final decision being made. And you would have to
model this decision and ensure that all stakeholders
understand what the model predicts, and what the impact in
the real world would be.