1
00:00:00,000 --> 00:00:02,969
Recuerdan que dije
que usar un valor grande

2
00:00:02,969 --> 00:00:07,085
en los segmentos hash
conduce a una representación muy dispersa.

3
00:00:07,595 --> 00:00:10,165
Pero ¿y si hacemos algo más?

4
00:00:10,165 --> 00:00:14,140
Si en vez de realizar la codificación
de un solo 1 de la combinación

5
00:00:14,140 --> 00:00:18,835
y usarla como está,
¿la pasamos por una capa densa?

6
00:00:19,365 --> 00:00:23,270
Podríamos entrenar el modelo
para predecir el tráfico como antes.

7
00:00:23,830 --> 00:00:28,360
Esta capa densa, representada
por los nodos amarillos y verdes

8
00:00:28,360 --> 00:00:32,189
crea lo que se conoce
como una "incorporación".

9
00:00:34,419 --> 00:00:38,600
Los cuadros grises y azules
indican ceros y unos

10
00:00:38,600 --> 00:00:41,220
para cualquier fila
en el conjunto de datos de entrada

11
00:00:41,220 --> 00:00:43,590
para cualquier ejemplo de entrenamiento

12
00:00:43,590 --> 00:00:46,230
solo una de las casillas está destacada

13
00:00:46,230 --> 00:00:50,205
y la que se muestra en azul es uno.

14
00:00:50,205 --> 00:00:54,495
Las casillas grises
en ese ejemplo son ceros.

15
00:00:54,495 --> 00:00:59,040
Un ejemplo de entrenamiento diferente
corresponderá a una hora diferente del día

16
00:00:59,040 --> 00:01:01,800
por lo que destacará una casilla diferente

17
00:01:01,800 --> 00:01:05,985
y esa casilla será uno
y las otras serán ceros.

18
00:01:06,665 --> 00:01:10,100
Sin embargo, las casillas amarillas
y las verdes son diferentes

19
00:01:10,100 --> 00:01:12,290
no tienen codificación de un solo 1

20
00:01:12,290 --> 00:01:16,270
son números con valores reales,
valores de punto flotante.

21
00:01:16,270 --> 00:01:19,755
¿Por qué? Porque son una suma
ponderada de los valores

22
00:01:19,755 --> 00:01:21,995
de la combinación de atributos.

23
00:01:21,995 --> 00:01:25,965
¿Qué ocurre en los nodos
amarillos y verdes?

24
00:01:26,475 --> 00:01:29,300
Lo que debemos entender es que los pesos

25
00:01:29,300 --> 00:01:32,850
que van a la capa de incorporación

26
00:01:32,850 --> 00:01:38,055
que van a los nodos amarillos y verdes,
se aprenden de los datos.

27
00:01:38,685 --> 00:01:42,665
Imaginen que tenemos
muchas observaciones de tráfico.

28
00:01:43,395 --> 00:01:46,650
Tal vez cada que un automóvil
o una bicicleta o un camión

29
00:01:46,650 --> 00:01:51,055
pasan por una señal en particular,
tenemos una observación de tráfico.

30
00:01:51,055 --> 00:01:55,735
Entonces, tenemos los datos 
de todas las señales de una ciudad entera

31
00:01:55,735 --> 00:01:57,785
millones de ejemplos de entrenamiento.

32
00:01:58,195 --> 00:02:01,960
Un momento. ¿Escuché bien?

33
00:02:01,960 --> 00:02:05,475
¿Que mi conjunto de datos
consiste en observaciones de tráfico?

34
00:02:05,475 --> 00:02:10,539
¿Un ejemplo de entrenamiento
por cada vehículo que pasa por una señal?

35
00:02:10,539 --> 00:02:15,110
Si recién comienzan con el AA,
les puedo asegurar que pensaron

36
00:02:15,110 --> 00:02:17,770
que nuestro conjunto de datos
de entrenamiento consistía

37
00:02:17,770 --> 00:02:20,470
en datos agregados de tráfico

38
00:02:20,470 --> 00:02:25,385
tal vez la cantidad total de vehículos
en ruta a cada hora de cada día.

39
00:02:25,905 --> 00:02:30,140
Pero ese es un conjunto de datos pequeño,
es un problema para jugar.

40
00:02:30,140 --> 00:02:33,885
Si usan eso, solo aprenderá promedios

41
00:02:33,885 --> 00:02:36,700
y eso no es interesante

42
00:02:36,700 --> 00:02:40,265
y solo sirve para escribir artículos
de noticias que digan

43
00:02:40,265 --> 00:02:43,520
"los modelos predicen que los niveles
de tráfico aumentarán en un 10%

44
00:02:43,520 --> 00:02:44,885
el próximo año".

45
00:02:44,885 --> 00:02:46,700
Pero recuerden lo que dijimos

46
00:02:46,700 --> 00:02:50,960
que el aprendizaje automático
es una forma de aprender

47
00:02:50,960 --> 00:02:55,510
para realizar predicciones detalladas
y obtener estadísticas

48
00:02:55,510 --> 00:02:58,240
más allá de promedios únicamente.

49
00:02:58,240 --> 00:03:01,735
Eso es lo que significa en la práctica.

50
00:03:01,735 --> 00:03:07,155
En vez de usar unos cuantos cientos
de filas de un conjunto de datos agregado

51
00:03:07,155 --> 00:03:11,250
tenemos observaciones muy detalladas

52
00:03:11,250 --> 00:03:16,375
de autos en cada señal
y ese es el conjunto de datos

53
00:03:16,375 --> 00:03:17,695
de tráfico que usaremos.

54
00:03:17,695 --> 00:03:19,630
Nuestras predicciones serán

55
00:03:19,630 --> 00:03:21,660
cantidad de autos, de camiones

56
00:03:21,660 --> 00:03:24,980
de bicicletas, a cualquier hora

57
00:03:24,980 --> 00:03:27,435
en cualquier punto de la ciudad.

58
00:03:27,435 --> 00:03:32,545
El aprendizaje automático
se trata de las predicciones detalladas.

59
00:03:33,515 --> 00:03:35,320
Regresemos a nuestra lección.

60
00:03:37,100 --> 00:03:39,700
Tenemos observaciones de vehículos.

61
00:03:39,700 --> 00:03:42,915
Es posible que el conjunto de datos
incluya el tipo de vehículo

62
00:03:42,915 --> 00:03:46,340
es decir, auto,
bicicleta, bus, camión, etcétera.

63
00:03:46,340 --> 00:03:50,190
La dirección del viaje,
la ubicación, etcétera.

64
00:03:50,190 --> 00:03:53,405
Ese conjunto de datos
incluye una marca de tiempo

65
00:03:53,405 --> 00:03:57,285
de la que extraemos el día y la hora

66
00:03:57,285 --> 00:04:00,280
y luego realizamos la combinación
de atributos para obtener x3

67
00:04:00,280 --> 00:04:01,610
en el diagrama.

68
00:04:02,180 --> 00:04:07,785
Como dijimos, x3
está codificado como un solo 1

69
00:04:07,785 --> 00:04:10,675
en una cantidad de segmentos hash.

70
00:04:11,355 --> 00:04:15,270
Ahora, pasamos esto por una capa densa

71
00:04:15,270 --> 00:04:20,183
en la que los pesos están entrenados
para predecir ciertos datos del tráfico

72
00:04:20,943 --> 00:04:26,205
tal vez la hora a la que el próximo
vehículo llegará a la intersección

73
00:04:26,205 --> 00:04:29,340
para controlar la duración
de la señal de tráfico.

74
00:04:29,960 --> 00:04:35,130
El punto es que, cuando se entrenan
estos pesos con este conjunto de datos

75
00:04:35,130 --> 00:04:37,320
algo genial ocurre.

76
00:04:37,950 --> 00:04:42,855
La combinación de atributos
del día y la hora tiene 168 valores únicos

77
00:04:43,505 --> 00:04:49,420
pero estamos forzando su representación
con solo dos números de valor real.

78
00:04:49,980 --> 00:04:54,690
Entonces, el modelo aprende
cómo incorporar la combinación

79
00:04:54,690 --> 00:04:57,830
de atributos
en un espacio dimensional inferior.

80
00:04:58,810 --> 00:05:05,395
Tal vez la casilla verde captura
el tráfico de peatones y bicicletas

81
00:05:05,395 --> 00:05:09,660
mientras que la amarilla
captura el de automóviles.

82
00:05:09,660 --> 00:05:13,840
Entonces, las 8 a.m. del martes
y las 9 a.m. del miércoles

83
00:05:13,840 --> 00:05:17,010
es posible que correspondan
a casillas totalmente diferentes

84
00:05:17,010 --> 00:05:19,010
en la combinación de atributos.

85
00:05:19,010 --> 00:05:21,370
Sin embargo, si los patrones de tráfico

86
00:05:21,370 --> 00:05:25,320
en la mayoría de las intersecciones
en la ciudad son similares

87
00:05:25,320 --> 00:05:29,510
a esas dos horas,
la representación de valor real

88
00:05:29,510 --> 00:05:34,645
de estas dos combinaciones de día y hora
terminarán siendo bastante similares.

89
00:05:35,435 --> 00:05:38,410
Tal vez hay muchas personas
que manejan bicicleta y caminan

90
00:05:38,410 --> 00:05:42,160
a esas horas y también muchos autos.

91
00:05:42,160 --> 00:05:47,450
Los pesos para las 8 a.m. y las 9 a.m.
se ajustarán de manera que los números

92
00:05:47,450 --> 00:05:52,195
de valor real en verde y amarillo
serán bastante similares a esa hora.

93
00:05:52,755 --> 00:05:55,015
Pero a las 11 a.m. del martes

94
00:05:55,015 --> 00:05:57,350
y a las 2 p.m. del miércoles

95
00:05:57,350 --> 00:06:02,880
no hay tantos peatones, pero aún hay
una cantidad moderada de autos.

96
00:06:02,880 --> 00:06:05,985
Vemos que los números son cercanos.

97
00:06:05,985 --> 00:06:09,925
De la misma forma, las 2 a.m. el martes
y las 3 a.m. el miércoles

98
00:06:09,925 --> 00:06:13,335
podrían terminar con números
muy similares que reflejen la ausencia

99
00:06:13,335 --> 00:06:15,075
de tráfico.

100
00:06:15,075 --> 00:06:16,350
La clave es que

101
00:06:16,350 --> 00:06:20,469
las combinaciones de día y hora
similares, en términos de tráfico

102
00:06:20,469 --> 00:06:21,839
tienden a ser similares

103
00:06:21,839 --> 00:06:25,290
y las combinaciones de día y hora
que tienen diferentes condiciones

104
00:06:25,290 --> 00:06:29,810
de tráfico, tienden a alejarse bastante
en el espacio de dos dimensiones.

105
00:06:29,810 --> 00:06:33,495
Esto es lo que queremos decir
cuando señalamos que el modelo

106
00:06:33,495 --> 00:06:36,550
aprende a incorporar
la combinación de atributos

107
00:06:36,550 --> 00:06:39,220
en un espacio dimensional inferior.

108
00:06:40,080 --> 00:06:43,310
¿Cómo se implementa esto en TensorFlow?

109
00:06:44,070 --> 00:06:46,325
Para crear una incorporación

110
00:06:46,325 --> 00:06:50,920
usamos el método embedding_column
en tf.feature_column.

111
00:06:51,380 --> 00:06:55,445
Pasamos la columna categórica
que deseamos incorporar

112
00:06:55,445 --> 00:06:58,135
aquí estamos pasando
la combinación de atributos

113
00:06:58,135 --> 00:07:02,480
y, luego, especificamos la cantidad
de dimensiones de incorporación

114
00:07:03,070 --> 00:07:04,455
y eso es todo.

115
00:07:04,935 --> 00:07:08,475
Para ser una idea tan poderosa,
es muy sencilla.

116
00:07:09,905 --> 00:07:12,140
¿Por qué digo que es una idea poderosa?

117
00:07:13,330 --> 00:07:18,510
Lo genial de las incorporaciones
es que la que se aprendió para un problema

118
00:07:19,140 --> 00:07:23,830
a menudo se puede aplicar
a otros modelos de AA similares.

119
00:07:24,330 --> 00:07:26,549
Tal vez aprendieron cómo representar

120
00:07:26,549 --> 00:07:30,010
combinaciones de día y hora
según un conjunto datos

121
00:07:30,010 --> 00:07:32,730
de tráfico detallado de Londres.

122
00:07:32,730 --> 00:07:35,070
Y ahora deben colocar señales de tráfico

123
00:07:35,070 --> 00:07:39,515
en Fráncfort, pero no recolectaron
esos datos para esta ciudad.

124
00:07:39,515 --> 00:07:41,440
Un atajo rápido

125
00:07:41,440 --> 00:07:44,315
sería usar el aprendizaje
de la incorporación de Londres

126
00:07:44,315 --> 00:07:45,845
en Fráncfort.

127
00:07:46,410 --> 00:07:50,020
Después de todo,
solo desean presentar combinaciones

128
00:07:50,020 --> 00:07:52,500
de día y hora de manera adecuada

129
00:07:52,500 --> 00:07:55,530
y la incorporación entrenada
con datos para Londres

130
00:07:55,530 --> 00:07:58,785
será mejor que discretizar los datos
mediante heurística

131
00:07:58,785 --> 00:08:01,675
como temprano en la mañana o la hora pico.

132
00:08:01,675 --> 00:08:03,090
¿Cómo lo hacemos?

133
00:08:03,090 --> 00:08:06,925
Simplemente, la cargamos
desde el modelo guardado para Londres

134
00:08:06,925 --> 00:08:11,100
y le decimos al modelo
que no entrene esta capa.

135
00:08:11,820 --> 00:08:15,745
También podrían cargar
la incorporación de Londres

136
00:08:15,745 --> 00:08:19,330
y usarla como punto de partida
para Fráncfort.

137
00:08:19,330 --> 00:08:21,355
Si quieren hacer eso

138
00:08:21,355 --> 00:08:25,570
deberán configurar trainable=true
en la capa.

139
00:08:26,490 --> 00:08:30,805
Las incorporaciones
son un concepto muy poderoso

140
00:08:30,805 --> 00:08:35,554
y transferir su aprendizaje
las hace aún más poderosas.

141
00:08:35,554 --> 00:08:39,755
Son especialmente útiles
cuando se tienen columnas muy dispersas.

142
00:08:39,755 --> 00:08:42,534
En las combinaciones de día y hora
para las que teníamos

143
00:08:42,534 --> 00:08:44,404
168 combinaciones únicas

144
00:08:44,404 --> 00:08:45,845
no es tan importante

145
00:08:45,845 --> 00:08:49,895
pero veremos mucho las incorporaciones
cuando veamos modelos de lenguaje.

146
00:08:50,445 --> 00:08:53,945
En ellos, podrían tener
100,000 palabras únicas

147
00:08:53,945 --> 00:08:57,145
y desean incorporarlas y representarlas

148
00:08:57,145 --> 00:09:01,325
en un espacio dimensional inferior
de tal vez 30 o 50 dimensiones.

149
00:09:01,975 --> 00:09:06,680
Las combinaciones de atributos
y las incorporaciones son muy útiles

150
00:09:06,680 --> 00:09:09,770
en los modelos de AA del mundo real.

151
00:09:09,770 --> 00:09:13,397
Entonces, si lo necesitan,
vuelvan a revisar estas dos lecciones

152
00:09:13,397 --> 00:09:14,927
antes de continuar.