Nous venons de voir
comment l'extraction de caractéristiques peut améliorer les performances
de vos modèles de machine learning. Nous avons appris à convertir 
des données brutes en caractéristiques, à réaliser un prétraitement des données
qui s'effectue aussi pendant la diffusion, à choisir parmi les colonnes
de caractéristiques de TensorFlow, à mémoriser de vastes ensembles de données avec des croisements de caractéristiques
et des modèles simples, et à simplifier
des pipelines de prétraitement avec TensorFlow Transform. Nous avons commencé par définir
l'extraction de caractéristiques comme nécessaire, car nos données brutes
ne seront pas toutes sous forme numérique. Il nous faudra créer des caractéristiques
à partir de données brutes de toute façon, alors faisons-le en améliorant 
le modèle de machine learning‮‭.‭ Nous avons aussi vu les actions 
effectuées lors du prétraitement, du filtrage de données 
au vocabulaire informatique en passant par
le redimensionnement d'image et la normalisation des niveaux de volume. Nous avons déterminé 
où effectuer ces actions et conclu qu'Apache Beam 
était idéal pour l'ensemble des actions. Nous avons vu le fonctionnement de Beam,
exécuté des pipelines sur Cloud Dataflow, créé des caractéristiques à partir 
de données brutes de deux façons. Les croisements de caractéristiques 
et les colonnes d'intégration ont été vus, puis nous avons appris à équilibrer 
la mémorisation et la généralisation. Enfin, nous vous avons montré comment
implémenter des méthodes de prétraitement avec TensorFlow Transform pour des ensembles de données prétraités 
créés de manière équilibrée avec Beam, mais aussi calculés efficacement 
avec le modèle graphique dans TensorFlow. C'est la fin du quatrième
cours de cette spécialisation. Dans le premier cours, nous avons parlé de Google SML, de ce que cela signifie
d'être axé sur l'IA et de comment formuler un problème de ML. Dans le deuxième cours, nous avons créé des ensembles de données
et optimisé des modèles de ML. Dans le troisième cours,
nous écrirons des modèles TensorFlow en utilisant l'API Estimator. Dans le cours que nous venons de terminer, nous avons appris à améliorer ces modèles avec l'extraction de caractéristiques. Le prochain cours traitera de l'art
et de la science du machine learning et présentera des astuces concernant
les performances des modèles de ML. Assistez à la prochaine spécialisation 
sur les sujets liés au machine learning. Il sera question 
du machine learning à grande échelle et des modèles de machine learning
spécialisés pour les images, séquenceurs et recommandations.
À bientôt.