1
00:00:00,220 --> 00:00:03,090
En este curso,
analizamos la ingeniería de funciones

2
00:00:03,250 --> 00:00:06,980
como forma de mejorar el rendimiento
de sus modelos de AA.

3
00:00:07,800 --> 00:00:12,795
Aprendió también a convertir datos
sin procesar en funciones

4
00:00:13,785 --> 00:00:19,410
preprocesar los datos
de modo que se realice durante la entrega

5
00:00:20,400 --> 00:00:23,870
a escoger entre varias columnas
de funciones en TensorFlow

6
00:00:24,750 --> 00:00:27,590
a memorizar conjuntos de datos grandes

7
00:00:27,660 --> 00:00:30,310
mediante combinaciones
de funciones y modelos simples.

8
00:00:31,530 --> 00:00:32,582
Por último

9
00:00:32,812 --> 00:00:35,525
aprendió a simplificar
el preprocesamiento de canalizaciones

10
00:00:35,855 --> 00:00:37,755
mediante transformaciones de TensorFlow.

11
00:00:39,180 --> 00:00:43,850
Comenzamos hablando sobre la importancia
de la ingeniería de funciones

12
00:00:44,260 --> 00:00:47,590
ya que no todos los datos sin procesar
son numéricos.

13
00:00:48,110 --> 00:00:51,520
Debemos crear funciones
con esos datos de todos modos.

14
00:00:52,030 --> 00:00:57,280
¿Por qué no hacerlos de tal manera
que el modelo de AA aprenda mejor?

15
00:00:58,270 --> 00:01:02,740
Luego, hablamos de las tareas
que se realizan en el preprocesamiento.

16
00:01:03,280 --> 00:01:07,580
Operaciones como filtración de datos
o procesamiento de vocabularios

17
00:01:07,970 --> 00:01:12,140
ajuste de tamaño de imágenes
y normalización del volumen.

18
00:01:13,100 --> 00:01:17,930
Consideramos también
dónde realizar estas operaciones

19
00:01:18,420 --> 00:01:24,380
y aprendimos que Apache Beam es ideal
porque permite realizar todas las tareas.

20
00:01:25,040 --> 00:01:29,715
Aprendimos cómo funciona Beam
y a ejecutar canalizaciones

21
00:01:29,955 --> 00:01:31,180
en Cloud Dataflow.

22
00:01:32,330 --> 00:01:37,330
Analizamos dos formas interesantes
de crear funciones nuevas

23
00:01:37,570 --> 00:01:39,030
con los datos sin procesar.

24
00:01:39,600 --> 00:01:43,520
Vimos las combinaciones de funciones
y las columnas de incorporación

25
00:01:43,880 --> 00:01:46,410
y hablamos sobre
la forma en que podemos compensar

26
00:01:46,570 --> 00:01:50,910
la memorización por un lado
y generalización por el otro.

27
00:01:51,820 --> 00:01:54,305
Por último,
combinamos todo lo aprendido

28
00:01:54,625 --> 00:01:58,630
mediante la implementación
de métodos de preprocesamiento

29
00:01:58,900 --> 00:02:01,220
con transformaciones de TensorFlow

30
00:02:01,320 --> 00:02:05,340
de modo que se creen
conjuntos de datos preprocesados

31
00:02:05,570 --> 00:02:07,790
de forma distribuida mediante Beam

32
00:02:08,280 --> 00:02:10,810
pero también procesados eficientemente

33
00:02:10,920 --> 00:02:14,330
como parte del gráfico modelo
mediante TensorFlow.

34
00:02:15,230 --> 00:02:21,270
Así llegamos al final
del cuarto curso en esta especialización.

35
00:02:22,010 --> 00:02:25,705
En el primer curso,
hablamos sobre Google SML

36
00:02:26,005 --> 00:02:30,660
qué significa priorizar la IA
y cómo definir un problema de AA.

37
00:02:31,360 --> 00:02:35,800
En el segundo curso,
aprendió a crear conjuntos de datos

38
00:02:36,030 --> 00:02:39,212
y cómo funciona la optimización
de modelos de AA.

39
00:02:40,072 --> 00:02:45,215
En el tercer curso,
comenzó a escribir modelos de TensorFlow

40
00:02:45,475 --> 00:02:47,540
con la API de Estimator.

41
00:02:47,950 --> 00:02:52,190
En este curso,
aprendió a mejorar esos modelos

42
00:02:52,540 --> 00:02:54,270
con la ingeniería de funciones.

43
00:02:55,140 --> 00:02:57,125
Únase al siguiente curso

44
00:02:57,935 --> 00:03:01,370
sobre el arte y la ciencia
del aprendizaje automático.

45
00:03:01,720 --> 00:03:05,520
Veremos sugerencias prácticas
para obtener el máximo rendimiento

46
00:03:05,520 --> 00:03:07,510
de sus modelos de aprendizaje automático.

47
00:03:08,590 --> 00:03:15,340
Participe en la siguiente especialización
sobre temas avanzados de AA

48
00:03:15,790 --> 00:03:18,410
como aprendizaje automático
a gran escala

49
00:03:18,940 --> 00:03:22,920
y modelos de aprendizaje automático
especializados para imágenes

50
00:03:23,070 --> 00:03:25,800
secuenciadores y recomendaciones.

51
00:03:26,830 --> 00:03:28,000
Nos vemos pronto.