1
00:00:00,000 --> 00:00:03,240
In diesem Kurs haben wir uns
mit Feature Engineering beschäftigt,

2
00:00:03,240 --> 00:00:07,500
um die Leistung Ihrer Modelle
für maschinelles Lernen zu verbessern.

3
00:00:07,500 --> 00:00:13,315
In diesem Kurs haben Sie gelernt,
Rohdaten in Merkmale zu konvertieren,

4
00:00:13,315 --> 00:00:15,970
Daten so vorzubereiten,

5
00:00:15,970 --> 00:00:20,070
dass die Vorbereitung
auch bei der Bereitstellung erfolgt,

6
00:00:20,070 --> 00:00:24,390
die verschiedenen 
Merkmalspalten in TensorFlow auszuwählen,

7
00:00:24,390 --> 00:00:30,930
große Datasets über Merkmalkreuzungen
und einfache Modellen zu memorieren

8
00:00:30,930 --> 00:00:37,565
und schließlich Vorbereitungspipelines
mit TensorFlow Transform zu vereinfachen.

9
00:00:37,565 --> 00:00:43,860
Zu Beginn haben wir festgehalten,
dass Feature Engineering notwendig ist,

10
00:00:43,860 --> 00:00:47,730
weil nicht immer alle
Rohdaten numerisch sind.

11
00:00:47,730 --> 00:00:51,890
Wir werden ohnehin Merkmale
aus Rohdaten erstellen müssen.

12
00:00:51,890 --> 00:00:57,750
Warum also nicht so, dass das 
Modell für maschinelles Lernen besser wird?

13
00:00:57,750 --> 00:01:03,070
Wir haben dann betrachtet,
was Sie bei der Vorbereitung tun,

14
00:01:03,070 --> 00:01:07,580
angefangen beim Filtern der Daten
und dem Berechnen von Vokabular

15
00:01:07,580 --> 00:01:12,540
bis hin zur Größenänderung von Bildern
und Normalisierung des Lautstärkeniveaus.

16
00:01:12,540 --> 00:01:18,660
Wir haben dann betrachtet, womit wir
diese Vorgänge durchführen können,

17
00:01:18,660 --> 00:01:24,660
und Apache Beam als ideal ermittelt,
weil damit alles möglich ist.

18
00:01:24,660 --> 00:01:27,050
Wir haben gelernt, wie Beam funktioniert

19
00:01:27,050 --> 00:01:31,600
und wie wir Beam-Pipelines
in Cloud Dataflow ausführen.

20
00:01:31,600 --> 00:01:39,150
Wir haben zwei Wege zum Erstellen
neuer Merkmale aus Rohdaten betrachtet.

21
00:01:39,150 --> 00:01:43,800
Wir haben Merkmalkreuzungen
und Einbettungsspalten betrachtet

22
00:01:43,800 --> 00:01:51,900
und besprochen, wie wir Memorieren
gegenüber Generalisieren abwägen.

23
00:01:51,900 --> 00:01:57,050
Schließlich haben wir alles
zusammengeführt und gezeigt,

24
00:01:57,050 --> 00:02:02,790
wie Sie Vorbereitungsmethoden mit
TensorFlow Transform so implementieren,

25
00:02:02,790 --> 00:02:07,965
dass die vorbereiteten Datasets
mit Beam verteilt erstellt werden,

26
00:02:07,965 --> 00:02:14,780
aber auch als Teil des Modellgraphen in
TensorFlow effizient berechnet werden.

27
00:02:14,780 --> 00:02:21,660
Damit sind wir am Ende des vierten
Kurses dieser Spezialisierung angelangt.

28
00:02:21,660 --> 00:02:28,270
Im ersten Kurs wurde erklärt, wie Google
ML einsetzt, was "AI first" bedeutet

29
00:02:28,270 --> 00:02:31,390
und wie man ein Problem
für maschinelles Lernen formuliert.

30
00:02:31,390 --> 00:02:35,880
Im zweiten Kurs haben Sie gelernt,
wie Sie Datasets erstellen

31
00:02:35,880 --> 00:02:39,705
und Modelle
für maschinelles Lernen optimieren.

32
00:02:39,705 --> 00:02:41,730
Im dritten Kurs

33
00:02:41,730 --> 00:02:47,650
haben Sie erste TensorFlow-Modelle
mit der Estimator API geschrieben.

34
00:02:47,650 --> 00:02:50,140
In diesem Kurs haben Sie gelernt,

35
00:02:50,140 --> 00:02:54,600
wie Sie diese Modelle mithilfe
von Feature Engineering verbessern können.

36
00:02:54,600 --> 00:02:58,140
Nehmen Sie auch am nächsten Kurs teil,

37
00:02:58,140 --> 00:03:01,590
in dem wir Kunst und Wissenschaft
des maschinellen Lernens behandeln

38
00:03:01,590 --> 00:03:08,010
und Praxistipps für eine höhere Leistung
Ihrer ML-Modelle besprechen.

39
00:03:08,010 --> 00:03:12,730
Nehmen Sie auch
an der nächsten Spezialisierung teil

40
00:03:12,730 --> 00:03:15,990
mit fortgeschrittenen Themen
rund ums maschinelle Lernen.

41
00:03:15,990 --> 00:03:18,685
Dabei geht es um
maschinelles Lernen im großen Maßstab

42
00:03:18,685 --> 00:03:22,850
und um spezialisierte
Modelle für maschinelles Lernen für Bilder,

43
00:03:22,850 --> 00:03:27,083
Sequenzer und Empfehlungen.

44
00:03:27,083 --> 00:03:28,623
Bis demnächst.