Nachdem wir 
die Wahrheitsmatrix eingerichtet haben, können wir alle möglichen Messwerte zur Evaluierung berechnen, an denen wir sehen, in welchen Bereichen
das System inklusiver sein sollte. Dabei konzentrieren wir uns
besonders auf den Anteil falscher Positive und den Anteil falscher Negative. So erkennen wir, 
wie stark eine Teilgruppe beeinträchtigt ist. Wir können Kennzahlen wie den Anteil
richtiger Positive, die Empfindlichkeit oder die Trefferquote berechnen,
zum Beispiel wie oft das Modell in einem Bild
ein Gesicht vorhersagt, wenn das Label ebenfalls
ein Gesicht im Bild angibt. Für die Trefferquote braucht
man nur die entsprechenden Werte für richtige Positive
und falsche Negative. Ein weiteres Beispiel dafür,
was man aus einer Wahrheitsmatrix berechnen kann, ist die Genauigkeit. Sie gibt an, zu welchem Anteil
das Modell die Label richtig vorhersagt. Darin enthalten sind positive Label,
etwa wenn das Bild ein Gesicht zeigt und das Modell
das positive Label vorhersagt. Ebenso negative Label,
wenn das Bild kein Gesicht zeigt und das Modell das
negative Label vorhersagt. Für diese Berechnung braucht man
also nur die entsprechenden Werte für richtige und falsche Positive. Anteil falscher Positive bzw. Negative, Anteil richtiger Positive,
Genauigkeit oder Trefferquote. Es gibt viele Messwerte. Wie wählen wir die Messwerte aus, mit denen wir unser maschinelles
Lernsystem inklusiver gestalten können? Es kommt darauf an. Es hängt von den falsch positiven
und falsch negativen Werten ab. Je nach dem Verhältnis zwischen
beiden soll das maschinelle Lernmodell etwa eine geringe Trefferquote haben
(ihm würde also viel entgehen), dafür aber hohe Genauigkeit. Die wenigen
gefundenen Fälle sind alle korrekt. Nehmen Sie folgendes Beispiel:
Ein Maschinenlernmodell soll entscheiden, ob ein Bild zwecks
Datenschutz verpixelt werden muss. Ein falsches Positiv bedeutet, dass etwas, das nicht verpixelt werden muss, doch verpixelt wird,
weil das Modell es vorhersagt. Das kann ärgerlich sein. Bei einem falschen Negativ wird
etwas, das verpixelt werden muss, nicht verpixelt, weil das
Modell es nicht vorhersagt. So etwas könnte 
zu Identitätsdiebstahl führen, da die Privatsphäre
des Betroffenen entblößt werden könnte. In diesem Beispiel
möchte man also möglichst wenig falsche Negative haben. Ihre Messwerte
sollten also einen geringen Anteil falscher Negative anzeigen. Umgekehrt gibt es Situationen,
in denen es besser wäre, falsche Negative in Kauf zu nehmen als falsche Positive. Nehmen wir an, Sie arbeiten
an einem Spamfilter-Modell. Ein falsches Negativ bedeutet,
dass Spam vom Modell nicht erkannt wird. Es landet also im Posteingang und das kann lästig sein. Aber was geschieht bei
einem falschen Positiv? In diesem Fall könnte die
die Nachricht eines Freundes oder geliebten Menschen
als Spam markiert und entfernt werden. Das kann ein großer Verlust sein. In diesem Fall sollte man also den
Messwert für den Anteil falscher Positive ansehen und möglichst senken. Wenn Sie festgestellt haben, welche
Evaluierungsmesswerte Sie brauchen, gehen Sie einen Schritt weiter und berechnen diese Messwerte über die
verschiedenen Teilgruppen in Ihren Daten. Wie in dieser Grafik können Sie
die Verteilung Ihrer Evaluierungsmesswerte über eine Teilgruppe visualisieren.
Die blauen und grünen Verteilungen repräsentieren je
eine Teilgruppe innerhalb Ihrer Daten. Wenn das geklärt ist, muss man nur noch
entscheiden, welcher Wert akzeptabel ist, und diese Werte über
die Teilgruppen hinweg vergleichen. Zum Beispiel könnten Sie feststellen, dass ein Anteil von 0,1
bei falschen Negativen für das Problem, das durch maschinelles
Lernen gelöst werden soll, akzeptabel ist. Wie sieht bei diesem Gesamtanteil
der Anteil in Ihren Teilgruppen aus? Mit diesen Methoden finden Sie dann
Möglichkeiten, Ihr maschinelles Lernsystem inklusiver zu gestalten. Noch einmal zusammengefasst:
Evaluierungsmesswerte sind eine wichtige Messmethode für die Inklusivität
eines maschinellen Lernsystems. Man muss wissen, welche Kompromisse zwischen falschen Positiven und
falschen Negativen akzeptabel sind.