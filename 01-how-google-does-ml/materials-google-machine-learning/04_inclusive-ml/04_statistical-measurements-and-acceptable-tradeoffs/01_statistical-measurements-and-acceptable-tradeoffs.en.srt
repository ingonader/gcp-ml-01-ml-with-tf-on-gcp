1
00:00:00,000 --> 00:00:02,624
So now that we have this
confusion matrix set up,

2
00:00:02,624 --> 00:00:06,272
we can start to calculate all kinds
of evaluation metrics that could

3
00:00:06,272 --> 00:00:10,633
help us identify areas where a machine
learning system could be more inclusive.

4
00:00:10,633 --> 00:00:14,634
But with respect to making machine
learning more inclusive, we tend to really

5
00:00:14,634 --> 00:00:18,633
focus on the false positive rates as well
as the false negative rates in order to

6
00:00:18,633 --> 00:00:22,233
get a sense of how adversely affected
a subgroup might be performing.

7
00:00:22,233 --> 00:00:27,033
We can calculate things like the true
positive rate, sensitivity, or recall, for

8
00:00:27,033 --> 00:00:31,564
example, all of which represent the
proportion of times your model predicts,

9
00:00:31,564 --> 00:00:35,820
say, a face in an image when the label
itself also shows there being a face in

10
00:00:35,820 --> 00:00:36,523
the image.

11
00:00:36,523 --> 00:00:39,739
All you need here are the corresponding
true positives and

12
00:00:39,739 --> 00:00:42,900
false negative values in order
to calculate the recall.

13
00:00:42,900 --> 00:00:46,320
Another example of the sort of
calculations you can get from a confusion

14
00:00:46,320 --> 00:00:50,196
matrix are things like the precision,
which represents the proportion of times

15
00:00:50,196 --> 00:00:52,484
when the model predicts
the labels correctly.

16
00:00:52,484 --> 00:00:55,721
Factoring in when it's a positive label,
for example,

17
00:00:55,721 --> 00:00:59,982
when there is a face in the image and
the model predicts the positive label.

18
00:00:59,982 --> 00:01:03,568
As well as when it's a negative label,
when there isn't a face in the image,

19
00:01:03,568 --> 00:01:05,901
and the model predicts
it's the negative label.

20
00:01:05,901 --> 00:01:09,708
So in this calculation, all you need
are the corresponding true positives and

21
00:01:09,708 --> 00:01:11,272
false positive measurements.

22
00:01:11,272 --> 00:01:15,808
False positive rates, false negative
rates, true positive rates, precision,

23
00:01:15,808 --> 00:01:18,482
recall, these are a lot
of metrics to deal with.

24
00:01:18,482 --> 00:01:21,414
So how should we go about selecting
which metrics to focus on for

25
00:01:21,414 --> 00:01:24,694
the purposes of making your machine
learning system more inclusive?

26
00:01:24,694 --> 00:01:26,239
The answer to that depends.

27
00:01:26,239 --> 00:01:29,433
It depends on the outcomes of your
false positive and false negatives.

28
00:01:29,433 --> 00:01:33,309
Depending on the trade-offs between
the two, perhaps you may want your machine

29
00:01:33,309 --> 00:01:36,900
learning model to have low recall,
missing a lot of stuff, in exchange for

30
00:01:36,900 --> 00:01:41,063
high precision, or when the limited amount
of stuff the ML classified is all correct.

31
00:01:41,063 --> 00:01:44,538
Take this example of a machine learning
model that's determining whether or

32
00:01:44,538 --> 00:01:46,902
not an image should be
blurred to preserve privacy.

33
00:01:46,902 --> 00:01:50,563
A false positive would result in something
that doesn't need to be blurred but

34
00:01:50,563 --> 00:01:53,292
gets blurred because the model
predicted that it should.

35
00:01:53,292 --> 00:01:54,542
That can be a bummer.

36
00:01:54,542 --> 00:01:57,766
But a false negative is when something
needs to be blurred but is not,

37
00:01:57,766 --> 00:02:00,220
because the model doesn't
predict that it should.

38
00:02:00,220 --> 00:02:03,057
And something like that could
result in identity theft,

39
00:02:03,057 --> 00:02:06,555
because the privacy of the individual
in that image could be exposed.

40
00:02:06,555 --> 00:02:07,791
So in this example,

41
00:02:07,791 --> 00:02:11,591
you may want to minimize as much
false negatives as possible.

42
00:02:11,591 --> 00:02:15,883
So you would focus your metrics around
achieving a low false negative rate.

43
00:02:15,883 --> 00:02:18,770
On the flip side,
you might have situations where

44
00:02:18,770 --> 00:02:22,763
it may be better to encounter a false
negative over a false positive.

45
00:02:22,763 --> 00:02:25,482
Let's say you're working
on a SPAM filtering model.

46
00:02:25,482 --> 00:02:28,933
A false negative will result in a SPAM
message not getting caught by the model,

47
00:02:28,933 --> 00:02:31,720
so you end up seeing it in your inbox,
and that can be annoying.

48
00:02:31,720 --> 00:02:34,630
But what happens when you
encounter a false positive?

49
00:02:34,630 --> 00:02:37,622
The result is that potentially
a message from a friend or

50
00:02:37,622 --> 00:02:40,756
a loved one gets marked as SPAM and
remove from your inbox.

51
00:02:40,756 --> 00:02:42,852
And that can be a total loss.

52
00:02:42,852 --> 00:02:46,968
So in this case, perhaps the metric to
focus on here is reducing the false

53
00:02:46,968 --> 00:02:49,001
positive rate as much as possible.

54
00:02:49,001 --> 00:02:52,764
So once you figure out what the right
set of evaluation metrics to focus on,

55
00:02:52,764 --> 00:02:54,795
make sure that you go one step further and

56
00:02:54,795 --> 00:02:59,002
calculate those metrics in mind across
the different subgroups within your data.

57
00:02:59,002 --> 00:03:03,010
As shown in this plot, you can visualize
the distributions of your evaluation

58
00:03:03,010 --> 00:03:05,801
metrics across a subgroup,
as depicted by the blue and

59
00:03:05,801 --> 00:03:10,012
green distributions, each representing
a separate subgroup within your data.

60
00:03:10,012 --> 00:03:14,191
But once all of that is in place then it's
just a matter of finding the point that's

61
00:03:14,191 --> 00:03:17,722
an acceptable value and compare
those values across the sub groups.

62
00:03:17,722 --> 00:03:22,083
For example you may find that a false
negative rate at 0.1 is acceptable for

63
00:03:22,083 --> 00:03:26,194
the problem you're trying to solve
with your machine learning system.

64
00:03:26,194 --> 00:03:30,844
So now, given that overall rate, how does
that rate look across your sub groups?

65
00:03:30,844 --> 00:03:35,001
By incorporating these methodologies,
you're one step closer to identifying ways

66
00:03:35,001 --> 00:03:38,303
in which you can make your machine
learning system more inclusive.

67
00:03:38,303 --> 00:03:42,597
So, to reiterate, evaluation metrics
are some of the key things we can do to

68
00:03:42,597 --> 00:03:45,633
measure how inclusive
a machine learning system is.

69
00:03:45,633 --> 00:03:49,217
And it's important to do so in light of
the acceptable trade-offs between your

70
00:03:49,217 --> 00:03:51,207
false positives and your false negatives.