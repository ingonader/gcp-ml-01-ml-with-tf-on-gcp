Agora que configuramos
a matriz de confusão, podemos calcular
as métricas de avaliação para identificar
onde o sistema pode ser mais inclusivo. Quando tentamos tornar
o aprendizado de máquina mais inclusivo, focamos em taxas de falsos positivos
e de falsos negativos para entender como isso pode
prejudicar o desempenho de um subgrupo. Calculamos taxa de verdadeiros positivos,
sensibilidade ou retorno, que representam a proporção
de vezes em que seu modelo prevê, por exemplo, um rosto em uma imagem
quando o rótulo mostra que há um rosto na imagem. Você só precisa
dos valores de verdadeiros positivos e de falsos negativos correspondentes
para calcular o retorno. Outro exemplo de cálculo
que usa a matriz de confusão é a precisão,
que representa a proporção de vezes em que o modelo prevê
os rótulos corretamente. Isso é determinar que há
um rótulo positivo, por exemplo, quando há um rosto na imagem
e o modelo prevê o rótulo positivo. E também quando há um rótulo negativo
e não há um rosto na imagem, e o modelo prevê
que é um rótulo negativo. Nesse cálculo, você só precisa
das medidas de verdadeiros positivos e de falsos positivos correspondentes. Taxas de falsos positivos,
falsos negativos, verdadeiros positivos, precisão, retorno,
há muitas métricas para lidar. Como selecionar
em quais métricas focar para tornar o sistema
de aprendizado de máquina mais inclusivo? A resposta depende. Ela depende dos resultados
de falsos positivos e falsos negativos. Dependendo da proporção entre os dois,
você pode querer que seu modelo tenha um retorno baixo,
deixando passar várias coisas, em troca de alta precisão, com todo
o baixo volume classificado corretamente. Veja um exemplo de modelo
de aprendizado de máquina que determina se uma imagem deve ser borrada
por questão de privacidade. Um falso positivo resultaria em algo
que não precisa ser borrado mas é borrado porque o modelo prevê
que isso é necessário. Isso pode incomodar. Mas um falso negativo é quando
algo precisa ser borrado mas não é, porque o modelo não prevê
que deveria ser borrado. E algo assim pode resultar
em roubo de identidade, porque a privacidade da pessoa
na imagem pode ser exposta. Então, neste exemplo, pode ser melhor minimizar
falsos negativos. Por isso, você focaria sua métrica
em uma baixa taxa de falsos negativos. Por outro lado,
pode haver situações em que é melhor encontrar um falso negativo
do que um falso positivo. Digamos que você está trabalhando
em um modelo de filtro de spam. Um falso negativo resultaria
em um spam não ser pego pelo modelo, então o spam apareceria na sua caixa,
o que pode ser irritante. Mas o que acontece
quando há um falso positivo? O resultado é que possivelmente
a mensagem de um amigo ou cônjuge será marcada como spam
e removida da caixa de entrada, e isso pode ser uma perda total. Nesse caso, a métrica
em que você deve focar é minimizar
a taxa de falsos positivos. Depois que você definir
em qual métrica de avaliação focar, certifique-se de dar um passo além e calcular essa métrica
em diferentes subgrupos de dados. Como mostrado aqui, você pode ver
as distribuições da métrica de avaliação em um subgrupo,
conforme mostrado pelas distribuições de azul e verde, cada uma representando
um subgrupo de dados. Mas quando isso estiver definido,
é só descobrir um valor aceitável e comparar esse valor
com outros subgrupos. Por exemplo, uma taxa de 0,1
pode ser aceitável para falsos negativos para o problema que você
quer resolver com seu sistema. Então, tendo a taxa geral,
como ela funciona em outros subgrupos? Ao incorporar essas metodologias,
você está mais perto de identificar formas de tornar seu sistema
de aprendizado de máquina mais inclusivo. Para reforçar,
a métrica de avaliação é importante para medir se um sistema
de aprendizado de máquina é inclusivo. E é importante fazer isso
sabendo a proporção aceitável entre falsos positivos
e falsos negativos. Escolha as métricas de avaliação
sabendo a proporção aceitável entre falsos positivos
e falsos negativos.