1
00:00:00,000 --> 00:00:02,792
混同行列をセットアップできたら

2
00:00:02,792 --> 00:00:05,542
あらゆる種類の評価指標を計算して

3
00:00:05,542 --> 00:00:10,633
MLシステムのどの分野を
もっと包括的にできるか判別できます

4
00:00:10,633 --> 00:00:13,834
MLをもっと包括的にする目的で しばしば

5
00:00:13,834 --> 00:00:18,033
偽陽性FP率と偽陰性FN率に注目して

6
00:00:18,033 --> 00:00:22,233
あるサブグループに関する悪影響を把握します

7
00:00:22,233 --> 00:00:26,833
真陽性TP率、感度、検出率
などとの指標を計算しますが

8
00:00:26,833 --> 00:00:29,734
これらは 同じものを表します つまりたとえば

9
00:00:29,734 --> 00:00:32,694
「画像の中に顔があると」モデルが予測し

10
00:00:32,694 --> 00:00:36,473
ラベルも顔の存在を示している
回数の比率を表します

11
00:00:36,473 --> 00:00:38,400
検出率を計算するには

12
00:00:38,400 --> 00:00:42,120
対応する真陽性TPと
偽陰性FNの値だけが必要です

13
00:00:42,900 --> 00:00:46,920
混同行列から可能な別の計算は

14
00:00:46,920 --> 00:00:52,496
精度 つまりモデルがラベルを
正しく予測した回数の比率です

15
00:00:52,496 --> 00:00:54,631
該当するケースは たとえば

16
00:00:54,631 --> 00:00:57,222
陽性ラベルで 画像の中に顔があり

17
00:00:57,222 --> 00:00:59,862
モデルも陽性ラベルを予測した場合

18
00:00:59,862 --> 00:01:03,408
それに加えて 陰性ラベルで画像に顔はなく

19
00:01:03,408 --> 00:01:05,981
モデルも陰性ラベルを予測した場合です

20
00:01:05,981 --> 00:01:08,998
この計算で必要なのは対応する真陽性TPと

21
00:01:08,998 --> 00:01:11,272
偽陽性FPの測定値だけです

22
00:01:11,272 --> 00:01:15,808
偽陽性FP率、偽陰性FN率
真陽性TP率、精度、検出率など

23
00:01:15,808 --> 00:01:18,482
多くの指標を扱います

24
00:01:18,482 --> 00:01:21,414
それで 注目すべき指標をどのように選択すれば

25
00:01:21,414 --> 00:01:24,614
機械学習システムが
もっと包括的になりますか?

26
00:01:24,614 --> 00:01:26,239
それは 状況によります

27
00:01:26,239 --> 00:01:29,433
偽陽性FPと偽陰性FNの出力に応じて
異なります

28
00:01:29,433 --> 00:01:31,729
つまり 2つの間のトレードオフです

29
00:01:31,729 --> 00:01:35,220
検出率が低く
多くのものを検出しない代わりに

30
00:01:35,220 --> 00:01:39,163
高い精度 または回数は少ないが
すべて正しく分類するような

31
00:01:39,163 --> 00:01:41,083
MLモデルを望むかもしれません

32
00:01:41,083 --> 00:01:42,495
MLモデルで たとえば

33
00:01:42,495 --> 00:01:46,932
プライバシーを守るために
画像を「ぼかす」かどうか決定するとします

34
00:01:46,932 --> 00:01:50,603
偽陽性TPの場合
鮮明でよいものが不鮮明になります

35
00:01:50,603 --> 00:01:53,292
ぼかすべきだとモデルが予測するからです

36
00:01:53,292 --> 00:01:54,522
残念ですね

37
00:01:54,522 --> 00:01:57,646
偽陰性FNでは
不鮮明にすべきものが鮮明なままです

38
00:01:57,646 --> 00:02:00,280
ぼかすべきだとモデルが予測しないからです

39
00:02:00,280 --> 00:02:03,057
すると 画像のプライバシーが公にさらされ

40
00:02:03,057 --> 00:02:06,555
個人情報漏洩になる可能性があります

41
00:02:06,555 --> 00:02:11,581
このサンプルでは できるだけ
偽陰性FNを少なくすべきでしょう

42
00:02:11,591 --> 00:02:15,883
それで偽陰性FN率を低くするための
指標に注目します

43
00:02:15,883 --> 00:02:20,423
反対に 偽陽性FPよりも
偽陰性FNのほうがましだと

44
00:02:20,423 --> 00:02:22,763
考えられる状況もあるでしょう

45
00:02:22,763 --> 00:02:25,482
スパムフィルターモデルの場合を考えます

46
00:02:25,482 --> 00:02:29,003
偽陰性FNは スパムメッセージが
モデルで捕まらない場合です

47
00:02:29,003 --> 00:02:31,720
スパムが受信トレイに入るので煩わしいです

48
00:02:31,720 --> 00:02:34,630
偽陽性FPの場合はどうなりますか

49
00:02:34,630 --> 00:02:37,622
友だちや家族からのメッセージに

50
00:02:37,622 --> 00:02:40,756
スパムのマークが付き
受信トレイから削除されます

51
00:02:40,756 --> 00:02:42,852
大きな損失になり得ます

52
00:02:42,852 --> 00:02:44,711
それで この場合はおそらく

53
00:02:44,711 --> 00:02:49,001
偽陽性FP率をできるだけ下げる
指標に注目すべきです

54
00:02:49,001 --> 00:02:53,025
注目すべき評価指標セットがわかったら

55
00:02:53,025 --> 00:02:54,795
次の段階に進み

56
00:02:54,795 --> 00:02:59,002
データ内の様々なサブグループについて
その指標を計算します

57
00:02:59,002 --> 00:03:00,651
このグラフに示すように

58
00:03:00,651 --> 00:03:05,151
1つのサブグループ全体にわたる
評価指標の分散を可視化できます

59
00:03:05,151 --> 00:03:10,012
青と緑はそれぞれデータ内の
1つのサブグループを表します

60
00:03:10,012 --> 00:03:14,861
すべて準備できたら 次に
許容される値の地点を見つけ

61
00:03:14,861 --> 00:03:17,722
サブグループ間で値を比較します

62
00:03:17,722 --> 00:03:22,083
たとえば ある問題をMLシステムで
解決するとき

63
00:03:22,083 --> 00:03:26,194
偽陰性FN率0.1は許容されると
判断するかもしれません

64
00:03:26,194 --> 00:03:30,844
その率が決まったら サブグループ間で
その率はどう見えますか

65
00:03:30,844 --> 00:03:33,261
このような方法論を組み込むと

66
00:03:33,261 --> 00:03:38,303
機械学習システムをさらに包括的にする
方法に一歩近づきます

67
00:03:38,303 --> 00:03:42,887
繰り返すとMLシステムが
どれほど包括的であるかを測るために

68
00:03:42,887 --> 00:03:45,633
評価指標は重要な指標です

69
00:03:45,633 --> 00:03:49,207
その際に重要なのは
偽陽性FPと偽陰性FNの間で

70
00:03:49,207 --> 00:03:52,637
許容可能なトレードオフを考慮することです