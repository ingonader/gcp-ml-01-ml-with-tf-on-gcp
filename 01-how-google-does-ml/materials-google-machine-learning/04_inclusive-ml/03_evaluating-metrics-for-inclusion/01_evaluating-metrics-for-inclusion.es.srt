1
00:00:00,000 --> 00:00:03,480
Su sistema de aprendizaje
automático cometerá errores.

2
00:00:03,480 --> 00:00:06,720
Es importante saber cómo lucen
estos errores y cómo podrían afectar

3
00:00:06,720 --> 00:00:10,820
la experiencia del usuario generada
por el resultado de su modelo de AA.

4
00:00:10,820 --> 00:00:14,210
En este módulo, analizaremos
algunas de las formas en las que pueden

5
00:00:14,210 --> 00:00:18,110
evaluar la inclusión, a medida
que desarrollan y prueban su modelo de AA.

6
00:00:18,110 --> 00:00:20,010
Uno de los aspectos clave

7
00:00:20,010 --> 00:00:22,380
que los ayudará
a comprender la inclusión

8
00:00:22,380 --> 00:00:25,425
y cómo introducirla en los
diferentes subgrupos de sus datos

9
00:00:25,425 --> 00:00:27,820
es comprender la matriz de confusión.

10
00:00:27,820 --> 00:00:31,900
Probablemente saben bien cómo evaluar
su modelo en todo el conjunto de datos

11
00:00:31,900 --> 00:00:35,155
pero también es importante
que lo evalúen en subgrupos.

12
00:00:35,155 --> 00:00:39,855
Así que, en lugar de ver cómo
se desempeña en todo el conjunto de datos

13
00:00:39,855 --> 00:00:42,395
nos enfocaremos
en analizar el rendimiento

14
00:00:42,395 --> 00:00:45,230
en el subgrupo en el que desean
mejorar el rendimiento.

15
00:00:45,680 --> 00:00:48,805
Por ejemplo, supongamos
que trabajan en la detección de rostros.

16
00:00:48,805 --> 00:00:51,240
Básicamente, están creando un modelo de AA

17
00:00:51,240 --> 00:00:54,160
para que diga si hay o no
un rostro humano en una foto.

18
00:00:54,160 --> 00:00:56,265
Esto en sí no es un problema sencillo.

19
00:00:56,265 --> 00:00:58,680
Los subgrupos podrían ser hombres, mujeres

20
00:00:58,680 --> 00:01:01,165
adultos, niños, personas con cabello

21
00:01:01,165 --> 00:01:02,550
personas sin cabello.

22
00:01:02,550 --> 00:01:04,940
Es conveniente analizar
el rendimiento de su modelo

23
00:01:04,940 --> 00:01:07,965
en estos subgrupos para identificar
las áreas que deben mejorar.

24
00:01:07,965 --> 00:01:10,300
Así que, una forma común
de evaluar el rendimiento

25
00:01:10,300 --> 00:01:13,230
en el AA es usar una matriz de confusión.

26
00:01:13,230 --> 00:01:16,200
Hay otros métodos
para los diferentes tipos de problemas

27
00:01:16,200 --> 00:01:18,120
pero, a los fines de este módulo

28
00:01:18,120 --> 00:01:21,420
nos enfocaremos en la matriz
de confusión para explicar estos puntos.

29
00:01:21,420 --> 00:01:25,380
La idea es usar la matriz
de confusión para analizar la inclusión.

30
00:01:25,380 --> 00:01:28,005
Y pueden hacerlo
mediante la creación de esa matriz

31
00:01:28,005 --> 00:01:30,550
para cada subgrupo presente en sus datos

32
00:01:30,550 --> 00:01:33,360
en los que les interesa
medir el rendimiento.

33
00:01:33,360 --> 00:01:34,980
Ahora, en la matriz de confusión

34
00:01:34,980 --> 00:01:37,070
se tienen comparaciones
entre las etiquetas

35
00:01:37,070 --> 00:01:40,590
que pueden o no reflejar
su conjunto de etiquetas confiables

36
00:01:40,590 --> 00:01:43,395
ya que no necesariamente
tenemos acceso a ellas.

37
00:01:43,395 --> 00:01:47,530
Sin embargo, comparan esas etiquetas
con las predicciones del modelo.

38
00:01:47,530 --> 00:01:49,980
Desde aquí vemos los
aspectos positivos y negativos.

39
00:01:49,980 --> 00:01:53,034
En nuestras etiquetas
hay cosas consideradas correctas

40
00:01:53,034 --> 00:01:54,790
que llamaremos etiquetas positivas

41
00:01:54,790 --> 00:01:57,435
y otras que se consideran incorrectas

42
00:01:57,435 --> 00:01:59,295
que llamaremos etiquetas negativas.

43
00:01:59,295 --> 00:02:00,875
En el lado del AA

44
00:02:00,875 --> 00:02:03,900
tenemos predicciones
positivas sobre lo que hay

45
00:02:03,900 --> 00:02:07,140
y predicciones sobre lo
que no hay, llamadas negativas.

46
00:02:07,140 --> 00:02:09,750
Las comparamos
en la matriz de confusión para entender

47
00:02:09,750 --> 00:02:12,585
la decisión que infiere
el sistema de aprendizaje automático

48
00:02:12,585 --> 00:02:14,145
desde los verdaderos positivos

49
00:02:14,145 --> 00:02:17,625
que es cuando la etiqueta
dice que hay algo y el modelo lo predice.

50
00:02:17,625 --> 00:02:19,530
En el caso de la detección de rostros

51
00:02:19,530 --> 00:02:21,655
un verdadero positivo
sería cuando el modelo

52
00:02:21,655 --> 00:02:24,690
predice correctamente
que hay un rostro en la imagen.

53
00:02:24,690 --> 00:02:27,150
Ahora, cuando la etiqueta
dice que hay algo

54
00:02:27,150 --> 00:02:30,610
y el modelo no
lo predice, es un falso negativo.

55
00:02:30,610 --> 00:02:33,165
Así que, en el mismo ejemplo
de detección de rostros

56
00:02:33,165 --> 00:02:36,630
el modelo no predice
que hay un rostro en la imagen

57
00:02:36,630 --> 00:02:40,170
cuando la etiqueta sí lo sugiere.

58
00:02:40,170 --> 00:02:43,988
Cuando la etiqueta dice que no existe
y su modelo no lo predice

59
00:02:43,988 --> 00:02:46,005
se denomina como verdadero negativo.

60
00:02:46,005 --> 00:02:47,985
Básicamente, eso significa

61
00:02:47,985 --> 00:02:50,080
que en este
ejemplo de detección de rostros

62
00:02:50,080 --> 00:02:52,980
cuando el modelo
no predice que hay un rostro presente

63
00:02:52,980 --> 00:02:57,015
en la imagen es correcto,
porque tampoco está en la etiqueta.

64
00:02:57,725 --> 00:03:00,255
Y, finalmente,
este es el caso del falso positivo

65
00:03:00,255 --> 00:03:02,550
donde la etiqueta
dice que no hay un rostro

66
00:03:02,550 --> 00:03:05,725
pero el modelo de AA
predice que debería haber uno.

67
00:03:05,725 --> 00:03:07,140
En esta instancia

68
00:03:07,140 --> 00:03:09,780
tal vez hay una estatua en la imagen

69
00:03:09,780 --> 00:03:13,245
y el modelo identifica
erróneamente el rostro de la estatua.

70
00:03:13,245 --> 00:03:15,500
Pero en lo quiero que se enfoquen

71
00:03:15,500 --> 00:03:18,250
es en que hay falsos negativos
y falsos positivos.

72
00:03:18,250 --> 00:03:20,660
Recuerden, los falsos negativos
son los elementos

73
00:03:20,660 --> 00:03:22,650
que erróneamente no se predicen

74
00:03:22,650 --> 00:03:25,735
lo que se excluye
cuando se debería incluir.

75
00:03:25,735 --> 00:03:27,705
Y los falsos positivos son los elementos

76
00:03:27,705 --> 00:03:29,245
que se predicen incorrectamente

77
00:03:29,245 --> 00:03:32,220
lo que se incluye
y que en realidad no está en la etiqueta

78
00:03:32,220 --> 00:03:34,380
y que debió excluirse.

79
00:03:34,380 --> 00:03:38,865
Y se los suele llamar errores
de tipo 1 y tipo 2 en otros dominios.

80
00:03:38,865 --> 00:03:41,730
Pero lo genial de este tipo de desglose

81
00:03:41,730 --> 00:03:44,610
en cuatro tipos
de coincidencias de etiqueta

82
00:03:44,610 --> 00:03:47,435
es que pueden comenzar a calcular
muchas métricas diferentes

83
00:03:47,435 --> 00:03:50,520
para medir el nivel
de inclusión en su modelo.