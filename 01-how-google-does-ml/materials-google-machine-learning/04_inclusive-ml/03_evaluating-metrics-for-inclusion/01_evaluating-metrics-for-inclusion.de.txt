Ihre Systeme für maschinelles Lernen machen Fehler. Man muss wissen,
wie diese Fehler aussehen und wie sie sich
auf den Nutzer auswirken, der mit der Ausgabe
des Maschinenlernmodells konfrontiert wird. In diesem Modul geht
um Möglichkeiten, bei Entwicklung und Test des Maschinenlernmodells
die Inklusion zu bewerten. Eine Sache muss man wirklich kennen, wenn man Inklusion verstehen und bei verschiedenen Teilgruppen
innerhalb der Daten anwenden möchte: die Wahrheitsmatrix. Sie wissen vielleicht schon, wie man das
Modell über das ganze Dataset auswertet, aber es ist auch wichtig,
das Modell über Teilgruppen auszuwerten. Wir sehen uns also nicht nur an, wie sich
Ihr Modell über das ganze Dataset verhält, wir sehen auch bei der
Teilgruppe genauer hin, für die Sie die Leistung
verbessern möchten. Nehmen wir Gesichtserkennung als Beispiel. Ihr Maschinenlernmodell soll feststellen, ob ein Foto das
Gesicht eines Menschen zeigt. Das ist nicht unbedingt einfach. Ihre Teilgruppen können Männer, Frauen, Erwachsene, Kinder, Menschen mit Haaren oder mit Glatze sein. Sie sollten sich die Leistung Ihres Modells bei all diesen
Teilgruppen ansehen. Wir beurteilen 
die Leistung des maschinellen Lernens deshalb oft mithilfe
einer Wahrheitsmatrix. Es gibt andere Methoden
für andere Arten von Problemen, aber in diesem Modul möchten wir diese Punkte anhand der
Wahrheitsmatrix erklären. Wir wollen die Wahrheitsmatrix
einsetzen, um Inklusion zu untersuchen. Dazu erstellen wir
zuerst die Wahrheitsmatrix, und zwar für jede der
Teilgruppen in den Daten, für die wir die Leistung messen möchten. In der Wahrheitsmatrix geht es um Vergleiche zwischen den
Labels, die natürlich nicht unbedingt die zugrunde liegende
Wahrheit wiedergeben. Manchmal können wir diese
Wahrheit gar nicht kennen. Dennoch vergleichen Sie diese Label
mit den Vorhersagen Ihres Modells. Dann sehen wir uns die
Positive und Negative an. Das bedeutet, dass wir Dinge,
die wir als korrekt empfinden, als positive Label bezeichnen, und die Dinge, die wir
nicht als korrekt ansehen, als negative Label. Auf der Maschinenlern-Seite gibt es positive Vorhersagen, die aussagen, was da ist, und negative Vorhersagen,
die aussagen, was nicht da ist. Dies vergleichen wir
in der Wahrheitsmatrix, um Entscheidungen des
Maschinenlernsystems zu verstehen. Zuerst die richtigen Positive: Das Label sagt aus, etwas sei da, und das Modell sagt es vorher. Bei der Gesichtserkennung bedeutet das: Ein richtiges Positiv ist, wenn das Modell zutreffend vorhergesagt hat,
dass das Bild ein Gesicht zeigt. Wenn das Label aussagt, etwas sei da, und das Modell sagt es nicht vorher, ist das ein falsches Negativ. Im Beispiel der
Gesichtserkennung hieße das, das Modell sagt nicht voraus,
dass das Bild ein Gesicht zeigt, das Label sagt aber, es sei ein Gesicht. Wenn das Label aussagt, es sei keines,
und das Modell auch keines vorhersagt, nennen wir das ein richtiges Negativ. Das bedeutet in diesem
Gesichtserkennungsbeispiel einfach, dass das Modell mit
der Aussage richtig liegt, das Bild zeige kein Gesicht,
denn das Label sagt dasselbe. Dann gibt es noch den
Fall des falschen Positivs: Das Label sagt aus,
es sei kein Gesicht da, aber das Maschinenlernmodell sagt, dass ein Gesicht vorhanden sei. In diesem Beispiel könnte das Bild
eine Statue zeigen und das Modell erkennt diese Statue
fälschlicherweise als Gesicht. Sie sollten sich dabei vor allem auf die falschen Negative und
falschen Positive konzentrieren. Falsche Negative sind also Dinge, die
fälschlicherweise nicht erkannt werden, Dinge, die ausgeschlossen werden,
obwohl man sie einbeziehen müsste, und falsche Positive sind
fälschlicherweise vorhergesagte Dinge, Dinge, die einbezogen werden, aber im Label nicht vorhanden sind
und ausgeschlossen werden sollten. In anderen Bereichen werden diese als
Typ-I-Fehler und Typ-II-Fehler bezeichnet. Das Schöne an dieser
einfachen Gliederung in vier verschiedene
Label-Trefferkategorien ist, dass man damit
jede Menge Messwerte berechnen und mit diesen die Inklusivität
des Modells bestimmen kann.