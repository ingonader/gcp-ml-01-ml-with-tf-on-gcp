1
00:00:00,209 --> 00:00:02,050
Juguemos.

2
00:00:02,050 --> 00:00:05,221
Cierren sus ojos
y traten de imaginar un zapato.

3
00:00:05,221 --> 00:00:06,110
Muy bien.

4
00:00:06,110 --> 00:00:07,694
¿Alguien imaginó esto?

5
00:00:08,574 --> 00:00:09,850
¿Esto?

6
00:00:09,850 --> 00:00:11,630
¿Y qué tal esto?

7
00:00:11,950 --> 00:00:14,510
Tal vez no sepamos la razón,
pero cada uno de nosotros

8
00:00:14,510 --> 00:00:17,020
se inclina más hacia un tipo
de zapato que a otro.

9
00:00:17,380 --> 00:00:19,970
Ahora imaginen que intentan
enseñarle a una computadora

10
00:00:19,970 --> 00:00:21,500
a reconocer un zapato.

11
00:00:21,500 --> 00:00:24,400
Podrían terminar predisponiéndola
a sus propias inclinaciones.

12
00:00:24,400 --> 00:00:26,800
Así es como funciona el sesgo en el AA.

13
00:00:27,390 --> 00:00:29,990
Pero primero, ¿qué es
el aprendizaje automático (AA)?

14
00:00:29,990 --> 00:00:33,260
Bueno, se usa
en muchas tecnologías actuales.

15
00:00:33,950 --> 00:00:36,570
El AA nos ayuda a ir de un lugar a otro

16
00:00:36,920 --> 00:00:40,370
nos ofrece sugerencias,
traduce información

17
00:00:40,370 --> 00:00:42,750
incluso comprende lo que le dicen.

18
00:00:42,750 --> 00:00:44,030
¿Cómo funciona?

19
00:00:44,030 --> 00:00:45,630
En la programación tradicional

20
00:00:45,630 --> 00:00:49,150
se codificaba manualmente
la solución a un problema, paso a paso.

21
00:00:49,640 --> 00:00:52,520
Con el AA,
las computadoras aprenden la solución

22
00:00:52,520 --> 00:00:55,010
mediante patrones en los datos

23
00:00:55,010 --> 00:00:57,595
así que es fácil pensar
que no hay prejuicios humanos.

24
00:00:57,595 --> 00:00:59,990
Pero solo porque algo se basa en los datos

25
00:00:59,990 --> 00:01:02,240
no lo convierte
automáticamente en algo neutral.

26
00:01:02,570 --> 00:01:04,720
Aún con las mejores
intenciones, es imposible

27
00:01:04,720 --> 00:01:07,530
separarnos de nuestros prejuicios humanos

28
00:01:07,820 --> 00:01:10,760
así que estos sesgos
se convierten en parte de la tecnología

29
00:01:10,760 --> 00:01:13,160
que creamos, de diferentes maneras.

30
00:01:13,720 --> 00:01:17,480
Hay sesgos de interacción,
como el juego que acabamos de hacer

31
00:01:17,480 --> 00:01:20,240
donde se pide
dibujar zapatos para la computadora.

32
00:01:20,240 --> 00:01:22,350
La mayoría dibujó este tipo de zapatos.

33
00:01:22,350 --> 00:01:24,380
Y a medida
que interactuaron más personas

34
00:01:24,380 --> 00:01:27,150
la computadora
no pudo reconocer los de este tipo.

35
00:01:27,740 --> 00:01:31,250
Sesgo latente, por ejemplo,
si enseñan a una computadora

36
00:01:31,250 --> 00:01:33,340
sobre la apariencia de un físico

37
00:01:33,340 --> 00:01:35,640
y usan imágenes
de físicos del pasado

38
00:01:35,640 --> 00:01:39,550
su algoritmo terminará
con un sesgo latente hacia los hombres.

39
00:01:40,550 --> 00:01:42,170
Y sesgo de selección.

40
00:01:42,170 --> 00:01:44,992
Supongamos que entrenan un modelo
para reconocer rostros.

41
00:01:44,992 --> 00:01:48,370
Ya sea que usen imágenes
de Internet o de sus propias bibliotecas

42
00:01:48,370 --> 00:01:50,060
¿se aseguran de seleccionar

43
00:01:50,060 --> 00:01:51,830
imágenes que representan a todos?

44
00:01:51,830 --> 00:01:55,100
Como nuestros productos
más avanzados usan aprendizaje automático

45
00:01:55,100 --> 00:01:57,080
trabajamos para evitar que esa tecnología

46
00:01:57,080 --> 00:01:59,370
perpetúe prejuicios humanos negativos

47
00:02:01,440 --> 00:02:04,654
por ejemplo, evitar
que información ofensiva o errónea

48
00:02:04,654 --> 00:02:07,440
aparezca en la parte superior
de su página de búsqueda

49
00:02:08,130 --> 00:02:10,070
o agregar una herramienta de comentarios

50
00:02:10,070 --> 00:02:12,830
en la barra de búsqueda
para que las personas puedan marcar

51
00:02:12,830 --> 00:02:15,450
sugerencias de autocompletado inapropiadas.

52
00:02:16,780 --> 00:02:19,540
Es un problema
complejo y no hay solución mágica

53
00:02:19,540 --> 00:02:21,830
pero comienza con estar al tanto de ello

54
00:02:21,830 --> 00:02:24,320
para que todos podamos
ser parte de la conversación

55
00:02:24,320 --> 00:02:27,030
porque la tecnología
debe ser para todos.