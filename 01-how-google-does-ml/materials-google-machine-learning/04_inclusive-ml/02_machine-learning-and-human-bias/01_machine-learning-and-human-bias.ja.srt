1
00:00:00,000 --> 00:00:01,960
ゲームを始めましょう

2
00:00:01,960 --> 00:00:05,151
目を閉じて 靴を思い描いてください

3
00:00:05,151 --> 00:00:06,030
さて

4
00:00:06,030 --> 00:00:08,424
こんな靴を描きましたか？

5
00:00:08,424 --> 00:00:10,030
これですか？

6
00:00:10,030 --> 00:00:11,750
それとも これですか？

7
00:00:11,750 --> 00:00:13,780
なぜかそれぞれの人には

8
00:00:13,780 --> 00:00:17,510
他の靴ではなく「これが靴だ」と思う
バイアス（偏り）があります

9
00:00:17,510 --> 00:00:21,460
さて 靴を認識するよう
あなたがコンピュータを教えるとします

10
00:00:21,460 --> 00:00:24,180
自分のバイアスが明らかになるでしょう

11
00:00:24,180 --> 00:00:27,220
機械学習ではこのようにバイアスが発生します

12
00:00:27,220 --> 00:00:30,000
そもそも 機械学習（ML）とは何でしょうか

13
00:00:30,000 --> 00:00:33,950
MLは今日 多くのテクノロジーで使われ
役立っています

14
00:00:33,950 --> 00:00:36,730
たとえば ある場所から別の場所に行く

15
00:00:36,730 --> 00:00:38,610
提案を得る

16
00:00:38,610 --> 00:00:40,200
翻訳する

17
00:00:40,200 --> 00:00:42,750
さらに音声認識もあります

18
00:00:42,750 --> 00:00:44,210
どのように機能しますか

19
00:00:44,210 --> 00:00:45,830
従来のプログラミングでは

20
00:00:45,830 --> 00:00:49,480
人間が1ステップずつ
ハードコーディングします

21
00:00:49,480 --> 00:00:52,700
MLではコンピュータが
データ内のパターンを見つけて

22
00:00:52,700 --> 00:00:54,740
ソリューションを学習します

23
00:00:54,740 --> 00:00:57,375
ですから人による偏りがないと思われがちです

24
00:00:57,375 --> 00:00:59,720
でも データに基づくとしても

25
00:00:59,720 --> 00:01:02,490
中立であるとは限りません

26
00:01:02,490 --> 00:01:04,200
たとえ良い意図があっても

27
00:01:04,200 --> 00:01:07,940
自分のバイアスを除くことは不可能です

28
00:01:07,940 --> 00:01:09,580
人間のバイアスは

29
00:01:09,580 --> 00:01:13,430
私たちが作るテクノロジーに
さまざまな形で入り込みます

30
00:01:13,430 --> 00:01:16,170
コミュニケーション上のバイアスがあります

31
00:01:16,170 --> 00:01:19,820
先ほどのような
コンピュータに靴を教えるゲームでは

32
00:01:19,820 --> 00:01:22,290
多くの人が ... こんな靴を描きました

33
00:01:22,290 --> 00:01:24,470
もっと多くの人がゲームに関わると

34
00:01:24,470 --> 00:01:27,740
コンピュータはこれらの靴を
認識できませんでした

35
00:01:27,740 --> 00:01:29,680
潜伏的なバイアス ... たとえば

36
00:01:29,680 --> 00:01:33,220
物理学者はどんな顔をしているか
コンピュータに学習させるとき

37
00:01:33,220 --> 00:01:35,630
過去の学者たちの絵を使うなら

38
00:01:35,630 --> 00:01:40,460
アルゴリズムに潜伏的バイアスが生じ
男性に偏ります

39
00:01:40,460 --> 00:01:43,220
選択バイアス ...
モデルをトレーニングして

40
00:01:43,220 --> 00:01:44,992
顔を認識させるとします

41
00:01:44,992 --> 00:01:46,540
画像をネットから または

42
00:01:46,540 --> 00:01:48,630
自分のライブラリから取得するとき

43
00:01:48,630 --> 00:01:51,850
あらゆる人を表わす写真を
必ず選択できますか?

44
00:01:51,850 --> 00:01:55,040
先進的なGoogleサービスではMLを使用するので

45
00:01:55,040 --> 00:01:58,660
このテクノロジの中に
負の人為的バイアスが持続しないよう

46
00:01:58,660 --> 00:02:01,670
努力してきました

47
00:02:01,670 --> 00:02:05,734
侮辱的または誤導的な情報が
検索結果トップに表示されないよう

48
00:02:05,734 --> 00:02:07,860
取り組んだり

49
00:02:07,860 --> 00:02:10,780
検索バーに
フィードバックツールを追加して

50
00:02:10,780 --> 00:02:13,170
不快/不適切な自動補完について

51
00:02:13,170 --> 00:02:17,010
ユーザーが報告できるようにしています

52
00:02:17,010 --> 00:02:19,540
これは複雑な問題であり特効薬はありません

53
00:02:19,540 --> 00:02:21,850
でも 気付くことが第一歩です

54
00:02:21,850 --> 00:02:24,040
全員が互いに協力して

55
00:02:24,040 --> 00:02:27,540
人のためのテクノロジを目指すべきです