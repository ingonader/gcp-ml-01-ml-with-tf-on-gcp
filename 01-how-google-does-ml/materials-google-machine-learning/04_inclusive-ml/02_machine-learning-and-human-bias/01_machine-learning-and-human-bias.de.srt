1
00:00:00,499 --> 00:00:02,050
Spielen wir ein Spiel.

2
00:00:02,050 --> 00:00:05,211
Schließen Sie die Augen und
denken Sie an einen Schuh.

3
00:00:05,211 --> 00:00:05,920
OK.

4
00:00:05,920 --> 00:00:08,154
Hat sich jemand das hier vorgestellt?

5
00:00:08,154 --> 00:00:09,850
Oder das hier?

6
00:00:09,850 --> 00:00:11,970
Oder das hier?

7
00:00:11,970 --> 00:00:13,570
Wir wissen nicht wieso,

8
00:00:13,570 --> 00:00:17,450
aber jeder bevorzugt
einen bestimmten Schuh.

9
00:00:17,450 --> 00:00:19,970
Nehmen Sie an, Sie wollen
einem Computer beibringen,

10
00:00:19,970 --> 00:00:21,430
einen Schuh zu erkennen.

11
00:00:21,430 --> 00:00:24,290
Es kann sein, dass Sie dabei
Ihre eigenen Vorlieben einbauen.

12
00:00:24,290 --> 00:00:27,220
So gelangen "Vorurteile"
in maschinelles Lernen.

13
00:00:27,220 --> 00:00:29,960
Aber zuerst einmal: Was
ist maschinelles Lernen?

14
00:00:29,960 --> 00:00:33,950
Es wird heute in
zahlreichen Technologien genutzt.

15
00:00:33,950 --> 00:00:35,390
Maschinelles Lernen hilft uns,

16
00:00:35,390 --> 00:00:36,920
von Ort zu Ort zu gelangen,

17
00:00:36,920 --> 00:00:40,240
macht uns Vorschläge, übersetzt Texte,

18
00:00:40,240 --> 00:00:42,750
und versteht sogar, was Sie sagen.

19
00:00:42,750 --> 00:00:44,000
Wie funktioniert das?

20
00:00:44,000 --> 00:00:45,580
Beim traditionellen Programmieren

21
00:00:45,580 --> 00:00:49,640
codiert man die Lösung 
eines Problems Schritt für Schritt.

22
00:00:49,640 --> 00:00:52,340
Beim maschinellen Lernen
finden Computer eine Lösung

23
00:00:52,340 --> 00:00:55,850
durch Erkennen von Mustern in Daten.
Dabei sollten menschliche Vorurteile

24
00:00:55,850 --> 00:00:57,485
eigentlich keine Rolle spielen.

25
00:00:57,485 --> 00:00:59,920
Aber nur weil etwas auf Daten basiert,

26
00:00:59,920 --> 00:01:02,490
ist es nicht automatisch neutral.

27
00:01:02,490 --> 00:01:04,680
Selbst bei guter Absicht ist es unmöglich,

28
00:01:04,680 --> 00:01:07,700
uns von unseren Vorurteilen zu lösen,

29
00:01:07,700 --> 00:01:11,370
daher gelangen menschliche Vorurteile
auf vielerlei Art in Technologien hinein,

30
00:01:11,370 --> 00:01:13,630
die wir entwickeln.

31
00:01:13,630 --> 00:01:15,950
Es gibt Verzerrungen durch Interaktion

32
00:01:15,950 --> 00:01:17,480
wie bei dem Spiel,

33
00:01:17,480 --> 00:01:20,240
als Leute für den Computer
Schuhe zeichnen sollten.

34
00:01:20,240 --> 00:01:22,350
Die meisten haben
etwas wie dies gezeichnet.

35
00:01:22,350 --> 00:01:24,380
Als mehr Menschen am Spiel teilnahmen,

36
00:01:24,380 --> 00:01:27,740
hat der Computer
diese hier gar nicht mehr erkannt.

37
00:01:27,740 --> 00:01:31,250
Latente Vorurteile, wenn Sie etwa
einen Computer darauf trainieren,

38
00:01:31,250 --> 00:01:34,190
wie ein Arzt aussieht, und dafür Bilder

39
00:01:34,190 --> 00:01:36,230
früherer Ärzte nehmen,
wird Ihr Algorithmus

40
00:01:36,230 --> 00:01:40,510
latent dazu neigen, Ärzte
als männlich zu erkennen.

41
00:01:40,510 --> 00:01:42,970
Oder selektive Verzerrung:
Nehmen wir an, Ihr Modell

42
00:01:42,970 --> 00:01:44,912
soll Gesichter erkennen.

43
00:01:44,912 --> 00:01:46,910
Ob Sie nun Bilder aus dem Internet nehmen

44
00:01:46,910 --> 00:01:48,400
oder eigene Fotos:

45
00:01:48,400 --> 00:01:51,790
Sind diese Bilder wirklich repräsentativ?

46
00:01:51,790 --> 00:01:53,550
Da einige unserer modernsten Produkte

47
00:01:53,550 --> 00:01:55,330
maschinelles Lernen nutzen,

48
00:01:55,330 --> 00:01:57,540
möchten wir verhindern,
dass diese Technologie

49
00:01:57,540 --> 00:01:59,190
menschliche Vorurteile übernimmt,

50
00:02:01,490 --> 00:02:04,684
dass etwa anstößige
oder irreführende Inhalte

51
00:02:04,684 --> 00:02:08,540
in Suchergebnissen oben stehen.

52
00:02:08,540 --> 00:02:11,240
Wir haben ein Feedback-Tool
in die Suchleiste eingebaut,

53
00:02:11,240 --> 00:02:13,510
um Vervollständigungsvorschläge

54
00:02:13,510 --> 00:02:17,020
als hetzerisch oder 
unangemessen zu kennzeichnen.

55
00:02:17,020 --> 00:02:19,540
Das Thema ist komplex
und es gibt keine Patentlösung.

56
00:02:19,540 --> 00:02:21,670
Wir alle müssen uns dessen bewusst sein,

57
00:02:21,670 --> 00:02:24,100
damit wir alle mitdiskutieren können,

58
00:02:24,100 --> 00:02:27,540
denn Technologie soll für alle da sein.