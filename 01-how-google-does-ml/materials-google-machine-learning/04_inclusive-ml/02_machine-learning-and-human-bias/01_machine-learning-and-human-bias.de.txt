Spielen wir ein Spiel. Schließen Sie die Augen und
denken Sie an einen Schuh. OK. Hat sich jemand das hier vorgestellt? Oder das hier? Oder das hier? Wir wissen nicht wieso, aber jeder bevorzugt
einen bestimmten Schuh. Nehmen Sie an, Sie wollen
einem Computer beibringen, einen Schuh zu erkennen. Es kann sein, dass Sie dabei
Ihre eigenen Vorlieben einbauen. So gelangen "Vorurteile"
in maschinelles Lernen. Aber zuerst einmal: Was
ist maschinelles Lernen? Es wird heute in
zahlreichen Technologien genutzt. Maschinelles Lernen hilft uns, von Ort zu Ort zu gelangen, macht uns Vorschläge, übersetzt Texte, und versteht sogar, was Sie sagen. Wie funktioniert das? Beim traditionellen Programmieren codiert man die Lösung 
eines Problems Schritt für Schritt. Beim maschinellen Lernen
finden Computer eine Lösung durch Erkennen von Mustern in Daten.
Dabei sollten menschliche Vorurteile eigentlich keine Rolle spielen. Aber nur weil etwas auf Daten basiert, ist es nicht automatisch neutral. Selbst bei guter Absicht ist es unmöglich, uns von unseren Vorurteilen zu lösen, daher gelangen menschliche Vorurteile
auf vielerlei Art in Technologien hinein, die wir entwickeln. Es gibt Verzerrungen durch Interaktion wie bei dem Spiel, als Leute für den Computer
Schuhe zeichnen sollten. Die meisten haben
etwas wie dies gezeichnet. Als mehr Menschen am Spiel teilnahmen, hat der Computer
diese hier gar nicht mehr erkannt. Latente Vorurteile, wenn Sie etwa
einen Computer darauf trainieren, wie ein Arzt aussieht, und dafür Bilder früherer Ärzte nehmen,
wird Ihr Algorithmus latent dazu neigen, Ärzte
als männlich zu erkennen. Oder selektive Verzerrung:
Nehmen wir an, Ihr Modell soll Gesichter erkennen. Ob Sie nun Bilder aus dem Internet nehmen oder eigene Fotos: Sind diese Bilder wirklich repräsentativ? Da einige unserer modernsten Produkte maschinelles Lernen nutzen, möchten wir verhindern,
dass diese Technologie menschliche Vorurteile übernimmt, dass etwa anstößige
oder irreführende Inhalte in Suchergebnissen oben stehen. Wir haben ein Feedback-Tool
in die Suchleiste eingebaut, um Vervollständigungsvorschläge als hetzerisch oder 
unangemessen zu kennzeichnen. Das Thema ist komplex
und es gibt keine Patentlösung. Wir alle müssen uns dessen bewusst sein, damit wir alle mitdiskutieren können, denn Technologie soll für alle da sein.