1
00:00:00,499 --> 00:00:02,060
Jouons à un petit jeu.

2
00:00:02,060 --> 00:00:04,961
Fermez les yeux et pensez à
une chaussure.

3
00:00:04,961 --> 00:00:06,100
Bien.

4
00:00:06,100 --> 00:00:08,044
Avez-vous imaginé ceci ?

5
00:00:08,044 --> 00:00:09,850
Ceci ?

6
00:00:09,850 --> 00:00:12,020
Ou cela ?

7
00:00:12,020 --> 00:00:14,540
Nous ne savons pas pourquoi,
mais chacun d'entre nous

8
00:00:14,540 --> 00:00:17,840
a tendance à privilégier un type de
chaussure au détriment des autres.

9
00:00:17,840 --> 00:00:20,150
Imaginez essayer d'apprendre
à un ordinateur

10
00:00:20,150 --> 00:00:21,500
à reconnaître une chaussure.

11
00:00:21,500 --> 00:00:24,290
Vous risquez bien de lui transmettre
votre propre préjugé.

12
00:00:24,290 --> 00:00:27,460
C'est comme cela qu'un biais se produit
en machine learning.

13
00:00:27,460 --> 00:00:29,990
Mais tout d'abord, qu'est-ce que le
machine learning ?

14
00:00:29,990 --> 00:00:33,950
Il est utilisé dans de
nombreuses technologies actuelles.

15
00:00:33,950 --> 00:00:36,980
Le machine learning nous aide à
aller d'un point A à un point B,

16
00:00:36,980 --> 00:00:40,490
il nous offre des suggestions,
il traduit des choses,

17
00:00:40,490 --> 00:00:43,110
il est même capable de comprendre
ce que vous lui dites.

18
00:00:43,110 --> 00:00:44,030
Comment ça marche ?

19
00:00:44,030 --> 00:00:47,120
En programmation traditionnelle,
les développeurs codent à la main

20
00:00:47,120 --> 00:00:49,640
la solution à un problème,
étape par étape.

21
00:00:49,640 --> 00:00:52,660
Avec le machine learning, les
ordinateurs apprennent la solution

22
00:00:52,660 --> 00:00:54,770
en identifiant des schémas dans les
données.

23
00:00:54,770 --> 00:00:58,030
On pourrait donc penser que
la subjectivité humaine n'intervient pas.

24
00:00:58,030 --> 00:01:00,490
Mais le fait qu'une chose soit
basée sur les données

25
00:01:00,490 --> 00:01:02,530
ne garantit pas sa neutralité.

26
00:01:02,530 --> 00:01:05,310
Même avec les meilleures intentions,
il nous est impossible

27
00:01:05,310 --> 00:01:07,730
de nous séparer totalement
de nos préjugés.

28
00:01:07,730 --> 00:01:10,850
Nous les intégrons donc malgré nous
dans les technologies

29
00:01:10,850 --> 00:01:13,860
que nous créons, et ce,
de différentes manières.

30
00:01:13,860 --> 00:01:16,860
On peut citer le biais d'interaction,
comme dans ce jeu récent,

31
00:01:16,860 --> 00:01:20,240
où les participants devaient
dessiner des chaussures pour l'ordinateur.

32
00:01:20,240 --> 00:01:22,540
La plupart ont dessiné
des chaussures de ce type.

33
00:01:22,540 --> 00:01:25,060
Ainsi, plus les interactions
avec le jeu augmentaient,

34
00:01:25,060 --> 00:01:28,130
moins l'ordinateur parvenait à
reconnaître les autres chaussures.

35
00:01:28,130 --> 00:01:31,250
Citons aussi le biais latent.
Par exemple, si vous entraînez

36
00:01:31,250 --> 00:01:34,190
un ordinateur à identifier un physicien à
l'aide de photos

37
00:01:34,190 --> 00:01:37,870
de physiciens du passé, votre algorithme
finira par développer un biais latent

38
00:01:37,870 --> 00:01:40,970
et ne prendra que les individus de
sexe masculin en considération.

39
00:01:40,970 --> 00:01:44,220
Passons au biais de sélection.
Imaginons que vous entraînez un modèle

40
00:01:44,220 --> 00:01:45,472
à reconnaître des visages.

41
00:01:45,472 --> 00:01:48,750
Qu'il s'agisse d'images provenant
d'Internet ou de vos propres photos,

42
00:01:48,750 --> 00:01:50,610
êtes-vous certain qu'elles représentent

43
00:01:50,610 --> 00:01:52,150
tous les morphotypes existants ?

44
00:01:52,150 --> 00:01:55,810
Comme certains de nos produits les plus
avancés utilisent le machine learning,

45
00:01:55,810 --> 00:01:59,100
nous redoublons d'efforts pour
que cette technologie ne reproduise pas

46
00:01:59,100 --> 00:02:00,870
les préjugés humains négatifs,

47
00:02:00,870 --> 00:02:04,654
par exemple en éliminant les informations
choquantes et manifestement trompeuses

48
00:02:04,654 --> 00:02:07,490
des premiers résultats
de votre page de recherche,

49
00:02:07,510 --> 00:02:10,670
ou en ajoutant un outil
de commentaire dans la barre de recherche

50
00:02:10,670 --> 00:02:13,090
afin que les utilisateurs
puissent signaler

51
00:02:13,090 --> 00:02:16,360
les propos haineux ou inappropriés
apparaissant dans les suggestions.

52
00:02:16,850 --> 00:02:19,870
Le problème est complexe et il n'existe
pas de solution miracle.

53
00:02:19,870 --> 00:02:22,240
Une prise de conscience collective
est nécessaire,

54
00:02:22,240 --> 00:02:24,650
pour que nous puissions tous participer
à ce débat,

55
00:02:24,650 --> 00:02:27,540
car la technologie doit travailler
pour le bien de tous.