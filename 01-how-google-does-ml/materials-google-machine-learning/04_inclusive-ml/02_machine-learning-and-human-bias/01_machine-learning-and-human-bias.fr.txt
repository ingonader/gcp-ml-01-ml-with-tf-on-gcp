Jouons à un petit jeu. Fermez les yeux et pensez à
une chaussure. Bien. Avez-vous imaginé ceci ? Ceci ? Ou cela ? Nous ne savons pas pourquoi,
mais chacun d'entre nous a tendance à privilégier un type de
chaussure au détriment des autres. Imaginez essayer d'apprendre
à un ordinateur à reconnaître une chaussure. Vous risquez bien de lui transmettre
votre propre préjugé. C'est comme cela qu'un biais se produit
en machine learning. Mais tout d'abord, qu'est-ce que le
machine learning ? Il est utilisé dans de
nombreuses technologies actuelles. Le machine learning nous aide à
aller d'un point A à un point B, il nous offre des suggestions,
il traduit des choses, il est même capable de comprendre
ce que vous lui dites. Comment ça marche ? En programmation traditionnelle,
les développeurs codent à la main la solution à un problème,
étape par étape. Avec le machine learning, les
ordinateurs apprennent la solution en identifiant des schémas dans les
données. On pourrait donc penser que
la subjectivité humaine n'intervient pas. Mais le fait qu'une chose soit
basée sur les données ne garantit pas sa neutralité. Même avec les meilleures intentions,
il nous est impossible de nous séparer totalement
de nos préjugés. Nous les intégrons donc malgré nous
dans les technologies que nous créons, et ce,
de différentes manières. On peut citer le biais d'interaction,
comme dans ce jeu récent, où les participants devaient
dessiner des chaussures pour l'ordinateur. La plupart ont dessiné
des chaussures de ce type. Ainsi, plus les interactions
avec le jeu augmentaient, moins l'ordinateur parvenait à
reconnaître les autres chaussures. Citons aussi le biais latent.
Par exemple, si vous entraînez un ordinateur à identifier un physicien à
l'aide de photos de physiciens du passé, votre algorithme
finira par développer un biais latent et ne prendra que les individus de
sexe masculin en considération. Passons au biais de sélection.
Imaginons que vous entraînez un modèle à reconnaître des visages. Qu'il s'agisse d'images provenant
d'Internet ou de vos propres photos, êtes-vous certain qu'elles représentent tous les morphotypes existants ? Comme certains de nos produits les plus
avancés utilisent le machine learning, nous redoublons d'efforts pour
que cette technologie ne reproduise pas les préjugés humains négatifs, par exemple en éliminant les informations
choquantes et manifestement trompeuses des premiers résultats
de votre page de recherche, ou en ajoutant un outil
de commentaire dans la barre de recherche afin que les utilisateurs
puissent signaler les propos haineux ou inappropriés
apparaissant dans les suggestions. Le problème est complexe et il n'existe
pas de solution miracle. Une prise de conscience collective
est nécessaire, pour que nous puissions tous participer
à ce débat, car la technologie doit travailler
pour le bien de tous.