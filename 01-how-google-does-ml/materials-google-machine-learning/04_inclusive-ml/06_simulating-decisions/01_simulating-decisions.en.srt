1
00:00:00,000 --> 00:00:04,855
So, now that we formally define what the principle behind equality of opportunity is,

2
00:00:04,855 --> 00:00:07,945
let's walk through the loan predict for example once more.

3
00:00:07,945 --> 00:00:12,800
In this scenario, we have two groups of people, blue and orange.

4
00:00:12,800 --> 00:00:14,540
And let's say, we're interested in making

5
00:00:14,540 --> 00:00:17,530
small loans subject to the following conditions.

6
00:00:17,530 --> 00:00:19,970
A successful loan makes $300 dollars.

7
00:00:19,970 --> 00:00:22,880
An unsuccessful loan costs $700 dollars.

8
00:00:22,880 --> 00:00:25,410
And everyone has a credit score between zero and 100.

9
00:00:25,410 --> 00:00:29,180
And let's first start by setting the threshold of a credit score of 50.

10
00:00:29,180 --> 00:00:32,660
Now, because the distributions of the two groups are slightly different,

11
00:00:32,660 --> 00:00:36,770
setting the threshold to a credit score of 50 gives us some decent results.

12
00:00:36,770 --> 00:00:40,970
For the Blue Group, a threshold of 50 leads to correct decisions,

13
00:00:40,970 --> 00:00:42,905
76 percent of the time.

14
00:00:42,905 --> 00:00:45,140
For the Orange group, a threshold of

15
00:00:45,140 --> 00:00:48,970
50 leads to correct decisions 87 percent of the time.

16
00:00:48,970 --> 00:00:53,180
So what does default threshold suggests is that it's better to be in the Orange group,

17
00:00:53,180 --> 00:00:57,230
than in the Blue group, meaning that there's room for improvement to be made here.

18
00:00:57,230 --> 00:01:00,200
Now, let's say you set your thresholds to maximize profit.

19
00:01:00,200 --> 00:01:03,955
If you look for pairs of thresholds that maximize total profit,

20
00:01:03,955 --> 00:01:07,955
maybe you'll see that the Blue group is held to a higher standard than the orange one.

21
00:01:07,955 --> 00:01:11,060
And that's depicted in the slide here by the increase in

22
00:01:11,060 --> 00:01:15,695
dark grey shaded regions which represents those that were denied a loan,

23
00:01:15,695 --> 00:01:17,910
even though they would have paid it back.

24
00:01:17,910 --> 00:01:20,840
That could be a problem and one that suggests not

25
00:01:20,840 --> 00:01:24,465
just picking thresholds to make as much money as possible.

26
00:01:24,465 --> 00:01:28,225
Another technique would be to implement what's called a group unaware approach,

27
00:01:28,225 --> 00:01:30,590
which holds all groups to the same standard.

28
00:01:30,590 --> 00:01:33,275
So in this scenario, we'll use the same threshold,

29
00:01:33,275 --> 00:01:35,785
55 for all groups.

30
00:01:35,785 --> 00:01:38,125
Is this really the right solution though?

31
00:01:38,125 --> 00:01:41,390
For one thing, if there are real differences between two groups,

32
00:01:41,390 --> 00:01:43,690
it might not be fair to ignore them.

33
00:01:43,690 --> 00:01:47,840
For example, women generally pay less for life insurance than men,

34
00:01:47,840 --> 00:01:49,385
since they tend to live longer.

35
00:01:49,385 --> 00:01:52,775
But there are other mathematical problems with group unaware approach,

36
00:01:52,775 --> 00:01:56,300
even if both groups are equally lone worthy.

37
00:01:56,300 --> 00:01:57,490
In the example above,

38
00:01:57,490 --> 00:02:01,490
the differences in score distributions means that the Orange group actually gets

39
00:02:01,490 --> 00:02:06,675
fewer loans when the bank looks for the most profitable group unaware threshold.

40
00:02:06,675 --> 00:02:09,530
But if we were to take the equality of opportunity approach,

41
00:02:09,530 --> 00:02:10,985
then in this example,

42
00:02:10,985 --> 00:02:13,185
among people who pay back a loan,

43
00:02:13,185 --> 00:02:15,945
Blue and Orange groups do equally well.

44
00:02:15,945 --> 00:02:19,250
This choice is almost as profitable as optimizing for

45
00:02:19,250 --> 00:02:23,690
maximum profits and about as many people get loans overall.

46
00:02:23,690 --> 00:02:27,395
Here the constraint is that of the people who can pay back a loan,

47
00:02:27,395 --> 00:02:30,995
the same fraction in each group should actually be granted a loan.

48
00:02:30,995 --> 00:02:35,265
Or using some of the jargon that was introduced in the earlier sections,

49
00:02:35,265 --> 00:02:38,795
the true positive rate is identical between the groups.

50
00:02:38,795 --> 00:02:40,505
So the takeaway to all of this,

51
00:02:40,505 --> 00:02:44,165
is that it's possible to find thresholds that meet any of these criteria.

52
00:02:44,165 --> 00:02:47,210
When you have control over your machine learning system,

53
00:02:47,210 --> 00:02:50,400
using these definitions can help clarify core issues.

54
00:02:50,400 --> 00:02:53,315
If your model isn't as effective for some group as others,

55
00:02:53,315 --> 00:02:56,605
it can cause problems for groups that have the most uncertainty.

56
00:02:56,605 --> 00:02:59,500
Restricting the equal opportunity thresholds

57
00:02:59,500 --> 00:03:02,815
transfers the burden of uncertainty away from the groups,

58
00:03:02,815 --> 00:03:05,050
and onto you, the creator of the model,

59
00:03:05,050 --> 00:03:09,000
doing to improvise the incentive to invest in the best classifiers.