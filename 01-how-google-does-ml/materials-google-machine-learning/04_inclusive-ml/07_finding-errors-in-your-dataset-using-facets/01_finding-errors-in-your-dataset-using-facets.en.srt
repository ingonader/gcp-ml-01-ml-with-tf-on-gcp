1
00:00:00,000 --> 00:00:02,730
So, we've covered some of the ways in which you can make

2
00:00:02,730 --> 00:00:06,305
your machine learning model more inclusive through your valuation metrics.

3
00:00:06,305 --> 00:00:11,580
But getting the best results out of a model requires that you truly understand your data.

4
00:00:11,580 --> 00:00:13,350
The challenge here, though, is that sometimes,

5
00:00:13,350 --> 00:00:16,395
datasets can contain hundreds of millions of data points,

6
00:00:16,395 --> 00:00:19,845
each consisting of hundreds or even thousands of features,

7
00:00:19,845 --> 00:00:25,200
making it nearly impossible to understand an entire dataset in an intuitive fashion.

8
00:00:25,200 --> 00:00:27,840
The key here is to utilize visualizations that

9
00:00:27,840 --> 00:00:31,425
help unlock nuances and insights into large datasets.

10
00:00:31,425 --> 00:00:33,645
And in this section, I'll talk about

11
00:00:33,645 --> 00:00:36,825
an open source data visualization tool called Facets.

12
00:00:36,825 --> 00:00:39,390
Facets was developed at Google and is one of

13
00:00:39,390 --> 00:00:42,465
the ways in which you can make machine learning models more inclusive.

14
00:00:42,465 --> 00:00:46,230
So, there's two parts of Facets: Overview and Dive.

15
00:00:46,230 --> 00:00:49,875
And in this slide, you're seeing the screenshot of Facets Overview,

16
00:00:49,875 --> 00:00:52,290
which automatically gives you a quick understanding of

17
00:00:52,290 --> 00:00:55,560
the distributions of values across the features of their datasets.

18
00:00:55,560 --> 00:00:59,445
The example you're seen in this slide comes from the UCI Census data.

19
00:00:59,445 --> 00:01:00,870
The data was extracted from

20
00:01:00,870 --> 00:01:03,510
the 1994 Census Bureau Database which

21
00:01:03,510 --> 00:01:07,050
contains anonymized information about the United States' population.

22
00:01:07,050 --> 00:01:08,820
The information in this dataset includes

23
00:01:08,820 --> 00:01:13,130
demographic and employment related variables such as age and salary.

24
00:01:13,130 --> 00:01:16,710
This dataset was put together by the Research Committee and is often used as

25
00:01:16,710 --> 00:01:19,440
a prediction task to determine whether a person is likely

26
00:01:19,440 --> 00:01:22,860
to earn $50,000 or more annually.

27
00:01:22,860 --> 00:01:26,010
Multiple datasets, such as a training set and a test set,

28
00:01:26,010 --> 00:01:28,125
can be compared on the same visualization.

29
00:01:28,125 --> 00:01:31,785
With Facets, common data issues that can hamper machine learning

30
00:01:31,785 --> 00:01:35,845
are pushed to the forefront such as unexpected feature values,

31
00:01:35,845 --> 00:01:38,715
featured with high percentages of missing values,

32
00:01:38,715 --> 00:01:43,585
features with unbalanced distributions or distribution skew between data sets.

33
00:01:43,585 --> 00:01:46,110
Using the same screenshot from the previous slide,

34
00:01:46,110 --> 00:01:48,360
what you're seeing here are two numeric features of

35
00:01:48,360 --> 00:01:52,645
the UCI Census Dataset: Capital Gain and Capital Loss.

36
00:01:52,645 --> 00:01:55,050
The features are sorted by non-uniformity with

37
00:01:55,050 --> 00:01:58,270
the feature with the most non-uniform distribution at the top.

38
00:01:58,270 --> 00:02:01,210
Numbers in red indicate possible trouble spots.

39
00:02:01,210 --> 00:02:05,875
In this case, numeric features with a high percentage of values set to zero.

40
00:02:05,875 --> 00:02:08,280
The histogram at the right allows you to compare

41
00:02:08,280 --> 00:02:11,040
the distributions between the training data which is in blue,

42
00:02:11,040 --> 00:02:12,915
and the test data which is an orange.

43
00:02:12,915 --> 00:02:16,635
Facets Overview can also visualize categorical features.

44
00:02:16,635 --> 00:02:18,690
In this example, what you're seeing here is

45
00:02:18,690 --> 00:02:21,450
a breakdown of the target feature which is the label

46
00:02:21,450 --> 00:02:26,520
that represents whether or not the person earned an annual salary of more than $50,000.

47
00:02:26,520 --> 00:02:29,220
But in particular, what we're looking at are

48
00:02:29,220 --> 00:02:33,770
all the instances where the annual salary is less than or equal to $50,000.

49
00:02:33,770 --> 00:02:37,240
But do you know that something's suspicious about this target feature?

50
00:02:37,240 --> 00:02:40,030
Notice that the label values differ between the training and

51
00:02:40,030 --> 00:02:43,665
the test datasets due to the trailing period in the test set.

52
00:02:43,665 --> 00:02:47,520
Facets Overview even went so far as to sort these discrepancies by

53
00:02:47,520 --> 00:02:51,600
distribution distance with the feature with the biggest skew between the training,

54
00:02:51,600 --> 00:02:52,995
which is in blue, and tests,

55
00:02:52,995 --> 00:02:55,060
which is in orange, at the top.

56
00:02:55,060 --> 00:02:58,066
Encountering a label mismatch like this would cause a model

57
00:02:58,066 --> 00:03:01,880
trained and tested on the data to not be evaluated correctly.

58
00:03:01,880 --> 00:03:03,795
Now, shifting over to Facets Dive,

59
00:03:03,795 --> 00:03:07,065
you can see in this slide that it provides an easy to customize

60
00:03:07,065 --> 00:03:09,090
intuitive interface for exploring

61
00:03:09,090 --> 00:03:13,185
the relationships between the data points across the different features of a dataset.

62
00:03:13,185 --> 00:03:16,545
With Facets Dive, you control the position, color,

63
00:03:16,545 --> 00:03:20,985
and visual representation of each of the data points based on its feature values.

64
00:03:20,985 --> 00:03:23,387
More specifically, in this example,

65
00:03:23,387 --> 00:03:28,185
Facets Dive is displaying all data points in the UCI Census test dataset.

66
00:03:28,185 --> 00:03:32,850
The animation shows a user coloring the data points by one feature, relationship,

67
00:03:32,850 --> 00:03:36,150
fastening in one dimension by a continuous feature, age,

68
00:03:36,150 --> 00:03:40,275
and then fastening in another dimension by a discrete feature, marital status.

69
00:03:40,275 --> 00:03:44,220
In Facets Dive, if the data points have images associated with them,

70
00:03:44,220 --> 00:03:47,105
the images can be used as the visual representation.

71
00:03:47,105 --> 00:03:51,590
So, in other words, it's not just only limited to categorical or numerical features.

72
00:03:51,590 --> 00:03:53,940
The example you see in this image comes from

73
00:03:53,940 --> 00:03:56,490
a research-based image dataset that contains

74
00:03:56,490 --> 00:04:00,270
many objects and animals in the world used to train an image classifier.

75
00:04:00,270 --> 00:04:02,430
The Ground Truth Labels are arranged by row,

76
00:04:02,430 --> 00:04:04,605
and the Predicted Labels are arranged by column.

77
00:04:04,605 --> 00:04:07,530
This configuration produces a confusion matrix view

78
00:04:07,530 --> 00:04:11,305
allowing us to draw into particular kinds of misclassifications.

79
00:04:11,305 --> 00:04:12,690
In this particular example,

80
00:04:12,690 --> 00:04:14,730
the machine learning model incorrectly labels

81
00:04:14,730 --> 00:04:17,760
some small percentage of true cats as frogs.

82
00:04:17,760 --> 00:04:20,245
Can you spot the frog cat in this image?

83
00:04:20,245 --> 00:04:22,860
The interesting thing we find by putting the real images

84
00:04:22,860 --> 00:04:25,830
in the confusion matrix using Facets Dive is that

85
00:04:25,830 --> 00:04:28,350
one of these true cats that the model predicted to be

86
00:04:28,350 --> 00:04:31,755
a frog is actually a frog from a visual inspection.

87
00:04:31,755 --> 00:04:34,050
With Facets Dive, we can determine that

88
00:04:34,050 --> 00:04:38,525
this one misclassification wasn't a true misclassification of the model.

89
00:04:38,525 --> 00:04:43,870
Instead, it was actually an incorrectly labeled data that was featured in a dataset.

90
00:04:43,870 --> 00:04:46,070
So, the hope here is that tools such as Facets

91
00:04:46,070 --> 00:04:48,560
can help you discover new and interesting things about

92
00:04:48,560 --> 00:04:50,840
your data that will hopefully lead you to

93
00:04:50,840 --> 00:04:54,000
creating more accurate and inclusive machine learning models.