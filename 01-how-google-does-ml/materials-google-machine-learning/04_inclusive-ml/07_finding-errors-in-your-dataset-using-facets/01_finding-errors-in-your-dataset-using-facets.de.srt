1
00:00:00,000 --> 00:00:02,730
Wir haben jetzt also
einige Möglichkeiten besprochen,

2
00:00:02,730 --> 00:00:06,305
Ihr Maschinenlernmodell mithilfe
von Messwerten inklusiver zu gestalten.

3
00:00:06,305 --> 00:00:11,580
Aber um Ihr Modell optimal zu nutzen, 
müssen Sie Ihre Daten wirklich verstehen.

4
00:00:11,580 --> 00:00:13,350
Das Problem dabei ist, dass Datasets

5
00:00:13,350 --> 00:00:14,995
manchmal Hunderte Millionen

6
00:00:14,995 --> 00:00:16,395
von Datenpunkten umfassen,

7
00:00:16,395 --> 00:00:19,845
von denen jeder Hunderte oder
sogar Tausende von Merkmalen aufweist.

8
00:00:19,845 --> 00:00:25,200
Deshalb ist es fast unmöglich, 
ein ganzes Dataset intuitiv zu verstehen.

9
00:00:25,200 --> 00:00:27,840
Dies lässt sich durch
Visualisierungen lösen.

10
00:00:27,840 --> 00:00:31,345
Sie machen Nuancen und
Informationen in großen Datasets sichtbar.

11
00:00:31,345 --> 00:00:34,085
In diesem Abschnitt
geht es um ein Open-Source-Tool

12
00:00:34,085 --> 00:00:35,825
zur Datenvisualisierung.

13
00:00:35,825 --> 00:00:36,825
Es heißt Facets.

14
00:00:36,825 --> 00:00:39,050
Facets wurde von Google entwickelt.

15
00:00:39,050 --> 00:00:40,165
Es dient dazu,

16
00:00:40,165 --> 00:00:42,465
ML-Modelle inklusiver zu gestalten.

17
00:00:42,465 --> 00:00:44,780
Facets besteht aus zwei Teilen:

18
00:00:44,780 --> 00:00:46,230
Overview und Dive.

19
00:00:46,230 --> 00:00:49,875
Diese Folie zeigt einen
Screenshot von Facets Overview.

20
00:00:49,875 --> 00:00:52,290
Es liefert einen
schnellen Überblick darüber,

21
00:00:52,290 --> 00:00:55,560
wie sich Werte über
die Merkmale von Datasets verteilen.

22
00:00:55,560 --> 00:00:59,125
Das Beispiel in dieser Folie
stammt aus UCI-Volkszählungsdaten.

23
00:00:59,125 --> 00:01:01,750
Die Daten von 1994
wurden aus der Datenbank

24
00:01:01,750 --> 00:01:03,500
der Volkszählungsbehörde entnommen.

25
00:01:03,510 --> 00:01:05,040
Es sind anonymisierte Daten

26
00:01:05,040 --> 00:01:07,050
über die US-Bevölkerung.

27
00:01:07,050 --> 00:01:09,180
In diesem Dataset gibt es Variablen

28
00:01:09,180 --> 00:01:11,260
zur Demografie und zum Arbeitsmarkt,

29
00:01:11,260 --> 00:01:13,020
zum Beispiel Alter und Gehalt.

30
00:01:13,020 --> 00:01:15,780
Das Dataset wurde vom 
Research Committee zusammengestellt.

31
00:01:15,780 --> 00:01:17,640
Eine typische Nutzung besteht darin,

32
00:01:17,640 --> 00:01:22,500
vorherzusagen, ob jemand
über 50.000 Dollar jährlich verdient.

33
00:01:22,500 --> 00:01:25,960
Man kann mehrere Datasets 
wie ein Trainings-Set und ein Test-Set

34
00:01:25,960 --> 00:01:28,125
mit der gleichen
Visualisierung vergleichen.

35
00:01:28,125 --> 00:01:31,785
Mit Facets kann man
häufige Probleme sichtbar machen,

36
00:01:31,785 --> 00:01:35,845
die das maschinelle Lernen stören:
Merkmale mit unerwarteten Werten,

37
00:01:35,845 --> 00:01:38,715
Merkmale, bei denen
größtenteils die Werte fehlen,

38
00:01:38,715 --> 00:01:43,585
mit ungleichmäßiger Werteverteilung
oder Verzerrungen zwischen Datasets.

39
00:01:43,585 --> 00:01:46,110
Am selben Screenshot
wie in der letzten Folie

40
00:01:46,110 --> 00:01:48,360
können Sie zwei numerische Merkmale

41
00:01:48,360 --> 00:01:52,645
des UCI-Datasets erkennen:
Kapitalgewinn und Kapitalverlust.

42
00:01:52,645 --> 00:01:55,050
Die Merkmale
sind nach Ungleichförmigkeit sortiert.

43
00:01:55,050 --> 00:01:57,270
Das am ungleichsten verteilte Merkmal

44
00:01:57,270 --> 00:01:58,270
steht ganz oben.

45
00:01:58,270 --> 00:02:01,200
Rote Zahlen 
kennzeichnen mögliche Problemfelder.

46
00:02:01,210 --> 00:02:03,155
Das wären hier numerische Merkmale,

47
00:02:03,155 --> 00:02:05,875
bei denen viele Werte null sind.

48
00:02:05,875 --> 00:02:08,850
Mit dem Histogramm rechts
können Sie die Verteilungen

49
00:02:08,850 --> 00:02:10,899
zwischen den Trainingsdaten (in Blau)

50
00:02:10,899 --> 00:02:12,915
und den Testdaten (in Orange) vergleichen.

51
00:02:12,915 --> 00:02:16,385
Mit Facets Overview kann man auch
kategorische Merkmale visualisieren.

52
00:02:16,385 --> 00:02:20,630
In diesem Beispiel sehen wir
eine Gliederung des Zielmerkmals,

53
00:02:20,640 --> 00:02:22,470
nämlich des Labels,

54
00:02:22,470 --> 00:02:26,520
ob jemand über 50.000 Dollar
jährlich verdient hat oder nicht.

55
00:02:26,520 --> 00:02:29,220
Wir sehen uns hier
insbesondere alle Fälle an,

56
00:02:29,220 --> 00:02:33,770
in denen das Jahresgehalt
höchstens 50.000 Dollar betrug.

57
00:02:33,770 --> 00:02:37,240
Aber erkennen Sie, dass etwas
an diesem Zielmerkmal verdächtig ist?

58
00:02:37,240 --> 00:02:40,030
Die Labelwerte zwischen
den Trainings- und Test-Datasets

59
00:02:40,030 --> 00:02:43,665
unterscheiden sich durch
den Punkt am Ende im Test-Set.

60
00:02:43,665 --> 00:02:45,940
Faces Overview hat diese Diskrepanzen

61
00:02:45,940 --> 00:02:48,960
bei diesem Merkmal sogar nach
dem Verteilungsabstand sortiert.

62
00:02:48,960 --> 00:02:50,580
Die größte Verzerrung zwischen

63
00:02:50,580 --> 00:02:53,845
den Trainingsdaten (blau)
und denTestdaten (orange)

64
00:02:53,845 --> 00:02:55,060
steht ganz oben.

65
00:02:55,060 --> 00:02:56,896
Wenn solche falschen Label auftreten,

66
00:02:56,896 --> 00:03:00,096
wird ein auf diesen Daten
trainiertes und getestetes Modell

67
00:03:00,096 --> 00:03:01,880
nicht richtig ausgewertet.

68
00:03:01,880 --> 00:03:03,795
Wenn wir uns jetzt Facets Dive ansehen,

69
00:03:03,795 --> 00:03:06,995
erkennen Sie in dieser Folie,
dass es eine leichte anpassbare,

70
00:03:06,995 --> 00:03:08,550
intuitive Oberfläche besitzt,

71
00:03:08,550 --> 00:03:11,675
mit der man Beziehungen
zwischen Merkmals-Datenpunkten

72
00:03:11,675 --> 00:03:13,185
eines Datasets betrachten kann.

73
00:03:13,185 --> 00:03:16,445
Bei Facets Dive
bestimmen Sie die Position, Farbe

74
00:03:16,445 --> 00:03:19,365
und visuelle Darstellung jedes Datenpunkts

75
00:03:19,365 --> 00:03:20,985
entsprechend seinen Merkmalswerten.

76
00:03:20,985 --> 00:03:23,387
In diesem Beispiel werden alle Datenpunkte

77
00:03:23,387 --> 00:03:28,035
des Test-Datasets aus der
Volkszählung in Facets Dive angezeigt.

78
00:03:28,035 --> 00:03:29,940
In der Animation sieht man einen Nutzer,

79
00:03:29,940 --> 00:03:32,880
der die Datenpunkte
nach einem Merkmal (Beziehung) einfärbt,

80
00:03:32,880 --> 00:03:35,990
sie in einer Dimension
nach einem stetigen Merkmal (Alter)

81
00:03:35,990 --> 00:03:37,775
und dann in einer anderen Dimension

82
00:03:37,775 --> 00:03:40,305
nach einem diskreten 
Merkmal (Familienstand) fixiert.

83
00:03:40,305 --> 00:03:44,220
In Facets Dive werden Bilder
mit den Datenpunkten verknüpft.

84
00:03:44,220 --> 00:03:47,105
Die Bilder dienen
als visuelle Darstellung.

85
00:03:47,105 --> 00:03:51,440
Mit anderen Worten: Es gibt hier nicht
nur kategorische und numerische Merkmale.

86
00:03:51,440 --> 00:03:53,380
Das Beispiel in diesem Bild

87
00:03:53,380 --> 00:03:56,490
stammt aus einem Dataset
mit Bildern aus der Forschung:

88
00:03:56,490 --> 00:04:00,270
Objekt- und Tierbilder, mit denen
ein Bild-Klassifizierer trainiert wird.

89
00:04:00,270 --> 00:04:02,430
Die Ground Truth-Label werden zeilenweise,

90
00:04:02,430 --> 00:04:04,565
die Predicted-Label
spaltenweise angeordnet.

91
00:04:04,565 --> 00:04:07,380
So entsteht eine Wahrheitsmatrix,

92
00:04:07,380 --> 00:04:11,105
an der wir bestimmte Arten von
Fehlklassifizierungen untersuchen können.

93
00:04:11,105 --> 00:04:12,610
In diesem speziellen Beispiel

94
00:04:12,610 --> 00:04:14,730
kennzeichnet das ML-Modell

95
00:04:14,730 --> 00:04:17,430
einige Katzen
fälschlicherweise als Frösche.

96
00:04:17,430 --> 00:04:19,715
Finden Sie die Frosch-Katze in dem Bild?

97
00:04:19,715 --> 00:04:22,590
Das Interessante, was 
wir an den echten Bildern

98
00:04:22,590 --> 00:04:25,360
in der Wahrheitsmatrix in
Facets Dive sehen können,

99
00:04:25,360 --> 00:04:27,040
ist, dass sich eine der Katzen,

100
00:04:27,040 --> 00:04:30,115
die das Modell für einen Frosch 
gehalten hat, bei Sichtkontrolle

101
00:04:30,115 --> 00:04:31,755
tatsächlich als Frosch erweist.

102
00:04:31,755 --> 00:04:34,050
Mit Facets Dive können wir feststellen,

103
00:04:34,050 --> 00:04:38,525
dass diese eine Fehlklassifikation keine
echte Fehlklassifikation des Modells war.

104
00:04:38,525 --> 00:04:43,870
In Wirklichkeit war es ein falsch
beschriftetes Bild aus dem Dataset.

105
00:04:43,870 --> 00:04:46,240
Mit Tools wie Facets kann man also

106
00:04:46,240 --> 00:04:48,420
neue und interessante Dinge

107
00:04:48,420 --> 00:04:50,840
über die eigenen Daten
erfahren und damit genauere

108
00:04:50,840 --> 00:04:54,000
und inklusivere Modelle für das
maschinelle Lernen entwickeln.