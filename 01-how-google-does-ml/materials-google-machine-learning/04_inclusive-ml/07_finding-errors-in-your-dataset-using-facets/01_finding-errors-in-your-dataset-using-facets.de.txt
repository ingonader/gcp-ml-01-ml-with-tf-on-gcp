Wir haben jetzt also
einige Möglichkeiten besprochen, Ihr Maschinenlernmodell mithilfe
von Messwerten inklusiver zu gestalten. Aber um Ihr Modell optimal zu nutzen, 
müssen Sie Ihre Daten wirklich verstehen. Das Problem dabei ist, dass Datasets manchmal Hunderte Millionen von Datenpunkten umfassen, von denen jeder Hunderte oder
sogar Tausende von Merkmalen aufweist. Deshalb ist es fast unmöglich, 
ein ganzes Dataset intuitiv zu verstehen. Dies lässt sich durch
Visualisierungen lösen. Sie machen Nuancen und
Informationen in großen Datasets sichtbar. In diesem Abschnitt
geht es um ein Open-Source-Tool zur Datenvisualisierung. Es heißt Facets. Facets wurde von Google entwickelt. Es dient dazu, ML-Modelle inklusiver zu gestalten. Facets besteht aus zwei Teilen: Overview und Dive. Diese Folie zeigt einen
Screenshot von Facets Overview. Es liefert einen
schnellen Überblick darüber, wie sich Werte über
die Merkmale von Datasets verteilen. Das Beispiel in dieser Folie
stammt aus UCI-Volkszählungsdaten. Die Daten von 1994
wurden aus der Datenbank der Volkszählungsbehörde entnommen. Es sind anonymisierte Daten über die US-Bevölkerung. In diesem Dataset gibt es Variablen zur Demografie und zum Arbeitsmarkt, zum Beispiel Alter und Gehalt. Das Dataset wurde vom 
Research Committee zusammengestellt. Eine typische Nutzung besteht darin, vorherzusagen, ob jemand
über 50.000 Dollar jährlich verdient. Man kann mehrere Datasets 
wie ein Trainings-Set und ein Test-Set mit der gleichen
Visualisierung vergleichen. Mit Facets kann man
häufige Probleme sichtbar machen, die das maschinelle Lernen stören:
Merkmale mit unerwarteten Werten, Merkmale, bei denen
größtenteils die Werte fehlen, mit ungleichmäßiger Werteverteilung
oder Verzerrungen zwischen Datasets. Am selben Screenshot
wie in der letzten Folie können Sie zwei numerische Merkmale des UCI-Datasets erkennen:
Kapitalgewinn und Kapitalverlust. Die Merkmale
sind nach Ungleichförmigkeit sortiert. Das am ungleichsten verteilte Merkmal steht ganz oben. Rote Zahlen 
kennzeichnen mögliche Problemfelder. Das wären hier numerische Merkmale, bei denen viele Werte null sind. Mit dem Histogramm rechts
können Sie die Verteilungen zwischen den Trainingsdaten (in Blau) und den Testdaten (in Orange) vergleichen. Mit Facets Overview kann man auch
kategorische Merkmale visualisieren. In diesem Beispiel sehen wir
eine Gliederung des Zielmerkmals, nämlich des Labels, ob jemand über 50.000 Dollar
jährlich verdient hat oder nicht. Wir sehen uns hier
insbesondere alle Fälle an, in denen das Jahresgehalt
höchstens 50.000 Dollar betrug. Aber erkennen Sie, dass etwas
an diesem Zielmerkmal verdächtig ist? Die Labelwerte zwischen
den Trainings- und Test-Datasets unterscheiden sich durch
den Punkt am Ende im Test-Set. Faces Overview hat diese Diskrepanzen bei diesem Merkmal sogar nach
dem Verteilungsabstand sortiert. Die größte Verzerrung zwischen den Trainingsdaten (blau)
und denTestdaten (orange) steht ganz oben. Wenn solche falschen Label auftreten, wird ein auf diesen Daten
trainiertes und getestetes Modell nicht richtig ausgewertet. Wenn wir uns jetzt Facets Dive ansehen, erkennen Sie in dieser Folie,
dass es eine leichte anpassbare, intuitive Oberfläche besitzt, mit der man Beziehungen
zwischen Merkmals-Datenpunkten eines Datasets betrachten kann. Bei Facets Dive
bestimmen Sie die Position, Farbe und visuelle Darstellung jedes Datenpunkts entsprechend seinen Merkmalswerten. In diesem Beispiel werden alle Datenpunkte des Test-Datasets aus der
Volkszählung in Facets Dive angezeigt. In der Animation sieht man einen Nutzer, der die Datenpunkte
nach einem Merkmal (Beziehung) einfärbt, sie in einer Dimension
nach einem stetigen Merkmal (Alter) und dann in einer anderen Dimension nach einem diskreten 
Merkmal (Familienstand) fixiert. In Facets Dive werden Bilder
mit den Datenpunkten verknüpft. Die Bilder dienen
als visuelle Darstellung. Mit anderen Worten: Es gibt hier nicht
nur kategorische und numerische Merkmale. Das Beispiel in diesem Bild stammt aus einem Dataset
mit Bildern aus der Forschung: Objekt- und Tierbilder, mit denen
ein Bild-Klassifizierer trainiert wird. Die Ground Truth-Label werden zeilenweise, die Predicted-Label
spaltenweise angeordnet. So entsteht eine Wahrheitsmatrix, an der wir bestimmte Arten von
Fehlklassifizierungen untersuchen können. In diesem speziellen Beispiel kennzeichnet das ML-Modell einige Katzen
fälschlicherweise als Frösche. Finden Sie die Frosch-Katze in dem Bild? Das Interessante, was 
wir an den echten Bildern in der Wahrheitsmatrix in
Facets Dive sehen können, ist, dass sich eine der Katzen, die das Modell für einen Frosch 
gehalten hat, bei Sichtkontrolle tatsächlich als Frosch erweist. Mit Facets Dive können wir feststellen, dass diese eine Fehlklassifikation keine
echte Fehlklassifikation des Modells war. In Wirklichkeit war es ein falsch
beschriftetes Bild aus dem Dataset. Mit Tools wie Facets kann man also neue und interessante Dinge über die eigenen Daten
erfahren und damit genauere und inklusivere Modelle für das
maschinelle Lernen entwickeln.