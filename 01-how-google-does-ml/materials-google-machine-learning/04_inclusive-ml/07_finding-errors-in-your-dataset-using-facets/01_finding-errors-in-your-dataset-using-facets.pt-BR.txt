Já cobrimos algumas maneiras de tornar seu modelo mais inclusivo
usando métricas de avaliação. Mas, para ter o melhor resultado,
você precisa entender seus dados. O desafio é que, às vezes, conjuntos de dados contêm
centenas de milhões de pontos de dados, cada um formado por centenas
ou milhares de recursos, então é quase impossível entender
todo o conjunto de dados intuitivamente. A chave é usar visualizações que ajudem a mostrar nuances
e ideias sobre conjuntos grandes de dados. Nesta seção, falarei sobre uma ferramenta aberta de visualização
de dados chamada Facets. O Facets foi desenvolvido
pelo Google e é uma forma de tornar modelos
de aprendizado de máquina mais inclusivos. O Facets é dividido em duas partes:
Overview e Dive. Neste slide, você está vendo uma tela
do Facets Overview, que mostra automaticamente
uma visão rápida das distribuições de valores
entre os recursos dos conjuntos de dados. Este exemplo vem dos dados
do censo da UCI. Os dados foram extraídos da Base de Dados da Secretaria
do Censo de 1994, que contém informações anônimas
sobre a população dos Estados Unidos. As informações nesse
conjunto de dados incluem variáveis demográficas e de emprego,
como idade e salário. Essa base de dados foi montada
pelo Comitê de Pesquisa e é usada para prever se um pessoa tem probabilidade de receber US$ 50.000 ou mais por ano. Vários conjuntos de dados,
como conjuntos de teste, podem ser comparados
na mesma visualização. Com o Facets, problemas comuns de dados
prejudiciais ao aprendizado de máquina são colocados em evidência,
como valores inesperados de recursos, recursos com altas porcentagens
de valores faltando, recursos com más distribuições ou desvio
de distribuição de conjuntos de dados. Usando a mesma tela do slide anterior, você agora está vendo
dois recursos numéricos do Conjunto de Dados do Censo da UCI:
ganho de capital e perda de capital. Os recursos são divididos
por não uniformidade, com o recurso que tem a distribuição
mais não uniforme no topo. Números em vermelho indicam
possíveis problemas. Neste caso, números com alta porcentagem
de valores definidos como zero. Este histograma na direita
permite comparar distribuições entre dados
de treinamento, em azul, e dados de teste, em laranja. O Facets Overview também permite
visualizar recursos categóricos. Neste exemplo, o que você vê é uma divisão do recurso buscado,
que é o rótulo que representa se a pessoa tem
salário anual maior que US$ 50.000 ou não. Mas estamos vendo especificamente todos os casos em que o salário anual
é menor ou igual a US$ 50.000. Mas sabia que há algo suspeito
sobre esse recurso? Observe que os valores do rótulo
são diferentes para conjuntos de dados de treinamento e teste,
pelo atraso no conjunto de teste. O Facets Overview até dividiu
essas discrepâncias pela distância de distribuição
com o recurso com mais desvio entre o treinamento em azul,
e os testes em laranja, no topo. Um erro de rótulo como esse
faria com que um modelo treinado e testado com base nos dados
não fosse avaliado corretamente. Vamos passar para o Facets Dive. Você pode ver neste slide
que ele tem uma interface fácil de customizar para explorar as relações entre pontos de dados de
diferentes recursos do conjunto de dados. Com o Facets Dive,
você pode controlar a posição, cor e representação visual de pontos de dados
com base nos valores do recurso. Mais especificamente, neste exemplo, o Facets Dive mostra
todos os pontos de dados do conjunto
de dados de teste do censo da UCI. A animação mostra
um usuário colorindo dados de acordo com um recurso,
o relacionamento, limitando uma dimensão
por um recurso contínuo, a idade, e limitando outra dimensão
por um recurso discreto, o estado civil. No Facets Dive, se os pontos de dados têm
imagens associadas, elas podem ser usadas
como representação visual. Em outras palavras, ele não é limitado
a recursos categóricos ou numéricos. O exemplo desta imagem vem de um conjunto de dados de imagem
baseado em pesquisa com vários objetos e animais do mundo
para treinar um classificador de imagens. Rótulos de dados de referência
ficam em linhas, e rótulos previstos
ficam em colunas. Essa configuração gera
uma visão de matriz de confusão que permite verificar tipos específicos
de classificações incorretas. Neste exemplo, o modelo rotula incorretamente uma baixa porcentagem de gatos
de verdade como sapos. Você consegue ver o sapo-gato
nesta imagem? O interessante de colocar
as imagens reais na matriz de confusão usando
o Facets Dive é que um dos gatos
que o modelo previu ser um sapo na verdade é um sapo
com base na inspeção visual. Com o Facets Dive,
podemos determinar que essa classificação errada não era
uma classificação errada real do modelo. Na verdade, era um dado rotulado errado
incluído em um conjunto de dados. Então, esperamos que ferramentas
como o Facets possam ajudar você a descobrir
coisas novas e interessantes sobre seus dados,
que talvez façam com que você crie modelos de aprendizado de máquina
mais precisos e inclusivos.