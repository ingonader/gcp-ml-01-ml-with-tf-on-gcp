Now, that we know how to calculate evaluation metrics of a model's predictions across subgroups, let's talk about an approach that builds on top of these metrics, in order to achieve a better performance across subgroups. The approach I'm going to introduce is known as equality of opportunity, and it goes something like this. Let's say you have a model that's intended to work across all users, irrespective of who they are or where they come from. Ideally, all users who qualify for a desirable outcome generated by our model, should have an equal chance amongst all users of being correctly classified for that desirable outcome. So, let's say we're working for a bank, and we are building a machine learning model to help determine whether or not to approve a loan. What is equality of opportunity mean in this context? Ideally, all users who qualify for a loan have an equal chance amongst all users of being correctly classified for that loan approval. In other words, the chances of a person being qualified for a loan, should be the same regardless of which protected subgroup they are part of. So, what we are seeing here is that if you keep everything about a person the same, and change them from being a member once a group to another, their chances of qualifying for the loan should remain the same. So, why should you incorporate such an approach into your machine learning system? Well, because an approach like this gives you a way to scrutinize your model, in order to discover possible areas of concern. Once you identify opportunities for improvement, you can now make this necessary adjustments to strike a better trade off between accuracy and non-discrimination, which in turn can make your machine learning model more inclusive. Let's now illustrate this approach using a toy classifier, that is not a real model, it's just a synthetic example to explain the concepts. The purpose of the model is to predict with high accuracy who will pay back the loan, and the bank can then use this model to help decide whether or not to give the loan to the applicant. So, in the diagram that you see here, the dark dots represent people who pay off the loan, and the light dots are those who wouldn't. The numbers at the top row represent credit score, which is simplified to a range of 0 to 100, where a higher score represents a higher likelihood of repaying the loan. In an ideal world, we would work with statistics that cleanly separate categories, as you can see in the example on the left. Unfortunately, it's far more common to see the situation on the right where the groups overlap. Now, a single statistic like a credit score can stand in for many different variables. You'll see later in the specialization that most machine learning models return a probability, and so the credit score here could stand in for that probability. The resulting probability from a machine learning model like credit score for example, which factor in a lot of things including income, provenance of paying debt and so on. So, the number might actually represent the likelihood that a person will pay off the loan or default. But it also might not. This is where the idea of setting a threshold can come in. Basically, you pick a particular cutoff point, and people whose credit score are below it are denied the loan, and people above it are granted the loan. As you can see in this diagram, picking the threshold requires some tradeoffs. Too low and he may grant more loans at default, too high and many people who deserve a loan won't get one. So, what is the best threshold? What threshold to use depends on your goals and motivation. One goal might be to maximize the number of correct decisions, as you can see in this diagram. On the left, the dark blue dots represent loans that were granted and paid back, and the light gray dots represent loans that were denied because they would default, all of these dots would represent correct predictions. Now on the right, you have the light blue dots which represent loans that were granted and defaulted, and dark grey dots representing loans that were denied to people that would have actually paid them off, these dots represent incorrect predictions. But some decisions are financially more costly than others. Perhaps there's a category of loans, perhaps loans for 15 year mortgages that are more profitable than other loans. So, you may not want to treat all decisions the same. So, another goal in a financial situation might be to maximize not the number of correct decisions, but the overall profit. And the bottom diagram that you're seeing here, represents the hypothetical profit based on our estimate of the profit associated with each loan. So, the question then becomes, what is the most profitable threshold, and does it match with the threshold with the most correct decisions? Questions like these become particularly thorny when a statistic like a credit score ends up distributed differently between two groups. This is where equality of opportunity can come in. The formal set up for equality of opportunity looks something like this. Let's say you have A which represents a predicted attribute. For simplicity, let's treat A as binary, and have it represent a membership of some protected group. Now, I'm not a lawyer, so I can't tell you what constitutes a protected group in your publication area, you should talk to your company's legal department to find out what is protected and what isn't. But to give you an example, in the United States, federal laws protect employees from discrimination based on age. So, depending on the application you're building, age might be a protected group. You also have a binary outcome which we'll call Y, where we can interpret the value of Y equals one as a desirable outcome. In this case, the acceptance of a loan. Consider Y in this example as your ground truth or label, but we're building a model of Y. So, we'll need to also have Y hat our predictor. In our example, the predictor is always a threshold defined using a score between zero and one. The predictor may use thresholds that depend on A, where we can use the different thresholds for different groups. So, the idea here is that individuals in A who qualify for a positive outcome, should have the same chance of getting positively classified, as individual who are not in A. More formally speaking, this desire coincides with an equal true positive rate in both groups. And this is the principle behind equality of opportunity.