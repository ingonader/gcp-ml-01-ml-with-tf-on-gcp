1
00:00:00,100 --> 00:00:03,320
Willkommen zurück.
Ich bin Andrew Zaldivar,

2
00:00:03,320 --> 00:00:07,100
Data Scientist in der Google-Gruppe
für Forschung und Maschinenintelligenz.

3
00:00:07,100 --> 00:00:09,180
Ich arbeite daran, künstliche Intelligenz

4
00:00:09,180 --> 00:00:11,490
und ML
für alle nutzbar zu machen.

5
00:00:11,490 --> 00:00:14,390
Und darüber möchte ich
in diesem Kurs sprechen.

6
00:00:14,390 --> 00:00:17,345
Bisher ging es um die Strategie
hinter dem maschinellen Lernen,

7
00:00:17,345 --> 00:00:18,845
seine Bedeutung,

8
00:00:18,845 --> 00:00:20,285
die zu lösenden Probleme

9
00:00:20,285 --> 00:00:21,635
und die praktische Umsetzung

10
00:00:21,635 --> 00:00:22,705
in Ihrem Unternehmen.

11
00:00:22,705 --> 00:00:25,165
Neben diesen technischen
und geschäftlichen Aspekten

12
00:00:25,165 --> 00:00:30,230
geht es auch darum, dass die Modelle
Ihre Nutzer fair und gleich behandeln.

13
00:00:30,230 --> 00:00:32,390
Bei der Strategie
ist es besonders wichtig,

14
00:00:32,390 --> 00:00:35,105
Systeme für maschinelles
Lernen auf Inklusion auszulegen.

15
00:00:35,105 --> 00:00:37,040
In diesem Modul zeige ich Ihnen daher

16
00:00:37,040 --> 00:00:39,590
Ursachen für "Vorurteile"
beim maschinellen Lernen.

17
00:00:39,590 --> 00:00:43,070
Manchmal entstehen diese
durch die Trainingsdaten selbst.

18
00:00:43,070 --> 00:00:45,425
Dann zeige ich Ihnen, 
wie Sie während des ganzen

19
00:00:45,425 --> 00:00:48,440
maschinellen Lernprozesses
auf Inklusion achten können,

20
00:00:48,440 --> 00:00:50,660
von der Datenexploration

21
00:00:50,660 --> 00:00:53,895
bis hin zur Auswertung der
Leistung Ihres Trainingsmodells.

22
00:00:53,895 --> 00:00:55,160
Damit genug der Vorrede.

23
00:00:55,160 --> 00:00:56,240
Wir sehen jetzt zuerst

24
00:00:56,240 --> 00:00:59,450
ein Video über die
Ursprünge von Vorurteilen beim ML

25
00:00:59,450 --> 00:01:01,775
und die Bedeutung
inklusiv ausgelegter Systeme

26
00:01:01,775 --> 00:01:03,075
für maschinelles Lernen an.

27
00:01:03,075 --> 00:01:06,150
Nach dem Video erläutere ich,
wie man die Beziehung zwischen

28
00:01:06,150 --> 00:01:08,635
den Ergebnissen des Maschinenlernsystems

29
00:01:08,635 --> 00:01:10,065
und den Nutzern verstehen kann

30
00:01:10,065 --> 00:01:13,625
und wie man daraus
Messwerte berechnet und auswertet.

31
00:01:13,625 --> 00:01:16,745
Anschließend stelle ich das
Konzept der Chancengleichheit vor,

32
00:01:16,745 --> 00:01:19,680
eine Methode,
die auf diesen Messwerten aufbaut,

33
00:01:19,680 --> 00:01:22,790
um ein adäquateres Ergebnis zu erzielen.

34
00:01:22,790 --> 00:01:25,010
Ein Ergebnis, bei dem
das Maschinenlernsystem

35
00:01:25,010 --> 00:01:27,980
die gleiche Chance hat,
ein Ergebnis richtig einzustufen,

36
00:01:27,980 --> 00:01:30,425
unabhängig von sensiblen Attributen.

37
00:01:30,425 --> 00:01:32,210
Und schließlich sind, wie wir wissen,

38
00:01:32,210 --> 00:01:33,360
maschinelle Lernsysteme

39
00:01:33,360 --> 00:01:34,360
auf Daten angewiesen.

40
00:01:34,360 --> 00:01:35,890
Damit ein Maschinenlernsystem

41
00:01:35,890 --> 00:01:39,200
optimale Ergebnisse liefern kann,
müssen Sie die Daten verstehen.

42
00:01:39,200 --> 00:01:42,320
Das gilt auch dann, wenn
man es inklusiv gestalten möchte.

43
00:01:42,320 --> 00:01:43,775
Im letzten Abschnitt werde ich

44
00:01:43,775 --> 00:01:48,440
ein Visualisierungstool für die
Lerndaten vorstellen. Es heißt Facets.

45
00:01:48,440 --> 00:01:51,515
Sie können die Feinheiten
Ihres Datasets damit untersuchen.

46
00:01:51,515 --> 00:01:53,600
Es liefert Vorschläge, worauf man

47
00:01:53,600 --> 00:01:57,760
bei der Inklusivität der
Trainingsdaten achten sollte.