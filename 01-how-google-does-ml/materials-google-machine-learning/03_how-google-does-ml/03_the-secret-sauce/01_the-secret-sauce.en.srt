1
00:00:00,000 --> 00:00:04,200
In this lecture, we're going to talk about The Secret Sauce.

2
00:00:04,200 --> 00:00:06,760
So Google is going to share The Secret Sauce with you.

3
00:00:06,760 --> 00:00:09,030
But that secret source is not code,

4
00:00:09,030 --> 00:00:10,760
it's not just an algorithm,

5
00:00:10,760 --> 00:00:15,090
it's actually this organizational know how that we've acquired over years of managing

6
00:00:15,090 --> 00:00:21,190
probably more value generating ML systems than any other company in the world.

7
00:00:21,190 --> 00:00:24,530
So if we're going to share this organizational know how,

8
00:00:24,530 --> 00:00:26,675
why start with technical ML skills?

9
00:00:26,675 --> 00:00:30,600
Well, we want you to become great ML strategists.

10
00:00:30,600 --> 00:00:33,560
And to do that, we believe that you need to get your hands dirty.

11
00:00:33,560 --> 00:00:35,285
You actually need to go up and you need to

12
00:00:35,285 --> 00:00:37,910
build some of these systems and learn about them.

13
00:00:37,910 --> 00:00:39,470
And the good news about that is that

14
00:00:39,470 --> 00:00:43,175
these technical ML skills that you're here looking for on course era,

15
00:00:43,175 --> 00:00:45,845
well, they're mostly software and data handling skills anyway.

16
00:00:45,845 --> 00:00:48,915
There are things you may already be very comfortable with.

17
00:00:48,915 --> 00:00:51,770
And as we talk about these technical skills,

18
00:00:51,770 --> 00:00:53,795
it also gives us an opportunity to leverage

19
00:00:53,795 --> 00:00:58,355
Google's experience to help you avoid some of these common pitfalls.

20
00:00:58,355 --> 00:01:02,055
What are some of these common pitfalls? I'm glad you asked.

21
00:01:02,055 --> 00:01:04,745
So here is our kind of click baity fun,

22
00:01:04,745 --> 00:01:09,415
top ten pitfalls organizations hit when they first try ML.

23
00:01:09,415 --> 00:01:12,730
And here's a list, very informally I've aggregated after

24
00:01:12,730 --> 00:01:16,880
several years of talking with new ML practitioners that come to us and they say,

25
00:01:16,880 --> 00:01:19,075
"We're so excited to this great new thing,

26
00:01:19,075 --> 00:01:20,740
it's going to be awesome."

27
00:01:20,740 --> 00:01:24,700
And then they might fall into some common pitfalls.

28
00:01:24,700 --> 00:01:28,180
I've seen it at Google, and I've seen it with our partners as well.

29
00:01:28,180 --> 00:01:30,250
First one, perhaps one of the most common,

30
00:01:30,250 --> 00:01:34,930
you thought training your own ML algorithm would be faster than writing the software.

31
00:01:34,930 --> 00:01:37,520
Usually, this is not the case.

32
00:01:37,520 --> 00:01:42,220
And the reason is that to make a great ML system beyond just the algorithm,

33
00:01:42,220 --> 00:01:44,995
you're going to need lots of things around

34
00:01:44,995 --> 00:01:48,100
the algorithm like a whole software stack to serve,

35
00:01:48,100 --> 00:01:52,743
to make sure that it's robust and it's scalable and has great up-time.

36
00:01:52,743 --> 00:01:55,875
And all of this, you're going to have to do for software anyway.

37
00:01:55,875 --> 00:01:57,910
But then if you try to use an algorithm,

38
00:01:57,910 --> 00:02:01,230
you put in additional complexities around data collection,

39
00:02:01,230 --> 00:02:04,810
training, all of that just gets little bit more complicated.

40
00:02:04,810 --> 00:02:10,810
So usually, we really push people to start with something simpler in software only.

41
00:02:10,810 --> 00:02:13,450
Next one, one of my favorites.

42
00:02:13,450 --> 00:02:16,780
You want to do ML, but you haven't collected the data yet.

43
00:02:16,780 --> 00:02:19,060
Full stop, you need the data.

44
00:02:19,060 --> 00:02:23,140
There's really no use talking about doing great ML if you have not

45
00:02:23,140 --> 00:02:27,770
collected great data or you do not have access to great data.

46
00:02:27,770 --> 00:02:29,725
And let's say you do have that data,

47
00:02:29,725 --> 00:02:30,870
you've been logging in for years,

48
00:02:30,870 --> 00:02:34,290
so it's written on some system that someone in another department controls,

49
00:02:34,290 --> 00:02:35,410
but you haven't looked at it,

50
00:02:35,410 --> 00:02:38,200
willing to bet that if you haven't looked,

51
00:02:38,200 --> 00:02:40,595
that data is not really ready to use,

52
00:02:40,595 --> 00:02:42,585
and it goes even beyond that.

53
00:02:42,585 --> 00:02:45,460
If there's not someone in your organization who's regularly

54
00:02:45,460 --> 00:02:48,635
reviewing that data or generating reports or new insights,

55
00:02:48,635 --> 00:02:53,090
if that data is not generating value already, likely,

56
00:02:53,090 --> 00:02:55,665
it's not the effort to maintain it is not being put

57
00:02:55,665 --> 00:02:59,280
in and data has this kind of magical way of going stale.

58
00:02:59,280 --> 00:03:01,175
Of all the clients I've ever talked to,

59
00:03:01,175 --> 00:03:02,815
I've never met one who

60
00:03:02,815 --> 00:03:07,505
overestimated the amount of effort it would take to collecting clean data.

61
00:03:07,505 --> 00:03:10,430
No one has ever said that was easier than I expected,

62
00:03:10,430 --> 00:03:13,780
wxpect there to be a lot of pain and friction here.

63
00:03:13,780 --> 00:03:15,160
What's the next one?

64
00:03:15,160 --> 00:03:19,130
You forgot to put and keep humans in the loop.

65
00:03:19,130 --> 00:03:22,420
So when we get into these ML systems that start to perform

66
00:03:22,420 --> 00:03:26,240
core tasks or core business processes in our organizations,

67
00:03:26,240 --> 00:03:27,670
they become really important.

68
00:03:27,670 --> 00:03:32,950
And appropriately, organizations become risk averse around these systems because they

69
00:03:32,950 --> 00:03:34,510
are the breadwinners of

70
00:03:34,510 --> 00:03:38,290
the organization and then becomes very important to mitigate this risk.

71
00:03:38,290 --> 00:03:41,020
And one of the myriad of ways we do that is we

72
00:03:41,020 --> 00:03:44,650
keep humans inside the loop so that they are reviewing the data,

73
00:03:44,650 --> 00:03:50,290
handling cases the ML did not handle very well and curating its training inputs.

74
00:03:50,290 --> 00:03:51,899
And we're going to talk about this more later,

75
00:03:51,899 --> 00:03:57,115
but this is a feature of every production ML system I know in Google,

76
00:03:57,115 --> 00:03:58,360
is that it has humans in the loop.

77
00:03:58,360 --> 00:03:59,680
What about this one?

78
00:03:59,680 --> 00:04:02,590
You launched a product whose initial value prop was

79
00:04:02,590 --> 00:04:06,430
its ML algorithm instead of some other feature.

80
00:04:06,430 --> 00:04:08,128
So this is a problem because A,

81
00:04:08,128 --> 00:04:11,510
your users probably don't care if what you're giving them is the ML,

82
00:04:11,510 --> 00:04:12,790
they just care if it's got

83
00:04:12,790 --> 00:04:15,880
that new cool feature or if its recommendations are really good.

84
00:04:15,880 --> 00:04:20,575
And, if you launch something whose initial value prop is just ML,

85
00:04:20,575 --> 00:04:22,135
it has new data to operate on.

86
00:04:22,135 --> 00:04:27,600
It needs lots of users to generate that data so it may learn how to interact better.

87
00:04:27,600 --> 00:04:30,190
What about you made a great end ML system,

88
00:04:30,190 --> 00:04:32,525
it just happens to optimize for the wrong thing.

89
00:04:32,525 --> 00:04:35,345
So imagine if Google search was optimizing for,

90
00:04:35,345 --> 00:04:38,320
let's say a user engagement as measured

91
00:04:38,320 --> 00:04:42,240
by how often someone clicked on search results. It sounds good.

92
00:04:42,240 --> 00:04:43,680
We want our users to like our product,

93
00:04:43,680 --> 00:04:45,455
we want our users to stay engaged.

94
00:04:45,455 --> 00:04:47,740
But if we optimize for how often they click,

95
00:04:47,740 --> 00:04:51,265
maybe then the ML algorithm will learn to kind of serve

96
00:04:51,265 --> 00:04:55,330
bad content because it forces users to come back, keep clicking.

97
00:04:55,330 --> 00:05:00,210
So we always want to be careful about optimizing for something that's pretty good,

98
00:05:00,210 --> 00:05:01,395
need not be perfect,

99
00:05:01,395 --> 00:05:04,135
but we will always want to look out for perverse incentives.

100
00:05:04,135 --> 00:05:06,295
So what happens if you forget to measure if

101
00:05:06,295 --> 00:05:09,355
your ML algorithm is actually improving things in the real world?

102
00:05:09,355 --> 00:05:12,865
You put it out there, you turned it on, it serves users,

103
00:05:12,865 --> 00:05:15,930
but you can't tell how much better it is,

104
00:05:15,930 --> 00:05:20,165
you can't tell if there's any uplifting customer engagement, or lifetime value.

105
00:05:20,165 --> 00:05:22,750
That's always really worry some because then how are you going to go

106
00:05:22,750 --> 00:05:25,570
back to your boss or your boss's boss and say,

107
00:05:25,570 --> 00:05:27,580
"Hey, I want to do this for another product if you

108
00:05:27,580 --> 00:05:29,500
cannot show the impact of the success."

109
00:05:29,500 --> 00:05:31,964
And then I've seen a couple of customers to this next ones,

110
00:05:31,964 --> 00:05:35,320
you confuse the ease of use and the value add of

111
00:05:35,320 --> 00:05:39,870
somebody else's pre-trained ML algorithm with building your own.

112
00:05:39,870 --> 00:05:43,320
So Google Cloud has a couple what we call ML APIs.

113
00:05:43,320 --> 00:05:45,540
For instance, with vision,

114
00:05:45,540 --> 00:05:48,010
you can send it an image and it will perform

115
00:05:48,010 --> 00:05:50,835
image classification on some predefined labels.

116
00:05:50,835 --> 00:05:53,680
Well that's great, it's super easy to use.

117
00:05:53,680 --> 00:05:55,870
You don't have to worry about any infrastructure,

118
00:05:55,870 --> 00:05:57,115
or any training data,

119
00:05:57,115 --> 00:06:00,285
or any data collection, very easy to use.

120
00:06:00,285 --> 00:06:04,435
It is a very different ballgame than if you went to start to build your own,

121
00:06:04,435 --> 00:06:10,050
especially if you want to do your own ML algorithm that does not kind of come pre canned,

122
00:06:10,050 --> 00:06:11,570
it's a lot more effort.

123
00:06:11,570 --> 00:06:15,550
We thought after we research that production ML algorithms were trained only once.

124
00:06:15,550 --> 00:06:17,825
You're like, "Hey, it's on my laptop,

125
00:06:17,825 --> 00:06:19,880
it's doing great on that data set.

126
00:06:19,880 --> 00:06:21,470
I'm basically done."

127
00:06:21,470 --> 00:06:25,480
No, you're probably about 10 percent of the way through.

128
00:06:25,480 --> 00:06:27,640
It turns out that if you're going to have

129
00:06:27,640 --> 00:06:31,120
an ML algorithm that's going to be part of your core business processes,

130
00:06:31,120 --> 00:06:32,650
it's going to be retrained many,

131
00:06:32,650 --> 00:06:35,320
many times and you're going to want to invest the effort

132
00:06:35,320 --> 00:06:39,415
to make that process very easy and seamless.

133
00:06:39,415 --> 00:06:43,685
And the final one is actually the only one these I have that

134
00:06:43,685 --> 00:06:49,680
addresses a confusion about the challenge involved an opera optimizing the ML algorithm,

135
00:06:49,680 --> 00:06:54,265
and that's, you want to design your own in-house perception, i.e.

136
00:06:54,265 --> 00:06:57,775
image or speech, or MLP classification,

137
00:06:57,775 --> 00:07:00,115
or that's natural language processing.

138
00:07:00,115 --> 00:07:03,280
So these are kind of a peculiar pitfall

139
00:07:03,280 --> 00:07:06,785
in the sense that they seem they're much easier than they really are.

140
00:07:06,785 --> 00:07:12,745
And in fact, all the algorithms we have to address these are very highly tuned from

141
00:07:12,745 --> 00:07:19,480
decades of academic research and you should almost always take one off the shelf,

142
00:07:19,480 --> 00:07:23,965
already made or already kind of defined,

143
00:07:23,965 --> 00:07:27,790
instead of trying to do your own research, it's very expensive.

144
00:07:27,790 --> 00:07:30,940
So that's a lot about it. That's a lot of pitfalls. That's a lot of problems.

145
00:07:30,940 --> 00:07:33,490
What's the good news? So the good news is,

146
00:07:33,490 --> 00:07:36,065
most of the value comes along the way.

147
00:07:36,065 --> 00:07:37,710
As you march towards ML,

148
00:07:37,710 --> 00:07:39,325
you may not get there,

149
00:07:39,325 --> 00:07:42,630
and you will still greatly improve everything you're working on.

150
00:07:42,630 --> 00:07:44,100
And if you do get there,

151
00:07:44,100 --> 00:07:48,565
ML improves almost everything it touches once you're ready.

152
00:07:48,565 --> 00:07:53,995
And think about this, if the process to build and use ML is hard for your company,

153
00:07:53,995 --> 00:07:57,935
it's likely hard for the other members of your industry, right?

154
00:07:57,935 --> 00:08:02,675
And once you have that ML enable product or internal process,

155
00:08:02,675 --> 00:08:05,320
it's going to provide the users or the consumers of

156
00:08:05,320 --> 00:08:09,370
that process great experiences that become very hard to

157
00:08:09,370 --> 00:08:12,400
duplicate or catch up to because of

158
00:08:12,400 --> 00:08:17,815
this beautiful feedback loop where it's collecting more data and learning all the time.

159
00:08:17,815 --> 00:08:24,545
So, I would like to double click into this idea that value comes along the way.

160
00:08:24,545 --> 00:08:28,770
I know it's tempting to try to jump to a fully machine learned,

161
00:08:28,770 --> 00:08:30,350
automated end to end,

162
00:08:30,350 --> 00:08:33,050
auto magic everything solution.

163
00:08:33,050 --> 00:08:34,595
We all want to make this leap,

164
00:08:34,595 --> 00:08:38,480
but it usually doesn't lead to great products organizational outcomes.

165
00:08:38,480 --> 00:08:39,740
I've seen that in Google,

166
00:08:39,740 --> 00:08:42,345
and I've seen that in our partner organizations as well.

167
00:08:42,345 --> 00:08:44,240
So what I want to do now is review

168
00:08:44,240 --> 00:08:49,000
a more realistic path and all the great things that come along the way.