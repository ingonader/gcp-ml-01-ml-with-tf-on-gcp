1
00:00:00,000 --> 00:00:04,840
In this lecture, we're going to talk about the the ML Surprise.

2
00:00:04,840 --> 00:00:07,180
By ML, or machine learning,

3
00:00:07,180 --> 00:00:09,025
what I mean is this process by which

4
00:00:09,025 --> 00:00:13,240
one computer writes a computer program to accomplish a task.

5
00:00:13,240 --> 00:00:15,460
The computer that is doing the writing figures out with

6
00:00:15,460 --> 00:00:19,930
the best program is by only looking at a set of examples.

7
00:00:19,930 --> 00:00:22,795
So, let's compare this to normal software engineering.

8
00:00:22,795 --> 00:00:25,003
Kind of this more typical approach,

9
00:00:25,003 --> 00:00:27,970
we have a human who analyzes the problem,

10
00:00:27,970 --> 00:00:29,500
writes a bunch of code, and then,

11
00:00:29,500 --> 00:00:33,485
this code becomes a program that can translate inputs to outputs.

12
00:00:33,485 --> 00:00:37,495
Maybe it's a calculator and it knows how to take two numbers and add them together.

13
00:00:37,495 --> 00:00:40,120
So, three and four produces seven.

14
00:00:40,120 --> 00:00:41,530
What happens in machine learning?

15
00:00:41,530 --> 00:00:44,695
Machine learning, we're kind of going to pull out the software engineer.

16
00:00:44,695 --> 00:00:48,910
And instead, we're going to use another computer that is only going to see many,

17
00:00:48,910 --> 00:00:53,075
many examples, many inputs paired with the desired output.

18
00:00:53,075 --> 00:01:01,085
And from these, that computer will figure out with the best "program" is to write.

19
00:01:01,085 --> 00:01:02,530
Now, obviously, this is not

20
00:01:02,530 --> 00:01:06,790
a technically correct fully mathematical academic definition of ML.

21
00:01:06,790 --> 00:01:08,140
That's fine.

22
00:01:08,140 --> 00:01:11,110
This is just going to give us the framework we need to have

23
00:01:11,110 --> 00:01:16,310
a conversation about ML in businesses for today's course.

24
00:01:16,310 --> 00:01:18,910
I want to talk about the broccoli surprise.

25
00:01:18,910 --> 00:01:22,380
It might seem like a tangent at first but it'll come back and it'll help us.

26
00:01:22,380 --> 00:01:27,580
So, when I was an undergrad, a new ice cream store opened up a couple doors down,

27
00:01:27,580 --> 00:01:30,395
and my friends and I decided to go check it out.

28
00:01:30,395 --> 00:01:32,645
We walk in, looks completely normal.

29
00:01:32,645 --> 00:01:33,850
They've got all the standard flavors.

30
00:01:33,850 --> 00:01:36,050
They've got mint, chocolate, peach.

31
00:01:36,050 --> 00:01:39,925
And then at the end, they've got this one that's the broccoli surprise.

32
00:01:39,925 --> 00:01:41,950
Being the great experimentalist I am,

33
00:01:41,950 --> 00:01:43,295
I have to try it.

34
00:01:43,295 --> 00:01:44,525
So, I asked for a sample.

35
00:01:44,525 --> 00:01:46,275
The lady gives me that tiny little scoop.

36
00:01:46,275 --> 00:01:47,810
It's white with green specks.

37
00:01:47,810 --> 00:01:49,510
It's sweet. It's creamy. It's richy.

38
00:01:49,510 --> 00:01:52,600
It's kind of just taste like vanilla. And so, I'm confused.

39
00:01:52,600 --> 00:01:54,490
There's no broccoli flavor here.

40
00:01:54,490 --> 00:01:56,645
So, I asked the lady, what's the surprise?

41
00:01:56,645 --> 00:02:00,615
And she says the surprise is there's no broccoli.

42
00:02:00,615 --> 00:02:01,810
With that in mind,

43
00:02:01,810 --> 00:02:03,265
I want to talk about the ML surprise,

44
00:02:03,265 --> 00:02:05,265
kind of leading the audience here.

45
00:02:05,265 --> 00:02:07,955
So, what I'm going to do is show you a couple of bar charts that

46
00:02:07,955 --> 00:02:11,815
portray how you would spend your effort

47
00:02:11,815 --> 00:02:14,920
in a variety of different tasks as you build

48
00:02:14,920 --> 00:02:18,805
a fully end to end ML system in your organization.

49
00:02:18,805 --> 00:02:21,025
We have things like defining the KPI,

50
00:02:21,025 --> 00:02:24,280
what you should even be trying to accomplish, collecting the data,

51
00:02:24,280 --> 00:02:28,510
building the infrastructure, optimizing the ML algorithm itself,

52
00:02:28,510 --> 00:02:34,150
and then integrating with the rest of the preexisting systems at your organization.

53
00:02:34,150 --> 00:02:38,170
Now, very informally, but from many conversations I have

54
00:02:38,170 --> 00:02:42,970
with new ML practitioners internally and with our external partners,

55
00:02:42,970 --> 00:02:48,900
I find most people really tend to focus just on optimizing the ML algorithm.

56
00:02:48,900 --> 00:02:50,470
They want to make sure they have the newest,

57
00:02:50,470 --> 00:02:53,040
coolest thing right out of the papers.

58
00:02:53,040 --> 00:02:54,970
They've tuned all the right hyperparameters.

59
00:02:54,970 --> 00:02:57,015
They have the right number of convolutional layers.

60
00:02:57,015 --> 00:03:00,295
A lot of very technical details about the ML.

61
00:03:00,295 --> 00:03:03,280
But when I look and I talk to practitioners inside

62
00:03:03,280 --> 00:03:06,859
Google that have had great success building these big systems,

63
00:03:06,859 --> 00:03:08,955
I find a very different story.

64
00:03:08,955 --> 00:03:12,130
In fact, what I find is that how optimize the ML algorithm takes

65
00:03:12,130 --> 00:03:16,195
a much smaller segment of effort than people expect.

66
00:03:16,195 --> 00:03:18,835
I've never found anyone who

67
00:03:18,835 --> 00:03:21,490
overestimated how hard it was going to

68
00:03:21,490 --> 00:03:24,235
be to get that data collection right in the first place.

69
00:03:24,235 --> 00:03:28,060
And we should really pay close attention to that data collection.

70
00:03:28,060 --> 00:03:30,145
And what I would say is infrastructure building,

71
00:03:30,145 --> 00:03:32,590
making sure that we can train our model many,

72
00:03:32,590 --> 00:03:35,800
many times and automatically and smoothly or making sure

73
00:03:35,800 --> 00:03:39,515
we can serve that model at scale to our end users.

74
00:03:39,515 --> 00:03:43,975
And in fact, these kind of more core, almost software tasks,

75
00:03:43,975 --> 00:03:47,260
end up really dominating how people spend their time

76
00:03:47,260 --> 00:03:51,125
and effort when they build these successful ML systems.

77
00:03:51,125 --> 00:03:55,465
And the final point is, once we get to ML,

78
00:03:55,465 --> 00:04:00,235
we have another advantage that everything about our users or operations are so

79
00:04:00,235 --> 00:04:05,138
well measured that we can actually spend a little bit less time defining KPIs,

80
00:04:05,138 --> 00:04:07,165
maybe a little less organizational effort.

81
00:04:07,165 --> 00:04:09,940
Because it's no longer a theoretical approach.

82
00:04:09,940 --> 00:04:11,155
We're no longer relying on

83
00:04:11,155 --> 00:04:14,635
someone's intuition from a previous slide for some market research.

84
00:04:14,635 --> 00:04:19,060
We just measured everything we need to know about our users and this gives us

85
00:04:19,060 --> 00:04:25,115
great insights to figure out not what intermediate KPIs to use,

86
00:04:25,115 --> 00:04:27,820
which is how to get to the right, ultimate one,

87
00:04:27,820 --> 00:04:31,975
like customer lifetime value or net present value.

88
00:04:31,975 --> 00:04:37,775
So, why are we learning about ML if the surprise is ML is not so important?

89
00:04:37,775 --> 00:04:41,500
So, ML is great because the path we take to get to

90
00:04:41,500 --> 00:04:45,625
it is going to yield a lot of value all along the path.

91
00:04:45,625 --> 00:04:49,420
Maybe not every problem ends in ML but many will.

92
00:04:49,420 --> 00:04:53,400
And even those that don't will benefit from going down this journey.