1
00:00:00,380 --> 00:00:03,790
Neste vídeo, vamos falar
sobre a surpresa do ML.

2
00:00:04,840 --> 00:00:07,180
Por ML, ou aprendizado de máquina,

3
00:00:07,180 --> 00:00:09,025
me refiro ao processo pelo qual

4
00:00:09,025 --> 00:00:13,210
um computador escreve um programa
para realizar uma tarefa.

5
00:00:13,210 --> 00:00:15,460
O computador que está escrevendo descobre

6
00:00:15,460 --> 00:00:19,930
qual é o melhor programa
apenas olhando um conjunto de exemplos.

7
00:00:19,930 --> 00:00:22,795
Então, vamos comparar isso à
engenharia de software normal.

8
00:00:22,795 --> 00:00:25,003
Em uma abordagem mais comum,

9
00:00:25,003 --> 00:00:27,970
um humano analisa o problema,

10
00:00:27,970 --> 00:00:29,500
escreve um código e, depois,

11
00:00:29,500 --> 00:00:33,485
esse código se torna um programa que
converte dados em resultados.

12
00:00:33,485 --> 00:00:37,495
Talvez seja uma calculadora e saiba como
pegar dois números e somá-los.

13
00:00:37,495 --> 00:00:39,750
Então, 3 e 4 geram um 7.

14
00:00:39,750 --> 00:00:41,700
O que acontece no aprendizado de máquina?

15
00:00:41,700 --> 00:00:44,695
No aprendizado de máquina,
retiramos o engenheiro de software.

16
00:00:44,695 --> 00:00:48,910
Em vez dele, usamos outro computador
que só verá

17
00:00:48,910 --> 00:00:53,075
muitos exemplos, muitos dados
emparelhados com o resultado desejado.

18
00:00:53,075 --> 00:00:59,915
E com isso, esse computador descobrirá
qual é o melhor "programa" para escrever.

19
00:01:01,085 --> 00:01:02,530
Obviamente, esta não é

20
00:01:02,530 --> 00:01:06,790
uma definição acadêmica matemática
tecnicamente correta do ML.

21
00:01:06,790 --> 00:01:08,140
Tudo bem.

22
00:01:08,140 --> 00:01:11,110
Isso nos dará a estrutura necessária
para termos

23
00:01:11,110 --> 00:01:15,560
uma conversa sobre ML nas empresas
no curso de hoje.

24
00:01:16,860 --> 00:01:18,910
Quero falar sobre a surpresa dos brócolis.

25
00:01:18,910 --> 00:01:22,380
Pode parecer superficial no começo,
mas vai ser importante depois.

26
00:01:22,380 --> 00:01:27,580
Quando eu estava na faculdade, uma
sorveteria nova foi inaugurada ali perto.

27
00:01:27,580 --> 00:01:30,015
Meus amigos e eu decidimos dar uma olhada.

28
00:01:30,395 --> 00:01:32,415
Entramos, e parecia completamente normal.

29
00:01:32,415 --> 00:01:33,850
Havia todos os sabores padrão.

30
00:01:33,850 --> 00:01:36,050
Eles tinham hortelã, chocolate, pêssego.

31
00:01:36,050 --> 00:01:39,925
Então, no fim, havia
a surpresa de brócolis.

32
00:01:40,155 --> 00:01:41,950
Como eu gosto de experimentar coisas,

33
00:01:41,950 --> 00:01:43,295
tive que provar.

34
00:01:43,295 --> 00:01:44,525
Então, pedi uma prova.

35
00:01:44,525 --> 00:01:46,275
A moça me deu aquela colherzinha.

36
00:01:46,275 --> 00:01:47,810
Era branco com manchas verdes.

37
00:01:47,810 --> 00:01:49,510
Doce. Cremoso. Consistente.

38
00:01:49,510 --> 00:01:52,600
Parecia ter gosto de baunilha.
Fiquei confuso.

39
00:01:52,600 --> 00:01:54,490
Não tinha sabor de brócolis aqui.

40
00:01:54,490 --> 00:01:56,645
Então, perguntei à moça
qual era a surpresa.

41
00:01:56,645 --> 00:01:59,265
E ela me disse que a surpresa
é que não havia brócolis.

42
00:02:00,615 --> 00:02:01,810
Com isso em mente,

43
00:02:01,810 --> 00:02:03,285
falarei sobre a surpresa do ML,

44
00:02:03,285 --> 00:02:05,265
guiando um pouco o público aqui.

45
00:02:05,265 --> 00:02:07,745
Então, vou mostrar a você
alguns gráficos de barras

46
00:02:07,745 --> 00:02:11,815
que mostram como você gastaria seu esforço

47
00:02:11,815 --> 00:02:14,920
em várias tarefas diferentes
à medida que você cria

48
00:02:14,920 --> 00:02:18,805
um sistema de ML de ponta a ponta
em sua organização.

49
00:02:18,805 --> 00:02:21,025
Podemos definir os IPDs,

50
00:02:21,025 --> 00:02:24,280
o que você deve estar tentando realizar,
coletar os dados,

51
00:02:24,280 --> 00:02:28,510
criar a infraestrutura,
otimizar o próprio algoritmo de ML

52
00:02:28,510 --> 00:02:34,150
e depois integrar com o restante
dos sistemas preexistentes da sua empresa.

53
00:02:34,150 --> 00:02:38,170
Agora, de modo muito informal,
mas a partir de muitas conversas que tenho

54
00:02:38,170 --> 00:02:43,540
com novos profissionais de ML internamente
e com nossos parceiros externos, acho que

55
00:02:43,540 --> 00:02:48,710
a maioria das pessoas tende a focar
só na otimização do algoritmo de ML.

56
00:02:48,710 --> 00:02:52,970
Elas querem ter certeza de que têm
a coisa mais nova e mais legal que existe.

57
00:02:52,970 --> 00:02:54,970
Ajustaram todos os hiperparâmetros certos.

58
00:02:54,970 --> 00:02:57,065
Têm o número ideal de
camadas convolucionais.

59
00:02:57,065 --> 00:03:00,295
Muitos detalhes técnicos sobre o ML.

60
00:03:00,295 --> 00:03:03,280
Mas quando olho e falo
com os profissionais dentro do

61
00:03:03,280 --> 00:03:06,859
Google que tiveram muito sucesso
criando esses grandes sistemas,

62
00:03:06,859 --> 00:03:08,955
encontro uma história muito diferente.

63
00:03:08,955 --> 00:03:12,260
Na verdade, o que encontro é que
otimizar o algoritmo de ML exige

64
00:03:12,260 --> 00:03:16,195
muito menos esforço
do que as pessoas esperam.

65
00:03:16,195 --> 00:03:18,835
Nunca encontrei alguém que tenha

66
00:03:18,835 --> 00:03:21,490
superestimado a dificuldade de

67
00:03:21,490 --> 00:03:24,235
acertar a coleta de dados antes de tudo.

68
00:03:24,235 --> 00:03:28,060
E devemos prestar muita atenção
nessa coleta de dados

69
00:03:28,060 --> 00:03:30,145
e na criação da infraestrutura,

70
00:03:30,145 --> 00:03:33,110
para que possamos treinar
nosso modelo muitas vezes,

71
00:03:33,110 --> 00:03:35,800
automaticamente e sem problemas,

72
00:03:35,800 --> 00:03:39,515
ou oferecer esse modelo em escala
para nossos usuários finais.

73
00:03:39,515 --> 00:03:43,975
Na verdade, esse tipo de tarefa
mais básica, quase de software,

74
00:03:43,975 --> 00:03:47,260
acaba tomando tempo e esforço

75
00:03:47,260 --> 00:03:51,125
quando elas criam esses sistemas
de ML de qualidade.

76
00:03:51,125 --> 00:03:55,465
E o ponto final é que,
quando chegamos ao ML,

77
00:03:55,465 --> 00:04:00,235
temos outra vantagem, que tudo sobre
nossos usuários ou operações é tão

78
00:04:00,235 --> 00:04:05,078
bem medido que podemos gastar
menos tempo definindo IPDs,

79
00:04:05,078 --> 00:04:07,315
e talvez menos tempo
nas tarefas organizacionais.

80
00:04:07,315 --> 00:04:09,940
Porque não é mais uma abordagem teórica.

81
00:04:09,940 --> 00:04:11,155
Não dependemos mais da

82
00:04:11,155 --> 00:04:14,635
intuição de alguém de um slide anterior
para algumas pesquisas de mercado.

83
00:04:14,635 --> 00:04:19,060
Acabamos de medir tudo o que precisamos
saber sobre nossos usuários, e isso nos dá

84
00:04:19,060 --> 00:04:25,115
ótimos insights para descobrir
não quais IPDs intermediários usar,

85
00:04:25,115 --> 00:04:27,820
mas como chegar ao
valor certo e definitivo

86
00:04:27,820 --> 00:04:31,975
como o valor da vida útil do cliente
ou o valor presente líquido.

87
00:04:31,975 --> 00:04:37,775
Por que estamos aprendendo sobre o ML se
a surpresa é que ele não é tão importante?

88
00:04:37,775 --> 00:04:41,500
O ML é ótimo porque o caminho
que tomamos para chegar a ele

89
00:04:41,500 --> 00:04:45,625
renderá muito valor ao longo do caminho.

90
00:04:45,625 --> 00:04:49,420
Talvez o ML não resolva
todos os problemas, mas resolverá vários.

91
00:04:49,420 --> 00:04:53,400
E mesmo os que não forem resolvidos
terão benefícios com essa jornada.