In this lecture, we're going to deep dive into The Path to ML. Let's examine each step a little bit more closely. Let's clarify the road map that a process or product goes through as it gets further automated and approaches and becomes ML. Let's keep in mind as we go through this, some examples from your company or your organization. Have they gone through any of these steps? How did it work out? Where did the company spend most of its time or where did it skip entirely? And do these phases seem hopeful like a constructive framework to think about? Or do they seem more like obstacles? So let's go ahead and live. For the first one, let's start with the individual contributor phase and let's examine it. So this is a great opportunity to prototype. Almost every product or process starts here. It's cheap, it's flexible, great for trying out many ideas, failing quickly and learning from that. There are some dangers of skipping this step. There's the inability to get organizational investment to scale up to a bigger effort. How are you going to convince your boss that you need a hundred people or you need to build this huge software system, if no one's even tried it, kind of manually? No one's then even that most basic prototyping. Perhaps even more worrisome, is that your organization does jump right on and then the product heads could make big incorrect assumptions, that once you've made investments are hard to change later. I've seen both of these happen. There are also dangers of lingering here too long. Imagine you've got one person who's very skilled at his or her job, and then leaves the company, maybe they retire. And all that organizational know how, walks right out the door with them. That can be a real problem. You have suddenly two weeks, you have no one's able to perform that process in the company. And then the one people more often think about at the individual contributor phase, is they just can't scale up the process to meet demand in time. You've got one person doing something, suddenly you need aid, and no one's even formalized the process. And this poor man or woman just can't answer the phone fast enough. So what happens? Well, ideally, we move on to the delegation phase. And here, we're going to increase the number of employees working on some business process to hundreds or if you're Walmart or the US Military, even to millions. What's nice about this, is it allows us to gently ramp up the investment while we maintain most of the flexibility of the previous stage when we only had one person doing it. The dangers of skipping this step. So if you skip this step, you're never forced to formalize the business process and to define success. Imagine, when we delegate. Imagine we're actually going to outsource, as an example. If you can't explain exactly what you need to happen in this business processes to someone 12 time zones away, you probably also can't explain it to a computer. Computers have even less context about what you're trying to accomplish than someone in India may. So this is a great halfway step to formalizing business processes. And also, getting organizational buy in for what is success, because this is not a cheap phase. There's also this great opportunity at this stage that human responses have an inherent diversity. And this becomes a test bed for great product learning. As each human, let's say as an example in a call center, each human answers the phone a little bit differently. And then, they have different customer outcomes. Then, in the organization, when you review that data, you can learn what's working and what's not. Then finally, great ML systems will need humans in the loop. And this is your opportunity to identify who you need. And inside Google, we have many ML systems. Many ML systems that generate a lot of value for the organization, for our customers, for our end users. And almost every single one has a team of people reviewing the algorithms, reviewing their responses, reviewing where they get confused, doing random sub-samples. Because if your ML system is very, very important, then it needs to be reviewed and you're going to have people doing this. And you should think about ML as a way to expand the impact or to scale the impact of your people, not as a way of completely removing them. Because that's a very high bar for an ML system to meet. What are the dangers of lingering too long here? I mean, the most obvious is, you're paying very high marginal cost to serve each user. When people answer phones, it's expensive. If you have someone sitting in a bank to wait someone to walk into the bank to open a mortgage, it's expensive. But we all know this. Perhaps a little bit more subtly, the more people you have in your organization, the more voices you have to say, automation is impossible. And this creates a kind of organizational lock-in, when you have so many stakeholders. Because the people have their own managers, their own H.R. reps, and so we want to win a delegate, but we want to always be moving forward. We want to always be going down this path whenever appropriate. And that leads us into the digitization phase, which is just a fancy term for getting computer systems to perform the mundane or repetitive parts of the process. And in general, the digitization is a part of automation. And in general, we think of automation economically as a way to trade upfront investment for a lower marginal cost or run rate. Now, automation gets us a lot of thing and maybe you first think about, Oh. Wait, we don't want to get rid of people. You're right. We want to scale their impact. We want to give our users a higher quality of service. And automation is a great way to do that. But because it involves so much upfront investment, it comes with its own risk. So the dangers of skipping this step. Even with a great machine learning algorithm, you will need all the infrastructure of this step to be able to serve your ML at scale. Remember, machine learning perform some core, almost numerical task but it doesn't serve that task in a website or it doesn't have unit tests of its own. And all of this stuff that comes with software, you are also going to need it for ML. And most just going to replace a little piece of your otherwise very large software stack. Also, if you skip this step, and I see many people try, you start to untangle an. IT project, which we may call software, with an ML project. And then suddenly, either one of them fails, the whole project fails. And organizationally, it's very tricky to say what really happened. And you may find that management is dis-incentivized in the future from investing, because it's so hard to untangle what's going on. So I always encourage people to try to do as much IT project, show its own success, and its own milestones, and then see ML as icing on the cake. The dangers of staying here too long. So, the other members of your industry are collecting data and they're tuning their offers, they're tuning their operation from these new insights. And this is giving them an edge. And this is giving them, this is constructing a very positive feedback loop for them. After digitization, we start to think about big data and analytics. And what we're going to do here is measure everything about your internal operations and external users. We're going to make it easy to review, summarize, deep dive, and this is a great moment to pause and reiterate your definitions of success, and then detune software algorithms that we described in the previous step. So why is this such a great opportunity to redefine success? So kind of the first stage, the initial individual contributor, all the way up to here, we've been using kind of like market research or kind of standard ways to hypothesize about what our users wants or wherever possible to apply data. But now that we're in the Big Data phase, we've automated the core process with digitization, which means that we may now extract an incredible amount of data because everything is digital for us. And with this new data, we can reassess our original definition and say, "Hey, we thought users wanted A, is that really true? Are we actually serving A correctly?" And this gives us many new insights. The dangers of skipping the step. So if you try to go from software right into ML without ever having this kind of manual insight generation phase, you're going to run into some obstacles. First, you won't be able train your ML algorithm, because your data is not clean and organized. If you cannot make a histogram of your data, your algorithm cannot effectively make that histogram either. And more or less, that's what your algorithm is doing, is it's making many, many plots and performing regression on them. So if you can't make that chart, neither can your algorithm. Also, if you skipped this step, then you won't build a measure of success. So it's hard to tell if your ML algorithm's actually improving things. So we're going to start by manually doing all these things and then when we're ready, ML will automatically be cleaning, and all be automatically acting on this clean and organized data. What happens if we stay here too long? Actually, the dangers of that are not as major as some of the other steps. As an example, Google search stayed here four years. Everyone thinks that Google search is like this really maniacally impressive ML, natural language processing algorithm. And maybe it is now. But it wasn't for many, many years. It was actually a hand-tuned algorithm. And this is actually really interesting. You should take this message to heart that like you can get very, very far without handing over everything to ML. But of course, without ML, you are going to limit the complexity of problems you can solve. And the speed at which you can solve them. So finally, let's talk about the last stage, the machine learning phase. Here, what we're going to do, is we're going to complete that feedback loop we talked about before. We're going to automate each of those blocks between measuring success and tuning the software algorithm. Eventually, this will outpaced humans ability to handle the number of inputs and the corner cases involved in your real world data, in your real world use case. Generally, roughly at Google, we expect about a 10 percent key performance indicator increase in Google products on top of all the human-hand tuning, just from ML's ability to handle each of those little details so incredibly well. And of course, the reason we're all here, what makes machine learning so fascinating is we're going to escape the limitations of human cognition in solving our business problem. We're going to get faster answers, more nuanced treatment of details, and perhaps what is most mind blowing to me, is there will be one brain learning from billions of interactions every day. Google search as an example from the last slide, is able to watch how one user is searching for new terms and apply that to searches happening for another user as it learns about the content to the world around it. And this is truly fascinating. In your organization, this will happen to. As you have one ML algorithm that is learning from many disparate interactions around it.