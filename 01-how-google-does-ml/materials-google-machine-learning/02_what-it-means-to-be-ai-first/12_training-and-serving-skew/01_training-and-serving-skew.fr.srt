1
00:00:00,240 --> 00:00:02,870
Comment bien démarrer
avec le machine learning ?

2
00:00:03,270 --> 00:00:07,814
D'après notre expérience,
le parcours client qui présente

3
00:00:07,814 --> 00:00:10,875
les plus fortes chances de réussite
consiste à sélectionner

4
00:00:10,875 --> 00:00:15,180
le cas d'utilisation pour lequel vous
effectuez une analyse manuelle des données.

5
00:00:16,510 --> 00:00:18,560
C'est ce qu'a fait Global Fishing Watch,

6
00:00:18,560 --> 00:00:21,650
une organisation à but non lucratif
dont la mission est de traquer

7
00:00:21,650 --> 00:00:22,510
la pêche illégale.

8
00:00:22,660 --> 00:00:25,005
Auparavant, l'organisation
analysait manuellement

9
00:00:25,005 --> 00:00:28,384
les sorties de pêche. Elle est ensuite
passée au machine learning.

10
00:00:28,724 --> 00:00:32,624
Aujourd'hui, elle est capable d'analyser
22 millions de points de données par jour.

11
00:00:33,384 --> 00:00:37,640
Plusieurs raisons peuvent vous pousser
à analyser manuellement vos données

12
00:00:37,640 --> 00:00:40,260
avant d'adopter le machine learning.

13
00:00:40,260 --> 00:00:43,560
Premièrement, si vous analysez
manuellement vos données,

14
00:00:43,560 --> 00:00:47,270
vous avez sûrement déjà accès
à vos données. Le plus dur est fait.

15
00:00:47,500 --> 00:00:51,235
La collecte de données est souvent l'étape
la plus longue, la plus compliquée

16
00:00:51,235 --> 00:00:54,290
et la plus risquée
d'un projet de ML.

17
00:00:54,930 --> 00:00:57,030
Si vous avez déjà accès à vos données,

18
00:00:57,030 --> 00:00:59,350
vos chances de réussite
sont donc plus élevées.

19
00:00:59,430 --> 00:01:01,780
Voilà la première raison
qui peut vous pousser

20
00:01:01,780 --> 00:01:03,535
à analyser manuellement vos données.

21
00:01:04,210 --> 00:01:07,840
Deuxièmement, si vous n'avez pas
encore accès à vos données,

22
00:01:07,840 --> 00:01:12,975
votre projet de ML implique donc
la collecte et l'évaluation des données.

23
00:01:12,975 --> 00:01:16,185
Par "évaluation", j'entends
l'attribution d'étiquettes aux données.

24
00:01:17,375 --> 00:01:20,330
L'analyse manuelle des données
peut alors être intéressante.

25
00:01:20,690 --> 00:01:23,945
En effet, si vous ne pouvez pas
analyser vos données

26
00:01:23,945 --> 00:01:27,775
pour obtenir des informations pertinentes
afin de prendre les bonnes décisions,

27
00:01:27,775 --> 00:01:30,095
alors le machine learning
n'a rien à vous offrir.

28
00:01:30,445 --> 00:01:35,680
L'analyse manuelle vous aide à échouer
rapidement pour tenter de nouvelles idées.

29
00:01:35,680 --> 00:01:38,500
N'ignorez pas cette étape d'analyse.

30
00:01:38,640 --> 00:01:43,815
Elle vous permet de savoir si vous pouvez
tirer des insights de vos données.

31
00:01:45,155 --> 00:01:48,968
Troisième raison pour laquelle
vous ne devez pas sauter cette étape :

32
00:01:50,698 --> 00:01:54,017
pour construire un bon modèle de ML,
vous devez connaître vos données.

33
00:01:54,370 --> 00:01:56,900
Comme il s'agit de la première étape,

34
00:01:56,900 --> 00:01:59,880
pourquoi ne pas les analyser
manuellement ?

35
00:02:00,550 --> 00:02:03,015
Ne passez pas directement au ML.

36
00:02:03,015 --> 00:02:05,705
Nous en parlerons plus en détail
dans le prochain module.

37
00:02:05,905 --> 00:02:11,635
Quatrièmement, le ML est une étape
vers l'automatisation et l'évolutivité.

38
00:02:12,195 --> 00:02:16,445
L'automatisation des analyses
permet leur évolutivité.

39
00:02:17,015 --> 00:02:19,105
Comme Global Fishing Watch,

40
00:02:19,105 --> 00:02:22,930
vous analysez peut-être manuellement
une petite partie des sorties de pêche,

41
00:02:22,930 --> 00:02:28,180
et vous souhaitez automatiser ce processus
pour analyser davantage de données.

42
00:02:29,720 --> 00:02:35,925
Mais sans analyses,
pas de machine learning.

43
00:02:36,395 --> 00:02:37,930
Lorsque l'on parle de ML,

44
00:02:37,930 --> 00:02:41,335
les ingénieurs pensent toute de suite
à l'apprentissage.

45
00:02:41,335 --> 00:02:46,025
Pourtant, tout l'intérêt du ML
réside dans les prédictions.

46
00:02:46,235 --> 00:02:48,380
C'est là que l'on peut
en tirer de la valeur.

47
00:02:48,590 --> 00:02:53,125
Vos modèles doivent avant tout se baser
sur la diffusion en continu des données.

48
00:02:53,415 --> 00:02:56,725
Vous devez optimiser
la diffusion en continu des données.

49
00:02:57,125 --> 00:03:00,920
Vous pensez peut-être pouvoir effectuer
des tâches comme le traitement par lot

50
00:03:00,920 --> 00:03:02,680
sur une base hebdomadaire ?

51
00:03:02,960 --> 00:03:06,445
Le problème est que la cadence
de votre activité s'accélère en permanence.

52
00:03:08,545 --> 00:03:11,800
Le biais apprentissage/invocation

53
00:03:11,800 --> 00:03:15,015
est l'une des principales causes
d'échec des produits de ML.

54
00:03:15,375 --> 00:03:18,180
Cela se produit si vous utilisez
un système de traitement

55
00:03:18,180 --> 00:03:20,895
des données d'historique
pour entraîner votre modèle.

56
00:03:21,095 --> 00:03:23,735
Il peut s'agir d'un système
de traitement par lot rédigé

57
00:03:23,735 --> 00:03:25,370
par une équipe de data scientists.

58
00:03:25,930 --> 00:03:29,640
En parallèle, vous avez un autre système
qui doit utiliser le modèle de ML

59
00:03:29,640 --> 00:03:31,070
pendant la prédiction.

60
00:03:31,780 --> 00:03:36,595
Le système qui invoque
ces prédictions est probablement

61
00:03:36,595 --> 00:03:40,100
rédigé et maintenu par votre
équipe d'ingénierie.

62
00:03:40,630 --> 00:03:44,345
Il peut être rédigé en Java
à l'aide de frameworks Web, par exemple.

63
00:03:45,315 --> 00:03:49,410
Si le modèle ne voit pas exactement

64
00:03:49,410 --> 00:03:51,790
les mêmes données pendant l'invocation

65
00:03:51,790 --> 00:03:55,450
et pendant l'apprentissage,

66
00:03:55,450 --> 00:03:57,880
ses prédictions risquent d'échouer.

67
00:03:59,010 --> 00:04:04,110
C'est ce qu'on appelle
le biais apprentissage/invocation.

68
00:04:04,640 --> 00:04:08,510
Le résultat du traitement par flux

69
00:04:08,510 --> 00:04:12,210
et le résultat du traitement par lot
doivent être identiques.

70
00:04:14,370 --> 00:04:16,647
Pour réduire les risques

71
00:04:16,647 --> 00:04:18,937
de biais apprentissage/invocation,

72
00:04:18,937 --> 00:04:22,460
on peut reprendre le code utilisé

73
00:04:22,460 --> 00:04:27,415
pour traiter les données d'historique
pendant l'apprentissage

74
00:04:27,415 --> 00:04:29,520
et le réutiliser pendant les prédictions.

75
00:04:30,310 --> 00:04:31,795
Pour cela,

76
00:04:31,795 --> 00:04:36,060
vos pipelines de données doivent
pouvoir traiter les lots et les flux.

77
00:04:36,900 --> 00:04:39,648
C'est un concept clé du traitement
de flux de données ;

78
00:04:39,768 --> 00:04:42,915
une manière de rédiger les pipelines
de données en Python,

79
00:04:42,915 --> 00:04:45,540
en Java, ou même visuellement
avec Cloud Data.

80
00:04:46,620 --> 00:04:49,185
La version Open Source est Apache Beam,

81
00:04:49,185 --> 00:04:51,035
où le "B" signifie "batch",

82
00:04:51,035 --> 00:04:53,735
et "eam" signifie "stream".

83
00:04:53,915 --> 00:04:57,291
C'est donc un système unique pour
les lots et les flux.

84
00:04:57,911 --> 00:05:01,670
En machine learning, il est très utile

85
00:05:01,670 --> 00:05:06,500
d'utiliser le même système
pour l'apprentissage et la prédiction.

86
00:05:09,080 --> 00:05:11,775
Les performances qui vous intéressent

87
00:05:11,775 --> 00:05:14,470
changent aussi entre l'apprentissage
et les prédictions.

88
00:05:15,065 --> 00:05:19,025
Pendant l'apprentissage,
nous nous intéressons surtout

89
00:05:19,025 --> 00:05:22,055
à l'évolutivité vers un volume
important de données :

90
00:05:22,055 --> 00:05:24,455
l'entraînement du distributeur,
si vous préférez.

91
00:05:25,195 --> 00:05:28,745
Pendant la prédiction, en revanche,
les performances recherchées

92
00:05:28,745 --> 00:05:32,410
concernent la vitesse de réponse
et le nombre de requêtes par seconde.

93
00:05:33,270 --> 00:05:36,120
C'est une caractéristique clé
de TensorFlow.

94
00:05:37,250 --> 00:05:40,490
Il existe de nombreux frameworks
de ML pour l'apprentissage.

95
00:05:41,149 --> 00:05:45,879
Mais les frameworks capables
d'opérationnalisation sont plus rares.