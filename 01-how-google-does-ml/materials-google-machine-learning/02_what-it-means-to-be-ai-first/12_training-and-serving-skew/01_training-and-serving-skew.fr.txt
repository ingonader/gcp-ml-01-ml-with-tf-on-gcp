Comment bien démarrer
avec le machine learning ? D'après notre expérience,
le parcours client qui présente les plus fortes chances de réussite
consiste à sélectionner le cas d'utilisation pour lequel vous
effectuez une analyse manuelle des données. C'est ce qu'a fait Global Fishing Watch, une organisation à but non lucratif
dont la mission est de traquer la pêche illégale. Auparavant, l'organisation
analysait manuellement les sorties de pêche. Elle est ensuite
passée au machine learning. Aujourd'hui, elle est capable d'analyser
22 millions de points de données par jour. Plusieurs raisons peuvent vous pousser
à analyser manuellement vos données avant d'adopter le machine learning. Premièrement, si vous analysez
manuellement vos données, vous avez sûrement déjà accès
à vos données. Le plus dur est fait. La collecte de données est souvent l'étape
la plus longue, la plus compliquée et la plus risquée
d'un projet de ML. Si vous avez déjà accès à vos données, vos chances de réussite
sont donc plus élevées. Voilà la première raison
qui peut vous pousser à analyser manuellement vos données. Deuxièmement, si vous n'avez pas
encore accès à vos données, votre projet de ML implique donc
la collecte et l'évaluation des données. Par "évaluation", j'entends
l'attribution d'étiquettes aux données. L'analyse manuelle des données
peut alors être intéressante. En effet, si vous ne pouvez pas
analyser vos données pour obtenir des informations pertinentes
afin de prendre les bonnes décisions, alors le machine learning
n'a rien à vous offrir. L'analyse manuelle vous aide à échouer
rapidement pour tenter de nouvelles idées. N'ignorez pas cette étape d'analyse. Elle vous permet de savoir si vous pouvez
tirer des insights de vos données. Troisième raison pour laquelle
vous ne devez pas sauter cette étape : pour construire un bon modèle de ML,
vous devez connaître vos données. Comme il s'agit de la première étape, pourquoi ne pas les analyser
manuellement ? Ne passez pas directement au ML. Nous en parlerons plus en détail
dans le prochain module. Quatrièmement, le ML est une étape
vers l'automatisation et l'évolutivité. L'automatisation des analyses
permet leur évolutivité. Comme Global Fishing Watch, vous analysez peut-être manuellement
une petite partie des sorties de pêche, et vous souhaitez automatiser ce processus
pour analyser davantage de données. Mais sans analyses,
pas de machine learning. Lorsque l'on parle de ML, les ingénieurs pensent toute de suite
à l'apprentissage. Pourtant, tout l'intérêt du ML
réside dans les prédictions. C'est là que l'on peut
en tirer de la valeur. Vos modèles doivent avant tout se baser
sur la diffusion en continu des données. Vous devez optimiser
la diffusion en continu des données. Vous pensez peut-être pouvoir effectuer
des tâches comme le traitement par lot sur une base hebdomadaire ? Le problème est que la cadence
de votre activité s'accélère en permanence. Le biais apprentissage/invocation est l'une des principales causes
d'échec des produits de ML. Cela se produit si vous utilisez
un système de traitement des données d'historique
pour entraîner votre modèle. Il peut s'agir d'un système
de traitement par lot rédigé par une équipe de data scientists. En parallèle, vous avez un autre système
qui doit utiliser le modèle de ML pendant la prédiction. Le système qui invoque
ces prédictions est probablement rédigé et maintenu par votre
équipe d'ingénierie. Il peut être rédigé en Java
à l'aide de frameworks Web, par exemple. Si le modèle ne voit pas exactement les mêmes données pendant l'invocation et pendant l'apprentissage, ses prédictions risquent d'échouer. C'est ce qu'on appelle
le biais apprentissage/invocation. Le résultat du traitement par flux et le résultat du traitement par lot
doivent être identiques. Pour réduire les risques de biais apprentissage/invocation, on peut reprendre le code utilisé pour traiter les données d'historique
pendant l'apprentissage et le réutiliser pendant les prédictions. Pour cela, vos pipelines de données doivent
pouvoir traiter les lots et les flux. C'est un concept clé du traitement
de flux de données ; une manière de rédiger les pipelines
de données en Python, en Java, ou même visuellement
avec Cloud Data. La version Open Source est Apache Beam, où le "B" signifie "batch", et "eam" signifie "stream". C'est donc un système unique pour
les lots et les flux. En machine learning, il est très utile d'utiliser le même système
pour l'apprentissage et la prédiction. Les performances qui vous intéressent changent aussi entre l'apprentissage
et les prédictions. Pendant l'apprentissage,
nous nous intéressons surtout à l'évolutivité vers un volume
important de données : l'entraînement du distributeur,
si vous préférez. Pendant la prédiction, en revanche,
les performances recherchées concernent la vitesse de réponse
et le nombre de requêtes par seconde. C'est une caractéristique clé
de TensorFlow. Il existe de nombreux frameworks
de ML pour l'apprentissage. Mais les frameworks capables
d'opérationnalisation sont plus rares.