Então, como você começa
no aprendizado de máquina? Em nossa experiência, vimos que
a jornada típica do cliente, a que tem mais probabilidade
de ter sucesso, é selecionar o caso de uso no qual
você faz a análise manual de dados hoje. A Global Fishing Watch fez isso, uma organização sem fins lucrativos
que tenta identificar a caça ilegal. Eles analisavam manualmente viagens de pesca, e depois
escalonavam o processamento usando aprendizado de máquina até analisar
22 milhões de pontos de dados diariamente. Então, há várias razões para passar pela análise manual de dados
para desenvolver o aprendizado de máquina. Primeiro: se estiver fazendo
análise manual de dados, você provavelmente já tem os dados,
e essa é a parte difícil. A coleta de dados geralmente
é a parte mais longa e difícil de um projeto de aprendizado de máquina
e a que tem mais chances de fracasso. Então, se você já tem os dados, suas chances de sucesso aumentaram. Então, essa é uma das razões para
passar pela análise manual de dados. Segundo: mesmo se você
não tiver os dados hoje, seu projeto de ML envolve primeiro
coletar e classificar os dados. Classificar significa
encontrar rótulos para os dados. Você precisa passar
por um estágio de análise manual. Porque se você não consegue
analisar os dados para ter material suficiente
para tomar decisões, não faz sentido
desenvolver o aprendizado de máquina. A análise manual ajuda você a falhar
rapidamente, tentar novas ideias. Portanto, não pule esta etapa de análise. A etapa de análise geralmente informa
se os dados geram insights. A terceira razão para passar pela análise
manual de dados e não ignorá-la é que, para criar um bom
modelo de aprendizado de máquina, você precisa conhecer seus dados. E já que esse é o primeiro passo, por que você não passa pelo
processo de análise manual de dados? Não pule direto para o ML. Falaremos mais sobre isso
no próximo módulo. E a quarta razão é que o ML é uma jornada
em direção à automação e ao escalonamento. Você está automatizando a análise manual
porque quer escaloná-la. Talvez como a Global Fishing Watch, você está analisando manualmente
uma pequena fração de viagens de pesca e quer automatizar isso para
poder analisar mais viagens. Mas infelizmente, se você não puder
fazer análises, não poderá fazer ML. Ao falamos sobre
aprendizado de máquina para engenheiros, eles continuam pensando em treinamento. Mas a verdadeira utilidade do aprendizado
de máquina vem durante as previsões. É quando você está extraindo valor dele. Uma coisa importante é que os modelos
precisam trabalhar com dados de streaming. Você precisa criar uma
sofisticação de dados de streaming. Se você está pensando
que poderia fazer coisas semanalmente como
processamento em lote, adivinhe. Seu negócio só está ficando mais rápido. Um motivo comum da falha em
produtos de aprendizado de máquina é algo chamado desvio de treinamento. Aqui você tinha um certo sistema
para processamento de dados históricos para que pudesse
treinar neles. Talvez fosse
um sistema de processamento em lote escrito por uma equipe de
ciência de dados. E então você tem um sistema diferente que precisa usar o modelo de aprendizado
de máquina durante a previsão. O sistema que atende
essas previsões provavelmente está escrevendo algo que a equipe de
engenharia de produção escreve e mantém. Talvez seja escrito em Java usando
bibliotecas da Web. O problema é que, a menos que o modelo veja exatamente
os mesmos dados sendo fornecidos como estava acostumado a ver
durante o treinamento, as previsões do modelo não serão precisas. Então esse é um problema chamado de
desvio de treinamento. O problema é que o resultado do
processamento de stream e do processamento em lote
precisa ser o mesmo. Então, uma maneira de reduzir
as chances desse problema, uma maneira de reduzir as chances
de um desvio de treinamento é pegar o mesmo código
que foi usado para processar dados históricos durante o treinamento
e reutilizá-los durante as previsões. Mas para que isso aconteça, seus canais de dados
precisam processar o stream e o fluxo. Esta é uma visão essencial
por trás do fluxo de dados. Uma maneira de criar
canais de dados em Python, Java ou até mesmo visualmente
com a marca Cloud Data. O código aberto é o Apache Beam. Em que "B" significa lote e "eam" significa stream. Então, um único sistema
para fazer lote e stream. Porque no aprendizado de máquina,
isso é útil. Eles usam o mesmo sistema
no treinamento e na previsão. As métricas de desempenho
importantes para você também mudam
entre treinamento e previsões. Durante o treinamento, o aspecto
de desempenho mais importante é o escalonamento para muitos dados. Treinamento de distribuidores,
se assim preferir. No entanto, durante a previsão, o principal aspecto de desempenho
é a velocidade de resposta, QPS alta. Portanto, este é um insight essencial
por trás do TensorFlow. Há muitas bibliotecas de
aprendizado de máquina para treinamento. Nem todas são igualmente capazes
de operacionalizar.