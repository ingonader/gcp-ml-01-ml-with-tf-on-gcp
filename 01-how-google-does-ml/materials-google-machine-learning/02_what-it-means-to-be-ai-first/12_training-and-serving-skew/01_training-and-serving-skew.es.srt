1
00:00:00,000 --> 00:00:03,270
¿Cómo pueden comenzar
con el aprendizaje automático?

2
00:00:03,270 --> 00:00:07,814
Según nuestra experiencia,
la ruta típica de un cliente

3
00:00:07,814 --> 00:00:10,875
la que tiene más
probabilidades de tener éxito

4
00:00:10,875 --> 00:00:14,050
es seleccionar un caso práctico
en el que los datos

5
00:00:14,050 --> 00:00:16,380
se analizan manualmente
en la actualidad.

6
00:00:16,690 --> 00:00:18,900
Esto es lo que hicieron
en Global Fishing Watch

7
00:00:18,900 --> 00:00:22,740
una organización sin fines
de lucro, para identificar la caza furtiva.

8
00:00:22,740 --> 00:00:24,300
Solían analizar de forma manual

9
00:00:24,300 --> 00:00:27,220
los viajes de pesca,
y luego escalaron el procesamiento

10
00:00:27,220 --> 00:00:31,070
mediante el AA hasta llegar
a analizar 22 millones

11
00:00:31,070 --> 00:00:32,730
de puntos de datos diariamente.

12
00:00:33,585 --> 00:00:36,224
Así que hay muchas razones para pasar

13
00:00:36,224 --> 00:00:40,400
por el análisis manual de datos
para llegar al aprendizaje automático.

14
00:00:40,400 --> 00:00:43,910
Número uno, si realizan
un análisis manual de los datos

15
00:00:43,910 --> 00:00:47,600
probablemente ya tienen
los datos y esa es la parte difícil.

16
00:00:47,600 --> 00:00:50,840
La recopilación de datos
suele ser la parte más larga y complicada

17
00:00:50,840 --> 00:00:54,605
de un proyecto de AA
y la que probablemente fallará.

18
00:00:54,605 --> 00:00:57,110
Así que, si ya tienen los datos

19
00:00:57,110 --> 00:00:59,480
sus probabilidades de éxito aumentan.

20
00:00:59,480 --> 00:01:04,190
Esa es una razón para pasar
por el análisis manual de datos.

21
00:01:04,190 --> 00:01:07,820
La segunda razón,
aún si no tienen los datos hoy

22
00:01:07,820 --> 00:01:13,205
y su proyecto de AA implica
primero recopilar y calificar los datos

23
00:01:13,205 --> 00:01:16,265
calificar significa
encontrar etiquetas para los datos

24
00:01:17,325 --> 00:01:20,375
les conviene pasar
por la etapa de análisis manual.

25
00:01:20,375 --> 00:01:23,710
La razón es que,
si no pueden analizar sus datos

26
00:01:23,710 --> 00:01:27,595
para obtener entradas
razonables a fin de tomar decisiones

27
00:01:27,595 --> 00:01:30,145
no tiene sentido realizar el AA.

28
00:01:30,145 --> 00:01:35,790
El análisis manual los ayuda
a probar nuevas ideas cuando fallan.

29
00:01:35,790 --> 00:01:38,500
No omitan este paso de análisis.

30
00:01:38,500 --> 00:01:44,105
El análisis les dirá si se pueden
obtener estadísticas con los datos.

31
00:01:44,925 --> 00:01:48,868
La tercera razón por la que deberían
realizar el análisis manual de los datos

32
00:01:48,868 --> 00:01:52,307
y no omitirlo
es que para crear un buen modelo de AA

33
00:01:52,307 --> 00:01:54,320
tienen que conocer sus datos.

34
00:01:54,320 --> 00:01:56,660
Y como ese es el primer paso

35
00:01:56,660 --> 00:02:00,220
¿por qué no llevar a cabo el proceso
de análisis manual de datos?

36
00:02:00,550 --> 00:02:03,015
No pasen directamente al AA.

37
00:02:03,015 --> 00:02:05,725
Hablaremos más
sobre esto en el siguiente módulo.

38
00:02:05,725 --> 00:02:09,585
La cuarta razón
es que el AA es una transición

39
00:02:09,585 --> 00:02:12,195
hacia la automatización y el escalamiento.

40
00:02:12,195 --> 00:02:16,265
Están automatizando el análisis
manual porque quieren que escale.

41
00:02:16,805 --> 00:02:19,105
Tal vez, como Global Fishing Watch

42
00:02:19,105 --> 00:02:23,440
analizan de forma manual una pequeña
fracción de viajes de pesca

43
00:02:23,440 --> 00:02:28,180
y quieren automatizarlo para poder
escalar y así analizar una gran cantidad.

44
00:02:29,900 --> 00:02:35,475
En pocas palabras, si no pueden
realizar análisis, no podrán usar el AA.

45
00:02:36,105 --> 00:02:38,720
Cuando mencionamos el AA a los ingenieros

46
00:02:38,720 --> 00:02:41,305
solo piensan en entrenamiento.

47
00:02:41,305 --> 00:02:46,235
Pero el uso real del AA
está en las predicciones.

48
00:02:46,235 --> 00:02:48,590
Ahí es donde les ofrece más valor.

49
00:02:48,590 --> 00:02:53,295
Un aspecto clave es que sus modelos
deben trabajar con datos de transmisión.

50
00:02:53,295 --> 00:02:56,965
Tienen que lograr una sofisticación
en la transmisión de datos.

51
00:02:56,965 --> 00:02:59,920
Si creen que pueden hacer las cosas
una vez a la semana

52
00:02:59,920 --> 00:03:02,960
como procesamiento por lotes,
adivinen qué.

53
00:03:02,960 --> 00:03:06,165
Su negocio solo será más rápido.

54
00:03:08,545 --> 00:03:11,830
Una razón común
de por qué fallan los productos de AA

55
00:03:11,830 --> 00:03:15,305
es por algo llamado desviación
entre el entrenamiento y la entrega.

56
00:03:15,305 --> 00:03:17,910
Es cuando tienen
un determinado sistema para procesar

57
00:03:17,910 --> 00:03:20,895
los datos históricos
para entrenar en ellos.

58
00:03:20,895 --> 00:03:25,395
Tal vez era un procesamiento por lotes
escrito por un equipo de ciencia de datos.

59
00:03:25,405 --> 00:03:28,380
Y, luego, tienen un sistema diferente

60
00:03:28,380 --> 00:03:31,840
que necesita usar
el modelo de AA durante la predicción.

61
00:03:31,840 --> 00:03:34,890
El sistema que entrega estas predicciones

62
00:03:34,890 --> 00:03:40,575
tal vez está en un formato que su equipo
de ingeniería escribe y mantiene.

63
00:03:40,575 --> 00:03:44,700
Quizá está escrito
en Java con marcos de trabajo web.

64
00:03:45,360 --> 00:03:46,965
El problema es que

65
00:03:46,965 --> 00:03:51,060
a menos que el modelo vea
los mismos datos en la entrega

66
00:03:51,060 --> 00:03:55,150
que estaba acostumbrado
a ver durante el entrenamiento

67
00:03:55,150 --> 00:03:58,200
las predicciones
del modelo serán erróneas.

68
00:03:58,930 --> 00:04:04,250
Es un problema denominado desviación
entre el entrenamiento y la entrega.

69
00:04:04,250 --> 00:04:08,870
El problema es que el resultado
del procesamiento de transmisión

70
00:04:08,870 --> 00:04:12,530
y el resultado del procesamiento
por lotes tiene que ser el mismo.

71
00:04:14,230 --> 00:04:17,860
Una forma de disminuir
las probabilidades de este problema

72
00:04:17,860 --> 00:04:21,737
y reducir la probabilidad de desviación
entre el entrenamiento y la entrega

73
00:04:21,737 --> 00:04:25,260
es tomar el mismo código que se utilizó
para procesar los datos históricos

74
00:04:25,260 --> 00:04:30,125
durante el entrenamiento
y reutilizarlo durante las predicciones.

75
00:04:30,125 --> 00:04:31,840
Pero para que ocurra eso

76
00:04:31,840 --> 00:04:36,375
sus canalizaciones de datos tienen
que procesar por lotes y transmisión.

77
00:04:36,975 --> 00:04:39,330
Este es un punto clave
detrás del Dataflow.

78
00:04:39,330 --> 00:04:42,978
Una forma de crear
canalizaciones de datos en Python

79
00:04:42,978 --> 00:04:46,125
Java o incluso de forma
visual con Cloud Dataproc.

80
00:04:46,125 --> 00:04:48,750
Su código abierto es Apache Beam.

81
00:04:48,750 --> 00:04:51,195
Donde la “B” significa lote (batch)

82
00:04:51,195 --> 00:04:53,935
y el resto, “eam”, es transmisión (stream).

83
00:04:53,935 --> 00:04:57,465
Entonces, un solo sistema
para procesar por lotes y transmitir

84
00:04:57,465 --> 00:05:03,511
porque en el aprendizaje automático
es útil usar el mismo sistema

85
00:05:03,511 --> 00:05:06,720
en el entrenamiento y la predicción.

86
00:05:09,230 --> 00:05:11,870
Las métricas de rendimiento importantes

87
00:05:11,870 --> 00:05:14,755
también cambian
entre entrenamiento y predicciones.

88
00:05:14,755 --> 00:05:22,180
Durante el entrenamiento, un aspecto clave
del rendimiento es escalar a muchos datos.

89
00:05:22,180 --> 00:05:24,745
Entrenamiento distribuido,
si lo prefieren.

90
00:05:25,275 --> 00:05:31,265
En la predicción, el aspecto clave del
rendimiento es la velocidad de respuesta.

91
00:05:31,265 --> 00:05:32,585
Una QPS alta.

92
00:05:33,115 --> 00:05:36,650
Este es un aspecto
clave detrás de TensorFlow.

93
00:05:36,650 --> 00:05:40,890
Muchos marcos de trabajo
de AA existen para el entrenamiento.

94
00:05:40,890 --> 00:05:46,000
No muchos son
capaces de la operacionalización.