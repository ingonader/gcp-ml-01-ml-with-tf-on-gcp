1
00:00:00,000 --> 00:00:04,810
The Google Translate app lets you point a phone camera at a street sign,

2
00:00:04,810 --> 00:00:07,485
and it translates the sign for you.

3
00:00:07,485 --> 00:00:13,260
This is a good example of a combination of several models that is quite intuitive.

4
00:00:13,260 --> 00:00:15,360
One model to find the sign,

5
00:00:15,360 --> 00:00:17,945
another model to read the sign,

6
00:00:17,945 --> 00:00:21,395
to do optical character recognition on it.

7
00:00:21,395 --> 00:00:24,835
A third model, to translate the sign or

8
00:00:24,835 --> 00:00:30,975
maybe a third model to detect the language and a fourth model to translate the sign.

9
00:00:30,975 --> 00:00:35,985
And a fifth model to superimpose the translated text.

10
00:00:35,985 --> 00:00:42,640
Perhaps even a sixth model to select the font to use.

11
00:00:42,690 --> 00:00:48,050
Smart Reply is a feature of inbox and Gmail,

12
00:00:48,050 --> 00:00:54,825
where the email program suggests three possible responses to received emails.

13
00:00:54,825 --> 00:00:56,465
This is in my view,

14
00:00:56,465 --> 00:01:00,385
the most sophisticated ML model in production today.

15
00:01:00,385 --> 00:01:03,745
Why do you think that is?

16
00:01:03,745 --> 00:01:06,975
It's a sequence to sequence model, in other words,

17
00:01:06,975 --> 00:01:09,870
it takes a received email as an input and

18
00:01:09,870 --> 00:01:12,980
generates a response to the email as the output.

19
00:01:12,980 --> 00:01:17,055
And text, as we'll see later in the specialization,

20
00:01:17,055 --> 00:01:21,705
is usually thought of as a sequence of words.

21
00:01:21,705 --> 00:01:24,190
The machine learning model here,

22
00:01:24,190 --> 00:01:27,160
needs to understand a small body of text,

23
00:01:27,160 --> 00:01:33,270
the incoming email and predict three dissimilar answers.

24
00:01:33,270 --> 00:01:38,580
We will look at sequence models in the last but one course of the specialization.

25
00:01:38,580 --> 00:01:42,000
We have lots of ground to cover before we get there.