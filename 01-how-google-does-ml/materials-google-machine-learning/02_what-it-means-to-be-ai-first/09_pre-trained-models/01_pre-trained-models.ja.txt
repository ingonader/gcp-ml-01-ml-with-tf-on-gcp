アートネットはTensorFlowを使って
カスタム画像モデルを構築しました 画像の左側にありますね しかし だんだんその必要も
なくなってきました Googleではトレーニング済みの 機械学習サービスを多数公開しています たとえば 会話の文字起こしをする際 Speech APIを使えば音声データの収集 トレーニングや予測は必要ありません このようなトレーニング済みのモデルが
たくさんあります トレーニング済みモデルは ユーザー入力を
機械学習で置き換える優れた方法です トレーニング済みモデルの例を紹介します オカドは世界最大級のネットスーパーです イギリスの会社です 以前は 顧客がメールで発注していました メールは読まれてから 担当部署に送られ また読まれます スケーラビリティがありませんね そこで オカドは
自然言語処理を利用しました メールから感情や内容を抽出し 何について書かれているか 構文まで認識できるようになりました この技術によってオカドは
メールの内容を解析し タグ付けして 担当者に送り 優先度や内容を効率的に
把握できるようになりました しかし近年 顧客はウェブサイトに
アクセスしなくなっています メールを送ることも嫌がります 直接話したいのです 欲しい情報をすぐに得たいというわけです 人間が電話応対していては
スケーラビリティがありません ガートナーによると数年のうちに 対話型インターフェースの利用が 
モバイルアプリでも増えるとのことです この場合 Speech APIを使って 会話を文字に起こして認識するのでしょうか そうではありません Dialogflowという高度な
対話型エージェントツールを使います 画面上のエージェントに注目してください 「いらっしゃいませ」と言います 顧客がこう答えます 「ベーコンとチーズのピザを1つ」 それに反応し Dialogflowは ピザ注文という趣旨の
JSONメッセージを作成し ベーコンとチーズのトッピングを追加します 次にエージェントは 「サイズは何にしますか？」と聞きます 必須事項の1つです Lサイズと標準クラストが追加され
「オリーブも追加」と言われます 今度はトッピングにオリーブが追加されます 高度な対話型のインターフェースの会話から JSON形式のメッセージが
作成されていきます この非常に構造化されたメッセージが 従来と同じ働きをするアプリに
入力されますが ユーザー入力は 顧客のプラットフォーム上の操作で
行われたのではなく 対話型インターフェースによって行われました