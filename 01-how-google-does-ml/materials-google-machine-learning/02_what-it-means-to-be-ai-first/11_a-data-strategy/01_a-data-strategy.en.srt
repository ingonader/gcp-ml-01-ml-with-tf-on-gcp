1
00:00:02,010 --> 00:00:04,790
Reimagine what data can help you do.

2
00:00:06,940 --> 00:00:11,500
I'm going to be using Google Maps
to illustrate several key points.

3
00:00:11,500 --> 00:00:13,720
Take this map for example.

4
00:00:13,720 --> 00:00:18,430
Every morning I glance at my phone, and
it tells me the way to get to work.

5
00:00:18,430 --> 00:00:20,470
There are three possible routes.

6
00:00:20,470 --> 00:00:23,960
And today,
the highlighted route is the fastest.

7
00:00:23,960 --> 00:00:26,210
Sometimes I do go to Google Seattle,

8
00:00:26,210 --> 00:00:29,310
crossing the floating bridge
across Lake Washington.

9
00:00:29,310 --> 00:00:33,050
And Maps tells me, helpfully,
that the bridge is closed today.

10
00:00:34,110 --> 00:00:35,600
So is this machine learning?

11
00:00:37,350 --> 00:00:41,030
You could think of this as
being just a set of rules.

12
00:00:41,030 --> 00:00:46,500
Sure, Google has to collect a lot of
data to make this use case possible.

13
00:00:46,500 --> 00:00:52,270
Where the roads are for one,
the traffic on each road, bridge closures.

14
00:00:52,270 --> 00:00:57,606
But the algorithm itself,
routing algorithms between point A and

15
00:00:57,606 --> 00:01:03,431
point B subject to a set of constraints,
that is just the A* algorithm.

16
00:01:03,431 --> 00:01:08,350
The A* algorithm is started
undergraduate computer science classes.

17
00:01:08,350 --> 00:01:11,150
So it's not that complex
once you have the data.

18
00:01:11,150 --> 00:01:14,750
This is the kind of thing you can do for
whole countries at a time.

19
00:01:14,750 --> 00:01:18,240
Get data on the road network,
provide routing directions.

20
00:01:19,510 --> 00:01:23,370
Traffic and bridge closures are a little
more difficult in that you have to work

21
00:01:23,370 --> 00:01:26,000
with a bunch of smaller
government entities.

22
00:01:26,000 --> 00:01:29,830
But it's still not such
a huge data problem.

23
00:01:29,830 --> 00:01:34,633
The logic, once you have the data,
seems to be quite tractable.

24
00:01:36,825 --> 00:01:41,350
But now take the case in the middle,
still Maps.

25
00:01:41,350 --> 00:01:45,080
I was in Japan, making my way from
my hotel to the Google office.

26
00:01:46,860 --> 00:01:49,809
I'm in a subway station called Roppongi,
and

27
00:01:49,809 --> 00:01:53,980
Maps tells me that I'm on floor
number two of the subway station.

28
00:01:55,360 --> 00:01:56,020
How does it know?

29
00:01:57,430 --> 00:02:02,640
Whatever the data sources it uses,
wi-fi points, barometric pressure,

30
00:02:02,640 --> 00:02:08,650
typical walking speed, it's pretty obvious
that this cannot be a simple set of rules.

31
00:02:10,000 --> 00:02:13,568
Plus the relevant data
to train the model and

32
00:02:13,568 --> 00:02:17,916
the relevant data to keep
the model remaining fresh.

33
00:02:17,916 --> 00:02:19,090
Once you have the data,

34
00:02:19,090 --> 00:02:22,980
you're now going to use machine learning
to sidestep having to write the logic.

35
00:02:24,300 --> 00:02:29,005
Maps here is anticipating that
you might want to know if you

36
00:02:29,005 --> 00:02:31,703
are in a multi-story building.

37
00:02:31,703 --> 00:02:33,360
What else can Maps anticipate?

38
00:02:35,170 --> 00:02:38,670
Take the map on the right, still in Japan.

39
00:02:38,670 --> 00:02:41,920
I glance at my phone,
in between meetings, and

40
00:02:41,920 --> 00:02:43,580
notice that I was getting
a recommendation.

41
00:02:44,780 --> 00:02:48,870
Maps is now connecting a past history,
that I like art, that I like museums, and

42
00:02:48,870 --> 00:02:51,440
that I am in Japan,
to now recommend things to me.

43
00:02:52,450 --> 00:02:54,920
This is even more of a data problem.

44
00:02:54,920 --> 00:02:59,590
The machine learning is what allows
the original limited how to get from point

45
00:02:59,590 --> 00:03:05,640
A to point B, how to take that to
now become a virtual assistant.

46
00:03:05,640 --> 00:03:09,920
Personalization of the Maps service is
possible only with machine learning.

47
00:03:11,090 --> 00:03:15,407
So machine learning is about
scaling beyond handwritten rules.

48
00:03:16,700 --> 00:03:21,680
But then you start being able to do
things that you could never achieve

49
00:03:21,680 --> 00:03:24,410
if you were writing handwritten rules.

50
00:03:24,410 --> 00:03:27,030
So think back to your business.

51
00:03:27,030 --> 00:03:31,860
Your business analysts are essentially
looking at the bulk of your business.

52
00:03:31,860 --> 00:03:35,140
That's akin to the use case on the left,

53
00:03:35,140 --> 00:03:37,940
the stuff that everybody
in the county needs.

54
00:03:37,940 --> 00:03:39,640
One set of rules for everyone.

55
00:03:40,750 --> 00:03:44,940
You might be thinking of machine learning
as a way to do the things in the middle.

56
00:03:44,940 --> 00:03:48,360
Of being able to take the data
that you happen to have, and

57
00:03:48,360 --> 00:03:49,740
training a machine learning model.

58
00:03:50,900 --> 00:03:55,231
But think of machine learning as a way to
get to the kinds of things on the right.

59
00:03:56,410 --> 00:04:01,350
Of being able to personalize your
services for each one of your customers.

60
00:04:02,880 --> 00:04:05,610
And notice a question at the bottom
of the card on the right,

61
00:04:06,990 --> 00:04:11,670
asking the user,
is this card useful right now?

62
00:04:11,670 --> 00:04:15,140
Asking for
user feedback to keep improving the model.

63
00:04:16,880 --> 00:04:20,530
What's needed though,
in this transformation from the left,

64
00:04:20,530 --> 00:04:24,946
which is quite generic, to the right,
which is quite personalized?

65
00:04:24,946 --> 00:04:26,723
What's needed?

66
00:04:28,722 --> 00:04:31,906
Data and lots of it.

67
00:04:31,906 --> 00:04:34,870
The rules and
models are actually quite simple.

68
00:04:35,940 --> 00:04:40,020
So if machine learning is a rocket engine,
data is the fuel.

69
00:04:41,050 --> 00:04:46,728
As we get into complex models and various
ways of tuning a model to get better and

70
00:04:46,728 --> 00:04:51,734
better performance, it can be very
easy to lose sight of a key point.

71
00:04:51,734 --> 00:04:54,791
Data wins every time.

72
00:04:56,927 --> 00:05:01,367
So given the choice between more data and
more complex models,

73
00:05:01,367 --> 00:05:05,010
spend your energy collecting more data.

74
00:05:05,010 --> 00:05:10,560
And by that I mean collecting not just
more quantity, also more variety.

75
00:05:10,560 --> 00:05:13,532
For example, imagine that your
data consists of these fractals.

76
00:05:13,532 --> 00:05:18,475
If you're zoomed way in you won’t see
the patterns, you don’t have enough data.

77
00:05:18,475 --> 00:05:21,117
So you'd end up sticking
to very complex rules.

78
00:05:21,117 --> 00:05:25,247
But as you get more and more data,
hopefully you fill out the domain and

79
00:05:25,247 --> 00:05:28,337
the overall pattern starts
to become more evident.

80
00:05:28,337 --> 00:05:33,100
So ML strategy is first and
foremost a data strategy.