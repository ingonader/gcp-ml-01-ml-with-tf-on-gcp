We looked at machine learning and said that it was a way to derive repeated predictive insights from data. Then, we talked about the two stages of ML, a training phase, where you teach the algorithm using labeled examples, and a prediction or inference stage, where you use a trained model to make inferences and new data. We then looked at a few examples of machine learning in action, photos, translate, Smart Reply, all from Google products. So, how do you get to the point where your company is innovating like this in machine learning? Our execs had a unique answer to the question of what kinds of problems can machine learning solve. This is Eric Schmidt, the Executive Chairman of the board at Google. He's talking about the new transformation going on at Google, where we're becoming an AI-first company. "Machine learning," says Eric, "This is the next transformation. The programming paradigm is changing. It's not programming a computer. You teach a computer to learn something and then it does what you want." Now, this seems strange. When you say ML to most people, they think predictions from data, but notice that there's nothing in Eric's quote about data. He's talking about machine learning as a way to replace programming. ML, according to Eric, is about logic, not just about data. What does he mean? Consider search. This is, of course, our flagship application here at Google. If you're typing "Giants", should we show you the San Francisco Giants or the New York Giants? How would you do it? A few years ago, this is how Google search worked. There were a bunch of rules that are part of the search engine code base to decide which sports team to show a user. If they're query is giants, and the users in the Bay Area, show them results about San Francisco Giants. If the user is in the New York area, show them results about New York Giants. If they're anywhere else, show them results about tall people, and this is just for one query. Multiply this by the large varieties of queries that people make, and you can imagine how complex the whole code base have become. The code base is getting unwieldy because handwritten code, hand-coded rules are really hard to maintain. So, why not to try machine learning? Machine learning scales better because it's automated. We knew when we showed people results which of the links they actually clicked on. So, how about training a machine learning model so that it could do the search ranking? That was the essential idea behind RankBrain, a deep neural network for search ranking. It outperformed many human built signals. We could replace many of the hand-coded rules with machine learning. And the neural network ended up improving our search quality dramatically, plus the system could continually improve itself based on what users actually preferred. Replacing heuristic rules by ML, that's what ML is about. So, what kinds of problems can you solve with ML? Answer, anything for which you are writing rules today. It's not just about predictive analytics. Google Search is not a predictive analytics application, but we use machine learning for it. Notice that saying that machine learning is a way to replace rules, notice that this is a far more expansive answer to what kinds of problems can machine learning solve. So, that's what we mean when we say Google is an AI-first company. We think of machine learning as a way to scale, to automate, to personalize. Think about all the heuristic rules you're coding up today. Provided you can collect the right data, you may be able to do it using machine learning. The way you think about problems changes when you do this, you don't think about coding up rules, you think about training models based on data. You don't think about fixing bug reports by adding your rules. You think in terms of continuously training the model as you get new data. And instead of thinking about applying specific rules to specific inputs, you instead think in terms of deploying models at scale so that you can make predictions.