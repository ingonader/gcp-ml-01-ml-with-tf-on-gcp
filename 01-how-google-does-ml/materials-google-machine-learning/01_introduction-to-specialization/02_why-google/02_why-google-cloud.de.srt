1
00:00:00,000 --> 00:00:04,040
Eine der wichtigsten Lektionen,
die wir im Laufe der Zeit gelernt haben,

2
00:00:04,040 --> 00:00:08,225
ist, dass man auch die Bereitstellung von
maschinellem Lernen bedenken sollte,

3
00:00:08,225 --> 00:00:12,540
also ML-Bereitstellung,
und nicht nur ML-Training.

4
00:00:12,540 --> 00:00:15,090
Die meisten Menschen
denken bei maschinellem Lernen

5
00:00:15,090 --> 00:00:19,080
an die komplexe Pipeline
links in diesem Diagramm.

6
00:00:19,080 --> 00:00:21,080
Bestimmt verbringen Sie

7
00:00:21,080 --> 00:00:23,520
als Data Engineer oder Data Scientist

8
00:00:23,520 --> 00:00:26,290
hier sehr viel Zeit.

9
00:00:26,290 --> 00:00:28,300
Den Hauptgrund für maschinelles Lernen

10
00:00:28,300 --> 00:00:31,810
finden Sie jedoch auf der 
rechten Seite des Diagramms.

11
00:00:31,810 --> 00:00:35,365
Sie möchten diese Vorhersagen
Entscheidungsträgern bereitstellen –

12
00:00:35,365 --> 00:00:39,450
z. B. über Notebooks,
Dashboards, Anwendungen und Berichte.

13
00:00:39,450 --> 00:00:43,220
Es geht um die
Operationalisierung eines ML-Modells,

14
00:00:43,220 --> 00:00:45,680
sprich ein trainiertes Modell auszuwählen

15
00:00:45,680 --> 00:00:49,645
und an den Punkt zu gelangen, an dem diese
Vorhersagen bereitgestellt werden können.

16
00:00:49,645 --> 00:00:52,531
Die Operationalisierung
eines ML-Modells ist nicht einfach

17
00:00:52,531 --> 00:00:56,535
und viele Projekte schaffen es
nicht bis zu diesem Prognosestadium.

18
00:00:56,535 --> 00:00:59,202
Eine Lektion, die wir
bei Google gelernt haben, ist,

19
00:00:59,202 --> 00:01:02,950
dass wir, um die Fehlerwahrscheinlichkeit
zu verringern, darauf achten müssen,

20
00:01:02,950 --> 00:01:09,290
Batch-Daten und Streamingdaten
gleichermaßen verarbeiten zu können.

21
00:01:09,290 --> 00:01:11,735
Die Open Source von Cloud Data Flow

22
00:01:11,735 --> 00:01:13,590
in diesem Diagramm ist Apache Beam.

23
00:01:13,590 --> 00:01:18,220
Cloud Data Flow hilft uns dabei, Batch-
und Streamingdaten gleich zu behandeln.

24
00:01:18,220 --> 00:01:21,935
Cloud Date Flow ist nur ein Beispiel,
dafür, wie Sie auf der Google Cloud

25
00:01:21,935 --> 00:01:25,415
von unserer Erfahrung,
der Erfahrung von Google,

26
00:01:25,415 --> 00:01:29,800
bei der Erstellung einer Infrastruktur für
maschinelles Lernen profitieren können.

27
00:01:29,800 --> 00:01:32,805
Wenn Sie das Spezialprogramm
zu Data Engineering auf Coursera

28
00:01:32,805 --> 00:01:35,895
noch nicht absolviert haben,
empfehle ich Ihnen, dies noch zu tun.

29
00:01:35,895 --> 00:01:37,380
Aber im Laufe dieses Programms

30
00:01:37,380 --> 00:01:39,470
behandeln wir 
die wichtigsten Bestandteile.

31
00:01:39,470 --> 00:01:42,905
Die gute Nachricht 
an alle Data Scientists:

32
00:01:42,905 --> 00:01:45,855
Es ist nicht so schwer,
Data Engineering zu lernen.

33
00:01:45,855 --> 00:01:51,535
Alle wichtigen Dienste auf der GCP sind
serverlos mit verwalteter Infrastruktur.

34
00:01:51,535 --> 00:01:53,540
In diesem Kurs zeigen wir Ihnen,

35
00:01:53,540 --> 00:01:57,105
wie Sie Pipelines für Batch-
und Streamingdaten erstellen.

36
00:01:57,105 --> 00:02:00,070
Indem Sie Ihre Datenpipelines
auf der Google Cloud erstellen,

37
00:02:00,070 --> 00:02:03,545
profitieren Sie maßgeblich
von der Skalierbarkeit,

38
00:02:03,545 --> 00:02:06,500
Zuverlässigkeit und den
Engineering-Fähigkeiten,

39
00:02:06,500 --> 00:02:10,639
die Google laufenden ML-Systemen bietet.