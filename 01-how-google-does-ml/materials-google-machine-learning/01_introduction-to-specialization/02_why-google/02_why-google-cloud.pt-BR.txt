Uma das principais lições
que aprendemos ao longo do tempo é que precisamos pensar
no uso do aprendizado de máquina, e não só no treinamento dela. Quando mencionamos
o aprendizado de máquina, a maioria das pessoas pensará no complexo
canal à esquerda deste diagrama. Essa é a parte que você como engenheiro ou cientista de dados passará mais tempo. Mas a principal razão
pela qual você está criando aprendizado de máquina
está à direita do diagrama. Você quer disponibilizar essas
previsões para tomadores de decisões usando blocos de anotações,
painéis, aplicativos e relatórios e operacionalizar um modelo
de aprendizado de máquina, ou seja, escolher um modelo treinado e treinar os dados até ser
possível disponibilizar as previsões. É difícil operacionalizar um
modelo de aprendizado de máquina, e muitos projetos não conseguem
chegar à etapa de previsão. Aprendemos no Google que, para reduzir a chance de falhas,
é preciso garantir que o processamento de dados em lote
e de stream seja realizado da mesma forma. O código aberto do Cloud Data Flow mostrado neste
diagrama é o Apache Beam. Com ele, podemos processar
lotes e stream da mesma forma. O Cloud Data Flow é só um exemplo de como usar o Google Cloud para
se beneficiar da experiência do Google em criar infraestrutura
de aprendizado de máquina. Recomendo que você faça
a especialização do Coursera sobre engenharia de dados,
caso ainda não tenha feito. Enquanto isso, falaremos sobre alguns temas
importantes ao longo do caminho. Para os cientistas de dados, não é tão difícil aprender
sobre engenharia de dados. No GCP, os principais serviços são sem
servidor e com infraestrutura gerenciada. Então, neste curso mostraremos como criar canais
de dados de lote e em stream. Ao criar seus canais
de dados no Google Cloud, você aproveitará a escalonabilidade, a confiabilidade e os
conhecimentos em engenharia que o Google disponibiliza para
executar seus sistemas de ML.