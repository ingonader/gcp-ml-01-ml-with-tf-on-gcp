1
00:00:00,000 --> 00:00:02,710
Cloud Vision is an API that lets you perform

2
00:00:02,710 --> 00:00:06,265
complex image detection with a single REST API requests.

3
00:00:06,265 --> 00:00:07,805
Before you get into the details,

4
00:00:07,805 --> 00:00:10,480
I want to show you an example of a company that's using Cloud Vision

5
00:00:10,480 --> 00:00:13,575
in production. Let's talk about Giphy.

6
00:00:13,575 --> 00:00:15,640
Giphy is an app that lets you search for gifs

7
00:00:15,640 --> 00:00:18,475
across the web and share them on various social channels.

8
00:00:18,475 --> 00:00:22,150
As many of you know, gifs often have text in them and they use

9
00:00:22,150 --> 00:00:26,260
the vision API to improve their search to account for text in gifs.

10
00:00:26,260 --> 00:00:30,310
So what they used was the vision API is optical character recognition feature or

11
00:00:30,310 --> 00:00:34,960
OCR to extract text from gifs and service that in their search results,

12
00:00:34,960 --> 00:00:38,740
and what they found was this greatly improved their search experience.

13
00:00:38,740 --> 00:00:42,780
You can learn more about how they did this following the link on the slide.

14
00:00:42,780 --> 00:00:46,910
Now let's talk about all the different things you can do with the vision API.

15
00:00:46,910 --> 00:00:48,740
At its core, the vision API provides

16
00:00:48,740 --> 00:00:51,730
label detection which will tell you what is this a picture of.

17
00:00:51,730 --> 00:00:55,100
For the image here, it might return elephant or animal.

18
00:00:55,100 --> 00:00:57,050
Then we have web detection which will go a step

19
00:00:57,050 --> 00:00:59,540
further and search for similar images across

20
00:00:59,540 --> 00:01:02,270
the web and extracts content from the pages where

21
00:01:02,270 --> 00:01:05,830
those images are found to return additional details on your image.

22
00:01:05,830 --> 00:01:10,430
Then we have OCR which is the Giphy used case that I talked about on the previous slide.

23
00:01:10,430 --> 00:01:13,568
Using OCR or Optical Character Recognition,

24
00:01:13,568 --> 00:01:16,180
the vision API will extract texture images.

25
00:01:16,180 --> 00:01:18,200
It will tell you where that text was found

26
00:01:18,200 --> 00:01:21,745
and it can even tell you what language that text is in.

27
00:01:21,745 --> 00:01:25,510
Then we have Logo detection which will identify company logos and an image.

28
00:01:25,510 --> 00:01:29,480
Landmark detection can tell if an image contains a common landmark.

29
00:01:29,480 --> 00:01:31,040
It will also provide the latitude,

30
00:01:31,040 --> 00:01:33,125
longitude coordinates of that landmark.

31
00:01:33,125 --> 00:01:38,230
Crop hints can help you crop your photos to focus on a particular subject.

32
00:01:38,230 --> 00:01:42,205
And finally, the vision API provides explicit content detection.

33
00:01:42,205 --> 00:01:46,145
This is really useful for any website or app that has user generated content.

34
00:01:46,145 --> 00:01:49,940
Instead of having somebody manually review whether an image is appropriate or not,

35
00:01:49,940 --> 00:01:53,210
you can automate this with an API call to the vision API,

36
00:01:53,210 --> 00:01:57,135
so you only have to review a subset of your images.

37
00:01:57,135 --> 00:01:59,270
You can try out all of our machine learning APIs

38
00:01:59,270 --> 00:02:02,300
directly in the browser before you start writing any code.

39
00:02:02,300 --> 00:02:04,460
In this example, you can upload your images to

40
00:02:04,460 --> 00:02:09,050
the vision API product page and see a response you get back from the vision API.

41
00:02:09,050 --> 00:02:11,507
Let's try this out in a demo.

42
00:02:11,507 --> 00:02:16,770
So if we go to the product page for the cloud vision API,

43
00:02:23,800 --> 00:02:29,580
here we can upload an image and see what the vision API will respond.

44
00:02:29,580 --> 00:02:33,873
So I'm going to click on this to select my image,

45
00:02:33,873 --> 00:02:39,190
and I'm going to choose a selfie that I took a couple of months ago on a trip to Japan.

46
00:02:39,190 --> 00:02:42,555
And here we can see everything the vision APIs able to find in our image.

47
00:02:42,555 --> 00:02:45,170
So, it's actually able to identify

48
00:02:45,170 --> 00:02:49,805
the exact landmark that I'm standing in front of with 71 percent confidence.

49
00:02:49,805 --> 00:02:53,300
The face detection feature of the vision API is able to identify

50
00:02:53,300 --> 00:02:58,328
my face where it is in the image and it's also able to detect an emotion,

51
00:02:58,328 --> 00:03:02,261
it detects that joy is likely.

52
00:03:02,261 --> 00:03:05,965
We can also see the labels return for this image

53
00:03:05,965 --> 00:03:08,430
and we can see the additional entities return

54
00:03:08,430 --> 00:03:12,150
from the web detection endpoint of the vision API.

55
00:03:12,150 --> 00:03:16,195
We also get the dominant colors in the image.

56
00:03:16,195 --> 00:03:18,730
And with Safe Search,

57
00:03:18,730 --> 00:03:21,870
this will tell us whether the image is appropriate or not,

58
00:03:21,870 --> 00:03:24,045
and it breaks it down into different categories.

59
00:03:24,045 --> 00:03:26,520
So adult looks for pornographic content,

60
00:03:26,520 --> 00:03:29,025
spoof looks for meme type content,

61
00:03:29,025 --> 00:03:34,425
medical looks for surgical graphic content and violence looks for bloody content.

62
00:03:34,425 --> 00:03:35,565
Obviously in this image,

63
00:03:35,565 --> 00:03:39,390
inappropriate content for each of these categories is very unlikely.

64
00:03:39,390 --> 00:03:43,350
And finally, we can see the full Json response from the API.

65
00:03:43,350 --> 00:03:49,345
If we look here, we can scroll through the entire API response.

66
00:03:49,345 --> 00:03:52,185
So I encourage you to try this out with your own images

67
00:03:52,185 --> 00:03:55,900
by going to cloud.google.com/vision.