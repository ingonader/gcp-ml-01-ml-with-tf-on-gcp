1
00:00:00,000 --> 00:00:04,080
Die Cloud Vision API ermöglicht
komplexe Prozesse zur Bilderkennung

2
00:00:04,080 --> 00:00:06,265
mit nur einer REST-API-Anfrage.

3
00:00:06,265 --> 00:00:07,585
Bevor wir ins Detail gehen,

4
00:00:07,585 --> 00:00:10,055
möchte ich zeigen,
wie ein Unternehmen Cloud Vision

5
00:00:10,055 --> 00:00:11,750
in der Produktion verwendet.

6
00:00:12,050 --> 00:00:13,575
Und zwar Giphy.

7
00:00:13,575 --> 00:00:16,570
Giphy ist eine App,
mit der man im Web nach GIFs sucht

8
00:00:16,570 --> 00:00:18,475
und diese dann
über soziale Kanäle teilt.

9
00:00:18,475 --> 00:00:21,690
GIFs enthalten ja oft Text.

10
00:00:21,690 --> 00:00:26,260
Also nutzen sie Vision API
zur besseren Textsuche in GIFs.

11
00:00:26,260 --> 00:00:30,910
Mit Vision API als optischer
Zeichenerkennung, kurz OCR,

12
00:00:30,910 --> 00:00:34,960
extrahierten sie Text in GIFs
und optimierten Suchergebnisse.

13
00:00:34,960 --> 00:00:38,740
Der Sucherfolg konnte so
erheblich gesteigert werden.

14
00:00:38,740 --> 00:00:42,780
Eine Beschreibung des Verfahrens
finden Sie unter dem Link auf der Folie.

15
00:00:43,430 --> 00:00:46,910
Reden wir jetzt über
die Funktionsfülle der Vision API.

16
00:00:46,910 --> 00:00:48,540
Im Kern bietet die Vision API

17
00:00:48,540 --> 00:00:49,540
eine Label-Erkennung.

18
00:00:49,540 --> 00:00:51,730
Man erfährt,
was auf dem Bild dargestellt ist.

19
00:00:51,730 --> 00:00:55,100
Dieses Bild könnte als Elefant
oder Tier interpretiert werden.

20
00:00:55,100 --> 00:00:57,570
Die Web-Erkennung geht
noch einen Schritt weiter.

21
00:00:57,570 --> 00:01:00,240
Sie sucht online nach ähnlichen Bildern

22
00:01:00,240 --> 00:01:02,150
und extrahiert Inhalte von den Seiten,

23
00:01:02,150 --> 00:01:03,320
wo sie gefunden wurden.

24
00:01:03,320 --> 00:01:05,830
So erhält man weitere Details zum Bild.

25
00:01:05,830 --> 00:01:10,430
OCR ist der bereits 
erwähnte Anwendungsfall von Giphy.

26
00:01:10,430 --> 00:01:13,568
Durch optische 
Zeichenerkennung, kurz OCR,

27
00:01:13,568 --> 00:01:15,180
extrahiert die Vision API

28
00:01:15,180 --> 00:01:16,180
Text aus den Bildern.

29
00:01:16,180 --> 00:01:18,200
Der Fundort des Textes wird angezeigt

30
00:01:18,200 --> 00:01:21,745
und sogar die Sprache,
in der er geschrieben ist.

31
00:01:21,745 --> 00:01:25,490
Die Logo-Erkennung
identifiziert Firmenlogos in einem Bild.

32
00:01:25,490 --> 00:01:27,490
Die Erkennung bekannter Sehenswürdigkeiten

33
00:01:27,490 --> 00:01:29,480
im Bild ist ebenfalls möglich.

34
00:01:29,480 --> 00:01:31,715
Die GPS-Koordinaten der Sehenswürdigkeit

35
00:01:31,715 --> 00:01:33,195
werden auch angezeigt.

36
00:01:33,195 --> 00:01:34,640
Zuschneidehinweise helfen,

37
00:01:34,640 --> 00:01:38,230
den Fokus
auf ein bestimmtes Motiv zu richten.

38
00:01:38,230 --> 00:01:39,825
Außerdem kann die Vision API

39
00:01:39,825 --> 00:01:43,875
explizite Inhalte erkennen.
Dies ist praktisch für Websites oder Apps

40
00:01:43,875 --> 00:01:46,035
mit von Nutzern erstellten Inhalten.

41
00:01:46,035 --> 00:01:48,180
Sie müssen nicht mehr per Hand prüfen,

42
00:01:48,180 --> 00:01:50,010
ob ein Bild angemessen ist oder nicht,

43
00:01:50,010 --> 00:01:53,210
sondern automatisieren dies
mit einem API-Aufruf der Vision API.

44
00:01:53,210 --> 00:01:57,135
Dann müssen Sie nur noch
einen Teil Ihrer Bilder prüfen.

45
00:01:57,135 --> 00:02:00,290
Sie können alle ML-APIs im Browser testen,

46
00:02:00,290 --> 00:02:02,300
bevor Sie anfangen,
damit zu programmieren.

47
00:02:02,300 --> 00:02:06,320
In diesem Beispiel laden Sie Ihre Bilder
auf der Produktseite der Vision API hoch,

48
00:02:06,320 --> 00:02:09,050
um die Antwort
der Vision API zu prüfen.

49
00:02:09,050 --> 00:02:11,507
Ich möchte das kurz demonstrieren.

50
00:02:11,507 --> 00:02:16,770
Als Erstes gehen wir
zur Produktseite für die Cloud Vision-API.

51
00:02:25,770 --> 00:02:29,580
Hier laden wir ein Bild hoch
und prüfen das Ergebnis der Vision API.

52
00:02:29,580 --> 00:02:33,873
Ich klicke hier und wähle mein Bild aus.

53
00:02:34,443 --> 00:02:37,025
Ich wähle ein Selfie,
das ich vor einigen Monaten

54
00:02:37,025 --> 00:02:39,175
in Japan gemacht habe.

55
00:02:39,190 --> 00:02:40,955
Hier sehen wir, 
was die Vision API

56
00:02:40,955 --> 00:02:42,555
in unserem Bild finden konnte.

57
00:02:42,555 --> 00:02:47,770
Es ist in der Lage,
den Tempel im Hintergrund

58
00:02:47,770 --> 00:02:49,805
mit 71 % Sicherheit zu bestimmen.

59
00:02:49,805 --> 00:02:52,130
Die Gesichtserkennung der Vision API

60
00:02:52,130 --> 00:02:58,328
identifiziert mein Gesicht im Bild
und kann auch ein Gefühl erkennen.

61
00:02:58,328 --> 00:03:02,261
Das Programm erkennt,
dass ich wahrscheinlich fröhlich bin.

62
00:03:02,261 --> 00:03:05,965
Es werden auch
die Labels für das Bild angezeigt,

63
00:03:05,965 --> 00:03:08,150
und es werden
zusätzliche Entitäten angezeigt,

64
00:03:08,150 --> 00:03:09,610
die vom Web-Erkennungsendpunkt

65
00:03:09,610 --> 00:03:11,760
der Vision API stammen.

66
00:03:13,650 --> 00:03:16,735
Wir erhalten auch
die dominierenden Farben im Bild.

67
00:03:16,735 --> 00:03:21,740
Und Safe Search zeigt an,
ob der Bildinhalt unbedenklich ist.

68
00:03:21,740 --> 00:03:24,045
Es gibt hier mehrere Kategorien.

69
00:03:24,045 --> 00:03:26,520
"adult" prüft auf pornografische Inhalte,

70
00:03:26,520 --> 00:03:29,025
"spoof" prüft auf Mem-Inhalte,

71
00:03:29,025 --> 00:03:32,575
"medical" prüft auf explizite OP-Inhalte,

72
00:03:32,575 --> 00:03:34,425
"violence" prüft auf blutige Inhalte.

73
00:03:34,425 --> 00:03:36,425
In diesem Bild sind unangemessene Inhalte,

74
00:03:36,425 --> 00:03:39,430
die in diese Kategorien fallen,
natürlich sehr unwahrscheinlich.

75
00:03:39,430 --> 00:03:43,350
Zum Schluss erhalten wir
die komplette JSON-Antwort der API.

76
00:03:43,350 --> 00:03:49,345
Hier können wir 
die gesamte API-Antwort durchgehen.

77
00:03:49,805 --> 00:03:52,245
Probieren Sie es mit eigenen Bildern aus.

78
00:03:52,245 --> 00:03:55,810
Gehen Sie dafür
zu cloud.google.com/vision.