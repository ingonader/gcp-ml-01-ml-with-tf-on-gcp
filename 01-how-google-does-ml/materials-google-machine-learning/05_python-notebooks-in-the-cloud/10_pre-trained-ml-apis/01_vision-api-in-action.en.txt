Cloud Vision is an API that lets you perform complex image detection with a single REST API requests. Before you get into the details, I want to show you an example of a company that's using Cloud Vision in production. Let's talk about Giphy. Giphy is an app that lets you search for gifs across the web and share them on various social channels. As many of you know, gifs often have text in them and they use the vision API to improve their search to account for text in gifs. So what they used was the vision API is optical character recognition feature or OCR to extract text from gifs and service that in their search results, and what they found was this greatly improved their search experience. You can learn more about how they did this following the link on the slide. Now let's talk about all the different things you can do with the vision API. At its core, the vision API provides label detection which will tell you what is this a picture of. For the image here, it might return elephant or animal. Then we have web detection which will go a step further and search for similar images across the web and extracts content from the pages where those images are found to return additional details on your image. Then we have OCR which is the Giphy used case that I talked about on the previous slide. Using OCR or Optical Character Recognition, the vision API will extract texture images. It will tell you where that text was found and it can even tell you what language that text is in. Then we have Logo detection which will identify company logos and an image. Landmark detection can tell if an image contains a common landmark. It will also provide the latitude, longitude coordinates of that landmark. Crop hints can help you crop your photos to focus on a particular subject. And finally, the vision API provides explicit content detection. This is really useful for any website or app that has user generated content. Instead of having somebody manually review whether an image is appropriate or not, you can automate this with an API call to the vision API, so you only have to review a subset of your images. You can try out all of our machine learning APIs directly in the browser before you start writing any code. In this example, you can upload your images to the vision API product page and see a response you get back from the vision API. Let's try this out in a demo. So if we go to the product page for the cloud vision API, here we can upload an image and see what the vision API will respond. So I'm going to click on this to select my image, and I'm going to choose a selfie that I took a couple of months ago on a trip to Japan. And here we can see everything the vision APIs able to find in our image. So, it's actually able to identify the exact landmark that I'm standing in front of with 71 percent confidence. The face detection feature of the vision API is able to identify my face where it is in the image and it's also able to detect an emotion, it detects that joy is likely. We can also see the labels return for this image and we can see the additional entities return from the web detection endpoint of the vision API. We also get the dominant colors in the image. And with Safe Search, this will tell us whether the image is appropriate or not, and it breaks it down into different categories. So adult looks for pornographic content, spoof looks for meme type content, medical looks for surgical graphic content and violence looks for bloody content. Obviously in this image, inappropriate content for each of these categories is very unlikely. And finally, we can see the full Json response from the API. If we look here, we can scroll through the entire API response. So I encourage you to try this out with your own images by going to cloud.google.com/vision.