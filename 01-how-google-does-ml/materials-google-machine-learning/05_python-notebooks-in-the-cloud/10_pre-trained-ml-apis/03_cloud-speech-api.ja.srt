1
00:00:00,000 --> 00:00:02,190
Cloud SpeechというAPIでは

2
00:00:02,190 --> 00:00:05,750
100以上の言語で
音声をテキストに変換できます

3
00:00:05,750 --> 00:00:08,785
Speech APIで何ができるか
見てみましょう

4
00:00:08,785 --> 00:00:12,140
基本的にSpeech APIに
音声ファイルを入力すると

5
00:00:12,140 --> 00:00:15,440
テキストへの「文字起こし」が返ってきます

6
00:00:15,440 --> 00:00:18,155
音声タイムスタンプ機能もあります

7
00:00:18,155 --> 00:00:20,405
この機能では 文字起こしの中の

8
00:00:20,405 --> 00:00:23,225
一語一語の開始/終了時間が返され

9
00:00:23,225 --> 00:00:26,700
これにより 音声ファイルの中を
簡単に検索できます

10
00:00:26,700 --> 00:00:29,250
また 不敬表現フィルタリング機能もあり

11
00:00:29,250 --> 00:00:33,255
バッチ/ストリーミングの両方で
文字起こしできます

12
00:00:33,255 --> 00:00:35,635
完成した音声ファイルを入力することも

13
00:00:35,635 --> 00:00:38,445
音声ストリームを入力し続けることもできます

14
00:00:38,445 --> 00:00:42,080
音声ストリームと同時進行で
文字起こしが返ってきます

15
00:00:43,180 --> 00:00:46,910
音声タイムスタンプ機能の
デモをご覧いただきますが

16
00:00:46,910 --> 00:00:49,615
その前に この機能をご説明します

17
00:00:49,615 --> 00:00:51,325
私がこのデモを制作した時

18
00:00:51,325 --> 00:00:53,735
まず数本の動画から音声を抽出し

19
00:00:53,735 --> 00:00:56,170
音声ファイルをCloud Speechに送って

20
00:00:56,170 --> 00:00:59,050
文字起こしとタイムスタンプを取得しました

21
00:00:59,050 --> 00:01:03,655
さらに動画文字起こしを
可視化/検索するUIを作りました

22
00:01:03,655 --> 00:01:05,164
見てみましょう

23
00:01:06,364 --> 00:01:08,170
この動画ではMoore氏が

24
00:01:08,170 --> 00:01:10,580
GCPの価格設定について話しています

25
00:01:10,580 --> 00:01:13,910
動画の下にSpeech APIでの
文字起こしがあります

26
00:01:13,910 --> 00:01:15,790
どれか単語をクリックすると

27
00:01:15,790 --> 00:01:18,640
動画で その単語の箇所にジャンプします

28
00:01:18,640 --> 00:01:20,948
たとえば ここをクリックすると

29
00:01:21,978 --> 00:01:24,555
動画でその箇所に直接移動できます

30
00:01:24,555 --> 00:01:27,591
ここでも 同じことができます

31
00:01:28,601 --> 00:01:31,980
このように1本の動画で
音声タイムスタンプを使えます

32
00:01:31,980 --> 00:01:34,420
でも大規模な動画ライブラリの中で

33
00:01:34,420 --> 00:01:38,045
特定の音声スニペットを
探したい場合もあるでしょう

34
00:01:39,465 --> 00:01:41,590
ここにいくつかの動画があります

35
00:01:41,590 --> 00:01:46,710
動画ライブラリ全体でFirebaseの
言及箇所をすべて検索したいとします

36
00:01:47,410 --> 00:01:49,350
Firebaseを検索します

37
00:01:49,890 --> 00:01:54,130
すると2つの動画で
Firebaseの言及箇所すべてを簡単に確認でき

38
00:01:54,130 --> 00:01:57,946
動画の中でそれらの箇所にジャンプできます

39
00:02:00,926 --> 00:02:03,897
この動画では1か所だけ
Firebaseに言及しています

40
00:02:03,897 --> 00:02:05,375
もし手動で確認すると

41
00:02:05,375 --> 00:02:07,225
見逃してしまうかもしれません

42
00:02:07,225 --> 00:02:09,600
Speech APIのタイムスタンプ機能では

43
00:02:09,600 --> 00:02:11,920
まさに この箇所にジャンプできます

44
00:02:13,570 --> 00:02:16,910
ぜひブラウザで直接
Speech APIを試してください

45
00:02:16,910 --> 00:02:20,149
cloud.google.com/speechをご覧ください

46
00:02:20,149 --> 00:02:25,115
Cloud Speechで音声ファイルから
テキストに変換する方法を見ました

47
00:02:25,115 --> 00:02:26,765
テキストを入手した後は

48
00:02:26,765 --> 00:02:28,605
それを さらに分析できます

49
00:02:28,605 --> 00:02:30,780
たとえば翻訳することができます

50
00:02:30,780 --> 00:02:33,415
その時にCloud Translationが役立ちます

51
00:02:33,415 --> 00:02:37,120
Cloud TranslationはGoogle翻訳の
機能を公開しているので

52
00:02:37,120 --> 00:02:40,535
デベロッパーは自分のアプリに
同様の機能を実装できます

53
00:02:40,535 --> 00:02:45,035
このAPIはテキストを
100以上の言語に翻訳できます

54
00:02:45,035 --> 00:02:47,920
Cloud Translationで何ができるか
見てみましょう

55
00:02:47,920 --> 00:02:50,355
APIを使ってテキストを翻訳できます

56
00:02:50,355 --> 00:02:53,140
テキストの言語も検知できます

57
00:02:53,140 --> 00:02:55,150
それで テキストボックスで

58
00:02:55,150 --> 00:02:57,930
ユーザーにさまざまな言語で入力してもらうと

59
00:02:57,930 --> 00:03:02,105
単に言語検知を使うだけで
テキストの言語を検知できます

60
00:03:02,105 --> 00:03:07,090
cloud.google.com/translationを開き
ブラウザでお試しください