1
00:00:00,000 --> 00:00:02,403
So, in my quick demo,

2
00:00:02,403 --> 00:00:08,690
you saw that I was able to query large data sets interactively in an ad hoc manner.

3
00:00:08,690 --> 00:00:13,125
My query itself was SQL:2011, a standard.

4
00:00:13,125 --> 00:00:16,240
Getting data into BigQuery is quite flexible.

5
00:00:16,240 --> 00:00:19,570
You can use anything from uploading files,

6
00:00:19,570 --> 00:00:22,300
from the web GUI to staging them on cloud storage,

7
00:00:22,300 --> 00:00:25,880
and pointing at them to streaming data into BigQuery.

8
00:00:25,880 --> 00:00:30,220
You can export from BigQuery quite easily because of the varieties of APIs.

9
00:00:30,220 --> 00:00:34,625
Run a SQL query and save the result in the format that you want.

10
00:00:34,625 --> 00:00:36,655
Storage is also quite cheap.

11
00:00:36,655 --> 00:00:39,340
And finally, key for our purposes,

12
00:00:39,340 --> 00:00:42,175
Datalab integrates nicely with BigQuery,

13
00:00:42,175 --> 00:00:45,355
so we can explore data, run a query,

14
00:00:45,355 --> 00:00:49,540
export into a Pandas DataFrame and plot it using Python.

15
00:00:49,540 --> 00:00:52,560
In fact, that's exactly what you're going to do.