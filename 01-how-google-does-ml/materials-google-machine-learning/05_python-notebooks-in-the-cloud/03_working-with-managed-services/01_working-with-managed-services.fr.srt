1
00:00:00,000 --> 00:00:04,155
Datalab fonctionne avec des technologies
que vous maîtrisez déjà.

2
00:00:04,155 --> 00:00:06,760
Vous pouvez donc commencer
à développer dès à présent,

3
00:00:06,760 --> 00:00:09,460
et gérer le scaling
dans un second temps.

4
00:00:09,460 --> 00:00:13,575
En guise d'exemple, nous allons effectuer
un exercice consistant à lire un fichier CSV.

5
00:00:13,835 --> 00:00:17,045
Vous pourrez ensuite traiter les données
dans Pandas et Apache Beam,

6
00:00:17,045 --> 00:00:19,480
avant d'entraîner le modèle
dans TensorFlow.

7
00:00:19,480 --> 00:00:21,915
Assurez-vous
que tout fonctionne,

8
00:00:21,915 --> 00:00:23,975
puis améliorez votre
modèle en l'entraînant.

9
00:00:23,975 --> 00:00:27,810
Au bout du compte, lorsque vous serez prêt
à procéder au scaling pour entraîner

10
00:00:27,810 --> 00:00:30,010
le modèle sur l'ensemble de vos données,

11
00:00:30,010 --> 00:00:33,835
vous pourrez utiliser Google Cloud Storage
pour stocker les données,

12
00:00:33,835 --> 00:00:37,615
assurer leur traitement avec
Cloud Dataflow sur un cluster FML,

13
00:00:37,615 --> 00:00:40,300
et enfin effectuer
l'entraînement distribué

14
00:00:40,300 --> 00:00:44,110
et l'optimisation des hyperparamètres
dans Cloud ML Engine.

15
00:00:44,110 --> 00:00:47,455
Tout cela est possible car Datalab

16
00:00:47,455 --> 00:00:51,915
s'intègre parfaitement
à tous les autres produits GCP.

17
00:00:51,925 --> 00:00:54,405
Dans quelques minutes,
vous participerez à un atelier

18
00:00:54,405 --> 00:00:56,665
qui vous démontrera
à quel point il est facile

19
00:00:56,665 --> 00:00:57,955
de se connecter à BigQuery

20
00:00:57,955 --> 00:01:02,600
et d'exploiter des milliers de machines
pour explorer et analyser vos données.

21
00:01:02,840 --> 00:01:04,885
Vous pouvez aussi écrire
du code TensorFlow

22
00:01:04,885 --> 00:01:07,865
et le connecter aux API
de machine learning de Google.

23
00:01:07,865 --> 00:01:09,955
L'authentification est un jeu d'enfant.

24
00:01:09,955 --> 00:01:13,885
Vous pouvez même démarrer des tâches
informatiques complexes dans Cloud ML Engine

25
00:01:13,885 --> 00:01:14,885
et Cloud Dataflow.

26
00:01:14,885 --> 00:01:17,815
Et bien sûr, vous pouvez faire
tout ce que vous feriez

27
00:01:17,815 --> 00:01:19,065
avec un bloc-notes Python.

28
00:01:19,065 --> 00:01:20,850
Analyser les données avec Pandas,

29
00:01:20,850 --> 00:01:23,110
ou encore visualiser
les résultats de requêtes

30
00:01:23,110 --> 00:01:25,080
à l'aide de Seaborn ou Plotly.

31
00:01:26,970 --> 00:01:30,640
Il est très simple de lancer Cloud Datalab.

32
00:01:30,640 --> 00:01:31,960
Accédez à Cloud Shell,

33
00:01:31,960 --> 00:01:34,210
et saisissez "datalab create".

34
00:01:34,570 --> 00:01:37,525
C'est simple si vous savez ce que
toutes ces choses signifient :

35
00:01:37,525 --> 00:01:40,240
Cloud Shell, compute zone (région),

36
00:01:40,240 --> 00:01:43,450
machine type (type de machine). 
Mais, revenons un peu en arrière.

37
00:01:43,450 --> 00:01:45,990
Je dois vous parler de Compute Engine.

38
00:01:46,750 --> 00:01:50,600
Sachez que Compute Engine
est une infrastructure "en location".

39
00:01:50,600 --> 00:01:53,515
Vous n'allez pas conserver
cette infrastructure pour toujours.

40
00:01:53,875 --> 00:01:56,776
Mais, si vous supprimez une machine,

41
00:01:56,776 --> 00:01:59,650
tout le travail effectué dessus
disparaît également.

42
00:02:00,630 --> 00:02:03,890
Vous devez donc enregistrer le code source
de votre bloc-notes dans git.

43
00:02:03,890 --> 00:02:05,645
C'est très facile.

44
00:02:06,065 --> 00:02:08,675
Au fait, qu'en est-il des résultats
de l'analyse ?

45
00:02:08,675 --> 00:02:10,460
Les données, etc.

46
00:02:10,460 --> 00:02:12,125
Vous ne pouvez pas les enregistrer,

47
00:02:12,125 --> 00:02:13,280
n'est-ce pas ?

48
00:02:13,280 --> 00:02:16,000
Je dois donc également vous parler
de Cloud Storage.