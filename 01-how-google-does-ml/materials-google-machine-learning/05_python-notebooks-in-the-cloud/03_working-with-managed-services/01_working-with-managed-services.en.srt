1
00:00:00,000 --> 00:00:04,305
Datalab works with the same technologies that you're comfortable with.

2
00:00:04,305 --> 00:00:06,640
So that you can start developing now,

3
00:00:06,640 --> 00:00:09,220
and then work on scale later.

4
00:00:09,220 --> 00:00:13,525
For example, we'll be doing an exercise where we read from a CSV file.

5
00:00:13,525 --> 00:00:16,765
You could then process it in pandas and Apache Beam,

6
00:00:16,765 --> 00:00:19,480
before training the model in TensorFlow.

7
00:00:19,480 --> 00:00:21,535
Make sure they all work.

8
00:00:21,535 --> 00:00:23,935
And then, improve the model through training.

9
00:00:23,935 --> 00:00:30,010
Eventually though, when you're ready to scale to train this model on all of your data,

10
00:00:30,010 --> 00:00:33,835
you can use Google Cloud Storage to hold your data,

11
00:00:33,835 --> 00:00:37,615
process it with Cloud Dataflow on an ephemeral cluster,

12
00:00:37,615 --> 00:00:40,300
and then run distributor training,

13
00:00:40,300 --> 00:00:44,110
and hyperparameter optimization in Cloud ML Engine.

14
00:00:44,110 --> 00:00:47,455
And you can do all those because Datalab

15
00:00:47,455 --> 00:00:52,315
integrates seamlessly with all other GCP products.

16
00:00:52,315 --> 00:00:53,815
In a few minutes,

17
00:00:53,815 --> 00:00:57,955
you'll do a lab that shows you how easy it is to connect to BigQuery,

18
00:00:57,955 --> 00:01:02,890
and harness thousands of machines to explore and analyze your data.

19
00:01:02,890 --> 00:01:04,885
You can also write TensorFlow code,

20
00:01:04,885 --> 00:01:07,865
and connect with Google machine learning APIs.

21
00:01:07,865 --> 00:01:10,145
Authentication is a breeze.

22
00:01:10,145 --> 00:01:14,885
You can even start big computational jobs in Cloud ML Engine and Dataflow.

23
00:01:14,885 --> 00:01:18,955
And of course, you can do all the things that you can do in a Python Notebook.

24
00:01:18,955 --> 00:01:20,850
Doing analysis with pandas,

25
00:01:20,850 --> 00:01:22,780
or visualizing query results

26
00:01:22,780 --> 00:01:25,710
using seaborn or plotly.

27
00:01:25,710 --> 00:01:30,640
So starting up Cloud Datalab is pretty simple.

28
00:01:30,640 --> 00:01:31,960
You go to Cloud Shell,

29
00:01:31,960 --> 00:01:34,210
and you type in "datalab create".

30
00:01:34,210 --> 00:01:37,525
Simple that is if you know what all these things mean.

31
00:01:37,525 --> 00:01:40,240
Cloud shell, compute zone,

32
00:01:40,240 --> 00:01:43,450
machine type. Let's back up a little.

33
00:01:43,450 --> 00:01:45,990
We need to tell you about Compute Engine.

34
00:01:45,990 --> 00:01:49,640
The point about using Compute Engine is that it's

35
00:01:49,640 --> 00:01:53,385
rented infrastructure. You're not going to keep it around forever.

36
00:01:53,385 --> 00:01:56,776
But when the machine goes away,

37
00:01:56,776 --> 00:02:00,000
your work also vanishes.

38
00:02:00,000 --> 00:02:03,890
So you need to save your notebook source code into Git.

39
00:02:03,890 --> 00:02:08,675
That's easy. So how about the results of that

40
00:02:08,675 --> 00:02:10,460
analysis, data, etc?

41
00:02:10,460 --> 00:02:11,775
You can't check those in,

42
00:02:11,775 --> 00:02:13,280
can you?

43
00:02:13,280 --> 00:02:16,000
So we also need to tell you about Cloud Storage.