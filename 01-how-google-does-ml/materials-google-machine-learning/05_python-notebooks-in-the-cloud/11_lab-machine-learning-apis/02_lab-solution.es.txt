En este lab, veremos cómo invocar las API
de aprendizaje automático en Datalab. Comencemos. Ahora, 
en lugar de crear un cuaderno de cero recuperamos un cuaderno que ya
está listo en el repositorio de GitHub. Tenemos que verificarlo. Veamos el cuaderno. Para hacerlo,
debemos clonar el repositorio. Abrimos un Datalab y ejecutamos un comando bash
desde Datalab. La idea es que podemos
comenzar un nuevo cuaderno. Le ponemos el nombre que deseemos. Llamémoslo "checkout". Ya vimos cómo ejecutar código
de Python en Datalab pero si usamos %bash, esto hace
que Datalab ejecute todo en esa celda. Es como lo que pasa en Jupyter. Usaremos el comando git clone
de nuestro repositorio. Hagamos eso. Puedo usar !ls que es otra forma de ejecutar Bash. Y notarán que hay una carpeta
que se llama training-data-analyst. Podemos cargar el cuaderno
y comenzar a ejecutarlo. Ahí está training-data-analyst. Ahora, vamos a
courses/machine_learning/deepdive y abrimos las API de ML,
el cuaderno IPython. Ahí está nuestro cuaderno. Lo primero que debemos hacer
es habilitar "API & services". De modo que
podamos ejecutar la API de Vision la API de Translate la API de Speech, etcétera. Vamos aquí abajo y escribimos "vision". Ahí está la API de Vision y está habilitada. Hagamos lo mismo
con las API de Translate y Speech. Ahí está la API de Google Translation,
que ya está habilitada. Y la API de Natural Language también está habilitada. Asegurémonos de que la API de Speech
esté habilitada. Lo está. Muy bien. Todas las API están habilitadas. Obtengamos las credenciales. Vamos a "APIs & services" para obtener las credenciales. Ya tenemos la clave de API. La usaremos. O podemos ir a "Create credentials" con un clave de API
y creamos una nueva clave. Copiamos eso. Y ya está. Esta es nuestra clave de API. Ahora, estamos listos
para ir a las API de ML. En nuestro cuaderno, donde dice
clave de API reemplazaremos con la nueva clave de API
y la ejecutaremos. Podemos hacer clic en el botón "Run" o presionar Mayús + Intro. Instalemos el cliente de Python. Ya está. Ahora, ejecutemos la API de Translate. Notarán que ahí están las entradas ¿es realmente tan sencillo? Pueden ver la traducción en francés,
porque pedimos que ese sea el objetivo. Cambiemos el objetivo a ES que es español, y ejecutemos. Ahora, obtenemos un texto en español. ¿Cómo funciona? Especificamos las entradas
como una matriz de strings y le pedimos al servicio
que hiciera una traducción del inglés al idioma que queremos,
entregándole esas entradas. Y lo que obtuvimos son las salidas,
la string traducida. De manera similar,
invocaremos la API de Vision. Para hacerlo, necesitamos una imagen. En este caso,
la imagen es la de un cartel de la calle. No hablo chino,
por lo que no sé exactamente lo que dice. Veamos qué dice.
Lo subiremos a Cloud Storage. Ya es público,
entonces no tenemos que cambiar nada. Podemos leer… podemos pedirle a la API de Vision
que lea la imagen y nos diga qué dice el texto. Ejecutemos eso. Y obtenemos la salida JSON. Lo que hacemos es invocar
la versión 1 de la API de Vision pasamos el URI de la imagen en GCS. GCS quiere decir Google Cloud Storage. La imagen está en Cloud Storage. También podemos pasar la imagen como parte de nuestra solicitud.
Pero si está en Cloud Storage es más rápido, pues no tenemos
que subirla con nuestra solicitud. Le estamos pidiendo
que haga detección de texto y lo que nos devuelve
es todo el texto de la imagen junto con el código del idioma,
que es ZH para chino y un polígono que rodea
las porciones de texto. Podríamos obtener la primera parte y tomar esa anotación de texto en el idioma
de la configuración regional, que es ZH y podemos imprimir lo que obtuvimos que es el texto en el idioma extranjero,
ZH, que es todo esto. Ahora podemos ejecutarlo. El resultado ya está aquí y podemos hacer clic en esta celda
y borrarla. Y ahora podemos ejecutarlo de nuevo. Asegúrense de que
lo que ejecuten sea suyo. Y vemos que el texto en chino
se tradujo al inglés. Otra API que podemos usar es
la de Language. Aquí tenemos un conjunto de citas. Lo que queremos es analizar
la opinión asociada con estas citas. Igual que antes borramos la celda y ejecutamos. En este caso,
imprimiremos la polaridad y la magnitud asociadas con estas citas. La polaridad es positiva si es una opinión positiva y es negativa si es una opinión negativa. Tiene sentido. Si decimos: "Para tener éxito 
se debe tener mucha perseverancia" es algo muy positivo. Pero si decimos "Cuando alguien que amas fallece" es algo muy negativo.
Entonces, la polaridad es negativa. Y la magnitud es un indicador de la frecuencia con la que se usa
lenguaje fuerte en este texto. Lo último que mostramos
es la API de Speech. Igual que antes, tenemos un archivo
de audio en Cloud Storage y le pedimos que lo convierta en texto. Ejecutamos eso y obtenemos una respuesta JSON. JSON responde con mucha confianza
que el texto en ese archivo de audio es "¿Cuántos años tiene
el puente de Brooklyn?" Lo que hicimos en este lab es usar Datalab para usar las API de Python
para invocar los modelos de AA. Recuerden que estos no son modelos
de AA que desarrollamos. Son modelos que podemos usar. Podemos incorporar estos modelos de AA
en nuestras aplicaciones. Deben tomar en cuenta
que no todas las herramientas de AA que necesiten deben crearse de cero. Si lo que quieren
es reconocer imágenes y texto simplemente usen la API de Vision.