1
00:00:00,360 --> 00:00:02,550
Neste laboratório, veremos como invocar

2
00:00:02,550 --> 00:00:05,780
APIs de aprendizado de máquina de
dentro do Datalab.

3
00:00:05,780 --> 00:00:07,290
Vamos lá.

4
00:00:07,290 --> 00:00:11,130
Desta vez, em vez de fazer este
bloco de notas desde o início,

5
00:00:11,130 --> 00:00:14,910
começaremos de um bloco de notas existente
em nosso repositório do GitHub.

6
00:00:14,910 --> 00:00:16,715
Primeiro precisamos verificá-lo.

7
00:00:16,715 --> 00:00:19,910
Vamos fazer isso.

8
00:00:19,910 --> 00:00:22,380
E para fazer isso, é preciso
clonar o repositório.

9
00:00:22,380 --> 00:00:26,280
Abriremos o Datalab,

10
00:00:26,280 --> 00:00:30,125
e executaremos o comando bash de
dentro do Datalab.

11
00:00:30,125 --> 00:00:34,180
A ideia aqui é que possamos criar
um novo bloco de notas

12
00:00:35,600 --> 00:00:37,605
e dar a ele o nome que quisermos.

13
00:00:37,605 --> 00:00:39,745
Vamos chamá-lo de "checkout".

14
00:00:43,395 --> 00:00:49,265
Até aqui, basicamente vimos o código do
Python em execução no Datalab, mas

15
00:00:49,265 --> 00:00:55,655
ao inserir %bash, isso
faz o Datalab executar tudo na célula

16
00:00:55,655 --> 00:00:56,655
usando bash.

17
00:00:56,655 --> 00:00:59,145
Isso é como todo o resto no Jupyter.

18
00:00:59,145 --> 00:01:03,895
Farei basicamente um clone do Git
do nosso repositório.

19
00:01:03,895 --> 00:01:06,075
Vamos fazer isso.

20
00:01:10,125 --> 00:01:11,865
Neste ponto,

21
00:01:11,865 --> 00:01:13,521
posso fazer "bangle S",

22
00:01:13,521 --> 00:01:15,415
essa é outra maneira de executar
o bash.

23
00:01:15,415 --> 00:01:20,380
Você vai perceber que há uma pasta chamada
"training data analyst".

24
00:01:20,380 --> 00:01:24,815
Podemos carregar esse bloco de notas e
começar a executá-lo.

25
00:01:27,015 --> 00:01:29,095
Aqui está "training data analyst".

26
00:01:30,915 --> 00:01:36,827
Dessa vez você irá em
"courses", "machine learning",

27
00:01:38,267 --> 00:01:47,465
"deepdive" e abrirá as APIs de ML.
Lá está o bloco de notas do IPython,

28
00:01:47,465 --> 00:01:49,240
e lá está nosso bloco de notas.

29
00:01:55,840 --> 00:01:59,895
A primeira coisa a se fazer é ativar APIs
e serviços.

30
00:01:59,895 --> 00:02:03,840
Assim podemos executar a Vision API,

31
00:02:03,840 --> 00:02:05,550
a Translate API,

32
00:02:05,550 --> 00:02:07,090
a Speech API etc.

33
00:02:07,090 --> 00:02:08,830
Então descemos até aqui

34
00:02:22,710 --> 00:02:24,765
e digitamos "vision".

35
00:02:24,765 --> 00:02:26,410
Aqui está a Vision API.

36
00:02:30,080 --> 00:02:33,105
Ela está ativada.

37
00:02:36,995 --> 00:02:40,230
Vamos fazer o mesmo para a Translate
e a Speech.

38
00:02:48,910 --> 00:02:54,645
Há a Google Translation API que também
já está ativada.

39
00:02:56,005 --> 00:02:57,860
E a Natural Language API.

40
00:03:04,260 --> 00:03:07,970
Lá está, também está ativada.

41
00:03:09,360 --> 00:03:13,695
E a Speech API, vamos só garantir
que esteja ativada.

42
00:03:13,695 --> 00:03:15,020
Também está ativada.

43
00:03:15,020 --> 00:03:18,210
Ótimo. Todas as APIs estão ativadas.

44
00:03:18,210 --> 00:03:21,300
Vamos avançar e pegar as credenciais.

45
00:03:21,300 --> 00:03:24,185
Vamos descer para "APIs e serviços",

46
00:03:24,185 --> 00:03:25,820
e pegar as credenciais.

47
00:03:38,150 --> 00:03:40,115
Já temos a chave de API.

48
00:03:40,115 --> 00:03:42,128
Então, eu a usei.

49
00:03:42,128 --> 00:03:43,330
Ou podemos ainda

50
00:03:43,330 --> 00:03:45,680
criar credenciais com uma chave de API,

51
00:03:45,680 --> 00:03:47,621
e criar uma chave nova,

52
00:03:47,621 --> 00:03:52,040
copiar e pronto.

53
00:03:52,040 --> 00:03:53,780
Aqui está nossa chave de API.

54
00:03:53,780 --> 00:03:54,845
Aqui está.

55
00:03:57,015 --> 00:04:00,650
Agora estamos prontos para entrar nas
APIs de ML.

56
00:04:00,650 --> 00:04:05,015
No nosso bloco de notas, onde diz
"API key",

57
00:04:05,015 --> 00:04:10,245
substituirei pela nova chave de API que
temos e a executarei.

58
00:04:10,245 --> 00:04:12,200
Posso tanto clicar no botão "Executar"

59
00:04:12,200 --> 00:04:13,845
quanto digitar Shift + Enter.

60
00:04:13,845 --> 00:04:15,910
Vamos avançar e

61
00:04:15,910 --> 00:04:19,093
instalar o cliente do Python.

62
00:04:35,333 --> 00:04:36,560
Tendo feito isso,

63
00:04:36,560 --> 00:04:40,045
vamos avançar e executar a
Translate API.

64
00:04:40,045 --> 00:04:43,031
Perceba que há entradas.

65
00:04:43,031 --> 00:04:44,541
É tão fácil assim?

66
00:04:44,541 --> 00:04:51,700
Você está vendo a tradução em francês
porque pedimos para ser assim.

67
00:04:51,700 --> 00:04:53,388
Vamos mudar para espanhol,

68
00:04:53,388 --> 00:04:55,920
que é "Español", e executar.

69
00:04:55,920 --> 00:04:58,600
Agora, o que temos é em espanhol.

70
00:04:58,600 --> 00:05:00,160
Como isso funciona?

71
00:05:00,160 --> 00:05:04,780
Especificamos as entradas como uma
matriz de strings

72
00:05:04,780 --> 00:05:08,230
e pedimos ao serviço para traduzir
do inglês

73
00:05:08,230 --> 00:05:11,767
para qualquer idioma que quisermos
passando nessas entradas.

74
00:05:11,767 --> 00:05:16,115
E o que tivemos como retorno foram as
saídas, a string traduzida.

75
00:05:16,115 --> 00:05:20,198
De modo similar, o que você fará é
invocar a Vision API.

76
00:05:20,198 --> 00:05:21,600
E para isso,

77
00:05:21,600 --> 00:05:23,058
precisamos de uma imagem.

78
00:05:23,058 --> 00:05:26,600
E nesse caso, é a imagem de uma
sinalização de rua.

79
00:05:26,600 --> 00:05:29,470
Eu não falo chinês, então não sei 
exatamente o que diz.

80
00:05:29,470 --> 00:05:34,235
Vamos ver o que diz. Vamos colocar isso
no Cloud Storage.

81
00:05:34,235 --> 00:05:37,965
Isso é público, então não temos
que alterar nada aqui.

82
00:05:37,965 --> 00:05:39,610
Podemos avançar e ler,

83
00:05:39,610 --> 00:05:44,425
podemos pedir para que a Vision API
leia essa imagem

84
00:05:44,425 --> 00:05:46,680
e nos diga qual é o texto nela.

85
00:05:46,680 --> 00:05:48,555
Podemos executá-la.

86
00:05:48,555 --> 00:05:52,585
Neste ponto, temos como retorno
a saída do JSON.

87
00:05:52,585 --> 00:05:59,150
Novamente, o que estamos fazendo aqui é
invocar a versão 1 da Vision API,

88
00:05:59,150 --> 00:06:02,970
passando o URI da imagem do GCS.

89
00:06:02,970 --> 00:06:06,100
GCS significa Google Cloud Storage.

90
00:06:06,100 --> 00:06:08,215
Temos essa imagem no Cloud Storage.

91
00:06:08,215 --> 00:06:10,210
Também poderíamos passar uma
imagem como

92
00:06:10,210 --> 00:06:13,430
parte da solicitação, mas tê-la no
Cloud Storage é mais rápido,

93
00:06:13,430 --> 00:06:17,900
por não termos que fazer upload dos dados
dessa imagem com a solicitação.

94
00:06:17,900 --> 00:06:20,345
E estamos pedindo que se faça
detecção de texto,

95
00:06:20,345 --> 00:06:23,885
e o que retorna é todo o texto
nessa imagem,

96
00:06:23,885 --> 00:06:28,075
com o idioma ZH, que é o chinês,

97
00:06:28,075 --> 00:06:32,180
e um polígono delimitador de cada um
dos pedaços do texto.

98
00:06:33,170 --> 00:06:38,055
Poderíamos, claro, pegar o primeiro
pedaço dele,

99
00:06:38,055 --> 00:06:40,935
pegar a anotação do texto,

100
00:06:40,935 --> 00:06:44,722
pegar o idioma, o local que dissemos que
era ZH,

101
00:06:44,722 --> 00:06:47,635
e imprimir o que temos,

102
00:06:47,635 --> 00:06:51,075
e o que temos é o idioma estrangeiro
para ZH,

103
00:06:51,075 --> 00:06:54,275
e o texto estrangeiro que é tudo isto.

104
00:06:54,275 --> 00:06:57,360
Agora podemos executar isto.

105
00:06:57,360 --> 00:07:00,120
Claro, o resultado já está aqui,

106
00:07:00,120 --> 00:07:03,300
então posso clicar nesta célula,
limpá-la

107
00:07:03,300 --> 00:07:05,070
e agora executar novamente.

108
00:07:05,070 --> 00:07:08,145
E você pode se certificar de que está
executando o que é seu,

109
00:07:08,145 --> 00:07:13,265
e vemos que o texto em chinês agora está
traduzido para inglês.

110
00:07:13,265 --> 00:07:16,685
Outra coisa que podemos fazer é a 
Language API.

111
00:07:16,685 --> 00:07:20,345
Aqui, temos um conjunto de citações,

112
00:07:20,345 --> 00:07:24,210
e o que queremos fazer é olhar para
o sentimento associado a elas.

113
00:07:24,210 --> 00:07:25,825
Novamente, como antes,

114
00:07:25,825 --> 00:07:29,000
vamos limpar a célula e executar.

115
00:07:29,000 --> 00:07:30,260
Nesse caso

116
00:07:30,260 --> 00:07:33,500
estamos imprimindo a polaridade
e a magnitude,

117
00:07:33,500 --> 00:07:36,245
tudo associado a cada um desses códigos.

118
00:07:36,245 --> 00:07:38,570
A polaridade é positiva,

119
00:07:38,570 --> 00:07:39,980
se é um sentimento positivo,

120
00:07:39,980 --> 00:07:42,270
se é negativo, se é um
sentimento negativo.

121
00:07:42,270 --> 00:07:43,670
E faz sentido.

122
00:07:43,670 --> 00:07:45,740
"Para ter sucesso, é preciso ter uma

123
00:07:45,740 --> 00:07:47,010
perseverança tremenda."

124
00:07:47,010 --> 00:07:48,065
É algo muito positivo.

125
00:07:48,065 --> 00:07:51,435
Mas, se você disser, por exemplo:

126
00:07:51,435 --> 00:07:53,195
"Quando alguém que você ama morre."

127
00:07:53,195 --> 00:07:55,025
Bem, é algo bem negativo.

128
00:07:55,025 --> 00:07:56,805
Então a polaridade é negativa.

129
00:07:56,805 --> 00:07:59,520
E a magnitude é um indicador da
frequência com que

130
00:07:59,520 --> 00:08:04,460
uma linguagem com palavras muito fortes
ocorre no texto.

131
00:08:05,190 --> 00:08:08,715
O pedaço final que estamos mostrando aqui
é a Speech API.

132
00:08:08,715 --> 00:08:13,190
E como antes, temos um arquivo de áudio
carregado no Cloud Storage e estamos

133
00:08:13,190 --> 00:08:17,835
pedindo para que o resultado dessa fala
seja convertido em texto.

134
00:08:17,835 --> 00:08:20,409
Vamos executar

135
00:08:20,409 --> 00:08:23,040
e receber a resposta do JSON.

136
00:08:23,040 --> 00:08:31,447
E o JSON responde com alto nível de
confiança que a fala no arquivo de áudio é

137
00:08:31,447 --> 00:08:33,909
"Quantos anos tem a Brooklyn Bridge?"

138
00:08:37,239 --> 00:08:43,429
Então, o que fizemos neste laboratório
foi usar o Datalab

139
00:08:43,429 --> 00:08:50,240
para usar APIs do Python a fim de invocar
modelos de aprendizado de máquina.

140
00:08:50,240 --> 00:08:53,595
Então lembre-se de que esses não são
modelos que precisamos criar.

141
00:08:53,595 --> 00:08:56,780
São modelos de aprendizado de máquina que
podemos usar.

142
00:08:56,780 --> 00:09:01,700
Podemos incorporar esses modelos
em nossos próprios aplicativos.

143
00:09:01,700 --> 00:09:04,430
Isto é algo que você gostaria
de reconhecer, que

144
00:09:04,430 --> 00:09:10,055
nem todo ML que você precisar fazer terá
de ser feito do começo.

145
00:09:10,055 --> 00:09:14,075
Se você quiser reconhecer texto e imagens,

146
00:09:14,075 --> 00:09:17,000
use a Vision API.