このラボでは Datalabから機械学習APIを
呼び出す方法を見てみます では始めましょう 今回は ゼロからNotebookを作る
代わりに すでにGitHubリポジトリにある
Notebookで作業を始めます まずチェックアウトが必要です Notebookをチェックアウトします そのためには
リポジトリをクローンする必要があります さてDatalabを開いて 次にDatalabでBashコマンドを実行します ここでの要点は
新しいNotebookを開始できることです このNotebookに好きな名前を付けます ここではcheckoutとしましょう ここまでDatalab内でPythonコードを
実行する方法を見ましたが %bashと入力すると DatalabはBashを使って
セルにあるすべてのものを実行します Jupyterの「他のすべて」に似ています ここでリポジトリのGitクローンを実行します やってみましょう ここでは「!ls」が可能です Bashを実行する別の方法です training-data-analystという
フォルダがありますね 次にNotebookを読み込んで
実行を始めることができます ここにtraining-data-analystがあります ここではcourses（コース）、
machine_learning、deepdiveと進みます そしてIPython Notebookである
「mlapis」を開きます これが今回のNotebookです まずAPIとサービスを
有効にする必要があります こうするとVision APIを実行でき Translate API、Speech APIなどを実行できます ここで下に進んで... visionと入力します Vision APIがあります そしてAPIが有効です 次にTranslate（翻訳）と
Speechでも同じことをします Google Translation APIです これもすでに有効です Natural Language APIです これも有効です 次にSpeech APIです
これも有効になっているか確認します これも有効です すべてのAPIが有効になっています では 認証情報を取得します 下に移動してAPIとサービスのところで Credentials（認証情報）を取得します
...これです すでにAPIキーがあるので そのキーを使いました あるいは たとえば APIキーで認証情報を作成できます そしてまったく新しいキーを作成し それをコピーできます これがAPIキーです このとおりです これでML APIに進む準備ができました Notebookの中の「APIKEY」という場所で 新しいAPIキーに置き換えて 実行します [Run]ボタンをクリックするか Shift + Enterも可能です さらに進んで Pythonクライアントをインストールします インストールが終わったら 次に Translate APIを実行します ここに入力があります 「is it really this easy?」です フランス語の翻訳が表示されます
ターゲットをフランス語にしたからです 対象言語をESにしてみましょう つまりスペイン語です 実行すると これでスペイン語になりました どのような仕組みでしょうか？ 入力を 文字列の配列として指定しました そして英語から いずれかの言語に翻訳するよう
サービスに指示して これらの入力を渡しました すると出力 つまり
翻訳された文字列が返されました 同様にVision APIを呼び出すこともできます Vision APIを呼び出すには画像が必要です この場合は道路標識の画像です 私は中国語が読めないので
正確な意味が分かりません どんな意味ですか これをCloud Storageに入力します これは公開情報なので
何も変更する必要がありません このまま読むことができます Vision APIに
その画像を読み取るよう命令すると その中のテキストを教えてくれます これを実行しましょう こうしてJSON出力が返ってきます さらに もう一度
Vision APIバージョン1を呼び出して GCS画像のURIを渡します GCSとはGoogle Cloud Storageです この画像がCloud Storageにあります 画像を要求に含めて渡すこともできますが Cloud Storageの方が処理が早いです 画像データを要求と一緒に
アップロードしなくて済むからです そしてテキストを検出するよう命令すると この画像にあるテキストがすべて返され それと一緒に 言語「ZH」つまり中国語と テキストの各部分の
境界（bounding）ポリゴンも返されます もちろん さらに操作を進めて
最初の部分を取り出し テキスト アノテーションを付け 言語ロケールつまりZHを得ることができます そして 取得したデータをプリントアウトすると 返ってくるのは外国語ZHと このとおり 外国語のテキストです 次に さらに実行を続けます もちろん すでに結果が得られたので このセルをクリックして これを消去すると もう一度実行できます 実行する内容をよく確認して このとおり 中国語のテキストが
英語に翻訳されました もう1つLanguage APIもあります ここに いくつかの引用文があります これらの引用に含まれる
感情を調べたいと思います 先程と同様に セルを消去してから実行します この場合は 極性（polarity）と
強度（magnitude）を出力します 引用文と関連した特性です 正の極性は 肯定的な感情です 負は否定的な感情です 意味が通りますね たとえば「成功するには
多くの忍耐が必要だ」という文は とても肯定的ですが たとえば「愛する人が
もし死んだら ...」という引用文は とても否定的な感情ですから 極性は負になります 強度（magnitude）という指標は
テキストの中で 非常に強い感情の言葉が
どれほど頻繁に使われるかを示します 最後にここに表示しているのはSpeech API です 先ほどと同じく Cloud Storageに音声ファイルがあり そのスピーチの結果をテキストに
変換するよう命令します では実行しましょう JSONレスポンスが得られます JSONはとても高い信頼率でレスポンスします それによると その音声ファイルのスピーチは 「How old is the Brooklyn Bridge?」
（ブルックリン橋は建設されて何年か）です このラボではDatalabを使用し Python APIを使って
機械学習モデルを呼び出しました これらのモデルを自分で作る
必要はありませんでした そのまま使用できる機械学習モデルです これらのモデルを ご自分の
アプリケーションに組み込むことができます 覚えていただきたい点ですが 機械学習を操作するとき すべてをゼロから行う必要はありません 画像の中のテキストを認識するには
Vision APIを使用するだけでよいのです