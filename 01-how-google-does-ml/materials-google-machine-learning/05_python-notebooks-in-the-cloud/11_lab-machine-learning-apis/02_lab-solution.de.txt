In diesem Lab sehen wir uns an, wie wir ML-APIs
aus Datalab heraus aufrufen. Fangen wir an. Dieses Mal starten wir mit einem Notebook, das bereits in unserem
GitHub-Repository vorhanden ist. Zuerst müssen wir es auschecken. Checken wir also das Notebook aus. Dazu müssen Sie das Repository klonen. Dann öffnen wir ein Datalab und führen in Datalab
einen Bash-Befehl aus. Wir möchten ein neues Notebook beginnen. Das Notebook
kann einen beliebigen Namen haben. Wir nennen es "checkout". Bisher haben wir in Datalab
nur Python-Code ausgeführt. Durch Eingabe von "%bash" 
führt Datalab nun alles in dieser Zelle mit Bash aus,
wie alles andere in Jupyter auch. Jetzt erstellen wir einen Git-Klon
von unserem Repository. An dieser Stelle
führe ich den Befehl "!ls" aus, ein weiterer Weg, Bash zu nutzen. Wir sehen hier einen Ordner
namens "training-data-analyst". Wir können jetzt das Notebook laden und dann ausführen. Hier haben wir "training-data-analyst". Jetzt öffnen wir "courses",
"machine_learning", "deepdive" und dann "mlapis",
unser IPython-Notebook. und hier ist unser Notebook Zuerst aktivieren wir APIs und Dienste, damit wir die Vision API, die Translate API, die Speech API usw. verwenden können. Wir öffnen die Suche in der API-Bibliothek und geben "Vision" ein. Da ist die Vision API. Die API ist aktiviert. Wir wiederholen das jetzt
für Translate und Speech. Da ist die Google Translation API, die auch bereits aktiviert ist, und die Natural Language API, hier haben wir sie, ist auch aktiviert. Jetzt noch die Speech API,
die auch aktiviert sein soll. Sie ist auch aktiviert. Alle APIs sind also aktiviert. Jetzt holen wir uns die Anmeldedaten. Wir öffnen "APIs und Dienste" und besorgen uns die Anmeldedaten. Wir haben ja einen API-Schlüssel,
den ich dafür verwenden konnte. Alternativ können wir auch
einen neuen API-Schlüssel erstellen. Wir kopieren ihn. Das ist unser API-Schlüssel. Jetzt können wir wieder "mlapis" aufrufen, im Notebook an der Stelle "APIKEY" den API-Schlüssel
mit dem neuen ersetzen und es ausführen. Wir können auf "Ausführen" klicken oder UMSCHALT+Eingabe verwenden. Wir installieren jetzt den Python-Client. Danach führen wir die Translate API aus. Sie sehen dort die Eingaben: "Is it really this easy?" Die Übersetzung ist Französisch, unser aktuelles Ziel. Ändern wir das zu ES, Spanisch, und führen sie aus. Jetzt erhalten wir Spanisch als Ausgabe. Wie funktioniert das? Wir haben die Eingaben
als String-Array angegeben und vom Dienst
eine Übersetzung der Eingaben von Englisch
in eine gewünschte Sprache angefordert. Wir erhalten die Ausgaben,
also den übersetzten String. Auf ähnliche Weise
führen wir die Vision API aus. Dazu benötigen wir ein Bild. Wir nehmen ein Bild
mit einem Straßenschild. Ich spreche kein Chinesich,
daher weiß ich nicht, was dort steht. Finden wir es heraus. Wir laden das Bild in Cloud Storage hoch. Dieser Ordner ist öffentlich,
daher müssen wir nichts ändern. Wir weisen dann
die Vision API an, das Bild zu lesen und den Text für uns zu übersetzen. Führen wir dies aus. An dieser Stelle
erhalten wir die JSON-Ausgabe. Wir rufen Version 1 der Vision API auf und übergeben "gcs-image-uri". "gcs" bedeutet "Google Cloud Storage", wo sich unser Bild befindet. Wir könnten auch ein Bild
als Teil der Anfrage übergeben, aber der Vorgang
ist über Cloud Storage schneller, da wir keine Bilddaten 
mit unserer Anfrage hochladen müssen. Wir fragen eine Texterkennung an und erhalten sämtlichen Text
in diesem Bild zusammen mit der Sprache. "zh" bedeutet Chinesisch. Wir erhalten auch
zu jedem Textteil ein Begrenzungspolygon. Wir können jetzt den ersten Teil abrufen, den Texthinweis
mit der Sprache "zh" nehmen und dann das Ergebnis ausgeben lassen. Wir erhalten als Fremdsprache "zh" und den fremdsprachigen Text. Diesen können wir jetzt
als Eingabe verwenden. Das Ergebnis wird bereits dargestellt, daher klicke ich
in diese Zelle und lösche den Inhalt. Jetzt können wir
die Ausführung noch einmal starten und sicherstellen,
dass unser Text verwendet wird. Der chinesische Text
wurde ins Englische übersetzt. Wir können außerdem
die Language API verwenden. Hier haben wir einige Zitate. Wir möchten uns ansehen, welche Stimmungen
mit diesen Zitaten verbunden sind. Wie zuvor löschen wir die Zelle und starten die Ausführung. In diesem Fall lassen wir
die Polarität und die Größe ausgeben, die mit den 
einzelnen Zitaten verbunden sind. Die Polarität ist positiv
bei einer positiven Stimmung. Sie ist negativ bei negativer Stimmung. Und das macht Sinn. "Um Erfolg zu haben, musst du eine
ungeheure Ausdauer besitzen" ist positiv. Das Zitat "Wenn eine Person,
die du liebst, stirbt" ist jedoch negativ. Die Polarität ist negativ. Die Größe zeigt an, wie viele
sehr starke Formulierungen im Text sind. Als Letztes zeigen wir die Speech API. Wir haben schon eine Audiodatei
in Cloud Storage hochgeladen. Wir möchten die Sprache
als Text ausgeben lassen. Wir führen das aus und erhalten eine JSON-Antwort. Die JSON-Antwort gibt
einen hohen Konfidenzwert dafür an, dass der Text lautet:
"How old is the Brooklyn Bridge?" Wir haben in diesem Lab Datalab verwendet, um über Python-APIs
Modelle für maschinelles Lernen zu nutzen. Wir mussten diese Modelle nicht erstellen, sondern konnten sie direkt verwenden und in unsere 
eigenen Anwendungen integrieren. Sie sehen also, dass Sie nicht jedes 
ML-Modell von Grund auf entwickeln müssen. Wenn Sie Text und Bilder
erkennen lassen möchten, können Sie auch einfach
die Vision API verwenden.