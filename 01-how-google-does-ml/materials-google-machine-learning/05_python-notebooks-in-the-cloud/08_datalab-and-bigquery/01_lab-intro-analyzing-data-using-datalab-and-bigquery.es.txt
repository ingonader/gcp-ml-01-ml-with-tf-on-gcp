En este lab,
podrán usar un patrón muy útil. Usarán BigQuery
para calcular agregados útiles valores de percentiles y otros,
en 70 millones de filas. El resultado se trasladará
a un DataFrame de Pandas de una docena de filas. Luego, pueden usar ese
DataFrame de Pandas en memoria para crear una visualización. Este es el tipo de tarea que les tomaría
horas si la hicieran de otra forma. Sin embargo, en el lab
crearán los gráficos en segundos. Es importante realizar este tipo de flujo
de trabajo de desarrollo interactivo. De otro modo, no será fácil trabajar
con grandes conjuntos de datos. Es posible que piensen
que no necesitan trabajar con todos los datos. Pueden hacer un muestreo del conjunto
y trabajar con una muestra más pequeña. Sin embargo,
esa no es una buena práctica en el AA. Algo que me gusta decir
es que la diferencia clave entre la estadística y el AA
es cómo manejamos los valores atípicos. En la estadística, se tiende
a quitar estos valores. Pero en el aprendizaje automático,
se tiende a aprender estos valores. Y si quieren hacerlo,
deben tener suficientes ejemplos de ellos lo que significa que tienen
que trabajar con todos los datos. Deben tener la distribución
de los valores atípicos distribuciones de valores poco comunes,
en todo el conjunto de datos. Para hacerlo, deben trabajar
con todo el conjunto de datos. Una forma de hacerlo,
es lo que harán en este lab que es usar servicios administrados,
como BigQuery para procesar los datos a escala y, luego, traerlos a estructuras
en memoria más familiares, como Pandas y usar herramientas como las bibliotecas
de gráficos de Python. Este es un paradigma común de trabajo
con el que debemos familiarizarnos. Aprenderán cómo hacerlo en el lab.