1
00:00:00,000 --> 00:00:02,160
ここからラボ2です

2
00:00:02,160 --> 00:00:07,415
Datalabを使ってBigQueryの
クエリを実行する方法を見てみましょう

3
00:00:07,415 --> 00:00:11,070
ここでは 比較的大きなデータセットを
分析します

4
00:00:11,070 --> 00:00:14,230
データは7,000万行 8GBです

5
00:00:14,230 --> 00:00:17,960
これをBigqueryと
Cloud Datalabで分析します

6
00:00:17,960 --> 00:00:20,950
まずCloud Datalabを立ち上げます

7
00:00:20,950 --> 00:00:23,620
Cloud Shellの中からこれを行えます

8
00:00:23,620 --> 00:00:25,450
最初にすることは

9
00:00:25,450 --> 00:00:28,730
どのコンピューティングゾーンか
把握することです

10
00:00:28,730 --> 00:00:32,225
いずれか1つのゾーンでDatalabを実行できます

11
00:00:32,225 --> 00:00:35,370
コンピューティングゾーンはU.S. Central 1だと
わかっているので

12
00:00:35,370 --> 00:00:36,720
この部分は飛ばして

13
00:00:36,720 --> 00:00:39,205
次にDatalabを作成します

14
00:00:39,205 --> 00:00:43,760
datalab createの後に
VMの名前とSUMゾーンです

15
00:00:43,760 --> 00:00:45,610
実際にやってみましょう

16
00:00:45,610 --> 00:00:48,305
Cloud Shellに戻ります

17
00:00:48,935 --> 00:00:50,660
Cloud Shellです

18
00:00:50,660 --> 00:00:53,935
「datalab create mydatalabvm」と入力します

19
00:00:53,935 --> 00:01:00,275
そしてゾーンは「us-central1-b」です

20
00:01:01,475 --> 00:01:06,795
このコマンドが完了するには
5分ほどかかるでしょう

21
00:01:06,795 --> 00:01:08,840
それでビデオを早送りして

22
00:01:08,840 --> 00:01:12,070
このようなメッセージが表示される
箇所まで飛ばします

23
00:01:12,070 --> 00:01:16,130
「Localhost 8081に接続できます」 または

24
00:01:16,130 --> 00:01:19,525
「8081でウェブプレビューを実行できます」

25
00:01:19,525 --> 00:01:22,950
これが表示されるのを待って次に進みます

26
00:01:24,430 --> 00:01:26,475
Datalabが起動している間

27
00:01:26,475 --> 00:01:28,965
BigQueryを試してみましょう

28
00:01:28,965 --> 00:01:31,165
これが実行したいクエリです

29
00:01:31,165 --> 00:01:35,045
標準的なSQLを実行したいので
ここのコメントはとても重要です

30
00:01:35,045 --> 00:01:41,095
そしてBigQueryユーザーインターフェースは
... 少なくとも録画中は

31
00:01:41,095 --> 00:01:44,480
デフォルトで いわゆるレガシーSQLです

32
00:01:44,480 --> 00:01:46,970
ではBigQueryコンソールに進みます

33
00:01:46,970 --> 00:01:50,810
GCPメニューから
BigQueryコンソールを開けます

34
00:01:52,270 --> 00:01:54,330
ここを選択して

35
00:01:55,430 --> 00:01:58,250
下に進みBigQueryを選択します

36
00:01:59,510 --> 00:02:03,000
パスワードを使って
サインインするよう求められます

37
00:02:03,000 --> 00:02:06,055
ここでもQwikLabのパスワードを使います

38
00:02:06,055 --> 00:02:09,715
Qwiklabのパスワードを取得して入力します

39
00:02:16,725 --> 00:02:19,460
BigQueryにサインインできました

40
00:02:19,460 --> 00:02:22,640
自分のプロジェクトであることを確認します

41
00:02:22,640 --> 00:02:27,185
この場合 これではなく...
QwikLabリソースでもなく

42
00:02:27,185 --> 00:02:30,400
これです
[COMPOSE QUERY]をクリックします

43
00:02:30,400 --> 00:02:33,545
ユーザーインターフェースは
多少異なるかもしれません

44
00:02:33,545 --> 00:02:35,505
UIはよく変更されます

45
00:02:35,505 --> 00:02:42,630
でも通常はこれらのボタン等を
見つけることができるでしょう

46
00:02:42,630 --> 00:02:48,045
こちらに進んで この特定の
クエリを実行しましょう

47
00:02:49,055 --> 00:02:51,005
クエリを実行します

48
00:02:51,005 --> 00:02:52,805
別の方法があります

49
00:02:52,805 --> 00:02:55,445
#standardSQLと入力する代わりに

50
00:02:55,445 --> 00:02:57,790
オプションを表示できます

51
00:02:57,790 --> 00:03:00,240
そしてレガシーSQLをオフにできます

52
00:03:00,240 --> 00:03:01,735
これが別の方法です

53
00:03:01,735 --> 00:03:04,885
いずれにせよ 標準SQLを実行します

54
00:03:04,885 --> 00:03:08,250
standardSQLを実行して
[Run Query]で実行します

55
00:03:08,930 --> 00:03:11,990
この操作は「bigquery-samples」と
呼ばれるデータセットで行われます

56
00:03:11,990 --> 00:03:15,475
このデータセットはBigQueryサンプルによる
プロジェクトです

57
00:03:15,475 --> 00:03:18,370
さらにairline_ontime_data
データセットがあり

58
00:03:18,370 --> 00:03:20,680
テーブル名はflights（フライト）です

59
00:03:20,680 --> 00:03:25,165
ここにbigquery-samplesが表示されています

60
00:03:25,165 --> 00:03:27,025
いや ここには見えません

61
00:03:27,025 --> 00:03:31,470
左側のメニューにないプロジェクトを
見るには どうしますか？

62
00:03:31,470 --> 00:03:34,540
このドロップダウンメニューをクリックします

63
00:03:34,540 --> 00:03:38,895
そして[Switch to project]
>[Display Project]で

64
00:03:38,895 --> 00:03:40,900
プロジェクトを入力すると

65
00:03:40,900 --> 00:03:43,700
bigquery-samplesが表示されます

66
00:03:43,700 --> 00:03:47,290
このBigQueryサンプルの中に
airline_ontime_dataがあり

67
00:03:47,290 --> 00:03:50,320
そこにflightsというテーブルがあります

68
00:03:50,320 --> 00:03:52,770
ここでフライトを確認して

69
00:03:53,400 --> 00:03:56,025
プレビューを見ると

70
00:03:57,125 --> 00:03:59,160
これらが列です

71
00:03:59,160 --> 00:04:02,765
いくつかのサンプルデータ値が
テーブルに入っています

72
00:04:02,765 --> 00:04:04,445
詳しく見てみましょう

73
00:04:04,445 --> 00:04:07,860
このテーブルはほぼ8GBあることがわかります

74
00:04:07,860 --> 00:04:10,435
行の数は7,000万を超えています

75
00:04:10,435 --> 00:04:12,065
このとおりです

76
00:04:12,065 --> 00:04:15,100
次に クエリを実行しましょう

77
00:04:23,470 --> 00:04:27,160
実行すると こうなります

78
00:04:27,160 --> 00:04:28,540
何をしたのでしょうか

79
00:04:28,540 --> 00:04:31,105
出発遅れ（departure_delay）を選択し

80
00:04:31,105 --> 00:04:33,110
フライト数を数えました

81
00:04:33,110 --> 00:04:35,800
これはdeparture_delay別に分類された

82
00:04:35,800 --> 00:04:38,355
特定の出発遅れのフライト数です

83
00:04:38,355 --> 00:04:41,990
たとえば 出発遅れが「マイナス37」であれば

84
00:04:41,990 --> 00:04:46,630
37分早く出発したという意味ですが

85
00:04:46,630 --> 00:04:48,885
このようなフライトは何回ありましたか

86
00:04:48,885 --> 00:04:52,275
データセットによると107回です

87
00:04:52,275 --> 00:04:55,720
そして これが分位点です

88
00:04:55,720 --> 00:05:00,325
それぞれ28パーセンタイルですね

89
00:05:00,325 --> 00:05:02,575
5で割ったからです

90
00:05:02,575 --> 00:05:05,875
これらのフライトの80%は

91
00:05:05,875 --> 00:05:09,860
66分またはそれより早く到着しました

92
00:05:09,860 --> 00:05:18,015
フライトの60～80%は
41～66分より早く到着しました

93
00:05:18,015 --> 00:05:20,715
ここで質問です

94
00:05:20,715 --> 00:05:23,955
departure_delayの出発が35分早い場合

95
00:05:23,955 --> 00:05:25,850
中央値はいくつでしょうか

96
00:05:25,850 --> 00:05:29,075
中央値とは ちょうど中間にある値ですね

97
00:05:29,075 --> 00:05:31,100
ですから28分です

98
00:05:32,890 --> 00:05:38,140
コンソールに戻ります

99
00:05:38,140 --> 00:05:43,165
Datalabを続行するか尋ねられたら

100
00:05:43,165 --> 00:05:45,015
「はい」と答えます

101
00:05:46,615 --> 00:05:49,280
これらをすべて受け入れます

102
00:05:50,580 --> 00:05:53,040
他のクエリも実行してみましょう

103
00:05:53,040 --> 00:05:56,100
airport-pair（空港のペア）を検出します

104
00:05:56,100 --> 00:06:00,100
これは 特定の出発空港と特定の到着空港のうち

105
00:06:00,100 --> 00:06:03,235
空港間のフライト数が最も多いペアです

106
00:06:03,235 --> 00:06:05,980
再び同じテーブルを使いますが

107
00:06:05,980 --> 00:06:09,980
今回はdeparture_airport（出発）と
arrival_airport（到着）を選んで

108
00:06:09,980 --> 00:06:11,730
フライト数を数えます

109
00:06:11,730 --> 00:06:15,115
出発空港と到着空港の両方でグループ分けして

110
00:06:15,115 --> 00:06:17,960
フライト数ごとに降順に並べます

111
00:06:17,960 --> 00:06:22,875
つまり フライトの最も多い空港ペアが
第1位になります

112
00:06:22,875 --> 00:06:24,740
第10位までに制限して

113
00:06:24,740 --> 00:06:26,590
上位10の空港を検出します

114
00:06:26,590 --> 00:06:29,035
トップ10ですね

115
00:06:30,755 --> 00:06:35,775
こうして 1,700万件もの記録を処理しました

116
00:06:36,345 --> 00:06:40,010
これに2.3 秒しかかかりませんでした

117
00:06:40,010 --> 00:06:42,515
どうしてそれが可能なのでしょうか

118
00:06:42,515 --> 00:06:44,725
この7,000万件の記録を

119
00:06:44,725 --> 00:06:48,345
ここにある1台のマシンで
処理した訳ではありません

120
00:06:48,345 --> 00:06:51,130
数千台のマシンで処理しました

121
00:06:51,130 --> 00:06:52,755
大規模に実行したのです

122
00:06:52,755 --> 00:06:56,015
サービスをクラウドで展開するとは
こういう意味です

123
00:06:56,015 --> 00:06:58,300
サーバーレスな方法で処理を行うのです

124
00:06:58,300 --> 00:07:00,450
ともかくここに戻ります

125
00:07:00,450 --> 00:07:04,050
出発空港がLAX（ロサンゼルス）で

126
00:07:04,050 --> 00:07:07,380
到着空港がSAN（サンディエゴ）の場合

127
00:07:07,380 --> 00:07:11,825
133,000回のフライトがあります

128
00:07:11,825 --> 00:07:16,045
空港間のフライトが最も多い
2空港の組み合わせです

129
00:07:16,045 --> 00:07:19,605
ここでCloud Shellに戻って

130
00:07:19,605 --> 00:07:22,320
ウェブプレビューをクリックします

131
00:07:22,320 --> 00:07:25,580
Datalabを使い始めるために
ポート8081に変更します

132
00:07:25,580 --> 00:07:29,850
ここにある項目です
ウェブプレビューを選択して

133
00:07:29,850 --> 00:07:32,390
ポートを8081に変更します

134
00:07:32,390 --> 00:07:35,805
これでDatalabの中に入りました

135
00:07:35,805 --> 00:07:37,380
ここまでBigQueryで

136
00:07:37,380 --> 00:07:39,370
素晴らしい機能を見てきました

137
00:07:39,370 --> 00:07:43,740
数百万行のデータに対してSQLクエリを実行し

138
00:07:43,740 --> 00:07:45,840
数秒で答えが得られました

139
00:07:45,840 --> 00:07:51,440
素晴らしいです でも本当は
こういう答えを得るだけではなく

140
00:07:51,440 --> 00:07:53,460
たとえばグラフを描いて

141
00:07:53,460 --> 00:07:55,635
データを可視化したいですね

142
00:07:55,635 --> 00:07:59,505
BigQueryコンソールでは可視化できません

143
00:07:59,505 --> 00:08:02,550
カスタム可視化ツールを使いたいと思います

144
00:08:02,550 --> 00:08:04,760
それにはDatalabを使用します

145
00:08:04,760 --> 00:08:08,130
これを使うとPythonの持つ
優れた機能を利用して

146
00:08:08,130 --> 00:08:10,580
さまざまなグラフィック機能を使えます

147
00:08:11,170 --> 00:08:15,055
ここでは1つのクエリを実行しますが

148
00:08:15,055 --> 00:08:19,315
これをBigQueryコンソールからではなく

149
00:08:19,315 --> 00:08:21,405
Datalabから実行します

150
00:08:21,405 --> 00:08:23,145
これはDatalabです

151
00:08:23,145 --> 00:08:26,265
ここからNotebookを起動します

152
00:08:28,805 --> 00:08:30,645
このNotebookの中には

153
00:08:30,645 --> 00:08:32,455
コードセルがあります

154
00:08:32,455 --> 00:08:34,870
このセルにコードを貼り付けます

155
00:08:34,870 --> 00:08:37,824
[Run]をクリックしてコードを実行します

156
00:08:39,224 --> 00:08:42,760
これはすべてBigQueryで実行されます

157
00:08:42,760 --> 00:08:44,595
ここでも数秒で

158
00:08:44,595 --> 00:08:47,705
何百万回ものフライトを分析します

159
00:08:47,705 --> 00:08:52,995
その結果がPandasの
データフレームとして返ってきます

160
00:08:52,995 --> 00:08:56,080
このto_dataframeはPandasデータフレームです

161
00:08:57,000 --> 00:09:02,125
データフレームの最初の数行を表示します

162
00:09:02,125 --> 00:09:05,080
すでに見たように
departure_delay（出発遅れ）と

163
00:09:05,080 --> 00:09:06,795
フライト数 さらに

164
00:09:06,795 --> 00:09:08,930
デシル（十分位数）があります

165
00:09:08,930 --> 00:09:12,440
ここでは分位点を10に設定したからです

166
00:09:12,440 --> 00:09:13,830
10件ありますね

167
00:09:13,830 --> 00:09:16,415
これをPythonリストとして受け取ります

168
00:09:16,415 --> 00:09:21,620
ここで 同じデータフレームで

169
00:09:23,120 --> 00:09:27,070
手早く名前を変更します

170
00:09:29,110 --> 00:09:34,350
こうして このデシルデータを使って

171
00:09:34,350 --> 00:09:36,325
それを分割し

172
00:09:36,325 --> 00:09:37,915
0% 10%

173
00:09:37,915 --> 00:09:39,775
20% 30%など

174
00:09:39,775 --> 00:09:41,765
別々の列にしました

175
00:09:41,765 --> 00:09:44,590
なぜこうするのでしょうか？ 別々の列にすると

176
00:09:44,590 --> 00:09:48,120
その次の操作が可能になるからです

177
00:09:51,740 --> 00:09:54,230
操作を進めます

178
00:10:05,840 --> 00:10:08,790
ここで0%を除外して

179
00:10:08,790 --> 00:10:10,700
100%も除外します

180
00:10:10,700 --> 00:10:14,980
こうしてデータ全体から10%～90%を選びます

181
00:10:14,980 --> 00:10:18,545
次にそれをグラフとしてプロットします

182
00:10:18,545 --> 00:10:19,850
ここで

183
00:10:20,700 --> 00:10:22,965
このグラフをどのように解釈しますか

184
00:10:22,965 --> 00:10:24,820
ここでたとえば

185
00:10:24,820 --> 00:10:27,260
departure_delayが10の場合

186
00:10:27,260 --> 00:10:29,245
つまり10分の遅れですが

187
00:10:29,825 --> 00:10:34,190
これらのフライトの10%は
それにもかかわらず早く到着します

188
00:10:34,190 --> 00:10:39,605
しかしフライトの90%は
21分以内の遅れで到着します

189
00:10:39,605 --> 00:10:41,145
これがデシルです

190
00:10:41,145 --> 00:10:44,450
一方 平均としてはdeparture-delayも

191
00:10:44,450 --> 00:10:46,440
arrival_delayも

192
00:10:46,440 --> 00:10:48,870
おそらく3～4分の遅れです

193
00:10:48,870 --> 00:10:51,590
これらの線の基本的な意味はこのとおりです

194
00:10:51,590 --> 00:10:55,540
特定の出発遅れの分布を示しています

195
00:10:55,540 --> 00:10:59,510
これを見ていくと すべての出発遅れで

196
00:10:59,510 --> 00:11:03,960
基本的に線形関係があることがわかります

197
00:11:03,960 --> 00:11:07,745
ただしdeparture_delaysが
約マイナス20になるまでです

198
00:11:07,745 --> 00:11:14,195
つまり20分以上早く出発したフライトですね

199
00:11:14,195 --> 00:11:16,180
かなり早く出発しました

200
00:11:16,180 --> 00:11:19,870
これは 線形関係というよりも ばらばらです

201
00:11:19,870 --> 00:11:21,995
線形モデルを構築するとしたら

202
00:11:21,995 --> 00:11:26,520
分布の真ん中ぐらいでは
線形モデルで問題ないでしょう

203
00:11:26,520 --> 00:11:28,350
でも 端では問題になります

204
00:11:28,350 --> 00:11:30,980
このような情報や洞察は

205
00:11:30,980 --> 00:11:34,635
他の方法では簡単に得られません

206
00:11:34,635 --> 00:11:37,155
分布をプロットする必要があります

207
00:11:37,155 --> 00:11:40,385
そしてPythonの能力を最大限に活用できるなら

208
00:11:40,385 --> 00:11:43,250
分布をプロットすることはとても簡単です