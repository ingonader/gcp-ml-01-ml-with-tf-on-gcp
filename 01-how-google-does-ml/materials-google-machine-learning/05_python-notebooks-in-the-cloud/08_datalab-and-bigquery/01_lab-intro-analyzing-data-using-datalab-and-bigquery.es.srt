1
00:00:00,780 --> 00:00:05,005
En este lab,
podrán usar un patrón muy útil.

2
00:00:05,775 --> 00:00:09,405
Usarán BigQuery
para calcular agregados útiles

3
00:00:09,405 --> 00:00:13,580
valores de percentiles y otros,
en 70 millones de filas.

4
00:00:14,080 --> 00:00:16,970
El resultado se trasladará
a un DataFrame de Pandas

5
00:00:16,970 --> 00:00:18,960
de una docena de filas.

6
00:00:18,960 --> 00:00:22,540
Luego, pueden usar ese
DataFrame de Pandas en memoria

7
00:00:22,540 --> 00:00:24,465
para crear una visualización.

8
00:00:24,465 --> 00:00:28,950
Este es el tipo de tarea que les tomaría
horas si la hicieran de otra forma.

9
00:00:29,610 --> 00:00:33,895
Sin embargo, en el lab
crearán los gráficos en segundos.

10
00:00:33,895 --> 00:00:38,580
Es importante realizar este tipo de flujo
de trabajo de desarrollo interactivo.

11
00:00:38,580 --> 00:00:43,115
De otro modo, no será fácil trabajar
con grandes conjuntos de datos.

12
00:00:43,575 --> 00:00:45,975
Es posible que piensen
que no necesitan trabajar

13
00:00:45,975 --> 00:00:47,125
con todos los datos.

14
00:00:47,125 --> 00:00:50,810
Pueden hacer un muestreo del conjunto
y trabajar con una muestra más pequeña.

15
00:00:50,810 --> 00:00:54,715
Sin embargo,
esa no es una buena práctica en el AA.

16
00:00:55,695 --> 00:00:58,205
Algo que me gusta decir
es que la diferencia clave

17
00:00:58,205 --> 00:01:02,145
entre la estadística y el AA
es cómo manejamos los valores atípicos.

18
00:01:02,450 --> 00:01:05,525
En la estadística, se tiende
a quitar estos valores.

19
00:01:05,525 --> 00:01:09,555
Pero en el aprendizaje automático,
se tiende a aprender estos valores.

20
00:01:09,555 --> 00:01:14,090
Y si quieren hacerlo,
deben tener suficientes ejemplos de ellos

21
00:01:14,090 --> 00:01:17,775
lo que significa que tienen
que trabajar con todos los datos.

22
00:01:17,775 --> 00:01:21,150
Deben tener la distribución
de los valores atípicos

23
00:01:21,150 --> 00:01:25,285
distribuciones de valores poco comunes,
en todo el conjunto de datos.

24
00:01:25,285 --> 00:01:28,855
Para hacerlo, deben trabajar
con todo el conjunto de datos.

25
00:01:29,275 --> 00:01:32,615
Una forma de hacerlo,
es lo que harán en este lab

26
00:01:32,615 --> 00:01:36,630
que es usar servicios administrados,
como BigQuery

27
00:01:36,630 --> 00:01:39,385
para procesar los datos a escala

28
00:01:39,385 --> 00:01:44,845
y, luego, traerlos a estructuras
en memoria más familiares, como Pandas

29
00:01:44,845 --> 00:01:49,595
y usar herramientas como las bibliotecas
de gráficos de Python.

30
00:01:49,595 --> 00:01:54,525
Este es un paradigma común de trabajo
con el que debemos familiarizarnos.

31
00:01:55,245 --> 00:01:57,595
Aprenderán cómo hacerlo en el lab.