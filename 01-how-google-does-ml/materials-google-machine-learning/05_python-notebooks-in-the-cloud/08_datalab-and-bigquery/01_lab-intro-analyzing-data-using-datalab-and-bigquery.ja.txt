このラボではとても役立つパターンを使います BigQueryを使って役立つ計算を行います 7千万を超える行の集計や
パーセンタイル値などです 結果はPandas DataFrameの
多数の行に入力されます そして そのインメモリPandas DataFrameを
可視化のために使用できます もし この作業を他の方法で行うなら
何時間もかかるでしょう でも このラボでは 数秒でグラフを作成します こうした対話式の開発ワークフローを
定めることは重要です これがないと 大量のデータセットで
簡単に作業できません でも「すべてのデータを使う必要はない」
と考えるかもしれません 単に小さなサンプルを抽出し
それを処理すればよいのでは？ しかし これは機械学習では
不適切なプラクティスです 1つお伝えしたい点ですが 統計学と機械学習には重要な違いがあります それは異常値の扱いです 統計学では 異常値をよく除外します しかし機械学習では 通常 異常値を学習します 異常値を学習したければ 十分な数の異常値の実例が必要です つまり実質的に
すべてのデータを使う必要があります 異常値や希少値がデータセット全体に よく分散している必要があります そのためには 完全なデータセットを使うべきです その1つの方法を このラボでお見せします それはBigQueryのようなマネージドサービスで 大規模にデータを処理することです そしてPandasのような使い慣れた
インメモリ構造にデータを戻し Pythonのプロッティング ライブラリ
などのツールを使います これを実例として このような作業の流れに慣れていただきます この方法をラボで学習します