ここからラボ2です Datalabを使ってBigQueryの
クエリを実行する方法を見てみましょう ここでは 比較的大きなデータセットを
分析します データは7,000万行 8GBです これをBigqueryと
Cloud Datalabで分析します まずCloud Datalabを立ち上げます Cloud Shellの中からこれを行えます 最初にすることは どのコンピューティングゾーンか
把握することです いずれか1つのゾーンでDatalabを実行できます コンピューティングゾーンはU.S. Central 1だと
わかっているので この部分は飛ばして 次にDatalabを作成します datalab createの後に
VMの名前とSUMゾーンです 実際にやってみましょう Cloud Shellに戻ります Cloud Shellです 「datalab create mydatalabvm」と入力します そしてゾーンは「us-central1-b」です このコマンドが完了するには
5分ほどかかるでしょう それでビデオを早送りして このようなメッセージが表示される
箇所まで飛ばします 「Localhost 8081に接続できます」 または 「8081でウェブプレビューを実行できます」 これが表示されるのを待って次に進みます Datalabが起動している間 BigQueryを試してみましょう これが実行したいクエリです 標準的なSQLを実行したいので
ここのコメントはとても重要です そしてBigQueryユーザーインターフェースは
... 少なくとも録画中は デフォルトで いわゆるレガシーSQLです ではBigQueryコンソールに進みます GCPメニューから
BigQueryコンソールを開けます ここを選択して 下に進みBigQueryを選択します パスワードを使って
サインインするよう求められます ここでもQwikLabのパスワードを使います Qwiklabのパスワードを取得して入力します BigQueryにサインインできました 自分のプロジェクトであることを確認します この場合 これではなく...
QwikLabリソースでもなく これです
[COMPOSE QUERY]をクリックします ユーザーインターフェースは
多少異なるかもしれません UIはよく変更されます でも通常はこれらのボタン等を
見つけることができるでしょう こちらに進んで この特定の
クエリを実行しましょう クエリを実行します 別の方法があります #standardSQLと入力する代わりに オプションを表示できます そしてレガシーSQLをオフにできます これが別の方法です いずれにせよ 標準SQLを実行します standardSQLを実行して
[Run Query]で実行します この操作は「bigquery-samples」と
呼ばれるデータセットで行われます このデータセットはBigQueryサンプルによる
プロジェクトです さらにairline_ontime_data
データセットがあり テーブル名はflights（フライト）です ここにbigquery-samplesが表示されています いや ここには見えません 左側のメニューにないプロジェクトを
見るには どうしますか？ このドロップダウンメニューをクリックします そして[Switch to project]
>[Display Project]で プロジェクトを入力すると bigquery-samplesが表示されます このBigQueryサンプルの中に
airline_ontime_dataがあり そこにflightsというテーブルがあります ここでフライトを確認して プレビューを見ると これらが列です いくつかのサンプルデータ値が
テーブルに入っています 詳しく見てみましょう このテーブルはほぼ8GBあることがわかります 行の数は7,000万を超えています このとおりです 次に クエリを実行しましょう 実行すると こうなります 何をしたのでしょうか 出発遅れ（departure_delay）を選択し フライト数を数えました これはdeparture_delay別に分類された 特定の出発遅れのフライト数です たとえば 出発遅れが「マイナス37」であれば 37分早く出発したという意味ですが このようなフライトは何回ありましたか データセットによると107回です そして これが分位点です それぞれ28パーセンタイルですね 5で割ったからです これらのフライトの80%は 66分またはそれより早く到着しました フライトの60～80%は
41～66分より早く到着しました ここで質問です departure_delayの出発が35分早い場合 中央値はいくつでしょうか 中央値とは ちょうど中間にある値ですね ですから28分です コンソールに戻ります Datalabを続行するか尋ねられたら 「はい」と答えます これらをすべて受け入れます 他のクエリも実行してみましょう airport-pair（空港のペア）を検出します これは 特定の出発空港と特定の到着空港のうち 空港間のフライト数が最も多いペアです 再び同じテーブルを使いますが 今回はdeparture_airport（出発）と
arrival_airport（到着）を選んで フライト数を数えます 出発空港と到着空港の両方でグループ分けして フライト数ごとに降順に並べます つまり フライトの最も多い空港ペアが
第1位になります 第10位までに制限して 上位10の空港を検出します トップ10ですね こうして 1,700万件もの記録を処理しました これに2.3 秒しかかかりませんでした どうしてそれが可能なのでしょうか この7,000万件の記録を ここにある1台のマシンで
処理した訳ではありません 数千台のマシンで処理しました 大規模に実行したのです サービスをクラウドで展開するとは
こういう意味です サーバーレスな方法で処理を行うのです ともかくここに戻ります 出発空港がLAX（ロサンゼルス）で 到着空港がSAN（サンディエゴ）の場合 133,000回のフライトがあります 空港間のフライトが最も多い
2空港の組み合わせです ここでCloud Shellに戻って ウェブプレビューをクリックします Datalabを使い始めるために
ポート8081に変更します ここにある項目です
ウェブプレビューを選択して ポートを8081に変更します これでDatalabの中に入りました ここまでBigQueryで 素晴らしい機能を見てきました 数百万行のデータに対してSQLクエリを実行し 数秒で答えが得られました 素晴らしいです でも本当は
こういう答えを得るだけではなく たとえばグラフを描いて データを可視化したいですね BigQueryコンソールでは可視化できません カスタム可視化ツールを使いたいと思います それにはDatalabを使用します これを使うとPythonの持つ
優れた機能を利用して さまざまなグラフィック機能を使えます ここでは1つのクエリを実行しますが これをBigQueryコンソールからではなく Datalabから実行します これはDatalabです ここからNotebookを起動します このNotebookの中には コードセルがあります このセルにコードを貼り付けます [Run]をクリックしてコードを実行します これはすべてBigQueryで実行されます ここでも数秒で 何百万回ものフライトを分析します その結果がPandasの
データフレームとして返ってきます このto_dataframeはPandasデータフレームです データフレームの最初の数行を表示します すでに見たように
departure_delay（出発遅れ）と フライト数 さらに デシル（十分位数）があります ここでは分位点を10に設定したからです 10件ありますね これをPythonリストとして受け取ります ここで 同じデータフレームで 手早く名前を変更します こうして このデシルデータを使って それを分割し 0% 10% 20% 30%など 別々の列にしました なぜこうするのでしょうか？ 別々の列にすると その次の操作が可能になるからです 操作を進めます ここで0%を除外して 100%も除外します こうしてデータ全体から10%～90%を選びます 次にそれをグラフとしてプロットします ここで このグラフをどのように解釈しますか ここでたとえば departure_delayが10の場合 つまり10分の遅れですが これらのフライトの10%は
それにもかかわらず早く到着します しかしフライトの90%は
21分以内の遅れで到着します これがデシルです 一方 平均としてはdeparture-delayも arrival_delayも おそらく3～4分の遅れです これらの線の基本的な意味はこのとおりです 特定の出発遅れの分布を示しています これを見ていくと すべての出発遅れで 基本的に線形関係があることがわかります ただしdeparture_delaysが
約マイナス20になるまでです つまり20分以上早く出発したフライトですね かなり早く出発しました これは 線形関係というよりも ばらばらです 線形モデルを構築するとしたら 分布の真ん中ぐらいでは
線形モデルで問題ないでしょう でも 端では問題になります このような情報や洞察は 他の方法では簡単に得られません 分布をプロットする必要があります そしてPythonの能力を最大限に活用できるなら 分布をプロットすることはとても簡単です