1
00:00:00,770 --> 00:00:05,265
Dans cet atelier,
vous allez utiliser un format très utile.

2
00:00:05,265 --> 00:00:09,405
Vous allez vous servir de BigQuery
pour calculer des données agrégées,

3
00:00:09,405 --> 00:00:13,580
des valeurs de centile, etc.,
sur plus de 70 millions de lignes.

4
00:00:13,580 --> 00:00:18,140
Le résultat s'affichera dans un dataframe
Pandas d'une dizaine de lignes.

5
00:00:18,140 --> 00:00:24,020
Vous pourrez alors utiliser le dataframe
en mémoire à des fins de visualisation.

6
00:00:24,020 --> 00:00:29,200
Ce genre d'opération prendrait des heures
si vous utilisiez une autre méthode.

7
00:00:29,200 --> 00:00:31,105
Toutefois, dans cet atelier,

8
00:00:31,105 --> 00:00:33,500
vous allez créer un graphique
en quelques secondes.

9
00:00:33,500 --> 00:00:38,135
Il est crucial de créer ce type de flux
de développement interactif.

10
00:00:38,135 --> 00:00:43,150
Autrement, vous aurez du mal à utiliser
de larges ensembles de données.

11
00:00:43,390 --> 00:00:46,415
Vous pensez peut-être
que toutes les données ne sont pas utiles,

12
00:00:46,415 --> 00:00:50,575
que vous pourriez échantillonner
l'ensemble de données pour le réduire.

13
00:00:50,575 --> 00:00:54,955
Toutefois, ce n'est pas du tout recommandé
avec le machine learning.

14
00:00:54,955 --> 00:00:56,650
Je dis souvent que

15
00:00:56,650 --> 00:00:59,815
la grande différence entre
les statistiques et le machine learning,

16
00:00:59,815 --> 00:01:02,045
c'est le traitement
des anomalies.

17
00:01:02,045 --> 00:01:05,425
En statistique,
les anomalies sont supprimées,

18
00:01:05,425 --> 00:01:07,100
mais dans le machine learning,

19
00:01:07,100 --> 00:01:09,255
les anomalies sont apprises.

20
00:01:09,255 --> 00:01:11,245
Si vous voulez les apprendre,

21
00:01:11,245 --> 00:01:14,080
vous devez disposer
de suffisamment d'exemples,

22
00:01:14,080 --> 00:01:17,775
ce qui revient à dire
qu'il faut utiliser toutes vos données.

23
00:01:17,775 --> 00:01:21,150
Vous avez besoin d'une distribution
d'anomalies,

24
00:01:21,150 --> 00:01:25,285
de distributions de valeurs rares
au sein de l'ensemble de données.

25
00:01:25,285 --> 00:01:26,795
Et pour cela,

26
00:01:26,795 --> 00:01:29,125
vous devez utiliser
tout l'ensemble de données.

27
00:01:29,125 --> 00:01:30,660
L'une des méthodes préconisées

28
00:01:30,660 --> 00:01:32,695
est de procéder comme dans cet atelier.

29
00:01:32,695 --> 00:01:36,665
Vous devez utiliser
des services gérés tels que BigQuery

30
00:01:36,665 --> 00:01:39,055
pour traiter des données à grande échelle,

31
00:01:39,055 --> 00:01:44,915
puis les ramener dans des structures
en mémoire de type Pandas

32
00:01:44,915 --> 00:01:49,105
et vous servir d'outils 
comme les bibliothèques de traçage Python.

33
00:01:49,105 --> 00:01:54,320
C'est une méthode de travail courante
à laquelle nous devons nous habituer.

34
00:01:54,320 --> 00:01:57,080
C'est ce que nous allons faire maintenant.