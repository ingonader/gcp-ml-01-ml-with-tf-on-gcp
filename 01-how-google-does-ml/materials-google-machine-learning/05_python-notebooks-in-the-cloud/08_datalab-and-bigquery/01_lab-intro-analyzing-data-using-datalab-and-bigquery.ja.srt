1
00:00:00,000 --> 00:00:05,305
このラボではとても役立つパターンを使います

2
00:00:05,305 --> 00:00:09,325
BigQueryを使って役立つ計算を行います

3
00:00:09,325 --> 00:00:13,565
7千万を超える行の集計や
パーセンタイル値などです

4
00:00:13,565 --> 00:00:18,140
結果はPandas DataFrameの
多数の行に入力されます

5
00:00:18,140 --> 00:00:24,040
そして そのインメモリPandas DataFrameを
可視化のために使用できます

6
00:00:24,040 --> 00:00:29,200
もし この作業を他の方法で行うなら
何時間もかかるでしょう

7
00:00:29,200 --> 00:00:31,245
でも このラボでは

8
00:00:31,245 --> 00:00:33,565
数秒でグラフを作成します

9
00:00:33,565 --> 00:00:38,145
こうした対話式の開発ワークフローを
定めることは重要です

10
00:00:38,145 --> 00:00:43,210
これがないと 大量のデータセットで
簡単に作業できません

11
00:00:43,210 --> 00:00:46,785
でも「すべてのデータを使う必要はない」
と考えるかもしれません

12
00:00:46,785 --> 00:00:50,455
単に小さなサンプルを抽出し
それを処理すればよいのでは？

13
00:00:50,815 --> 00:00:54,925
しかし これは機械学習では
不適切なプラクティスです

14
00:00:54,925 --> 00:00:56,950
1つお伝えしたい点ですが

15
00:00:56,950 --> 00:00:59,900
統計学と機械学習には重要な違いがあります

16
00:00:59,900 --> 00:01:02,105
それは異常値の扱いです

17
00:01:02,105 --> 00:01:05,435
統計学では 異常値をよく除外します

18
00:01:05,435 --> 00:01:07,400
しかし機械学習では 通常

19
00:01:07,400 --> 00:01:09,270
異常値を学習します

20
00:01:09,270 --> 00:01:11,305
異常値を学習したければ

21
00:01:11,305 --> 00:01:14,055
十分な数の異常値の実例が必要です

22
00:01:14,055 --> 00:01:17,795
つまり実質的に
すべてのデータを使う必要があります

23
00:01:17,795 --> 00:01:21,375
異常値や希少値がデータセット全体に

24
00:01:21,375 --> 00:01:25,275
よく分散している必要があります

25
00:01:25,275 --> 00:01:26,405
そのためには

26
00:01:26,405 --> 00:01:29,145
完全なデータセットを使うべきです

27
00:01:29,145 --> 00:01:30,600
その1つの方法を

28
00:01:30,600 --> 00:01:32,720
このラボでお見せします

29
00:01:32,720 --> 00:01:36,225
それはBigQueryのようなマネージドサービスで

30
00:01:36,225 --> 00:01:38,975
大規模にデータを処理することです

31
00:01:38,975 --> 00:01:44,965
そしてPandasのような使い慣れた
インメモリ構造にデータを戻し

32
00:01:44,965 --> 00:01:49,125
Pythonのプロッティング ライブラリ
などのツールを使います

33
00:01:49,125 --> 00:01:50,740
これを実例として

34
00:01:50,740 --> 00:01:54,320
このような作業の流れに慣れていただきます

35
00:01:54,320 --> 00:01:57,790
この方法をラボで学習します