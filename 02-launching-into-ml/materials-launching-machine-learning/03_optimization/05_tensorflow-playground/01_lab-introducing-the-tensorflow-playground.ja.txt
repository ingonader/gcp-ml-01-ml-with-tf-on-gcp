ここまでは 
勾配降下法の仕組みを見てきました ここからは 説明した現象の多くを
リアルタイムで確認できるツールを使って 実際の学習の様子を見ていきましょう TensorFlow Playgroundは ニューラルネットワーク（NN）の仕組みを
可視化するための強力なツールです 「ニューラルネットワークの話はまだでは？」
と思った方がいるかもしれません ご安心ください
この後すぐに説明します 理由はこれから説明しますが 最もシンプルなNNは
数学的に線形モデルと同等なので このツールは これまでに学んだ内容の
実演にも適しています MLに関する洞察力を高めるため このツールを使って ここまでに説明した
理論的な部分を検証します 学習率の設定が与える影響と MLモデルの勾配が降下する様子を
目で確認できます また このコースや後のコースで取り上げる
トピックについても関連付けて説明します まず インターフェースについてですが このツールの機能のうち 後で説明する内容に関連するものは
一部除外しましたが 調整できる項目はたくさんあります まず FEATURES欄は モデルに入力されるデータです 各ボックス内の色分けは 
特徴量の値の正負を表していて オレンジは負の値 青は正の値です 次に HIDDEN LAYERS欄には 重みが表示されます 重み線にカーソルを合わせると
重みの値を確認できます モデルがトレーニングするにつれ 線の太さと不透明度が変わり 全体から見た重みの値を
感覚的にとらえることができます 次に OUTPUT欄には 学習データと特徴量領域のすべての点に対する モデルの現在の予測の両方が表示されます 現在の学習の損失も表示されます FEATURES欄と同様に
色分けは値の正負を表しています 画面上部のコントロールバーには 学習をリセットする 開始する
ステップ単位で進めるためのボタンがあります 学習率を設定するための
ドロップダウンもあります DATA欄では さまざまなデータセットを
選択し バッチサイズを設定できます まず 線形モデルに
データの分類を学習させます このリンクをクリックすると 必要最低限の機能のみを備えた
TensorFlow Playgroundが表示されます HIDDEN LAYERSは 
ここではおいておきます ツールのこの構成では モデルに特徴量ベクターを入力すると 重み係数とのドット積を計算し バイアス項を足し 合計値の符号を使って決定境界を求めます したがって この構成は
線形モデルと考えることができます 2つの異なるクラスタに属するデータを
分類するモデルから見ていきましょう 再生ボタンの右にある
ステップボタンをクリックし インターフェースの変化を
よく見ていてください エポック数が1増え 重み線の色とサイズが変化し 損失関数の現在の値が変化し 損失グラフの傾きが下向きになり 出力された決定境界も変化しました 重み1の線にカーソルを合わせると この重みの値を確認できます 続いて 再生ボタンをクリックして
学習を再開しますが 損失が0.002を下回ったら
すぐに一時停止します 目安は200エポック弱です これで最初のモデルに
学習させることができました ここから 少し複雑になります まず 3つの異なる学習率がモデルの学習に
どのように影響するのか見ていきましょう 学習率はハイパーパラメータです モデルのトレーニングが始まる前に設定し ループが反復するたびに重みを
どれだけ変更するかを判断するため 微分係数を掛け合わせます このリンクをクリックして学習率が
非常に小さいモデルの学習を開始します 損失が約100エポックに到達するまで待ちます 目安は約2秒後です 100エポックに達したら
モデルを一時停止します 現在の学習の損失はどれくらいですか 学習した重みはどれくらいですか 続いて 学習率を0.001に上げて
学習を再開します 再び約100エポックに達したら停止します
損失はどうなったでしょうか 今回の方が大幅に少なくなっているはずです 重み1の値も覚えおいてください 続いて 学習率を0.1に上げて
学習を再開し 再び100エポック目まで学習を行います 損失曲線の下がり方は 前と比べてどうですか 今回の方が下がり方が非常に速いはずです では これらの観察内容をまとめて 最適化に関して学んだことを使って
説明できるか確認しましょう 学習率を10に上げてモデルの学習を再開します 最初はステップボタンを使って
ステップ単位で進めます 重みの大きさを見てください 続いて 100エポック目まで学習を続けます 今回の損失曲線の下がり方はどうでしたか 急激に下がっているはずです では これらの観察内容をまとめて 最適化に関して学んだことを使って
説明できるか確認しましょう こちらは ツールから得られた
結果をまとめた表です 皆さんの結果は 
このとおりでなくても構いません 結果が異なるのは 実験を再実行した場合に
結果が異なるのと同じ理由です TensorFlow Playgroundは
重みをランダムに初期化します つまり 毎回ランダムな場所から
探索を開始するということです 重み1の欄を見ていきましょう 重みの大きさは 学習率が
高くなるにつれて増えています なぜでしょうか モデルのステップが大きいからです 実際に学習率が10の場合 最初のステップによって
重みが著しく変化しました 経時的な損失の変化の欄を見てみましょう 学習率が高くなるにつれ 損失曲線の傾きが急になっています これは先ほど見た結果を
異なる視点からとらえたものです