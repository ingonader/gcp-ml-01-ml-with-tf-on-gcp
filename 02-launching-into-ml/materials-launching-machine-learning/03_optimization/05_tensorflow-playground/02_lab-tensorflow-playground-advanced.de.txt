Fällt Ihnen an diesem Dataset etwas auf? Klicken Sie auf den Link und beginnen Sie 
mit dem Modelltraining im neuen Fenster. Was fällt Ihnen am Verlust
und an der Verlustkurve auf? Sehen Sie eine Konvergenz gegen null? Wenn Sie direkt auf die Schaltfläche
"Training starten" geklickt haben, sollten Sie eine
Ausgabe wie diese hier sehen. Beachten Sie, dass die Entscheidungsgrenze
die Daten unzureichend nach Klassen trennt. Woran liegt das? Der Grund ist
die nicht lineare Beziehung der Daten, Sie können also keine gerade Linie
ziehen, die Orange von Blau trennt. Diese Daten erfordern eine
nichtlineare Entscheidungsgrenze, die wir hier als einen Kreis
um die blauen Datenpunkte erkennen. Aber es ist nicht alles verloren. Klicken Sie einige Felder
in der Eingabespalte an und versuchen Sie neue Merkmale hinzuzufügen,
um die Leistung zu verbessern. Ihre Ausgabe sollte
nun so aussehen, wenn Sie die Merkmale "X1 hoch 2" und
"X2 hoch 2" ausgewählt haben. Beachten Sie die 
nun kreisförmige Entscheidungsgrenze. Wie kann ein lineares Modell eine 
nicht lineare Entscheidungsgrenze lernen? Wir erinnern uns: Lineare Modelle 
können eine Reihe von Gewichtungen lernen, die sie dann mit ihren Eigenschaften
multiplizieren, um Vorhersagen zu treffen. Wenn diese Merkmale Terme
ersten Grades sind, wie x und y, ist das Ergebnis
ein Polynom ersten Grades, wie 2x oder 2/3y. Dann sehen die Vorhersagen des Modells
wie eine Linie oder eine Hyperebene aus, aber die Merkmale eines linearen Modells
müssen nicht Terme ersten Grades sein. Ebenso wie Sie "x hoch 2"
nehmen und mit 2 multiplizieren können, können Sie ein Merkmal jeden Grades nehmen und dafür eine Gewichtung
in einem linearen Modell lernen. Mal sehen, wie weit wir
mit dieser neuen Idee kommen. Was ist mit dieser Kurve? Das letzte Mal konnten wir zwei nichtlineare Merkmale finden,
die das Problem linear lösbar machten. Wird diese Strategie auch
hier funktionieren? Versuchen Sie es. Wir wissen jetzt,
dass mit den verfügbaren Merkmalen und diesem Modelltyp dieses
bestimmte Dataset nicht linear lösbar ist. Das beste Modell, das ich trainieren 
konnte, hatte einen Verlust von ca. 0,6. Die verfügbaren Qualifizierer oder
Merkmale sind jedoch entscheidend, da es ein Merkmal gibt, das das
Lernen dieser Beziehung vereinfacht. Stellen Sie sich etwa ein
Merkmal vor, das die Daten so entwirrt, dass Blau und Orange einfach
als zwei parallele Linien erscheinen. Diese parallelen Linien wären dann 
leicht durch eine dritte Linie trennbar. Es ist toll, solche Merkmale zu finden, aber man kann das nicht
erwarten. Und das ist problematisch. Zwar finden wir nicht oft so tolle 
Merkmale wie in den Spielzeug-Beispielen, aber Feature Engineering, also
die systematische Verbesserung oder der Erwerb neuer Merkmale ist ein
wichtiger Teil des maschinellen Lernens. Darauf konzentrieren wir uns in Kurs 3. Was können wir tun, wenn das Entwickeln neuer Merkmale
für lineare Modelle fehlschlägt? Die Antwort ist,
komplexere Modelle zu verwenden. Es gibt viele Arten von Modellen,
die nicht lineare Entscheidungsgrenzen lernen können. In diesem Kurs konzentrieren
wir uns auf neuronale Netzwerke. Neuronale Netzwerke sind nicht
besser als jede andere Art von Modell. Sie sind deshalb populärer geworden,
weil sie ideal sind, um typische Probleme moderner Unternehmen zu lösen.