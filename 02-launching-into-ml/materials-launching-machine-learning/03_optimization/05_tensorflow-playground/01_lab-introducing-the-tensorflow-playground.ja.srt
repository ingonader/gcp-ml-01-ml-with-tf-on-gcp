1
00:00:00,320 --> 00:00:03,985
ここまでは 
勾配降下法の仕組みを見てきました

2
00:00:03,985 --> 00:00:08,920
ここからは 説明した現象の多くを
リアルタイムで確認できるツールを使って

3
00:00:08,920 --> 00:00:12,065
実際の学習の様子を見ていきましょう

4
00:00:13,285 --> 00:00:15,170
TensorFlow Playgroundは

5
00:00:15,170 --> 00:00:18,660
ニューラルネットワーク（NN）の仕組みを
可視化するための強力なツールです

6
00:00:18,660 --> 00:00:22,560
「ニューラルネットワークの話はまだでは？」
と思った方がいるかもしれません

7
00:00:22,560 --> 00:00:24,925
ご安心ください
この後すぐに説明します

8
00:00:24,925 --> 00:00:27,095
理由はこれから説明しますが

9
00:00:27,095 --> 00:00:30,825
最もシンプルなNNは
数学的に線形モデルと同等なので

10
00:00:30,825 --> 00:00:34,750
このツールは これまでに学んだ内容の
実演にも適しています

11
00:00:34,750 --> 00:00:37,240
MLに関する洞察力を高めるため

12
00:00:37,240 --> 00:00:41,985
このツールを使って ここまでに説明した
理論的な部分を検証します

13
00:00:41,985 --> 00:00:44,290
学習率の設定が与える影響と

14
00:00:44,290 --> 00:00:47,095
MLモデルの勾配が降下する様子を
目で確認できます

15
00:00:47,095 --> 00:00:52,500
また このコースや後のコースで取り上げる
トピックについても関連付けて説明します

16
00:00:52,550 --> 00:00:55,455
まず インターフェースについてですが

17
00:00:55,455 --> 00:00:57,755
このツールの機能のうち

18
00:00:57,755 --> 00:01:01,435
後で説明する内容に関連するものは
一部除外しましたが

19
00:01:01,435 --> 00:01:04,475
調整できる項目はたくさんあります

20
00:01:04,475 --> 00:01:07,300
まず FEATURES欄は

21
00:01:07,300 --> 00:01:10,190
モデルに入力されるデータです

22
00:01:10,190 --> 00:01:14,415
各ボックス内の色分けは 
特徴量の値の正負を表していて

23
00:01:14,415 --> 00:01:17,550
オレンジは負の値 青は正の値です

24
00:01:17,550 --> 00:01:22,310
次に HIDDEN LAYERS欄には 重みが表示されます

25
00:01:22,310 --> 00:01:27,100
重み線にカーソルを合わせると
重みの値を確認できます

26
00:01:27,100 --> 00:01:29,015
モデルがトレーニングするにつれ

27
00:01:29,015 --> 00:01:31,350
線の太さと不透明度が変わり

28
00:01:31,350 --> 00:01:35,750
全体から見た重みの値を
感覚的にとらえることができます

29
00:01:35,750 --> 00:01:38,210
次に OUTPUT欄には

30
00:01:38,210 --> 00:01:41,810
学習データと特徴量領域のすべての点に対する

31
00:01:41,810 --> 00:01:45,165
モデルの現在の予測の両方が表示されます

32
00:01:45,165 --> 00:01:47,740
現在の学習の損失も表示されます

33
00:01:47,740 --> 00:01:52,340
FEATURES欄と同様に
色分けは値の正負を表しています

34
00:01:53,280 --> 00:01:55,105
画面上部のコントロールバーには

35
00:01:55,105 --> 00:01:59,505
学習をリセットする 開始する
ステップ単位で進めるためのボタンがあります

36
00:01:59,505 --> 00:02:02,775
学習率を設定するための
ドロップダウンもあります

37
00:02:02,775 --> 00:02:07,755
DATA欄では さまざまなデータセットを
選択し バッチサイズを設定できます

38
00:02:07,755 --> 00:02:11,740
まず 線形モデルに
データの分類を学習させます

39
00:02:11,740 --> 00:02:14,020
このリンクをクリックすると

40
00:02:14,020 --> 00:02:18,330
必要最低限の機能のみを備えた
TensorFlow Playgroundが表示されます

41
00:02:18,330 --> 00:02:20,967
HIDDEN LAYERSは 
ここではおいておきます

42
00:02:20,967 --> 00:02:22,825
ツールのこの構成では

43
00:02:22,825 --> 00:02:24,780
モデルに特徴量ベクターを入力すると

44
00:02:24,780 --> 00:02:27,230
重み係数とのドット積を計算し

45
00:02:27,230 --> 00:02:28,585
バイアス項を足し

46
00:02:28,585 --> 00:02:32,440
合計値の符号を使って決定境界を求めます

47
00:02:32,440 --> 00:02:37,535
したがって この構成は
線形モデルと考えることができます

48
00:02:38,455 --> 00:02:44,640
2つの異なるクラスタに属するデータを
分類するモデルから見ていきましょう

49
00:02:45,655 --> 00:02:48,585
再生ボタンの右にある
ステップボタンをクリックし

50
00:02:48,585 --> 00:02:52,060
インターフェースの変化を
よく見ていてください

51
00:02:52,060 --> 00:02:54,415
エポック数が1増え

52
00:02:54,415 --> 00:02:57,620
重み線の色とサイズが変化し

53
00:02:57,620 --> 00:03:00,285
損失関数の現在の値が変化し

54
00:03:00,285 --> 00:03:02,780
損失グラフの傾きが下向きになり

55
00:03:02,780 --> 00:03:07,015
出力された決定境界も変化しました

56
00:03:08,085 --> 00:03:10,605
重み1の線にカーソルを合わせると

57
00:03:10,605 --> 00:03:14,280
この重みの値を確認できます

58
00:03:15,340 --> 00:03:18,195
続いて 再生ボタンをクリックして
学習を再開しますが

59
00:03:18,195 --> 00:03:21,595
損失が0.002を下回ったら
すぐに一時停止します

60
00:03:21,595 --> 00:03:24,900
目安は200エポック弱です

61
00:03:24,900 --> 00:03:29,005
これで最初のモデルに
学習させることができました

62
00:03:30,725 --> 00:03:33,500
ここから 少し複雑になります

63
00:03:33,500 --> 00:03:38,720
まず 3つの異なる学習率がモデルの学習に
どのように影響するのか見ていきましょう

64
00:03:38,720 --> 00:03:41,700
学習率はハイパーパラメータです

65
00:03:41,700 --> 00:03:44,110
モデルのトレーニングが始まる前に設定し

66
00:03:44,110 --> 00:03:48,370
ループが反復するたびに重みを
どれだけ変更するかを判断するため

67
00:03:48,370 --> 00:03:50,815
微分係数を掛け合わせます

68
00:03:51,845 --> 00:03:56,100
このリンクをクリックして学習率が
非常に小さいモデルの学習を開始します

69
00:03:56,100 --> 00:03:59,195
損失が約100エポックに到達するまで待ちます

70
00:03:59,195 --> 00:04:01,765
目安は約2秒後です

71
00:04:01,765 --> 00:04:04,495
100エポックに達したら
モデルを一時停止します

72
00:04:05,995 --> 00:04:08,750
現在の学習の損失はどれくらいですか

73
00:04:09,670 --> 00:04:13,490
学習した重みはどれくらいですか

74
00:04:16,260 --> 00:04:20,800
続いて 学習率を0.001に上げて
学習を再開します

75
00:04:20,800 --> 00:04:26,395
再び約100エポックに達したら停止します
損失はどうなったでしょうか

76
00:04:26,395 --> 00:04:29,900
今回の方が大幅に少なくなっているはずです

77
00:04:29,900 --> 00:04:34,420
重み1の値も覚えおいてください

78
00:04:36,230 --> 00:04:39,805
続いて 学習率を0.1に上げて
学習を再開し

79
00:04:39,830 --> 00:04:42,445
再び100エポック目まで学習を行います

80
00:04:42,445 --> 00:04:45,495
損失曲線の下がり方は 前と比べてどうですか

81
00:04:45,495 --> 00:04:48,280
今回の方が下がり方が非常に速いはずです

82
00:04:48,280 --> 00:04:51,160
では これらの観察内容をまとめて

83
00:04:51,160 --> 00:04:55,770
最適化に関して学んだことを使って
説明できるか確認しましょう

84
00:04:55,780 --> 00:04:59,550
学習率を10に上げてモデルの学習を再開します

85
00:04:59,550 --> 00:05:03,805
最初はステップボタンを使って
ステップ単位で進めます

86
00:05:03,805 --> 00:05:06,285
重みの大きさを見てください

87
00:05:06,285 --> 00:05:10,185
続いて 100エポック目まで学習を続けます

88
00:05:10,185 --> 00:05:13,780
今回の損失曲線の下がり方はどうでしたか

89
00:05:13,780 --> 00:05:16,920
急激に下がっているはずです

90
00:05:17,520 --> 00:05:19,490
では これらの観察内容をまとめて

91
00:05:19,490 --> 00:05:24,345
最適化に関して学んだことを使って
説明できるか確認しましょう

92
00:05:24,345 --> 00:05:27,800
こちらは ツールから得られた
結果をまとめた表です

93
00:05:27,800 --> 00:05:31,020
皆さんの結果は 
このとおりでなくても構いません

94
00:05:31,020 --> 00:05:32,810
結果が異なるのは

95
00:05:32,810 --> 00:05:36,630
実験を再実行した場合に
結果が異なるのと同じ理由です

96
00:05:36,630 --> 00:05:40,655
TensorFlow Playgroundは
重みをランダムに初期化します

97
00:05:40,655 --> 00:05:45,530
つまり 毎回ランダムな場所から
探索を開始するということです

98
00:05:45,530 --> 00:05:48,945
重み1の欄を見ていきましょう

99
00:05:48,945 --> 00:05:53,545
重みの大きさは 学習率が
高くなるにつれて増えています

100
00:05:53,545 --> 00:05:56,265
なぜでしょうか

101
00:05:56,265 --> 00:06:00,380
モデルのステップが大きいからです

102
00:06:00,380 --> 00:06:02,790
実際に学習率が10の場合

103
00:06:02,790 --> 00:06:06,035
最初のステップによって
重みが著しく変化しました

104
00:06:06,035 --> 00:06:09,760
経時的な損失の変化の欄を見てみましょう

105
00:06:09,760 --> 00:06:11,850
学習率が高くなるにつれ

106
00:06:11,850 --> 00:06:14,325
損失曲線の傾きが急になっています

107
00:06:14,325 --> 00:06:18,780
これは先ほど見た結果を
異なる視点からとらえたものです