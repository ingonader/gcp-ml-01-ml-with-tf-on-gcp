Ya vimos cómo funciona
el descenso de gradientes. Usaremos una herramienta
que nos permitirá ver en tiempo real varios de los fenómenos que analizamos. TensorFlow Playground nos permite
ver cómo funcionan las redes neuronales. Tal vez pensarán, "un momento aún no sabemos
qué son las redes neuronales”. No se preocupen, ya lo veremos. Por razones que ya explicaremos las redes neuronales más sencillas
son equivalentes a los modelos lineales. Así que esta herramienta también
es ideal para demostrar lo que aprendimos. La usaremos para verificar de forma experimental
los aspectos teóricos que presentamos a fin de que puedan
respaldar sus intuiciones de AA. Verán el impacto
de configurar la tasa de aprendizaje y cómo los modelos
de AA descienden gradientes. También mencionaré las conexiones a temas que exploraremos en detalle
en este curso y en otros posteriores. Primero, hablemos sobre la interfaz. Quité algunas
funciones de la herramienta porque incluyen
material que veremos después pero aun así tiene
muchas opciones interesantes. Primero, la columna de atributos. Estas son las entradas que ve su modelo. El color de las casillas
es el valor de cada atributo. El naranja significa
negativo y el azul positivo. Tenemos la columna de capas ocultas,
donde podemos decir que están los pesos. Si se desplazan sobre una línea
de peso, verán el valor de ese peso. A medida que se entrena el modelo,
el ancho y la opacidad de estas líneas cambiarán para permitirles
entender sus valores rápidamente. Luego está la columna de salida en la que se ven datos
de entrenamiento y las predicciones actuales de los modelos para todos
los puntos en el espacio de atributos. También pueden ver la pérdida
actual de entrenamiento. El color también
se usa para representar valores. La barra de control superior incluye
botones para restablecer el entrenamiento comenzarlo y dar un solo paso. También hay un menú
desplegable para la tasa de aprendizaje. En la columna de datos,
se pueden seleccionar diferentes conjuntos de datos
y controlar el tamaño del lote. Comencemos por entrenar
un modelo lineal para clasificar datos. Si hacen clic en este vínculo,
verán una ventana de TensorFlow Playground con lo esencial; no se preocupen
por las capas ocultas en este momento. En esta configuración de la herramienta,
el modelo acepta un vector de atributos calcula un producto
escalar con un factor de peso agrega un término de la ordenada al origen y usa el signo de suma
para construir el límite de decisión. Por lo tanto, pueden pensar
en esta configuración como un modelo lineal. Comenzaremos con un modelo
que intentará clasificar los datos de dos clústeres distintos. Hagan clic en el botón Paso,
que está a la derecha del botón Reproducir y observen todo
lo que cambia en la interfaz. La cantidad de ciclos aumenta en 1 las líneas que representan
los pesos cambian de color y de tamaño el valor actual
de la función de pérdida cambia el gráfico de pérdida
muestra una pendiente hacia abajo y el límite de decisión
de salida también cambia. Muevan el mouse
sobre la línea que representa el peso 1 y podrán ver el valor de ese peso. Hagan clic en Reproducir
para reanudar el entrenamiento pero pausen justo después
de que la pérdida sea inferior a 0.002 lo que debería ocurrir
antes de los 200 ciclos. Felicitaciones,
entrenaron su primer modelo. Ahora, agreguemos algo de complejidad. Primero, veamos cómo tres diferentes
tasas de aprendizaje afectan al modelo. Recuerden que la tasa
de aprendizaje es el hiperparámetro que establecemos antes del entrenamiento y que se multiplica
por la derivada para determinar cuánto cambiamos los pesos
en cada iteración de nuestro bucle. Sigan este vínculo para entrenar
con una tasa de aprendizaje pequeña. Esperen hasta que
la pérdida alcance los 100 ciclos lo que debería
ocurrir después de dos segundos y luego pausen el modelo. ¿Cuál es la tendencia de pérdida actual? Y ¿cuáles son los pesos aprendidos? Aumenten la tasa de aprendizaje
a 0.001, reinicien el entrenamiento y vuelvan a detenerse
cerca de los 100 ciclos. ¿Cuál es la pérdida? Debería ser mucho menor esta vez. Observen el valor para el peso 1. Ahora,
aumenten la tasa de aprendizaje a 0.1 reinicien el entrenamiento del modelo
y vuelvan a entrenar por 100 ciclos. ¿Qué tan rápido cayó
la curva de pérdida esta vez? Debería haber caído muy rápido. Bien, reunamos estas observaciones y tratemos de explicarlas
con lo que aprendimos sobre optimización. Aumenten la tasa de aprendizaje a 10 reinicien el entrenamiento del modelo y den un solo paso con el botón Paso. Observen la magnitud del peso. Ahora, continúen con el entrenamiento
hasta los 100 ciclos. ¿Qué tan rápido cayó la curva esta vez? Debe haber caído precipitadamente. Reunamos estas observaciones y veamos si podemos explicarlas
con lo que aprendimos sobre optimización. En esta tabla,
se muestran los resultados que obtuve. Es posible que sus resultados
se vean diferentes, no hay problema. Se ven diferentes
a mis resultados por la misma razón que se ven diferentes
si vuelven a ejecutar el experimento. TensorFlow Playground
inicia los pesos al azar y, debido a ello, nuestra búsqueda
comienza en una posición aleatoria. Hablemos sobre la columna Peso1 (Weight1). Observen cómo aumenta la magnitud
de los pesos cuando aumentan las tasas. ¿Por qué creen que ocurre esto? Es porque el modelo
está dando pasos más grandes. De hecho, cuando la tasa
de aprendizaje era 10 el primer paso
cambió drásticamente los pesos. Hablemos de la columna
de pérdida con el tiempo (Loss Over Time). A medida que aumenta
la tasa de aprendizaje la curva de pérdida
se vuelve más pronunciada. Este es el mismo efecto que vimos
antes, desde una perspectiva diferente.