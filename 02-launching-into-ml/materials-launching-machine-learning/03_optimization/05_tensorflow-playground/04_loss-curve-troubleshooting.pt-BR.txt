Durante os testes com
arquiteturas diferentes de rede neural, alguns de seus modelos treinados podem
ter entrado em status terminal, como este. Observe a curva de perda e a saída. O que você fez para consertá-los?
E o que está acontecendo aqui? Você pode ter alterado
a sua arquitetura de rede, mas, muitas vezes, podemos corrigir esses
problemas treinando o modelo novamente. Lembre-se: ainda há elementos que não
controlamos no treinamento de modelos, como as sugestões aleatórias
dos inicializadores de peso. O problema neste caso é que aparentemente encontramos na superfície de perda
uma posição pequena em relação às adjacentes, mas ainda muito maior do que zero. Em outras palavras,
encontramos um mínimo local. Observe como o gráfico
de perda ao longo do tempo atingiu um valor de perda
menor antes na pesquisa. A existência e o poder de sedução dos mínimos locais não ideais são dois
exemplos de falhas em nossa abordagem atual. Outras desvantagens incluem problemas como tempos longos de treinamento e a existência
de mínimos insignificantes, mas inadequados. Esses problemas não têm uma única causa. Portanto, há métodos
diversos para lidar com eles. As técnicas de otimização avançadas
destinam-se a reduzir o tempo de treinamento e evitar que modelos sejam
seduzidos por um mínimo local. Vamos voltar a alguns desses
tópicos posteriormente no curso. A espera e a sobreamostragem de dados,
bem como a criação de dados sintéticos, destinam-se a remover os mínimos inadequados
do espaço de pesquisa. As métricas de desempenho,
que discutiremos na próxima seção, lidam com o problema
em um nível mais elevado. Em vez de mudar como pesquisamos
ou o próprio espaço de pesquisa, as métricas de desempenho mudam
como pensamos sobre os resultados da pesquisa, alinhando-os mais estreitamente
com o que nos interessa. Isso nos permite tomar decisões embasadas
e melhores sobre futuras pesquisas.