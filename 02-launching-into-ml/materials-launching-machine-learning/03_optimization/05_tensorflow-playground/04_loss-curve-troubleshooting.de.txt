Beim Experimentieren mit verschiedenen 
Architekturen neuronaler Netzwerke habe Sie vielleicht Modelle trainiert,
die in den Endstatus eingetreten sind. Beachten Sie sowohl die
letzte Kurve als auch die Ausgabe. Wie haben Sie sie angepasst? 
Und was passiert hier? Sie haben vielleicht 
Ihre Netzwerkarchitektur geändert. Solche Probleme im Modell können Sie
oft beheben, indem Sie es neu trainieren. Der Ablauf des Modelltrainings hat immer 
noch Teile, die nicht kontrolliert werden, wie die zufälligen Seeds zur 
Initialisierung der Gewichtung. Das Problem in diesem Fall ist, 
das wir bei der Verlustoberfläche anscheinend eine Position gefunden haben, die im Vergleich zu 
ihren Nachbarn klein ist, aber trotzdem deutlich größer als null. Anders gesagt, haben wir
ein lokales Minimum gefunden. Beachten Sie, 
dass die Verlustverlaufskurve früher einen niedrigeren 
Wert in der Suche erreicht hat. Dass suboptimale lokale Minima
existieren und so verlockend sind, verdeutlicht die Nachteile
unserer Herangehensweise. Weitere Nachteile umfassen lange Trainingszeiten und die Existenz 
trivialer, aber ungeeigneter Minima. Diese Probleme 
haben verschiedene Ursachen, daher gibt es 
verschiedene Methoden, sie zu beheben. Erweiterte Optimierungstechniken 
zielen darauf ab, die Trainingszeit zu verbessern und zu verhindern, dass 
Modelle auf lokale Minima hereinfallen. Einige davon 
betrachten wir später im Kurs. Das Warten auf Daten, Oversampling
und synthetische Datenerstellung zielen darauf ab, ungeeignete Minima
aus dem Suchbereich zu entfernen. Leistungsmetriken, die wir 
im nächsten Abschnitt behandeln, gehen das Problem 
auf einer höheren Ebene an. Statt das Suchverfahren oder 
den Suchbereich selbst zu verändern, verändern Leistungsmetriken 
die Denkweise in Bezug auf die Ergebnisse unserer Suche, indem wir sie näher an dem 
ausrichten, was uns wirklich interessiert. So können wir bessere Entscheidungen
treffen, wann wir eine neue Suche starten.