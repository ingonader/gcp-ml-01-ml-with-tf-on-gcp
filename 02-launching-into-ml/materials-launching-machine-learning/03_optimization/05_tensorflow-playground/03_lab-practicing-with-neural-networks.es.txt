Ya vimos cómo se puede ejecutar
un modelo lineal en el conjunto de datos. Veamos cómo lo hace una red neuronal. Pero antes de hacerlo, necesitamos revisar unas funciones adicionales
que habilité en TensorFlow Playground. Lo primero que habilité es la activación. La activación se refiere
a la función de activación. La analizaremos en el curso Cinco sobre el arte y la ciencia del AA. Por ahora,
lo más importante es que la opción de la función de activación
separa los modelos lineales de las redes neuronales. Antes, sin que lo sepan la función de activación
estaba establecida como lineal. La segunda función adicional
que habilité es la de capas ocultas. Esta función
les permite cambiar la cantidad de capas ocultas y la cantidad
de neuronas en cada capa oculta. Pueden considerarla
como cambiar la cantidad de transformaciones
que realiza la red en sus datos. Cada neurona de las capas ocultas recibe todo
el resultado de la capa que la precede transforma la entrada y pasa la salida
a todas las neuronas de la capa posterior. La forma abreviada
para describir la cantidad de neuronas y cómo se pasan información
entre sí es la arquitectura de la red. También habilité el tamaño del lote que usaremos pronto en un experimento. Sigan el vínculo y entrenen un modelo
que clasifique este conjunto de datos. Pero en lugar
de agregar atributos no lineales traten de mejorar el rendimiento
cambiando la arquitectura de la red. Aún no explico cómo funciona
una red neuronal, así que no se preocupen. Por ahora, diviértanse con la interfaz hasta que tengan una red
que se desempeñe lo bastante bien. A estas alturas, deberían tener
un modelo que se desempeñe bien y un polígono en la región
azul de la columna de salida. Veamos esto para tener
una idea de cómo puede hacerlo el modelo. Fíjense otra vez
en las neuronas de la primera capa oculta. Cuando me desplazo por ellas la casilla cambia
para reflejar lo que aprendió la neurona. Pueden leer estas neuronas
igual que los atributos y la salida. Los valores de los atributos
X1 y X2 se codifican en el cuadrado. Y el color indica el valor que generará esta neurona
para esa combinación de X1 y X2. Cuando me desplazo
en orden por los cuadrados imagino cómo se verían superpuestos. El azul sobre el azul se vuelve más azul el azul sobre el blanco es un azul claro y el azul sobre el naranja sería blanco. Deberían comenzar a ver cómo cada neurona participa en el límite
de decisión del modelo cómo la forma del resultado
es una función de las capas ocultas. Por ejemplo, esta neurona aporta
este borde al límite de decisión mientras que
esta otra aporta este borde. Ahora, según su conocimiento de geometría ¿qué tan pequeña creen que podrían hacer esta red
sin sacrificar su rendimiento? Para darles una pista,
¿cuál es la forma más sencilla que podrían dibujar alrededor de los puntos
azules para llevar a cabo el trabajo? Prueben en TensorFlow Playground
y descubran si su intuición es correcta. Vimos cómo el resultado
de las neuronas en la primera capa oculta de la red se puede usar
para crear el límite de decisión. ¿Y qué pasa con las otras capas? ¿En qué se diferencia una red neuronal
con una capa oculta de otra con muchas? Hagan clic en el vínculo para entrenar una red neuronal y clasificar
este conjunto de datos en espiral. Aprovechemos esta
oportunidad para comprender cómo el tamaño del lote
influye en el descenso de gradientes. Configuren el parámetro
de tamaño del lote en 1 y experimenten con las arquitecturas de redes
neuronales hasta encontrar una que sirva. Entrenen su modelo por 300 ciclos y pausen para tomar notas
de la curva de pérdida. Establezcan el parámetro de tamaño de lote
en 10 y reinicien el entrenamiento. Entrenen su modelo por 300 ciclos y pausen para tomar nota
de la curva de pérdida. Finalmente, háganlo una vez más,
pero con un tamaño de lote igual a 30. ¿Qué observaron y cómo podemos darles sentido a estas observaciones? Lo que deberían haber visto es que hay diferencias claras
en la fluidez de las curvas de pérdida. A medida que aumenta el tamaño del lote también lo hace la fluidez. ¿Por qué? Piensen cómo el tamaño del lote
influye en el descenso de gradientes. Cuando el tamaño de lote es pequeño el modelo actualiza sus parámetros basándose en la pérdida de un ejemplo. Sin embargo, los ejemplos
varían y ahí radica el problema. A medida que aumenta el tamaño del lote el ruido de los puntos
de datos aparece y forma una señal clara. Algo que no deberían concluir
a partir de estas observaciones es que los cambios en el tamaño del lote
influirán en la tasa de convergencia. Tal como la tasa de aprendizaje,
el tamaño óptimo de lote depende del problema y se encuentra
con el ajuste de hiperpárametros. Sus modelos ya deben haber terminado
el entrenamiento y se deberían ver así. Lo primero que
se debe destacar es la relación entre la primera capa
oculta y las que vienen después. Debería ser evidente que,
aunque las salidas de las neuronas en la primera capa
oculta eran básicamente líneas. Las capas ocultas posteriores
tuvieron salidas mucho más complejas. Estas capas posteriores
se complementaron con las que venían antes casi de la misma forma en que
apilamos los resultados de la capa oculta. Piensen en la red neuronal
como una jerarquía de atributos. La idea de tomar entradas y transformarlas en formas
complejas antes de clasificarlas es típica de las redes
neuronales y representa una diferencia importante del enfoque
que se usa en el aprendizaje automático. Antes de esto, los científicos de datos
se dedicaban a la ingeniería de atributos. Ahora, es el mismo modelo
el encargado de algunas responsabilidades y pueden pensar en las capas como
parte de una ingeniería de atributos. Lo siguiente que destacaremos serán
las cosas extrañas que aprendió el modelo. El modelo parece haber
interpretado la ausencia de puntos naranjas en estas dos regiones
como evidencia para respaldar lo azul. A este tipo de errores donde
el modelo interpreta el ruido en el conjunto de datos
se lo conoce como sobreajuste. Y puede ocurrir cuando el modelo tiene más poder de decisión
que el necesario para el problema. Cuando los modelos sobreajustan,
no generalizan bien y esto significa que no funcionarán bien con datos nuevos,
que no tendrán el mismo patrón de ruido aun cuando permanezca la señal subyacente. ¿Cómo podemos combatir eso? Para saber la respuesta, participe en la siguiente clase
sobre generalización y muestreo.