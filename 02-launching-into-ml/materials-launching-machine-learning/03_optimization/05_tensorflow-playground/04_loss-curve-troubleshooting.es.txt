Como experimentaron con diferentes
arquitecturas de redes neuronales tal vez tengan modelos entrenados
en un estado terminal, como este. Fíjense en la curva de pérdida
y en la salida ¿Qué hicieron para corregirlos?
¿Qué ocurre aquí? Aún si cambiaron su arquitectura de red a menudo se pueden solucionar problemas
como este volviendo a entrenar su modelo. Recuerden, hay partes del proceso
de entrenamiento del modelo que no se controlan,
como las fuentes aleatorias de sus iniciadores de peso. En este caso,
el problema es que al parecer encontramos una posición
en la superficie de pérdida que es pequeña en comparación con sus pares,
pero mucho mayor que cero. En otras palabras,
encontramos un mínimo local. Observen cómo
el gráfico de pérdida con el tiempo anteriormente alcanzó un menor
valor de pérdida en la búsqueda. La existencia
y el atractivo de un mínimo local subóptimo son dos ejemplos
de las limitaciones de este enfoque. Otros incluyen problemas
como tiempos extensos de entrenamiento y la existencia de mínimos triviales
pero inapropiados. Estos problemas
no se originan de una sola manera por eso tenemos métodos
variados para lidiar con ellos. El objetivo de las técnicas
de optimización avanzadas es mejorar el tiempo de entrenamiento
y que los modelos no se vean seducidos por el mínimo local.
Revisaremos esto más adelante en el curso. Los datos en espera y el sobremuestreo,
y la creación de datos sintéticos pretenden eliminar del todo el mínimo
inapropiado del espacio de búsqueda. Las métricas de rendimiento,
que veremos en la siguiente sección enfrentan el problema a un nivel superior. En lugar de cambiar cómo
buscamos o el espacio de búsqueda estas métricas cambian
la forma en la que vemos los resultados de la búsqueda, ya que los alinean
más cerca de lo que nos importa. Con ello, nos permiten tomar decisiones
mejor fundamentadas sobre nuevas búsquedas