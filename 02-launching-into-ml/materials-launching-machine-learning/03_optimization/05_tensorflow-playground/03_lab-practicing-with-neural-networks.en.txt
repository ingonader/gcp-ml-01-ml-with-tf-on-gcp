We've already seen how a linear model can perform on this dataset. Let's see how a neural network does. Before we do though, we need to review some additional features I've enabled in TenserFlow playground. The first I've enabled is activation. Activation refers to the activation function. We'll cover these in more depth in Course 5, the art and science of ML. The crucial point for now is that the choice of activation function is what separates linear models from neural networks. Previously unbeknownst to you, the activation function was set to be linear. The second additional feature I've enabled is the hidden layers feature. The hidden layers feature allows you to change the number of hidden layers and the number of neurons within each hidden layer. You can think of this as changing the number of transformations that the network performs on your data. Each neuron in every hidden layer, receives all the output from the layer that proceeds it, transforms that input, and passes output to all the neurons in the subsequent layer. The shorthand way for describing the number of neurons and how they pass information to each other is the networks architecture. I've also enabled batch size, which we'll use in an experiment momentarily. Follow the link on the slide and try to train a model that can classify this dataset. However, instead of introducing non-linear features, try to improve performance only by changing the network's architecture. I realized we haven't actually explained how a neural network works and that's okay. For now, simply play around in the interface until you have a network that performs reasonably well. At this point, you should have a model that performs reasonably well and the shape of the blue region in the output column should be a polygon. Let's take a look under the hood to get an intuition of how the model is able to do this. Take a look again at the neurons in the first hidden layer. As I hover over each one, the output box changes to reflect what the neuron has learned. You can read these neurons the same way you read the features and the output. The values of the features X1 and X2 are encoded in the position within the square. And the color indicates the value that this neuron will output for that combination of X1 and X2. As I hover over each one of the squares in sequence, mentally start imagining what they would look like superimposed on each other. Blue atop blue becomes even bluer, blue atop white becomes a light blue, and blue atop orange becomes white. What you should start to see is how each neuron participates in the model's decision boundary, how the shape of the output is a function of the hidden layers. For example, this neuron contributes this edge to the decision boundary, while this neuron contributes this edge. Now, given your knowledge of geometry, how small do you think you could make this network and still get reasonable performance out of it? To give you a hint, what's the simplest sort of shape you could draw around the blue dots that would still somewhat do the job? Experiment in TenserFlow playground and see if your intuition is correct. Now you've seen how output of the neurons in the first hidden layer of the network can be used to compose the decision boundary. What about those other layers? How does a neural network with one hidden layer differ from a neural network with many? Click on the link below to start training a neural network to classify this spiral dataset. Let's take this opportunity to understand more about how batch size affects gradient descent. Set the batch size parameter to one and then experiment with neural network architectures until you found one that seems to work. Then train your model for 300 appox and paused to take note of the last curve. Now set the batch size parameter to 10 and restart the training. Train your model for 300 appox and then pause and once again take note of the loss curve. Finally, do this once more but with the batch size equal to 30. What have you observed and how can we make sense of these observations given what we know? What you should have seen is that there are marked differences in the smoothness of the loss curves. As batch size increased, so did the smoothness. Why might this be? Think about how batch size affects gradient descent. When batch size is small, the model makes an update to its parameters on the basis that the loss from a single example. Examples vary however and therein lies the problem. As batch size increases though, the noise of individual data points settles out and a clear signal begins to take shape. One thing you shouldn't conclude on the basis of these observations, is that changes in batch size will have a simple effect on the rate of convergence. As with learning rate, the optimal batch size is problem dependent and can be found using hyper parameter tuning. Now your model should have finished training and it should look something like this. The first thing to call out is the relationship between the first hidden layer and those that come after it. What should be apparent is that although the outputs from the neurons in the first hidden layer, were basically lines. Subsequent hidden layers had far more complicated outputs. These subsequent layers build upon those that came before in much the same way we did when stacking up the outputs of the hidden layer. Consequently, you can think of a neural network as a hierarchy of features. And this idea of taking inputs and then transforming them in complex ways before ultimately classifying them, is typical of neural networks and represents a significant departure from the approach used classically in machine learning. Before neural networks, data scientists spent much more time doing feature engineering. Now, the model itself is taking over some of that responsibility and you can think of the layers as being a form of feature engineering onto themselves. The next thing to call out are some strange things that the model has learned. The model seems to have interpreted the absence of orange points in these two regions as evidence to support their blueness. We call mistakes like this where the model has interpreted noise in the dataset as significant over-fitting. And they can occur when the model has more decision making power than is strictly necessary for the problem. When models over-fit, they generalize poorly meaning that they don't do well on new data, which are unlikely to have quite the same pattern of noise even though the underlying signal should remain. How do we combat this? For that, you'll have to stick around for our next lecture on generalization and sampling.