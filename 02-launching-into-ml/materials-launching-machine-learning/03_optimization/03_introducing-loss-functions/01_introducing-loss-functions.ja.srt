1
00:00:00,350 --> 00:00:02,600
前のセクションでは

2
00:00:02,600 --> 00:00:06,605
パラメータとハイパーパラメータを使った
数学的関数としてモデルを定義し

3
00:00:06,605 --> 00:00:09,135
線形モデルのパラメータを紹介しました

4
00:00:09,135 --> 00:00:13,480
次に 解析の手法を使って
モデルの最適なパラメータセットを求めるには

5
00:00:13,480 --> 00:00:14,825
限界があること

6
00:00:14,825 --> 00:00:16,835
そして パラメータの最適化は

7
00:00:16,835 --> 00:00:19,445
パラメータ領域の探索と
考えられることに触れました

8
00:00:19,445 --> 00:00:24,240
しかしデータポイントを比べるには
比較基準が必要です

9
00:00:24,240 --> 00:00:27,050
このセクションでは
損失関数について説明します

10
00:00:27,050 --> 00:00:31,590
この関数は トレーニングセットの
データポイント群の予測の質から

11
00:00:31,590 --> 00:00:33,230
1つの数字を導き出し

12
00:00:33,230 --> 00:00:38,035
それを基にモデルのカレント
パラメータの質を推定します

13
00:00:38,035 --> 00:00:40,955
ある点における予測の質の比較基準の１つは

14
00:00:40,955 --> 00:00:45,825
符号付きで表した予測値と実際値の差です

15
00:00:45,825 --> 00:00:48,325
これを誤差と呼びます

16
00:00:49,485 --> 00:00:53,000
一連の誤差値を
どのようにまとめるのでしょうか

17
00:00:53,000 --> 00:00:56,070
最も簡単な方法は値の和を求めることです

18
00:00:56,070 --> 00:00:59,995
しかし 合計関数を使って誤差の項を求めると

19
00:00:59,995 --> 00:01:04,584
符号が異なる誤差の項が
互いに打ち消し合ってしまいます

20
00:01:04,584 --> 00:01:08,710
モデルはこうした相反する証拠に
対処する必要がある一方で

21
00:01:08,710 --> 00:01:12,140
いくら正の誤差と負の誤差の
差の中間を取っても

22
00:01:12,140 --> 00:01:14,715
完璧な解決法とは言えません

23
00:01:14,715 --> 00:01:22,040
完璧とは予測がデータセット内の
すべての点のラベルに一致するモデルを指します

24
00:01:22,040 --> 00:01:25,700
互いに打ち消し合う
符号付き誤差を求めるモデルではありません

25
00:01:25,720 --> 00:01:29,730
誤差の絶対値の和を求めるのが
妥当な選択肢に思えますが

26
00:01:29,730 --> 00:01:31,675
後ほど説明するとおり

27
00:01:31,675 --> 00:01:34,985
この方法でデータを求める
場合にも問題があります

28
00:01:34,985 --> 00:01:39,305
代わりによく使用されるのが
平均二乗誤差と呼ばれる方法です

29
00:01:39,305 --> 00:01:41,580
平均二乗誤差 略してMSEは

30
00:01:41,580 --> 00:01:45,505
データセットの一連の
誤差の項を基に計算されます

31
00:01:45,505 --> 00:01:48,345
2乗することで負の値を取り除き

32
00:01:48,345 --> 00:01:51,110
この2乗した値の平均を計算します

33
00:01:51,110 --> 00:01:54,305
MSEは十分有効な損失関数ですが

34
00:01:54,305 --> 00:01:56,005
1つ問題があります

35
00:01:56,005 --> 00:02:00,190
誤差の単位は ポンド
キロメートルまたはドルかもしれません

36
00:02:00,190 --> 00:02:05,040
このとき 二乗誤差はポンドの2乗
kmの2乗 ドルの2乗となるため

37
00:02:05,040 --> 00:02:08,250
MSEの解釈が困難になります

38
00:02:08,250 --> 00:02:13,470
そこで 理解しやすい単位にするため
MSEの平方根を求めます

39
00:02:13,470 --> 00:02:18,195
RMSEは二乗平均誤差の平方根です

40
00:02:18,195 --> 00:02:22,115
RMSEが大きければ大きいほど
予測の質が低いことを意味するため

41
00:02:22,115 --> 00:02:26,560
RMSEを最小化する必要があります

42
00:02:26,560 --> 00:02:28,340
このとき使用する表記法では

43
00:02:28,340 --> 00:02:31,680
モデルの予測を表すのに
Yの上にハット記号が付いたもの

44
00:02:31,680 --> 00:02:35,665
ラベルを表すのに普通のYを使用します

45
00:02:37,505 --> 00:02:40,855
これで パラメータ領域の2つの点を
比較する指標ができました

46
00:02:40,855 --> 00:02:46,120
線形モデルのカレントパラメータ値は
この方法でコード化します

47
00:02:47,350 --> 00:02:49,900
赤ちゃんの体重に対する
39歳より上の母親の年齢をプロットした

48
00:02:49,900 --> 00:02:53,685
こちらの散布図と回帰直線を見てください

49
00:02:53,685 --> 00:02:56,180
基盤となるデータにより適した直線を

50
00:02:56,180 --> 00:02:59,135
見ただけで判断するのは極めて困難です

51
00:02:59,135 --> 00:03:04,280
そこで 損失指標を使って
どちらのモデルが優れているかを判断します

52
00:03:04,280 --> 00:03:08,545
左側のモデルのRMSEは0.145です

53
00:03:08,545 --> 00:03:12,670
一方 右側のモデルのRMSEは0.149です

54
00:03:12,670 --> 00:03:14,645
したがって 損失関数は

55
00:03:14,645 --> 00:03:17,340
左側のモデルの重み値とバイアス値の方が

56
00:03:17,340 --> 00:03:19,795
右側より優れていることを示しています

57
00:03:19,795 --> 00:03:23,600
RMSEは線形回帰の問題には
問題なく使用できますが

58
00:03:23,600 --> 00:03:27,355
クラス分類のための
損失関数としては機能しません

59
00:03:27,355 --> 00:03:31,775
分類の問題ではラベルは
カテゴリ変数となります

60
00:03:31,775 --> 00:03:34,560
RMSEをクラス分類に使用する際の問題点は

61
00:03:34,560 --> 00:03:39,885
モデル内でカテゴリ変数がどのように
表現されるかに関係しています

62
00:03:39,885 --> 00:03:41,250
先ほど説明したとおり

63
00:03:41,250 --> 00:03:45,880
カテゴリ変数は多くの場合2進整数で表します

64
00:03:45,950 --> 00:03:48,625
これがなぜ問題なのかを直感的に理解するには

65
00:03:48,625 --> 00:03:51,295
こちらの損失曲線を見てください

66
00:03:51,295 --> 00:03:54,410
X軸の定義域は予測を

67
00:03:54,410 --> 00:03:59,480
Y 軸の値域は与えられた
予測に対する損失を表します

68
00:03:59,480 --> 00:04:01,270
ラベルごとに色分けしています

69
00:04:01,270 --> 00:04:03,625
緑はラベル1を

70
00:04:03,625 --> 00:04:06,485
青はラベル0を表します

71
00:04:07,445 --> 00:04:09,860
この曲線のどこが問題なのでしょうか

72
00:04:10,560 --> 00:04:15,180
それは 質の低い予測ほど
より大きな罰則を科されるべきであるという

73
00:04:15,180 --> 00:04:18,029
直感が反映されない点です

74
00:04:18,029 --> 00:04:20,480
ターゲットが0で 予測が1のときと

75
00:04:20,480 --> 00:04:23,755
同じくターゲットが0で
予測が0.5のときを比べると

76
00:04:23,755 --> 00:04:26,275
予測の質の低さは3倍になっています

77
00:04:26,275 --> 00:04:28,575
そこで RMSEに代わる

78
00:04:28,575 --> 00:04:33,025
クラス分類の問題に関して
直感どおりに罰則を科す

79
00:04:33,025 --> 00:04:35,610
新たな損失関数が必要です

80
00:04:37,040 --> 00:04:39,290
クラス分類で最もよく使用される損失関数は

81
00:04:39,290 --> 00:04:43,425
交差エントロピーまたは対数損失と呼ばれます

82
00:04:43,425 --> 00:04:46,975
先ほどのスライドと似たグラフですが

83
00:04:46,975 --> 00:04:49,960
こちらはRMSEによる損失ではなく

84
00:04:49,960 --> 00:04:53,160
交差エントロピーの値を示しています

85
00:04:53,160 --> 00:04:56,540
交差エントロピーでは RMSEとは違い

86
00:04:56,540 --> 00:05:00,520
質の低い予測には非常に
大きな罰則が科されます

87
00:05:00,535 --> 00:05:04,900
どのような式を使うのか
例を挙げて見ていきましょう

88
00:05:04,900 --> 00:05:08,325
交差エントロピーの式には 2つの項があります

89
00:05:08,325 --> 00:05:13,680
あるデータポイントの損失に関して
有効なのはいずれか1つの項のみです

90
00:05:13,680 --> 00:05:19,255
正のケース つまり ラベルYが
1のときは最初の項が

91
00:05:19,260 --> 00:05:23,880
ラべルが0のときは2つ目の項が有効となります

92
00:05:25,630 --> 00:05:28,650
これは 画像分類タスクにおけるラベルと

93
00:05:28,650 --> 00:05:32,620
2枚の写真に関する予測を示した表です

94
00:05:32,620 --> 00:05:37,920
ラベルは人の顔が写っているか
否かをコード化したものです

95
00:05:37,920 --> 00:05:40,695
このモデルはうまく機能しているようです

96
00:05:40,695 --> 00:05:43,720
上の写真の予測の方が下と比べて

97
00:05:43,720 --> 00:05:46,185
はるかに高くなっています

98
00:05:46,185 --> 00:05:50,170
この式の仕組みを見ていきましょう

99
00:05:50,170 --> 00:05:52,770
この損失関数の構造上

100
00:05:52,770 --> 00:05:55,455
最初のケースの負の項と

101
00:05:55,455 --> 00:05:59,445
2つ目のケースの正の項は
両方とも除外されます

102
00:05:59,445 --> 00:06:02,925
ラベルが0と1の 2つのデータポイントについて

103
00:06:02,925 --> 00:06:05,600
予測が0.7と0.2のとき

104
00:06:05,600 --> 00:06:07,750
交差エントロピー損失は

105
00:06:07,750 --> 00:06:10,480
最初のデータポイントの正の項に

106
00:06:10,480 --> 00:06:13,000
2番目の項の負の項を足して

107
00:06:13,000 --> 00:06:15,675
-1/2をかけたものとなり

108
00:06:15,675 --> 00:06:17,420
0.13となります

109
00:06:17,420 --> 00:06:21,540
モデルが質の低い予測をすると
どうなるのでしょうか

110
00:06:21,540 --> 00:06:25,570
この場合 人の顔でない写真が
誤って分類されています

111
00:06:25,570 --> 00:06:27,890
その結果 損失が上がっています

112
00:06:27,890 --> 00:06:32,685
損失を小さくしたいのですから
この結果は理に適っています

113
00:06:32,685 --> 00:06:36,655
回帰のためのRMSE
クラス分類のための交差エントロピーという

114
00:06:36,655 --> 00:06:41,015
パラメータ領域の2つの点の
比較方法を学習しました

115
00:06:41,015 --> 00:06:43,960
しかし あくまでも目標は
最適なパラメータセット

116
00:06:43,960 --> 00:06:47,345
つまり パラメータ領域の
最適な点を見つけることです

117
00:06:47,345 --> 00:06:49,970
これまでに学んだ知識を使って

118
00:06:49,970 --> 00:06:53,015
探索ストラテジーを構築する方法は

119
00:06:53,025 --> 00:06:55,000
次のセクションで説明します