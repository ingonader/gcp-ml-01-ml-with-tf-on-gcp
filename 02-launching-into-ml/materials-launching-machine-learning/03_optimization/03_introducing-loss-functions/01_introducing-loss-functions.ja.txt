前のセクションでは パラメータとハイパーパラメータを使った
数学的関数としてモデルを定義し 線形モデルのパラメータを紹介しました 次に 解析の手法を使って
モデルの最適なパラメータセットを求めるには 限界があること そして パラメータの最適化は パラメータ領域の探索と
考えられることに触れました しかしデータポイントを比べるには
比較基準が必要です このセクションでは
損失関数について説明します この関数は トレーニングセットの
データポイント群の予測の質から 1つの数字を導き出し それを基にモデルのカレント
パラメータの質を推定します ある点における予測の質の比較基準の１つは 符号付きで表した予測値と実際値の差です これを誤差と呼びます 一連の誤差値を
どのようにまとめるのでしょうか 最も簡単な方法は値の和を求めることです しかし 合計関数を使って誤差の項を求めると 符号が異なる誤差の項が
互いに打ち消し合ってしまいます モデルはこうした相反する証拠に
対処する必要がある一方で いくら正の誤差と負の誤差の
差の中間を取っても 完璧な解決法とは言えません 完璧とは予測がデータセット内の
すべての点のラベルに一致するモデルを指します 互いに打ち消し合う
符号付き誤差を求めるモデルではありません 誤差の絶対値の和を求めるのが
妥当な選択肢に思えますが 後ほど説明するとおり この方法でデータを求める
場合にも問題があります 代わりによく使用されるのが
平均二乗誤差と呼ばれる方法です 平均二乗誤差 略してMSEは データセットの一連の
誤差の項を基に計算されます 2乗することで負の値を取り除き この2乗した値の平均を計算します MSEは十分有効な損失関数ですが 1つ問題があります 誤差の単位は ポンド
キロメートルまたはドルかもしれません このとき 二乗誤差はポンドの2乗
kmの2乗 ドルの2乗となるため MSEの解釈が困難になります そこで 理解しやすい単位にするため
MSEの平方根を求めます RMSEは二乗平均誤差の平方根です RMSEが大きければ大きいほど
予測の質が低いことを意味するため RMSEを最小化する必要があります このとき使用する表記法では モデルの予測を表すのに
Yの上にハット記号が付いたもの ラベルを表すのに普通のYを使用します これで パラメータ領域の2つの点を
比較する指標ができました 線形モデルのカレントパラメータ値は
この方法でコード化します 赤ちゃんの体重に対する
39歳より上の母親の年齢をプロットした こちらの散布図と回帰直線を見てください 基盤となるデータにより適した直線を 見ただけで判断するのは極めて困難です そこで 損失指標を使って
どちらのモデルが優れているかを判断します 左側のモデルのRMSEは0.145です 一方 右側のモデルのRMSEは0.149です したがって 損失関数は 左側のモデルの重み値とバイアス値の方が 右側より優れていることを示しています RMSEは線形回帰の問題には
問題なく使用できますが クラス分類のための
損失関数としては機能しません 分類の問題ではラベルは
カテゴリ変数となります RMSEをクラス分類に使用する際の問題点は モデル内でカテゴリ変数がどのように
表現されるかに関係しています 先ほど説明したとおり カテゴリ変数は多くの場合2進整数で表します これがなぜ問題なのかを直感的に理解するには こちらの損失曲線を見てください X軸の定義域は予測を Y 軸の値域は与えられた
予測に対する損失を表します ラベルごとに色分けしています 緑はラベル1を 青はラベル0を表します この曲線のどこが問題なのでしょうか それは 質の低い予測ほど
より大きな罰則を科されるべきであるという 直感が反映されない点です ターゲットが0で 予測が1のときと 同じくターゲットが0で
予測が0.5のときを比べると 予測の質の低さは3倍になっています そこで RMSEに代わる クラス分類の問題に関して
直感どおりに罰則を科す 新たな損失関数が必要です クラス分類で最もよく使用される損失関数は 交差エントロピーまたは対数損失と呼ばれます 先ほどのスライドと似たグラフですが こちらはRMSEによる損失ではなく 交差エントロピーの値を示しています 交差エントロピーでは RMSEとは違い 質の低い予測には非常に
大きな罰則が科されます どのような式を使うのか
例を挙げて見ていきましょう 交差エントロピーの式には 2つの項があります あるデータポイントの損失に関して
有効なのはいずれか1つの項のみです 正のケース つまり ラベルYが
1のときは最初の項が ラべルが0のときは2つ目の項が有効となります これは 画像分類タスクにおけるラベルと 2枚の写真に関する予測を示した表です ラベルは人の顔が写っているか
否かをコード化したものです このモデルはうまく機能しているようです 上の写真の予測の方が下と比べて はるかに高くなっています この式の仕組みを見ていきましょう この損失関数の構造上 最初のケースの負の項と 2つ目のケースの正の項は
両方とも除外されます ラベルが0と1の 2つのデータポイントについて 予測が0.7と0.2のとき 交差エントロピー損失は 最初のデータポイントの正の項に 2番目の項の負の項を足して -1/2をかけたものとなり 0.13となります モデルが質の低い予測をすると
どうなるのでしょうか この場合 人の顔でない写真が
誤って分類されています その結果 損失が上がっています 損失を小さくしたいのですから
この結果は理に適っています 回帰のためのRMSE
クラス分類のための交差エントロピーという パラメータ領域の2つの点の
比較方法を学習しました しかし あくまでも目標は
最適なパラメータセット つまり パラメータ領域の
最適な点を見つけることです これまでに学んだ知識を使って 探索ストラテジーを構築する方法は 次のセクションで説明します