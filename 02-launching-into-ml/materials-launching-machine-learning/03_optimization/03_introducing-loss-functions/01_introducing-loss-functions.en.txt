In the previous section, we defined models as mathematical functions using parameters and hyper parameters, and introduce the parameters for linear models. We then discussed how analytical methods for finding the best set of model parameters don't scale. And how we can think of optimizing our parameters, as searching through parameter space. But to compare one point to another, we'll need some sort of measure. In this section, we'll talk about loss functions which are able to take the quality of predictions for a group of data points from our training set and compose them into a single number, with which to estimate the quality of the models current parameters. One measure of the quality of the prediction at a single point, is simply this sign difference between the prediction and the actual value. This difference is called the error. How might we put a bunch of error values together? The simplest way, is to compose them as a sum. However, if we were to use the sum function to compose our terms, the resulting model would treat error terms of opposite sign as canceling each other out. And while our model does need to cope with contradictory evidence, it's not the case that a model that splits the difference between positive and negative errors, has found a perfect solution. Instead, we'd like to reserve that designation for a model in which the predictions match the label for all points in our dataset, not for a model that makes signed errors, they cancel each other out. The sum of the absolute values of the error seems like a reasonable alternative, but there are problems with this method of composing data as well, which we'll tackle shortly. Instead, what is often used as what is called The Mean Squared Error. The Mean Squared Error, or MSE is computed by taking the set of error terms from our dataset. Taking their squares to get rid of the negatives, and computing the average of the squares. The MSE is a perfectly valid loss function, but it has one problem. Although errors might be in pounds, or kilometers, or dollars, the square error will be in pounds squared, kilometers squared, or dollars squared. That can make the MSE kind of hard to interpret. So, we often take the square root of the MSE instead to get units that we can understand. RMSE is the root of the mean squared error. The bigger the RMSE, the worse the quality of the predictions. So what we want to do is, to minimize RMSE. The notation here is to use a little ^ symbol on top of the Y that represents our model's prediction, and to use a plain Y to represent the label. Now, we have a metric to compare two points in parameter space, which remember, is how we encode the current parameter values in our linear model. Take a look at these two scatter plots in regression lines for baby weight versus mother's age for moms above 39. It can be incredibly hard to visually spot which line is a better fit for the underlying data. And that's where our loss metrics aid in deciding which model is better. The model on the left, has an RMSE of point 145, and the model on the right, has an RMSE of point 149. Thus, the loss functions indicate, that the values for weight and bias on the left hand side are better than on the right hand side. Although RMSE works fine for linear regression problems, it doesn't work as a loss function for classification. Remember, classification problems are ones in which the label is a categorical variable. The problem with using RMSE for classification, has to do with how these categorical variables are represented in our model. As we talked about earlier, categorical variables are often represented as binary integers. For an intuition as to why this presents a problem, look at the loss curves we've depicted. The domain on the X axis represents the prediction, the range on the Y axis represents the loss, given that prediction. Color here, denotes the label. Green indicates that the label was one, and blue indicates that the label was zero. What's wrong with this curve? The problem is, it fails to capture our intuitive belief that predictions that are really bad should be penalized much more strongly. Note how a prediction of one, when the target is zero, is about three times worse than a prediction of point five for the same target. Instead of RMSE then, we need a new loss function. One that penalizes in accordance with our intuitions for classification problems. One of the most commonly used loss functions for classification is called Cross Entropy, or log loss. Here, we have a similar graph to what we saw in the last slide, only instead of showing the loss for RMSE, I've shown the value of a new loss function called Cross Entropy. Note that unlike RMSE, cross entropy penalizes bad predictions very strongly, even in this limited domain. Let's walk through an example so we can better understand how the formula works. The formula for cross entropy boils down to two different terms. Only one of which will participate in the loss for a given data point. The first term participates for positive examples, which is to say, examples where the label, Y is one. The second term participates when the label is zero. Here, we have a table showing both the labels, as well as, the predictions for two pictures in an image classification task. The label encodes whether the picture depicts a human face. The model seems to be doing a decent job. The prediction is much higher for the example on the top, as compared with the example on the bottom. Let's see how the function works. Here, the way the loss function is constructed, the negative term from the first example, and the positive term from the second example, both drop out. So, given predictions of point seven and point two, for two data points with labels one and zero, the cross entropy loss is effectively, the positive term for the first data point, plus the negative term for the second data point, multiplied by negative one half. The result is point 13. What happens when our model doesn't make a good prediction? Here, the negative example seems to have been misclassified and as a result, the loss has gone up, which makes sense because remember, loss is what we're trying to minimize. So, we now know how to compare two points in parameter space, whether we're using RMSE for regression or cross entropy for classification. But remember, that our goal is to find the best set of parameters or the best point in parameter space. How can we use our knowledge and how to compare two sets of parameters and turn it into a search strategy? Well, that's what we'll do in the next section.