1
00:00:00,870 --> 00:00:02,890
Você já deve ter visto esta matriz

2
00:00:02,890 --> 00:00:07,245
quando falamos sobre ML inclusivo e
reconhecimento facial em um curso anterior.

3
00:00:07,245 --> 00:00:10,660
Naquele exemplo, examinamos um
modelo de ML de detecção de faces

4
00:00:10,660 --> 00:00:13,555
que previu incorretamente
uma estátua como uma face humana,

5
00:00:13,555 --> 00:00:15,310
o que chamamos de falso positivo.

6
00:00:15,310 --> 00:00:20,005
Ele também não detectou no conjunto de dados
uma face real coberta por roupas de inverno.

7
00:00:20,005 --> 00:00:22,205
Chamamos essa falha de falso negativo.

8
00:00:23,665 --> 00:00:25,850
Uma matriz de confusão como esta permite

9
00:00:25,850 --> 00:00:29,785
avaliar de maneira quantificável o
desempenho do modelo de classificação.

10
00:00:29,785 --> 00:00:32,160
Agora, temos quatro números,
um para cada quadrante.

11
00:00:32,160 --> 00:00:34,930
Mas os responsáveis pelas decisões
de negócios querem ver apenas um.

12
00:00:34,930 --> 00:00:36,730
Qual devemos apresentar?

13
00:00:37,760 --> 00:00:39,305
Para nos aprofundar nessa questão,

14
00:00:39,305 --> 00:00:42,430
vamos analisar outro
exemplo de classificação de fotos.

15
00:00:42,430 --> 00:00:45,070
Quando sabemos que uma vaga
de estacionamento está vazia,

16
00:00:45,070 --> 00:00:46,960
ou seja, tem rótulo positivo,

17
00:00:46,960 --> 00:00:49,375
e o modelo também
prevê que ela está vazia,

18
00:00:49,375 --> 00:00:51,150
chamamos o resultado de verdadeiro positivo.

19
00:00:52,720 --> 00:00:55,070
Quando sabemos que uma vaga
de estacionamento está ocupada,

20
00:00:55,070 --> 00:00:56,730
mas o modelo prevê que está vazia,

21
00:00:56,730 --> 00:00:59,975
chamamos o resultado de
falso positivo ou erro do tipo I.

22
00:01:01,135 --> 00:01:04,430
Para comparar o desempenho
do modelo com as previsões positivas,

23
00:01:04,430 --> 00:01:06,550
usamos uma métrica chamada de precisão.

24
00:01:06,550 --> 00:01:10,340
Quando a precisão é alta,
se dizemos que a vaga está vazia,

25
00:01:10,340 --> 00:01:12,190
temos certeza de que realmente está.

26
00:01:12,190 --> 00:01:16,600
Uma precisão de 1,0 significa que
todas as vagas vazias identificadas

27
00:01:16,600 --> 00:01:18,585
estão realmente vazias.

28
00:01:18,585 --> 00:01:21,700
Mas talvez haja outras
vagas vazias não detectadas

29
00:01:21,700 --> 00:01:23,040
que chamamos de falso negativos.

30
00:01:24,200 --> 00:01:25,720
A precisão é definida formalmente como

31
00:01:25,720 --> 00:01:29,870
o número de verdadeiros positivos dividido
pelo total classificado como positivo.

32
00:01:31,250 --> 00:01:35,305
Analisando a matriz, um aumento
em qual fator reduziria a precisão?

33
00:01:38,175 --> 00:01:39,990
Um aumento em falsos positivos.

34
00:01:41,040 --> 00:01:42,525
No nosso exemplo do estacionamento,

35
00:01:42,525 --> 00:01:44,760
quanto mais o modelo
prevê vagas vazias

36
00:01:44,760 --> 00:01:47,245
que na realidade estão ocupadas,
menor é a precisão.

37
00:01:49,495 --> 00:01:52,970
Geralmente, a revocação está
inversamente relacionada à precisão.

38
00:01:52,970 --> 00:01:54,560
Quando a revocação é alta,

39
00:01:54,560 --> 00:01:57,850
somos recompensados por
encontrar várias vagas realmente vazias.

40
00:01:57,850 --> 00:02:02,675
Uma revocação de 1,0 significa que
encontramos todas as vagas vazias.

41
00:02:02,675 --> 00:02:06,690
Mas significa também que talvez muitas
vagas vazias encontradas estavam ocupadas.

42
00:02:06,690 --> 00:02:08,800
Chamamos esses resultados
 de falsos positivos.

43
00:02:10,810 --> 00:02:13,285
Qual era a revocação
no exemplo do estacionamento?

44
00:02:13,285 --> 00:02:16,245
Lembre-se: tínhamos
10 vagas realmente vazias,

45
00:02:16,245 --> 00:02:18,830
mas o modelo identificou apenas uma delas.

46
00:02:21,320 --> 00:02:24,225
A resposta é 1 de 10 ou 0,1.

47
00:02:26,825 --> 00:02:29,610
Temos aqui um conjunto de dados de imagens.

48
00:02:29,610 --> 00:02:32,680
Cada imagem tem um gato ou não.

49
00:02:32,680 --> 00:02:35,460
Pare por um instante e tente identificá-las.

50
00:02:40,430 --> 00:02:43,990
Espero que você tenha encontrado todos
os gatos domésticos como mostrado aqui.

51
00:02:43,990 --> 00:02:46,270
Repare no gato escondido
destacado em vermelho

52
00:02:46,270 --> 00:02:49,520
e que não classificamos o tigre como um gato.

53
00:02:51,180 --> 00:02:53,720
Vamos ver como o modelo faz a classificação.

54
00:02:55,970 --> 00:02:57,940
Estes são os resultados do nosso modelo.

55
00:02:59,090 --> 00:03:01,855
Vamos comparar os resultados
com o que sabemos ser verdade.

56
00:03:04,525 --> 00:03:08,585
Agora temos os pontos de dados rotulados
corretamente ao lado das previsões do modelo.

57
00:03:09,885 --> 00:03:12,220
No total, temos oito
exemplos, ou instâncias,

58
00:03:12,220 --> 00:03:13,615
que mostramos ao modelo.

59
00:03:14,605 --> 00:03:16,600
Quantas vezes o modelo acertou?

60
00:03:20,440 --> 00:03:23,155
Três de um total de oito instâncias
foram previstas corretamente.

61
00:03:23,155 --> 00:03:26,485
Isso dá ao modelo uma acurácia de 0,375.

62
00:03:28,555 --> 00:03:32,285
A acurácia é a melhor métrica para
descrever o desempenho do modelo?

63
00:03:32,285 --> 00:03:34,230
Antes de entrarmos em outro assunto,

64
00:03:34,230 --> 00:03:36,420
vamos falar sobre uma armadilha comum.

65
00:03:37,740 --> 00:03:40,065
Voltando ao exemplo dos gatos,

66
00:03:40,065 --> 00:03:42,215
qual é a precisão do modelo?

67
00:03:42,215 --> 00:03:46,125
Estas cinco imagens foram
classificadas como positivas.

68
00:03:46,125 --> 00:03:48,355
Quantas realmente são de gatos domésticos?

69
00:03:50,685 --> 00:03:54,370
Duas das cinco imagens,
ou uma taxa de precisão de 0,4.

70
00:03:54,370 --> 00:03:59,860
Revocação é como alguém que nunca
quer ser excluído de uma decisão positiva.

71
00:03:59,860 --> 00:04:02,660
Aqui vemos todos os exemplos
de gato com rótulo de verdadeiro

72
00:04:02,660 --> 00:04:04,697
e o desempenho do modelo.

73
00:04:04,697 --> 00:04:06,655
Qual foi a revocação?

74
00:04:06,655 --> 00:04:11,320
Em outras palavras, quantos
verdadeiros positivos o modelo acertou?

75
00:04:13,830 --> 00:04:19,200
O modelo acertou apenas dois dos quatro
gatos verdadeiros, com uma revocação de 0,5.

76
00:04:23,210 --> 00:04:26,885
Vamos revisar rapidamente tudo o que
aprendemos até agora sobre otimização.

77
00:04:28,405 --> 00:04:32,400
Primeiro, definimos modelos de ML como
conjuntos de parâmetros e hiperparâmetros

78
00:04:32,400 --> 00:04:36,355
e tentamos definir a otimização
como uma pesquisa em parâmetro-espaço.

79
00:04:37,735 --> 00:04:39,500
Depois, apresentamos as funções de perda,

80
00:04:39,500 --> 00:04:41,980
que é como medimos e
avaliamos de modo quantificável

81
00:04:41,980 --> 00:04:44,780
o desempenho do modelo
em cada etapa do treinamento.

82
00:04:44,780 --> 00:04:50,220
Os dois exemplos da função que discutimos
foram RMSE, para a regressão linear,

83
00:04:50,220 --> 00:04:52,750
e entropia cruzada,
para tarefas de classificação.

84
00:04:52,750 --> 00:04:55,710
Aprendemos como diferenciar
as superfícies de perda com eficiência,

85
00:04:55,710 --> 00:04:58,385
analisando as inclinações
das funções de perda,

86
00:04:58,385 --> 00:05:01,480
que indicam a direção e o tamanho do passo.

87
00:05:01,480 --> 00:05:04,155
Esse processo é chamado
de gradiente descendente.

88
00:05:05,305 --> 00:05:09,265
Testamos diferentes modelos de ML
no TensorFlow Playground,

89
00:05:09,265 --> 00:05:13,080
vimos como modelos lineares
podem aprender relações não lineares

90
00:05:13,080 --> 00:05:14,800
quando recebem características não lineares

91
00:05:14,800 --> 00:05:18,175
e como redes neurais aprendem
hierarquias de características.

92
00:05:18,175 --> 00:05:20,440
Também vimos como hiperparâmetros,

93
00:05:20,440 --> 00:05:23,755
como taxa de aprendizado e tamanho do lote,
afetam o gradiente descendente.

94
00:05:23,755 --> 00:05:27,985
Em seguida, mostramos como escolher
entre acurácia, precisão e revocação

95
00:05:27,985 --> 00:05:29,920
para melhorar o desempenho
de um modelo de classificação

96
00:05:29,920 --> 00:05:32,310
dependendo do problema a ser resolvido.

97
00:05:32,310 --> 00:05:34,330
Como você viu neste módulo,

98
00:05:34,330 --> 00:05:38,380
o modelo aprendeu a partir do nosso
conjunto de dados de treinamento rotulados.

99
00:05:38,380 --> 00:05:40,015
No módulo seguinte,

100
00:05:40,015 --> 00:05:44,310
falaremos como dividir o conjunto
em dados por treinamento e avaliação

101
00:05:44,310 --> 00:05:47,000
e sobre as armadilhas a serem evitadas.