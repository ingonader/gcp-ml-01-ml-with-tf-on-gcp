1
00:00:00,000 --> 00:00:04,610
前のセクションでは 
勾配降下法を使ってモデルにトレーニングさせました

2
00:00:04,610 --> 00:00:06,385
作成したモデルでは

3
00:00:06,385 --> 00:00:08,920
学習した特徴量の階層を使って

4
00:00:08,920 --> 00:00:11,295
複雑な非線形の関係を学習できました

5
00:00:11,295 --> 00:00:13,490
しかし セクションの終わりには

6
00:00:13,490 --> 00:00:16,495
現在の手法に問題があることがわかりました

7
00:00:16,495 --> 00:00:19,150
その結果 トレーニング時間が長くなり

8
00:00:19,150 --> 00:00:22,370
準最適な最小値 不適切な最小値が生じます

9
00:00:22,370 --> 00:00:26,710
このセクションでは 不適切な最小値とは何か
なぜ存在するのか

10
00:00:26,710 --> 00:00:31,265
パフォーマンス指標によってより優れた
結果が得られる仕組みを見ていきます

11
00:00:31,265 --> 00:00:34,055
不適切な最小値とは何でしょうか

12
00:00:34,055 --> 00:00:36,210
うまく汎化できない

13
00:00:36,210 --> 00:00:39,830
または モデル化する関係を
正しく反映していないストラテジーの

14
00:00:39,830 --> 00:00:43,405
いずれかまたは両方が反映された
パラメータ領域の点です

15
00:00:43,405 --> 00:00:47,590
たとえば 駐車場の画像から駐車スペースが
空いているかどうかの予測を

16
00:00:47,590 --> 00:00:49,960
モデルにトレーニングさせるとします

17
00:00:49,960 --> 00:00:55,765
単純にすべてのスペースが埋まっていると
予測するのは不適切なストラテジーです

18
00:00:55,765 --> 00:01:00,225
空車とそうでない駐車スペースの数が
等しいデータセットでは

19
00:01:00,225 --> 00:01:03,775
このようなストラテジーは
最適化プロセスに耐えられません

20
00:01:03,775 --> 00:01:09,045
しかし データセットに偏りがあり
片方のクラスがもう一方よりはるかに多い場合

21
00:01:09,045 --> 00:01:13,305
このようなストラテジーの誘引性が
はるかに高くなる可能性があります

22
00:01:13,305 --> 00:01:17,900
私たちなら 空きスペースの見た目の
特徴が関係するだろうと予測しますが

23
00:01:17,900 --> 00:01:20,440
このようなストラテジーは

24
00:01:20,440 --> 00:01:24,020
特徴量とラベルの関係を
正しく理解しようとしません

25
00:01:24,035 --> 00:01:26,930
その結果 基本的な関係は同じでも

26
00:01:26,930 --> 00:01:31,220
空きスペースの割合が異なる
新たな駐車場については

27
00:01:31,220 --> 00:01:32,955
うまく汎化できません

28
00:01:32,955 --> 00:01:35,470
不適切な最小値の存在を

29
00:01:35,470 --> 00:01:38,460
損失関数の問題として考えたいところですが

30
00:01:38,460 --> 00:01:40,545
残念ながら

31
00:01:40,545 --> 00:01:46,015
最適なストラテジーを高く評価して
そうでないものには罰則を科す

32
00:01:46,015 --> 00:01:49,225
完璧な損失関数はありません

33
00:01:49,240 --> 00:01:53,200
私たちが使用したい指標と
勾配降下法でうまく機能する指標には

34
00:01:53,200 --> 00:01:56,115
常に隔たりがあります

35
00:01:56,115 --> 00:02:00,975
駐車スペースの分類の例に戻ると

36
00:02:00,975 --> 00:02:05,480
一見 完璧な損失関数は
誤った予測の数を最小化しますが

37
00:02:05,480 --> 00:02:08,235
このような損失関数は区分的です

38
00:02:08,235 --> 00:02:12,705
つまり 損失関数が取る値は
実数ではなく整数です

39
00:02:12,705 --> 00:02:15,515
意外にもこれが問題です

40
00:02:15,515 --> 00:02:18,810
要するに問題は微分可能性にあります

41
00:02:18,810 --> 00:02:22,245
勾配降下法では インクリメンタルに
重みを変化させます

42
00:02:22,245 --> 00:02:26,770
そのため 重みを損失について
微分できる必要があります

43
00:02:26,770 --> 00:02:30,170
しかし 区分的関数の範囲は連続していません

44
00:02:30,170 --> 00:02:32,640
TensorFlowで微分することはできますが

45
00:02:32,640 --> 00:02:35,730
結果として得られる損失面には
途切れがあるため

46
00:02:35,730 --> 00:02:38,065
トラバースするのがより一層困難です

47
00:02:38,065 --> 00:02:41,310
このため 問題を構成し直す必要があります

48
00:02:41,310 --> 00:02:44,610
学習中に完璧な損失関数を探索するのではなく

49
00:02:44,610 --> 00:02:47,725
学習完了後に新しい種類の指標を使います

50
00:02:47,725 --> 00:02:50,105
この新しい種類の指標によって

51
00:02:50,105 --> 00:02:53,895
不適切な最小値に収束したモデルを
却下できます

52
00:02:54,995 --> 00:02:58,590
こうした指標をパフォーマンス指標と呼びます

53
00:02:58,590 --> 00:03:02,370
パフォーマンス指標には
損失関数に勝る利点が2つあります

54
00:03:02,370 --> 00:03:04,755
1つ目は わかりやすいことです

55
00:03:04,755 --> 00:03:09,070
これは数えられる統計情報を単純に
組み合わせたものが多いためです

56
00:03:09,070 --> 00:03:13,520
2つ目は ビジネス上の目標に
直接関係している点です

57
00:03:13,520 --> 00:03:15,545
とらえにくい点ですが

58
00:03:15,545 --> 00:03:17,910
要するに 損失とビジネス上の目標は

59
00:03:17,910 --> 00:03:20,990
常に一致するとは限らないということです

60
00:03:20,990 --> 00:03:23,365
場合によっては 損失が下がっても

61
00:03:23,365 --> 00:03:27,620
ビジネス上の目標達成に向けた
進展がほとんどないこともあります

62
00:03:28,170 --> 00:03:30,275
次は 3つのパフォーマンス指標

63
00:03:30,275 --> 00:03:32,720
混同行列、適合率、再現率と

64
00:03:32,720 --> 00:03:35,000
使用するタイミングについて説明します