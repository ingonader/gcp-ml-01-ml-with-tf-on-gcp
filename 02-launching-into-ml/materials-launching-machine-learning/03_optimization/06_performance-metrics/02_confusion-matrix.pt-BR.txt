Você já deve ter visto esta matriz quando falamos sobre ML inclusivo e
reconhecimento facial em um curso anterior. Naquele exemplo, examinamos um
modelo de ML de detecção de faces que previu incorretamente
uma estátua como uma face humana, o que chamamos de falso positivo. Ele também não detectou no conjunto de dados
uma face real coberta por roupas de inverno. Chamamos essa falha de falso negativo. Uma matriz de confusão como esta permite avaliar de maneira quantificável o
desempenho do modelo de classificação. Agora, temos quatro números,
um para cada quadrante. Mas os responsáveis pelas decisões
de negócios querem ver apenas um. Qual devemos apresentar? Para nos aprofundar nessa questão, vamos analisar outro
exemplo de classificação de fotos. Quando sabemos que uma vaga
de estacionamento está vazia, ou seja, tem rótulo positivo, e o modelo também
prevê que ela está vazia, chamamos o resultado de verdadeiro positivo. Quando sabemos que uma vaga
de estacionamento está ocupada, mas o modelo prevê que está vazia, chamamos o resultado de
falso positivo ou erro do tipo I. Para comparar o desempenho
do modelo com as previsões positivas, usamos uma métrica chamada de precisão. Quando a precisão é alta,
se dizemos que a vaga está vazia, temos certeza de que realmente está. Uma precisão de 1,0 significa que
todas as vagas vazias identificadas estão realmente vazias. Mas talvez haja outras
vagas vazias não detectadas que chamamos de falso negativos. A precisão é definida formalmente como o número de verdadeiros positivos dividido
pelo total classificado como positivo. Analisando a matriz, um aumento
em qual fator reduziria a precisão? Um aumento em falsos positivos. No nosso exemplo do estacionamento, quanto mais o modelo
prevê vagas vazias que na realidade estão ocupadas,
menor é a precisão. Geralmente, a revocação está
inversamente relacionada à precisão. Quando a revocação é alta, somos recompensados por
encontrar várias vagas realmente vazias. Uma revocação de 1,0 significa que
encontramos todas as vagas vazias. Mas significa também que talvez muitas
vagas vazias encontradas estavam ocupadas. Chamamos esses resultados
 de falsos positivos. Qual era a revocação
no exemplo do estacionamento? Lembre-se: tínhamos
10 vagas realmente vazias, mas o modelo identificou apenas uma delas. A resposta é 1 de 10 ou 0,1. Temos aqui um conjunto de dados de imagens. Cada imagem tem um gato ou não. Pare por um instante e tente identificá-las. Espero que você tenha encontrado todos
os gatos domésticos como mostrado aqui. Repare no gato escondido
destacado em vermelho e que não classificamos o tigre como um gato. Vamos ver como o modelo faz a classificação. Estes são os resultados do nosso modelo. Vamos comparar os resultados
com o que sabemos ser verdade. Agora temos os pontos de dados rotulados
corretamente ao lado das previsões do modelo. No total, temos oito
exemplos, ou instâncias, que mostramos ao modelo. Quantas vezes o modelo acertou? Três de um total de oito instâncias
foram previstas corretamente. Isso dá ao modelo uma acurácia de 0,375. A acurácia é a melhor métrica para
descrever o desempenho do modelo? Antes de entrarmos em outro assunto, vamos falar sobre uma armadilha comum. Voltando ao exemplo dos gatos, qual é a precisão do modelo? Estas cinco imagens foram
classificadas como positivas. Quantas realmente são de gatos domésticos? Duas das cinco imagens,
ou uma taxa de precisão de 0,4. Revocação é como alguém que nunca
quer ser excluído de uma decisão positiva. Aqui vemos todos os exemplos
de gato com rótulo de verdadeiro e o desempenho do modelo. Qual foi a revocação? Em outras palavras, quantos
verdadeiros positivos o modelo acertou? O modelo acertou apenas dois dos quatro
gatos verdadeiros, com uma revocação de 0,5. Vamos revisar rapidamente tudo o que
aprendemos até agora sobre otimização. Primeiro, definimos modelos de ML como
conjuntos de parâmetros e hiperparâmetros e tentamos definir a otimização
como uma pesquisa em parâmetro-espaço. Depois, apresentamos as funções de perda, que é como medimos e
avaliamos de modo quantificável o desempenho do modelo
em cada etapa do treinamento. Os dois exemplos da função que discutimos
foram RMSE, para a regressão linear, e entropia cruzada,
para tarefas de classificação. Aprendemos como diferenciar
as superfícies de perda com eficiência, analisando as inclinações
das funções de perda, que indicam a direção e o tamanho do passo. Esse processo é chamado
de gradiente descendente. Testamos diferentes modelos de ML
no TensorFlow Playground, vimos como modelos lineares
podem aprender relações não lineares quando recebem características não lineares e como redes neurais aprendem
hierarquias de características. Também vimos como hiperparâmetros, como taxa de aprendizado e tamanho do lote,
afetam o gradiente descendente. Em seguida, mostramos como escolher
entre acurácia, precisão e revocação para melhorar o desempenho
de um modelo de classificação dependendo do problema a ser resolvido. Como você viu neste módulo, o modelo aprendeu a partir do nosso
conjunto de dados de treinamento rotulados. No módulo seguinte, falaremos como dividir o conjunto
em dados por treinamento e avaliação e sobre as armadilhas a serem evitadas.