1
00:00:00,130 --> 00:00:03,650
Diese Matrix 
haben Sie vielleicht schon einmal gesehen,

2
00:00:03,650 --> 00:00:07,245
als wir in einem früheren Kurs 
ML und Gesichtserkennung besprochen haben.

3
00:00:07,245 --> 00:00:10,830
In diesem Beispiel haben wir ein ML-Modell
zur Gesichtserkennung betrachtet,

4
00:00:10,830 --> 00:00:13,555
das eine Statue falsch
als menschliches Gesicht einstufte,

5
00:00:13,565 --> 00:00:15,480
was als "falsch positiv" bezeichnet wird.

6
00:00:15,480 --> 00:00:20,005
Es übersah auch ein Gesicht im Datensatz, 
das durch Winterkleidung verdeckt wurde,

7
00:00:20,005 --> 00:00:22,895
dieser Fehler 
wird als "falsch negativ" bezeichnet.

8
00:00:22,895 --> 00:00:25,850
Mit einer solchen 
Wahrheitsmatrix können wir

9
00:00:25,850 --> 00:00:29,395
die Leistung eines Klassifizierungsmodells
quantifizierbar bewerten.

10
00:00:29,395 --> 00:00:31,090
Doch jetzt haben wir vier Zahlen,

11
00:00:31,090 --> 00:00:35,090
eine für jeden Quadranten, aber die
Entscheidungsträger wollen nur eine sehen.

12
00:00:35,090 --> 00:00:37,250
Welche präsentieren wir ihnen?

13
00:00:37,250 --> 00:00:39,245
Untersuchen wir dies ein wenig genauer

14
00:00:39,245 --> 00:00:42,680
und werfen einen Blick auf ein 
weiteres Beispiel der Fotoklassifizierung.

15
00:00:42,680 --> 00:00:45,070
Wenn wir wissen, 
dass ein Parkplatz frei ist,

16
00:00:45,070 --> 00:00:46,960
sein Label also "positiv" ist,

17
00:00:46,960 --> 00:00:49,375
und das Modell den
Platz auch als frei voraussagt,

18
00:00:49,375 --> 00:00:51,890
nennen wir das "richtig positiv".

19
00:00:51,890 --> 00:00:55,070
Wenn wir wissen,
dass ein Parkplatz besetzt ist,

20
00:00:55,070 --> 00:00:57,100
aber das Modell 
ihn als frei voraussagt,

21
00:00:57,100 --> 00:01:00,495
bezeichnen wir das als
"falsch positiv" oder als Typ-I-Fehler.

22
00:01:00,495 --> 00:01:04,430
Um zu vergleichen, wie gut unser
Modell positive Vorhersagen getroffen hat,

23
00:01:04,430 --> 00:01:06,550
verwenden wir den Messwert "Präzision".

24
00:01:06,550 --> 00:01:10,340
Hohe Präzision heißt: Ich bin
mir sicher, dass ein freier Parkplatz

25
00:01:10,340 --> 00:01:12,190
auch wirklich frei ist.

26
00:01:12,190 --> 00:01:16,600
Eine Präzision von 1,0
bedeutet, dass von den freien Plätzen,

27
00:01:16,600 --> 00:01:19,162
die ich identifiziert
habe, alle wirklich frei sind.

28
00:01:19,162 --> 00:01:23,110
Aber ich könnte freie Plätze übersehen
haben, sogenannte falsch Negative.

29
00:01:23,110 --> 00:01:27,080
Die formale Definition von Präzision ist:
die Anzahl der richtig Positiven geteilt

30
00:01:27,080 --> 00:01:30,460
durch die Gesamtzahl 
der als positiv Eingestuften.

31
00:01:30,460 --> 00:01:36,075
Betrachten Sie die Matrix. Wo würde 
ein höherer Wert die Präzision verringern?

32
00:01:38,075 --> 00:01:40,290
Eine Zunahme von 
falsch positiven Ergebnissen.

33
00:01:40,290 --> 00:01:43,365
Je mehr freie Plätze das Modell 
im Parkplatzbeispiel voraussagt,

34
00:01:43,365 --> 00:01:45,517
die in Wahrheit nicht frei sind,

35
00:01:45,517 --> 00:01:47,140
desto geringer ist die Präzision.

36
00:01:49,910 --> 00:01:53,015
Recall ist oft 
umgekehrt proportional zur Präzision.

37
00:01:53,015 --> 00:01:57,850
Der Recall ist höher, je mehr 
tatsächlich freie Parkplätze ich finde.

38
00:01:57,850 --> 00:02:02,675
Ein Recall von 1,0 bedeutet, dass ich
10 von 10 freien Plätzen gefunden habe.

39
00:02:02,675 --> 00:02:06,690
Ich könnte aber auch viele "freie" Plätze
gefunden haben, die gar nicht frei sind.

40
00:02:06,690 --> 00:02:09,770
Diese werden als 
falsch Positive bezeichnet.

41
00:02:09,770 --> 00:02:13,285
Wie war der Recall im Parkplatzbeispiel?

42
00:02:13,285 --> 00:02:16,245
Wir hatten 10 tatsächlich freie Plätze

43
00:02:16,245 --> 00:02:19,970
und unser Modell hat
nur nur einen als frei erkannt.

44
00:02:19,970 --> 00:02:25,265
Die Antwort ist 1 von 10 oder 0,1.

45
00:02:25,265 --> 00:02:29,610
Hier sehen Sie ein Dataset mit Bildern.

46
00:02:29,610 --> 00:02:32,680
Auf jedem Bild ist entweder
eine Katze zu sehen oder nicht.

47
00:02:32,680 --> 00:02:37,280
Sehen Sie kurz selbst, 
ob Sie alle richtig zuordnen können.

48
00:02:40,400 --> 00:02:43,990
Hoffentlich haben Sie alle 
hier gezeigten Hauskatzen gefunden.

49
00:02:43,990 --> 00:02:46,760
Beachten Sie die versteckte
Katze in Rot und dass der Tiger

50
00:02:46,760 --> 00:02:50,420
für unsere Zwecke nicht als Katze gilt.

51
00:02:50,420 --> 00:02:54,650
Betrachten wir, wie das
Modell die Klassifizierung durchführt.

52
00:02:54,650 --> 00:02:58,320
Hier sehen wir, 
was unser Modell ergeben hat.

53
00:02:58,320 --> 00:03:01,605
Vergleichen wir die Ergebnisse 
mit der uns bekannten Wahrheit.

54
00:03:04,535 --> 00:03:09,175
Da sind die Datenpunkte mit dem richtigen
Label neben den Modellvorhersagen.

55
00:03:09,175 --> 00:03:11,440
Insgesamt haben wir acht Beispiele

56
00:03:11,440 --> 00:03:13,955
oder Instanzen, 
die wir dem Modell gezeigt haben.

57
00:03:13,955 --> 00:03:17,850
Wie oft lag das Modell richtig?

58
00:03:20,530 --> 00:03:23,155
Drei von insgesamt acht 
wurden richtig vorhergesagt.

59
00:03:23,155 --> 00:03:27,405
Somit hat das Modell
eine Präzision von 0,375.

60
00:03:27,405 --> 00:03:32,265
Ist die Präzision das beste Maß
für die Beschreibung der Modellleistung?

61
00:03:32,265 --> 00:03:34,230
Bevor wir uns anderen Methoden zuwenden,

62
00:03:34,230 --> 00:03:37,050
wollen wir zuerst 
eine typische Falle besprechen.

63
00:03:37,050 --> 00:03:40,065
Zurück zu unserem Beispiel mit den Katzen:

64
00:03:40,065 --> 00:03:42,215
Wie ist die Präzision des Modells?

65
00:03:42,215 --> 00:03:45,675
Diese fünf Bilder hier 
wurden als positiv klassifiziert.

66
00:03:45,675 --> 00:03:49,425
Wie viele sind wirklich Hauskatzen?

67
00:03:49,425 --> 00:03:54,370
Zwei der fünf oder 
eine Präzision von 0,4.

68
00:03:54,370 --> 00:03:59,140
Recall ist wie jemand, der bei positiven 
Entscheidungen immer dabei sein möchte.

69
00:03:59,140 --> 00:04:02,740
Hier sehen Sie alle 
Katzenbilder mit richtigem Label

70
00:04:02,740 --> 00:04:06,655
und die entsprechende Leistung 
des Modells. Wie war der Recall?

71
00:04:06,655 --> 00:04:12,530
Oder anders gesagt: Wie viele 
richtige Positive hat das Modell gefunden?

72
00:04:12,530 --> 00:04:20,920
Das Modell hat nur 2 der 4 Katzen 
gefunden, was einen Recall von 0,5 ergibt.

73
00:04:23,080 --> 00:04:27,545
Fassen wir kurz zusammen, was wir 
bisher über Optimierung gelernt haben.

74
00:04:27,545 --> 00:04:32,400
Zuerst haben wir ML-Modelle als Sets von
Parametern und Hyperparametern definiert

75
00:04:32,400 --> 00:04:36,915
und versucht, Optimierung als
Suche im Parameterraum zu definieren.

76
00:04:36,915 --> 00:04:39,440
Als Nächstes haben wir 
Verlustfunktionen eingeführt,

77
00:04:39,440 --> 00:04:41,750
mit denen wir die Leistung unseres Modells

78
00:04:41,750 --> 00:04:44,890
bei jedem Trainingsschritt 
quantifizierbar messen und bewerten.

79
00:04:44,890 --> 00:04:48,920
Wir haben zwei Beispiele für spezifische 
Verlustfunktionen besprochen, RMSE

80
00:04:48,920 --> 00:04:52,750
für lineare Regression und Kreuzentropie 
bei unserer Klassifikationsaufgabe.

81
00:04:52,750 --> 00:04:56,070
Wir haben gelernt, unsere
Verlustoberflächen zu diversifizieren,

82
00:04:56,070 --> 00:04:58,815
indem wir das Gefälle der 
Verlustfunktionen analysieren,

83
00:04:58,815 --> 00:05:01,480
das uns Richtung und Schrittgröße liefert.

84
00:05:01,480 --> 00:05:04,825
Dieser Vorgang wird 
Gradientenabstieg genannt.

85
00:05:04,825 --> 00:05:09,265
In TensorFlow Playground haben
wir verschiedene ML-Modelle getestest

86
00:05:09,265 --> 00:05:12,710
und gesehen, wie lineare Modelle 
nicht lineare Beziehungen lernen können,

87
00:05:12,710 --> 00:05:14,710
wenn sie nicht lineare Merkmale erhalten,

88
00:05:14,710 --> 00:05:18,175
und wie neuronale Netzwerke
Hierarchien von Merkmalen lernen.

89
00:05:18,175 --> 00:05:20,440
Wir haben auch gesehen,
wie Hyperparameter wie

90
00:05:20,440 --> 00:05:23,755
die Lernrate und die Batch-Größe
den Gradientenabstieg beeinflussen.

91
00:05:23,755 --> 00:05:27,415
Wir haben dann anhand der Modellleistung 
bei der Klassifizierung besprochen,

92
00:05:27,415 --> 00:05:30,180
wie Sie zwischen Genauigkeit,
Präzision und Recall wählen,

93
00:05:30,180 --> 00:05:32,410
je nachdem,
welches Problem Sie lösen möchten.

94
00:05:32,410 --> 00:05:34,240
Wie Sie in diesem Modul gesehen haben,

95
00:05:34,240 --> 00:05:37,580
war unser Trainings-Dataset
mit Labels das wesentliche Element,

96
00:05:37,580 --> 00:05:39,300
mit dem das Modell gelernt hat.

97
00:05:39,300 --> 00:05:41,115
Im nächsten Modul behandeln wir,

98
00:05:41,115 --> 00:05:44,310
wie Sie Ihr Dataset effektiv
für Training und Evaluierung aufteilen

99
00:05:44,310 --> 00:05:47,000
und welche Fallstricke 
Sie umgehen sollten.