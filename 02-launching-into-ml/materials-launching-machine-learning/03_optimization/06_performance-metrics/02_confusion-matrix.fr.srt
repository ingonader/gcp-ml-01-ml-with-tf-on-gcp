1
00:00:00,580 --> 00:00:04,440
Vous avez peut-être déjà vu cette matrice
lorsque nous avons abordé le ML inclusif

2
00:00:04,440 --> 00:00:07,245
et la reconnaissance faciale
dans un précédent cours.

3
00:00:07,245 --> 00:00:10,130
Dans cet exemple, un modèle de ML
de reconnaissance faciale

4
00:00:10,130 --> 00:00:13,975
faisait une prédiction incorrecte en
confondant une statue avec un visage humain.

5
00:00:13,975 --> 00:00:15,750
Ce cas de figure est un faux positif.

6
00:00:15,750 --> 00:00:19,137
Dans le même ensemble de données,
ce modèle n'avait pas non plus détecté

7
00:00:19,137 --> 00:00:21,515
un visage réel, assombri
par des vêtements d'hiver.

8
00:00:21,515 --> 00:00:23,305
Ce cas de figure est un faux négatif.

9
00:00:23,305 --> 00:00:25,210
Une matrice de confusion comme celle-ci,

10
00:00:25,210 --> 00:00:29,395
permet de quantifier les performances
de notre modèle de classification.

11
00:00:29,395 --> 00:00:32,180
Mais nous avons maintenant quatre chiffres,
un par case,

12
00:00:32,180 --> 00:00:35,100
et les décisionnaires de l'entreprise
n'en veulent qu'un.

13
00:00:35,100 --> 00:00:37,240
Lequel choisir ?

14
00:00:37,240 --> 00:00:39,235
Pour approfondir,

15
00:00:39,235 --> 00:00:42,460
regardons un autre exemple
de classification de photos.

16
00:00:42,460 --> 00:00:45,180
Si nous savons qu'une place
de stationnement est libre,

17
00:00:45,180 --> 00:00:46,970
donc si son étiquette est positive,

18
00:00:46,970 --> 00:00:49,465
et que le modèle prédit
également qu'elle est libre,

19
00:00:49,465 --> 00:00:51,890
nous parlons de vrai positif.

20
00:00:51,890 --> 00:00:54,920
Si nous savons qu'une place
de stationnement est occupée,

21
00:00:54,920 --> 00:00:57,020
mais que le modèle prédit qu'elle est libre,

22
00:00:57,020 --> 00:01:00,535
nous parlons de faux positif,
ou d'erreur de type 1.

23
00:01:00,535 --> 00:01:04,520
Afin d'évaluer le niveau d'exactitude
des prédictions positives du modèle,

24
00:01:04,520 --> 00:01:07,090
nous utilisons une métrique
qui s'appelle la précision.

25
00:01:07,090 --> 00:01:10,750
Avec une précision élevée, si je dis
qu'une place de stationnement est libre,

26
00:01:10,750 --> 00:01:12,570
je suis vraiment sûr qu'elle l'est.

27
00:01:12,570 --> 00:01:15,947
Une précision de 1 signifie que les places
libres que j'ai identifiées

28
00:01:15,947 --> 00:01:18,547
sont toutes réellement disponibles.

29
00:01:18,547 --> 00:01:21,540
Mais je pourrais ne pas avoir
identifié d'autres places libres :

30
00:01:21,540 --> 00:01:23,670
on les appelle "faux négatifs".

31
00:01:23,670 --> 00:01:26,920
Par définition, la précision correspond
au nombre de vrais positifs

32
00:01:26,920 --> 00:01:30,490
divisé par le nombre total d'éléments
classifiés comme positifs.

33
00:01:30,490 --> 00:01:35,627
Dans la matrice, quel facteur devrait
augmenter pour que la précision baisse ?

34
00:01:36,635 --> 00:01:40,430
Le nombre de faux positifs.

35
00:01:40,430 --> 00:01:42,525
Dans notre exemple du parking,

36
00:01:42,525 --> 00:01:46,290
plus le modèle prédit que des places
sont libres alors qu'elles ne le sont pas,

37
00:01:46,290 --> 00:01:49,455
plus la précision baisse.

38
00:01:49,455 --> 00:01:52,840
Le rappel est souvent
inversement lié à la précision.

39
00:01:52,840 --> 00:01:55,530
Un rappel élevé indique
que j'ai identifié

40
00:01:55,530 --> 00:01:58,130
un grand nombre de places
effectivement libres.

41
00:01:58,130 --> 00:02:02,675
Un rappel de 1 signifie
que j'ai trouvé 10 des 10 places libres,

42
00:02:02,675 --> 00:02:05,432
mais également que j'ai pu
identifié comme libres

43
00:02:05,432 --> 00:02:07,190
de nombreuses places ne l'étant pas.

44
00:02:07,190 --> 00:02:09,790
C'est ce que l'on appelle
des faux positifs.

45
00:02:09,790 --> 00:02:13,655
À combien s'élevait le rappel
dans notre exemple du parking ?

46
00:02:13,655 --> 00:02:16,305
Souvenez-vous que 10 places étaient libres,

47
00:02:16,305 --> 00:02:20,000
et que le modèle n'en avait identifié qu'une.

48
00:02:20,000 --> 00:02:25,275
La réponse est 1 sur 10, soit 0,1.

49
00:02:25,275 --> 00:02:29,610
Voici un ensemble de données
constitué d'images.

50
00:02:29,610 --> 00:02:32,690
Chaque image comporte ou
ne comporte pas un chat.

51
00:02:32,690 --> 00:02:36,670
Prenez un instant, et voyez si vous pouvez
les identifier.

52
00:02:38,590 --> 00:02:43,970
J'espère que vous avez trouvé
tous les chats domestiques indiqués ici.

53
00:02:43,970 --> 00:02:46,740
Notez bien qu'il y a un chat caché
encadré en rouge

54
00:02:46,740 --> 00:02:50,450
et que le tigre n'est pas classifié
comme un chat.

55
00:02:50,450 --> 00:02:55,870
Voyons maintenant quelle est
la classification établie par le modèle.

56
00:02:55,870 --> 00:02:58,380
Voici les résultats.

57
00:02:58,380 --> 00:03:04,355
Comparons-les à ce que nous savons être vrai.

58
00:03:04,355 --> 00:03:06,030
Voici nos points de données.

59
00:03:06,030 --> 00:03:09,785
Ils sont correctement étiquetés, côte à côte
avec les prédictions du modèle.

60
00:03:09,785 --> 00:03:13,990
Au total, nous avons montré huit exemples
(ou instances) au modèle.

61
00:03:13,990 --> 00:03:18,350
Dans combien de cas ses prédictions
sont-elles correctes ?

62
00:03:18,350 --> 00:03:23,155
Dans trois cas sur un total de huit.

63
00:03:23,155 --> 00:03:28,585
Cela donne une justesse de 0,375.

64
00:03:28,585 --> 00:03:32,605
La justesse est-elle la meilleure métrique
pour décrire les performances du modèle ?

65
00:03:32,605 --> 00:03:34,910
Avant de nous intéresser
à d'autres possibilités,

66
00:03:34,910 --> 00:03:37,330
commençons par examiner un piège courant.

67
00:03:37,330 --> 00:03:40,085
Revenons à notre exemple des chats.

68
00:03:40,085 --> 00:03:42,245
Quelle est la précision du modèle ?

69
00:03:42,245 --> 00:03:45,675
Ces cinq images étaient
dans la classe positive.

70
00:03:45,675 --> 00:03:49,455
Combien contiennent réellement
des chats domestiques ?

71
00:03:49,455 --> 00:03:53,517
Deux sur cinq, soit un taux
de précision de 0,4.

72
00:03:54,370 --> 00:03:55,975
Le rappel est comme une personne

73
00:03:55,975 --> 00:03:59,190
qui ne veut jamais rester
à l'écart d'une décision positive.

74
00:03:59,190 --> 00:04:02,120
Voici toutes les images étiquetées
comme contenant des chats

75
00:04:02,120 --> 00:04:05,217
que nous pouvons utiliser
pour évaluer les performances du modèle.

76
00:04:05,217 --> 00:04:07,822
À combien s'élevait le rappel ?
Ou, en d'autres termes,

77
00:04:07,822 --> 00:04:12,530
combien de vrais positifs
le modèle a-t-il pu identifier ?

78
00:04:12,530 --> 00:04:20,920
Seulement 2 sur 4, soit un rappel de 0,5.

79
00:04:23,550 --> 00:04:27,565
Récapitulons rapidement ce que vous avez
appris jusqu'à présent sur l'optimisation.

80
00:04:27,565 --> 00:04:30,052
Nous avons tout d'abord défini
les modèles de ML

81
00:04:30,052 --> 00:04:32,640
comme des ensembles
de paramètres et d'hyperparamètres,

82
00:04:32,640 --> 00:04:34,797
et nous avons tenté
d'envisager l'optimisation

83
00:04:34,797 --> 00:04:37,115
comme une recherche
dans l'espace des paramètres.

84
00:04:37,115 --> 00:04:39,550
Nous avons ensuite présenté
les fonctions de perte,

85
00:04:39,550 --> 00:04:43,130
qui permettent de quantifier et d'évaluer
les performances du modèle

86
00:04:43,130 --> 00:04:44,830
pour chaque pas de l'entraînement.

87
00:04:44,830 --> 00:04:48,050
Nous avons vu deux exemples
de fonctions de perte spécifiques :

88
00:04:48,050 --> 00:04:52,665
la RMSE pour la régression linéaire,
et l'entropie croisée pour la classification.

89
00:04:52,665 --> 00:04:55,810
Nous avons appris à diversifier
efficacement les surfaces de perte

90
00:04:55,810 --> 00:04:58,485
en analysant les pentes
des fonctions de perte,

91
00:04:58,485 --> 00:05:01,480
lesquelles indiquent la direction
et la magnitude des pas.

92
00:05:01,480 --> 00:05:04,845
Ce processus est appelé descente de gradient.

93
00:05:04,845 --> 00:05:07,545
Nous avons fait des tests
avec différents modèles de ML

94
00:05:07,545 --> 00:05:09,627
dans TensorFlow Playground,
et nous avons vu

95
00:05:09,627 --> 00:05:13,150
comment les modèles linéaires peuvent
apprendre des relations non linéaires

96
00:05:13,150 --> 00:05:15,600
en se basant sur des caractéristiques
non linéaires.

97
00:05:15,600 --> 00:05:17,582
Nous avons vu que les réseaux de neurones

98
00:05:17,582 --> 00:05:19,785
apprennent des hiérarchies
de caractéristiques,

99
00:05:19,785 --> 00:05:22,320
et comment les hyperparamètres
de taux d'apprentissage

100
00:05:22,320 --> 00:05:24,875
et de taille de lot affectent
la descente de gradient.

101
00:05:24,875 --> 00:05:28,755
Nous avons ensuite vu comment choisir
entre la justesse, la précision et le rappel

102
00:05:28,755 --> 00:05:31,540
pour évaluer les performances
d'un modèle de classification

103
00:05:31,540 --> 00:05:33,780
en fonction de la nature
du problème à résoudre.

104
00:05:33,780 --> 00:05:37,440
Vous avez pu constater que notre ensemble
de données d’entraînement étiqueté

105
00:05:37,440 --> 00:05:39,690
était déterminant pour l'entraînement
du modèle.

106
00:05:39,690 --> 00:05:43,185
Dans le prochain module, nous apprendrons
à répartir l'ensemble de données

107
00:05:43,185 --> 00:05:45,422
entre l'entraînement et l'évaluation,

108
00:05:45,422 --> 00:05:47,150
et nous verrons les pièges à éviter.