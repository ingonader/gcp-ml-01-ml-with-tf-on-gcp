前のセクションでは 
勾配降下法を使ってモデルにトレーニングさせました 作成したモデルでは 学習した特徴量の階層を使って 複雑な非線形の関係を学習できました しかし セクションの終わりには 現在の手法に問題があることがわかりました その結果 トレーニング時間が長くなり 準最適な最小値 不適切な最小値が生じます このセクションでは 不適切な最小値とは何か
なぜ存在するのか パフォーマンス指標によってより優れた
結果が得られる仕組みを見ていきます 不適切な最小値とは何でしょうか うまく汎化できない または モデル化する関係を
正しく反映していないストラテジーの いずれかまたは両方が反映された
パラメータ領域の点です たとえば 駐車場の画像から駐車スペースが
空いているかどうかの予測を モデルにトレーニングさせるとします 単純にすべてのスペースが埋まっていると
予測するのは不適切なストラテジーです 空車とそうでない駐車スペースの数が
等しいデータセットでは このようなストラテジーは
最適化プロセスに耐えられません しかし データセットに偏りがあり
片方のクラスがもう一方よりはるかに多い場合 このようなストラテジーの誘引性が
はるかに高くなる可能性があります 私たちなら 空きスペースの見た目の
特徴が関係するだろうと予測しますが このようなストラテジーは 特徴量とラベルの関係を
正しく理解しようとしません その結果 基本的な関係は同じでも 空きスペースの割合が異なる
新たな駐車場については うまく汎化できません 不適切な最小値の存在を 損失関数の問題として考えたいところですが 残念ながら 最適なストラテジーを高く評価して
そうでないものには罰則を科す 完璧な損失関数はありません 私たちが使用したい指標と
勾配降下法でうまく機能する指標には 常に隔たりがあります 駐車スペースの分類の例に戻ると 一見 完璧な損失関数は
誤った予測の数を最小化しますが このような損失関数は区分的です つまり 損失関数が取る値は
実数ではなく整数です 意外にもこれが問題です 要するに問題は微分可能性にあります 勾配降下法では インクリメンタルに
重みを変化させます そのため 重みを損失について
微分できる必要があります しかし 区分的関数の範囲は連続していません TensorFlowで微分することはできますが 結果として得られる損失面には
途切れがあるため トラバースするのがより一層困難です このため 問題を構成し直す必要があります 学習中に完璧な損失関数を探索するのではなく 学習完了後に新しい種類の指標を使います この新しい種類の指標によって 不適切な最小値に収束したモデルを
却下できます こうした指標をパフォーマンス指標と呼びます パフォーマンス指標には
損失関数に勝る利点が2つあります 1つ目は わかりやすいことです これは数えられる統計情報を単純に
組み合わせたものが多いためです 2つ目は ビジネス上の目標に
直接関係している点です とらえにくい点ですが 要するに 損失とビジネス上の目標は 常に一致するとは限らないということです 場合によっては 損失が下がっても ビジネス上の目標達成に向けた
進展がほとんどないこともあります 次は 3つのパフォーマンス指標 混同行列、適合率、再現率と 使用するタイミングについて説明します