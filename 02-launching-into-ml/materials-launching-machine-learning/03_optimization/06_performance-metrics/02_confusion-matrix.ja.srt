1
00:00:00,130 --> 00:00:02,580
こちらは 前のコースで

2
00:00:02,580 --> 00:00:07,245
包括的MLと顔認識について
説明した際に使った表です

3
00:00:07,245 --> 00:00:09,910
このとき 顔検出MLモデルが

4
00:00:09,910 --> 00:00:13,555
人の顔でないものを
誤って人の顔だと予測した場合は

5
00:00:13,555 --> 00:00:15,310
偽陽性と呼び

6
00:00:15,310 --> 00:00:20,005
人の顔が冬服で隠れていたために
誤って人の顔でないと予測した場合は

7
00:00:20,005 --> 00:00:22,895
偽陰性と呼ぶと説明しました

8
00:00:22,895 --> 00:00:25,850
このような混同行列を使用することで

9
00:00:25,850 --> 00:00:29,395
分類モデルのパフォーマンスを
定量的に評価できます

10
00:00:29,395 --> 00:00:31,970
4区画それぞれに数字がありますが

11
00:00:31,970 --> 00:00:35,090
ビジネスリーダーが求める数字は1つです

12
00:00:35,090 --> 00:00:37,250
どれを伝えればよいでしょうか

13
00:00:37,250 --> 00:00:39,245
もう少し掘り下げるため

14
00:00:39,245 --> 00:00:42,430
画像分類の例をもう1つ見てみましょう

15
00:00:42,430 --> 00:00:44,680
駐車スペースが空いている

16
00:00:44,680 --> 00:00:46,960
つまり ラベルが陽性のとき

17
00:00:46,960 --> 00:00:49,375
モデルの予測も空きなら

18
00:00:49,375 --> 00:00:51,320
真陽性と呼びます

19
00:00:51,890 --> 00:00:54,890
駐車スペースが埋まっているのに

20
00:00:54,890 --> 00:00:57,000
モデルの予測が空きなら

21
00:00:57,000 --> 00:01:00,495
偽陽性 または 第一種過誤と呼びます

22
00:01:00,495 --> 00:01:04,430
モデルの陽性の予測の
パフォーマンスを比較するには

23
00:01:04,430 --> 00:01:06,550
適合率という指標を使います

24
00:01:06,550 --> 00:01:08,960
適合率が高ければ

25
00:01:08,960 --> 00:01:12,190
空きと予測した場合に その確信度が高く

26
00:01:12,190 --> 00:01:14,420
適合率が1.0なら

27
00:01:14,420 --> 00:01:18,585
空きと予測した駐車スペースが実際に
すべて空いていることを意味します

28
00:01:18,585 --> 00:01:23,550
ただし 空きスペースを見逃した可能性もあり
これを偽陰性と呼びます

29
00:01:23,550 --> 00:01:25,720
適合率は正式には

30
00:01:25,720 --> 00:01:30,460
真陽性の数を陽性に分類された
データの総数で割ったものと定義されます

31
00:01:30,460 --> 00:01:36,635
表を参考に何が増加すると
適合率が減少するでしょうか

32
00:01:36,635 --> 00:01:40,430
答えは偽陽性です

33
00:01:40,430 --> 00:01:42,525
駐車場の例では

34
00:01:42,525 --> 00:01:46,070
モデルが実際には空いていない
スペースを空きと予測すると

35
00:01:46,070 --> 00:01:48,455
適合率が下がります

36
00:01:48,455 --> 00:01:52,970
再現率と適合率は多くの場合
逆相関の関係にあります

37
00:01:52,970 --> 00:01:57,310
再現率が高ければ 実際に空いている
スペースを多く見つけられます

38
00:01:57,310 --> 00:02:02,675
再現率が1.0なら 空いている10か所の
スペースうちすべてを見つけたことを意味します

39
00:02:02,675 --> 00:02:06,690
ただし 空きと予測したスペースが
実際は埋まっていた可能性もあり

40
00:02:06,690 --> 00:02:09,770
これを偽陽性と呼びます

41
00:02:09,770 --> 00:02:13,285
駐車場の例では再現率はいくつでしょうか

42
00:02:13,285 --> 00:02:16,245
実際に空いていたスペースは10か所

43
00:02:16,245 --> 00:02:19,970
モデルが空きとしたのは1か所です

44
00:02:19,970 --> 00:02:25,265
答えは10分の1 つまり 0.1です

45
00:02:25,265 --> 00:02:28,410
こちらにいくつか画像があります

46
00:02:28,410 --> 00:02:32,680
猫が写っている画像と
写っていない画像があります

47
00:02:32,680 --> 00:02:36,790
猫が写っている画像はどれでしょうか

48
00:02:40,380 --> 00:02:43,990
すべて見つけられたでしょうか

49
00:02:43,990 --> 00:02:46,910
赤で囲った部分に猫が隠れています

50
00:02:46,910 --> 00:02:50,420
また ここではトラは猫には分類されません

51
00:02:50,420 --> 00:02:54,650
では モデルによる分類を見ていきましょう

52
00:02:54,650 --> 00:02:58,320
こちらがモデルによる分類です

53
00:02:58,320 --> 00:03:02,885
分類結果と正解を比べてみましょう

54
00:03:02,885 --> 00:03:09,175
適切にラベリングされたデータポイントと
モデルによる予測を並べて表示しました

55
00:03:09,175 --> 00:03:12,530
モデルに入力したデータ つまり インスタンスは

56
00:03:12,530 --> 00:03:13,955
全部で8つです

57
00:03:13,955 --> 00:03:18,320
モデルの予測が正しかったのは何回ですか

58
00:03:18,320 --> 00:03:23,155
合計8回のうち正しく予測したのは3回でした

59
00:03:23,155 --> 00:03:27,405
したがって モデルの正解率は0.375となります

60
00:03:27,405 --> 00:03:32,265
正解率は モデルのパフォーマンスを
説明する上で最適な指標でしょうか

61
00:03:32,265 --> 00:03:34,430
他の指標について説明する前に

62
00:03:34,430 --> 00:03:37,050
よくある落とし穴について説明します

63
00:03:37,050 --> 00:03:40,065
猫の画像の分類の例に戻ると

64
00:03:40,065 --> 00:03:42,215
モデルの適合率はどうでしょうか

65
00:03:42,215 --> 00:03:45,675
5枚の画像を陽性カテゴリに分類しました

66
00:03:45,675 --> 00:03:49,425
このうち実際に猫が写っていたのは
何枚でしょうか

67
00:03:49,425 --> 00:03:54,370
5枚中2枚なので 適合率は0.4となります

68
00:03:54,370 --> 00:03:59,140
再現率とは 陽性のものはすべて
陽性と判断できることです

69
00:03:59,140 --> 00:04:04,430
こちらは実際に猫が写っている画像と
それに対するモデルの予測です

70
00:04:04,430 --> 00:04:06,655
再現率はどうでしょうか

71
00:04:06,655 --> 00:04:12,530
言い換えると 実際に猫が写っている画像のうち
モデルが正しく予測できたのは何枚ですか

72
00:04:12,530 --> 00:04:19,910
実際に猫が写っている4枚のうち
正解は2枚だけなので 再現率は0.5です

73
00:04:21,630 --> 00:04:27,545
最適化についてここまでに学んだことを
簡単にまとめます

74
00:04:27,545 --> 00:04:32,400
まず MLモデルを一連のパラメータと
ハイパーパラメータとして定義し

75
00:04:32,400 --> 00:04:36,915
最適化をパラメータ領域の
探索として構成しました

76
00:04:36,915 --> 00:04:39,440
次に 損失関数を取り上げました

77
00:04:39,440 --> 00:04:42,240
これは 学習の各ステップで
モデルのパフォーマンスを

78
00:04:42,240 --> 00:04:44,780
定量的に測定し 評価する手段です

79
00:04:44,780 --> 00:04:49,830
線形回帰向けのRMSEと
分類タスク向けの交差エントロピーという

80
00:04:49,830 --> 00:04:52,750
2つの損失関数を例に説明しました

81
00:04:52,750 --> 00:04:55,710
損失関数の傾きを分析することで

82
00:04:55,710 --> 00:04:58,385
探索の方向とステップの大きさを求め

83
00:04:58,385 --> 00:05:01,800
損失曲面を効率的にトラバースする方法を
学びました

84
00:05:01,800 --> 00:05:04,825
このプロセスは勾配降下法と呼ばれます

85
00:05:04,825 --> 00:05:08,635
TensorFlow Playgroundを使って
さまざまなMLモデルを構成し

86
00:05:08,635 --> 00:05:12,120
線形モデルでも 非線形の特徴量によって

87
00:05:12,120 --> 00:05:14,710
非線形の関係を学習できることと

88
00:05:14,710 --> 00:05:18,175
NNが特徴量の階層を
学習する仕組みを説明しました

89
00:05:18,175 --> 00:05:21,360
また 学習率やバッチサイズなどの
ハイパーパラメータが

90
00:05:21,360 --> 00:05:24,145
勾配降下法に与える影響についても
説明しました

91
00:05:24,145 --> 00:05:28,295
続いて 問題に応じて
分類モデルのパフォーマンス指標を

92
00:05:28,295 --> 00:05:32,310
正解率、適合率、再現率の中から
選択する方法を説明しました

93
00:05:32,310 --> 00:05:34,330
このモジュールで見てきたように

94
00:05:34,330 --> 00:05:38,380
ラベリングされた学習データセットは
モデルの学習の原動力です

95
00:05:38,380 --> 00:05:40,015
次のモジュールでは

96
00:05:40,015 --> 00:05:44,310
データセット全体を効果的に
学習と評価に分割する方法と

97
00:05:44,310 --> 00:05:47,000
注意すべき落とし穴を取り上げます