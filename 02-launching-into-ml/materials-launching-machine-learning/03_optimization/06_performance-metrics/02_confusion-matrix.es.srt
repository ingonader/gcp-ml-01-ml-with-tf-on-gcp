1
00:00:00,130 --> 00:00:03,650
Probablemente ya vieron
esta matriz cuando analizamos

2
00:00:03,650 --> 00:00:06,885
el AA inclusivo
y el reconocimiento facial.

3
00:00:07,195 --> 00:00:09,410
En ese ejemplo, analizamos un modelo

4
00:00:09,410 --> 00:00:13,555
de AA de detección de rostros que predecía
incorrectamente una estatua como un rostro

5
00:00:13,555 --> 00:00:15,470
lo que se denomina como falso positivo.

6
00:00:15,470 --> 00:00:20,005
Y no reconoció un rostro en el conjunto
de datos porque estaba oculto por la ropa

7
00:00:20,005 --> 00:00:22,805
a esto se le llama falso negativo.

8
00:00:23,195 --> 00:00:25,850
Una matriz de confusión
como esta nos permitirá evaluar

9
00:00:25,850 --> 00:00:29,395
de forma cuantificable el rendimiento
de nuestro modelo de clasificación.

10
00:00:29,395 --> 00:00:31,360
Ahora tenemos cuatro números

11
00:00:31,360 --> 00:00:35,170
uno para cada cuadrante y quienes toman
decisiones comerciales solo quieren uno.

12
00:00:35,200 --> 00:00:37,250
¿Cuál presentamos?

13
00:00:37,250 --> 00:00:39,245
Para explorar más esto

14
00:00:39,245 --> 00:00:42,160
veamos otro ejemplo
de clasificación de fotos.

15
00:00:42,820 --> 00:00:45,070
Si sabemos que hay
un estacionamiento disponible

16
00:00:45,070 --> 00:00:46,960
que está etiquetado como positivo

17
00:00:46,960 --> 00:00:49,375
y el modelo también
predice que está disponible

18
00:00:49,375 --> 00:00:51,800
lo llamamos un verdadero positivo.

19
00:00:52,330 --> 00:00:55,070
Si sabemos que
el estacionamiento no está disponible

20
00:00:55,070 --> 00:00:56,730
pero el modelo predice que sí

21
00:00:56,730 --> 00:01:00,335
lo llamamos un falso
positivo o error de tipo 1.

22
00:01:00,785 --> 00:01:04,430
Para comparar cómo le fue a nuestro
modelo con sus predicciones positivas

23
00:01:04,430 --> 00:01:06,550
usaremos una métrica llamada precisión.

24
00:01:06,550 --> 00:01:10,340
Con una alta precisión, puedo decir
que hay un estacionamiento disponible

25
00:01:10,340 --> 00:01:12,190
estoy seguro de ello.

26
00:01:12,190 --> 00:01:16,600
Una precisión de 1.0 significa que
los espacios disponibles que identifiqué

27
00:01:16,600 --> 00:01:18,585
están todos disponibles.

28
00:01:18,585 --> 00:01:22,970
Pero es posible que haya omitido otros
espacios disponibles, o falsos negativos.

29
00:01:23,690 --> 00:01:26,200
La precisión se define
formalmente como la cantidad

30
00:01:26,200 --> 00:01:30,060
de verdaderos positivos dividida
por la cantidad clasificada como positiva.

31
00:01:31,100 --> 00:01:35,935
Si vemos la matriz, ¿el aumento
de qué factor disminuiría la precisión?

32
00:01:37,745 --> 00:01:40,350
Un aumento en los falsos positivos.

33
00:01:40,800 --> 00:01:42,625
En nuestro ejemplo de estacionamientos

34
00:01:42,625 --> 00:01:44,350
mientras más espacios considere

35
00:01:44,350 --> 00:01:47,655
disponibles el modelo
sin estarlo, menor es la precisión.

36
00:01:49,475 --> 00:01:52,970
La recuperación tiene
una relación inversa con la precisión.

37
00:01:52,970 --> 00:01:57,850
Con una alta recuperación, puedo
encontrar muchos espacios disponibles.

38
00:01:57,850 --> 00:02:02,675
Con una recuperación de 1.0 encontraría
los estacionamientos disponibles, 10 de 10

39
00:02:02,675 --> 00:02:06,690
pero también podría tener muchos espacios
que pensé que estaban disponible, pero no.

40
00:02:06,690 --> 00:02:09,230
Estos se llaman falsos positivos.

41
00:02:10,520 --> 00:02:13,535
¿Cuál fue la recuperación
de nuestro ejemplo de estacionamiento?

42
00:02:13,535 --> 00:02:16,245
Recuerden, teníamos
10 estacionamientos disponibles

43
00:02:16,245 --> 00:02:19,130
y nuestro modelo
identificó uno solo disponible.

44
00:02:21,080 --> 00:02:25,005
La respuesta es 1 de 10 o 0.1.

45
00:02:26,545 --> 00:02:29,610
Aquí se les presenta
un conjunto de imágenes.

46
00:02:29,610 --> 00:02:32,680
En las imágenes hay un gato o no lo hay.

47
00:02:32,680 --> 00:02:36,050
Tomen un momento
para identificar cuál es cuál.

48
00:02:40,140 --> 00:02:43,990
Con suerte, encontrarán todos
los gatos domésticos que se muestran aquí.

49
00:02:43,990 --> 00:02:46,340
Observen que el gato
oculto en el cuadrado rojo

50
00:02:46,340 --> 00:02:49,930
y el tigre no califican
como gatos para nuestros fines.

51
00:02:51,120 --> 00:02:54,030
Ahora, veamos cómo clasifica el modelo.

52
00:02:55,870 --> 00:02:58,320
Y este es el resultado del modelo.

53
00:02:58,730 --> 00:03:01,955
Comparemos los resultados
con lo que sabemos que es verdad.

54
00:03:04,005 --> 00:03:09,025
Tenemos nuestros puntos de datos
junto a las predicciones del modelo.

55
00:03:09,475 --> 00:03:11,440
En total, tenemos ocho ejemplos

56
00:03:11,440 --> 00:03:13,955
o instancias que le mostramos al modelo.

57
00:03:14,335 --> 00:03:17,190
¿Cuántas veces acertó el modelo?

58
00:03:19,960 --> 00:03:23,155
Predijo correctamente
tres de un total de ocho.

59
00:03:23,155 --> 00:03:26,885
Esto le da una exactitud de 0.375.

60
00:03:28,145 --> 00:03:32,075
¿Es la exactitud la mejor métrica
para describir el rendimiento del modelo?

61
00:03:32,635 --> 00:03:34,230
Antes de seguir avanzando

62
00:03:34,230 --> 00:03:36,650
analicemos un obstáculo común.

63
00:03:37,470 --> 00:03:40,065
Ahora repasaremos
nuestro ejemplo de gato y no gato

64
00:03:40,065 --> 00:03:42,215
¿cuál es la precisión del modelo?

65
00:03:42,645 --> 00:03:45,505
Las cinco imágenes
estaban en la clase positiva.

66
00:03:45,945 --> 00:03:48,705
¿Cuántos son gatos domésticos?

67
00:03:50,575 --> 00:03:54,370
Dos de cinco
o una tasa de precisión de 0.4.

68
00:03:54,370 --> 00:03:59,160
La recuperación es como alguien que
no quiere quedarse fuera de la decisión.

69
00:03:59,630 --> 00:04:02,900
Aquí pueden ver todos los ejemplos
correctamente etiquetados de gatos

70
00:04:02,900 --> 00:04:06,655
y el rendimiento del modelo
para ellos. ¿Cuál fue la recuperación?

71
00:04:06,655 --> 00:04:11,590
Dicho de otra forma, ¿cuántos
verdaderos positivos acertó el modelo?

72
00:04:13,620 --> 00:04:19,630
El modelo solo obtuvo 2 de 4 gatos
correctos para una recuperación de 0.5.

73
00:04:23,250 --> 00:04:27,255
Resumamos lo que aprendieron
sobre optimización hasta ahora.

74
00:04:28,045 --> 00:04:30,190
Primero, definimos modelos de AA

75
00:04:30,190 --> 00:04:32,460
como conjuntos
de parámetros e hiperparámetros

76
00:04:32,460 --> 00:04:36,725
y tratamos de enmarcar la optimización
como búsqueda en el espacio de parámetros.

77
00:04:37,375 --> 00:04:39,440
Luego, presentamos
las funciones de pérdida

78
00:04:39,440 --> 00:04:41,750
que es cómo medimos y evaluamos

79
00:04:41,750 --> 00:04:44,780
el rendimiento de nuestro
modelo en cada paso del entrenamiento.

80
00:04:45,180 --> 00:04:48,920
Dos ejemplos de funciones
de pérdidas que analizamos fueron RMSE

81
00:04:48,920 --> 00:04:52,750
para la regresión lineal y entropía
cruzada para la tarea de clasificación.

82
00:04:52,750 --> 00:04:55,710
Aprendimos cómo diversificar
nuestras superficies de pérdida

83
00:04:55,710 --> 00:04:58,665
con el análisis de pendientes
de nuestras funciones de pérdida

84
00:04:58,665 --> 00:05:01,450
que nos proporcionaron
la dirección y la magnitud del paso.

85
00:05:01,720 --> 00:05:04,435
Este proceso
se llama descenso de gradientes.

86
00:05:05,255 --> 00:05:09,265
Experimentamos con diferentes modelos
de AA en TensorFlow Playground y vimos

87
00:05:09,265 --> 00:05:11,100
y vimos cómo los modelos lineales

88
00:05:11,100 --> 00:05:14,710
pueden aprender relaciones no lineales
cuando se les asignan atributos no lineales

89
00:05:14,710 --> 00:05:18,175
y cómo las redes neuronales
aprenden las jerarquías de atributos

90
00:05:18,175 --> 00:05:20,440
También vimos cómo los hiperparámetros

91
00:05:20,440 --> 00:05:24,055
tasa de aprendizaje y tamaño del lote
influyen en el descenso de gradientes.

92
00:05:24,255 --> 00:05:27,985
Luego, hablamos sobre cómo elegir
entre exactitud, precisión y recuperación

93
00:05:27,985 --> 00:05:30,250
con el rendimiento
de un modelo de clasificación

94
00:05:30,250 --> 00:05:32,310
según el problema que intentan solucionar.

95
00:05:32,310 --> 00:05:34,330
Y como vimos en este módulo

96
00:05:34,330 --> 00:05:38,450
nuestro conjunto de datos etiquetados
es el motor donde aprende nuestro modelo.

97
00:05:38,450 --> 00:05:40,015
En el siguiente módulo

98
00:05:40,015 --> 00:05:44,310
cubriremos cómo dividir el conjunto
de datos en entrenamiento y evaluación

99
00:05:44,310 --> 00:05:47,000
y los obstáculos que debemos evitar.