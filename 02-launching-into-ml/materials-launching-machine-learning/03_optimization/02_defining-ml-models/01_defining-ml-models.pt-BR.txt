Este módulo tem quatro tópicos principais. Primeiro, daremos uma definição
funcional, mas formal, de modelo. Depois, como a otimização
sempre exige um padrão para mostrar as melhorias,
discutiremos as funções de perda. Veremos como o gradiente descendente é
parecido com achar a base de uma colina definido pela função de perda. Depois, praticaremos em um sandbox
onde você verá as superfícies de perda dos modelos decrescendo em tempo real. Por fim, mostraremos como
medir o desempenho de um modelo fora do contexto de treinamento. Vamos começar com uma revisão
do que é um modelo de ML e onde os parâmetros entram na equação. Modelos de ML são funções matemáticas
com parâmetros e hiperparâmetros. Parâmetro é uma variável com valor real
que muda durante o treinamento do modelo. Hiperparâmetro é uma configuração
que definimos antes do treinamento e nunca mais é alterada. Como falamos no módulo anterior, os modelos lineares foram um dos
primeiros tipos de modelo de ML. Eles ainda são uma classe de modelos
importante e muito usada hoje em dia. No modelo linear, mudanças pequenas
nas variáveis independentes, ou características, como são chamadas
no aprendizado de máquina, produzem a mesma quantidade de alterações
na variável dependente ou no rótulo, não importando onde a mudança
ocorre no espaço de entrada. Visualmente, é semelhante a
uma linha em um espaço bidimensional. A fórmula usada para modelar o
relacionamento é y = mx + b, em que m representa a quantidade de
alterações observadas no rótulo como consequência de uma mudança
pequena na característica. O mesmo conceito de relacionamento definido
por mudança de proporção fixa entre rótulos e características pode ser aplicado
à dimensionalidade arbitrariamente alta com relação às entradas e saídas. Ou seja, podemos criar modelos que
aceitam mais características como entrada, modelar vários rótulos
simultaneamente ou fazer ambos Quando aumentamos a
dimensionalidade da entrada, o termo de inclinação m precisa
se tornar n-dimensional. Chamamos esse termo novo de peso. Visualmente, esse processo gera a
generalização n-dimensional de uma linha chamada hiperplano,
retratado no lado direito. Não entrarei em detalhes, mas
quando aumentamos a dimensionalidade das saídas, os termos y e c precisam 
se tornar vetores bidimensionais. O termo b, seja como escalar ou
vetor, é chamado de termo de tendência. Fazer uma regressão usando um
modelo linear é de certo modo intuitivo. Basta usar a fórmula b + m * x
para resultar na previsão y. Mas como fazer uma classificação
usando um modelo linear? Como interpretar um número
contínuo como uma classe? Para transformar a saída numérica
do modelo em uma classe, primeiro precisamos saber como
codificar a associação à classe. O modo mais simples de codificar uma
associação à classe é com um valor binário: você é um membro ou não. É claro que, muitas vezes, as variáveis
categóricas podem ter mais de dois valores. Porém, essa abordagem ainda funciona. Basta fingir que cada valor está
em uma classe própria independente. Vamos nos concentrar em
uma única classe binária por enquanto. Voltaremos à representação de
características no terceiro curso. Após adotar essa representação do
rótulo, gerenciar a tarefa será mais fácil. Agora precisamos aprender como mapear a linha
em uma regra de classificação binária. Um jeito fácil de fazer isso é
se basear nos indícios da saída. Graficamente, é como
dividir o gráfico em duas regiões, os pontos acima e os pontos abaixo da linha. Chamamos essa linha de limite de decisão porque ela reflete a decisão de
onde as classes começam e terminam. Fundamentalmente, o limite de decisão não serve apenas
como uma descrição dos dados atuais. Ele também serve para
prever os dados não vistos. A propriedade de se estender a exemplos
não vistos é chamada de generalização e é essencial para modelos de ML. Falaremos mais sobre
generalização no próximo módulo. Aprender sobre ML de maneira
abstrata pode ser um pouco chato. Então, vamos falar sobre um problema
importante que é um candidato para o ML e depois vamos discutir como estruturá-lo.