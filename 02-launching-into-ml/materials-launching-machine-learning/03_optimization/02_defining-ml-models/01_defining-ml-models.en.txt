There are five main topics in this module. First, we'll create a working, but
formal definition of what a model is. Then because optimization
always requires a standard by which to say we're improving,
we'll discuss loss functions. Then we'll show how gradient descent is
like trying to find the bottom of a hill defined by the loss function. Next, we'll play around in a sandbox
where you can see models descending loss surfaces in real time. Lastly, we'll discuss how to
measure a model's performance outside the context of training. Let's start with reviewing
exactly what an ML model is and where parameters fit into the equation. ML models are mathematical functions
with parameters and hyper-parameters. A parameter is a real-valued variable
that changes during model training. A hyper-parameter is a setting
that we set before training and which doesn't change afterwards. As we talked about in the last module, linear models were one of
the first sorts of ML models. They remain an important and
widely used class of models today though. In a linear model, small changes
in the independent variables, or features as we refer to
them in machine learning, yield the same amount of change in
the dependent variable or label. Regardless of where that change
takes place in the input space. Visually, this looks
like a line in 2D space. And the formula used to model
the relationship is simply y = mx + b. Where m captures the amount of change
we've observed in our label in response to a small change in our feature. This same concept of a relationship
defined by a fixed ratio change between labels and features can be extended
to arbitrarily high dimensionality, both with respect to the inputs and
the outputs. Meaning, we can build models that
accept many more features as input, model multiple labels simultaneously,
or both. When we increase the dimensionality
of the input, our slope term m, must become n-dimensional. We call this new term the weight. Visually, this process yields the
n-dimensional generalization of a line, which is called a hyperplane, which
I've depicted on the right-hand side. I won't go into detail here but
when we increase the dimensionality of the outputs, our y and c terms must
become vectors of dimensionality and two. The b term, whether as a scalar or
a vector, is referred to as the bias term. How a linear model can be used for
regression should be somewhat intuitive. You simply use the formula b plus m
times x to get your prediction y. But how can a linear model be used for
classification? How do you take a continuous number and
interpret it as a class? In order to take our model's numerical
output and turn it into a class, we need to first think about how
class membership can be encoded. The simplest way to encode class
membership is with a binary. Either you're a member, or you're not. Of course in many cases categorical
variables can take more than two values. This approach still works though. Just pretend that each value
is its own independent class. For now though,
let's stick with a single binary class. We'll return to the topic of feature
representation in course three. Once you adopt this representation of
the label, the task is more manageable. Now we need a way to map our line
onto a binary classification rule. One easy way to do this is to simply
rely on the sign of the output. Graphically, that looks like
dividing our graph into two regions, the points above the line and
the points below it. We call this line the decision boundary, because it reflects our decision about
where the classes begin and end. And critically, the decision boundary is intended not just
to be descriptive of the current data. It's intended to be
predictive of unseen data. This property of extending to unseen
examples is called generalization, and it's essential to ML models. We will talk more about
generalization in the next module. Learning about ML in the in
the abstract can be rather dry though. So let's talk about an important
problem that is a candidate for ML, and then talk about how you would frame it.