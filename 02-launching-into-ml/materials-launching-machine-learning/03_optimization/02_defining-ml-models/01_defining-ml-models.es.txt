En este módulo,
hay cinco temas importantes. Primero, crearemos una definición
funcional, pero formal, de un modelo. Luego, como la optimización
siempre requiere de un estándar para ver mejoras, hablaremos
sobre las funciones de pérdida. Veremos que el descenso
de gradientes es como tratar de llegar al pie de la colina
según la función de pérdida. En la zona de pruebas
verán cómo los modelos descienden superficies
de pérdida en tiempo real. Por último, veremos cómo
medir el rendimiento de un modelo fuera del contexto del entrenamiento. Comencemos
por revisar qué es un modelo de AA y dónde encajan
los parámetros en la ecuación. Los modelos de AA
son funciones matemáticas con parámetros e hiperparámetros. Un parámetro es una variable de valor
real que cambia durante el entrenamiento. Un hiperparámetro es una configuración
que se establece antes del entrenamiento y que no cambia después. Como mencionamos en el módulo anterior los modelos lineales fueron algunos
de los primeros tipos de modelos de AA. Hoy, siguen siendo una clase
de modelos importante y muy usada. En un modelo lineal, pequeños
cambios en las variables independientes o atributos, como decimos en el AA producen los mismos cambios
en la variable dependiente o etiqueta. Sin importar dónde se produzca ese cambio
en el espacio de entrada. Visualmente, se parece
a una línea en un espacio 2D. La fórmula para modelar
la relación es y = mx + b. Donde “m” captura la cantidad
de cambios observados en nuestra etiqueta en respuesta
a un pequeño cambio en el atributo. Este mismo concepto de una relación
definida por un cambio de proporción fija entre etiquetas y atributos
se puede extender a una dimensionalidad alta y arbitraria con relación
a las entradas y las salidas. Significa que podemos crear modelos
que acepten más atributos como entrada,
modelar varias etiquetas a la vez o ambos. Si aumentamos la dimensionalidad
de la entrada el término “m” de la pendiente
debe convertirse en n-dimensional. A este nuevo término
lo llamamos peso. Visualmente, este proceso
produce la generalización n-dimensional de una línea, llamada hiperplano,
representada en el lado derecho. No entraré en detalles, pero
cuando aumentamos la dimensionalidad de las salidas, “y” y “c” deben
convertirse en vectores dimensionales n2. El término “b”, ya sea escalar o vector,
se denomina la ordenada al origen. La forma de usar un modelo lineal
para la regresión debería ser intuitiva. Solo deben usar la fórmula “b + m * x”
para obtener la predicción “y”. Pero ¿cómo se puede usar
un modelo lineal para la clasificación? ¿Cómo pueden tomar un número
continuo e interpretarlo como una clase? Para hacer que la salida numérica
de nuestro modelo sea una clase primero hay que pensar cómo
codificar la pertenencia de clases. La forma más sencilla de hacerlo
es con una clasificación binaria. Es un miembro o no lo es. A veces, las variables categóricas
pueden aceptar más de dos valores. Aun así, este enfoque funciona. Supongan que cada valor
es su propia clase independiente. Por ahora, quedémonos
con una sola clase binaria. Regresaremos a la representación
de atributos en el tercer curso. Una vez que adopten
esta representación de la etiqueta la tarea será más fácil. Ahora, tenemos que asignar nuestra línea
a una regla de clasificación binaria. Una forma sencilla de hacerlo
es depender de la señal de la salida Gráficamente, es como dividir
nuestro gráfico en dos regiones los puntos sobre la línea
y los que están debajo de ella. Esta línea es el límite de decisión
porque refleja nuestra decisión sobre dónde comienzan
y terminan las clases. Lo que es muy importante este límite no se diseñó solo para ser
una descripción de los datos actuales. La idea es que sea
predictivo de los datos no conocidos. Esta propiedad de ampliar a ejemplos
no conocidos se llama generalización y es vital para los modelos de AA. Profundizaremos sobre la generalización
en el siguiente módulo. Aprender sobre el AA
solo en teoría puede ser difícil. Así que, veamos un problema
importante que es candidato para el AA y analicemos cómo lo enfocarían.