Before we go into one of the first ways that researchers have addressed this problem, let's put some of the things we've learned together. Let's put ourselves into the shoes of our model, and look at how loss might change over time during training. Imagine that we're performing gradient descent, and updating our model's parameters with respect to the derivative of the loss function, and we've configured things that we can see how our loss is changing over time. This is a common scenario in machine learning, particularly when model training comprises hours, or possibly even days. You can imagine how important it is not to waste days of time. So with that in mind, let's troubleshoot a loss curve. Here is a common loss curve shape. The loss drops off rapidly with our big steps down the gradient, and then smooths out over time with smaller steps as it reaches a minima on the loss surface. What if you see a loss curve like this one? Assume for a moment that the scale of the loss axis is large. What does this tell you about your model, and the way your search is going on the loss surface? What it means is that our search is jumping all around, and not as we'd like making steady progress toward a particular minima. What about this one? This one means we are probably still in the same valley, but it will take a very, very long time to reach the bottom. In both these cases though, the stepsize wasn't correct for the particular problem. In the first case, the step size was too big, in the second it was too small. What we need then is a scaling parameter. In the literature, this is referred to as the learning rate, and with its introduction into our code we now have classic gradient descent. Note how I've changed the line where we did our for loop updating the parameter values. You can imagine using brute force to figure out the best value for learning rate. But recall that learning rate is likely to have a problem specific best value. Because it is said before learning begins, learning the rate is a hyperparameter. And to determine the best value for hyperparameters, there is a better method available and it's called hyperparameter tuning. We'll review how to do this in Cloud ML Engine in a later module. Generally though, learning rate is a fraction significantly less than one. For now, simply remember this formulation of gradient descent, and that learning rate is a hyperparameter that is fixed during training.