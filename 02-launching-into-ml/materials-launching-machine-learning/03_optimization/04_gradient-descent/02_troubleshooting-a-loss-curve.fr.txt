Avant d'examiner l'une
des premières méthodes utilisées par les chercheurs
pour traiter ce problème, faisons le point sur ce que
nous avons appris ensemble. Mettons-nous à la place de notre modèle, et voyons comment la perte peut évoluer
au fil du temps pendant l'entraînement. Imaginez que nous procédons
à une descente de gradient et que nous mettons à jour
les paramètres de notre modèle par rapport à la dérivée
de la fonction de perte, ceci après avoir tout configuré
de manière à voir comment la perte évolue au fil du temps. Il s'agit d'un scénario courant
en machine learning, surtout lorsque l'entraînement
de modèle dure des heures, et parfois même des jours. Vous pouvez imaginer à quel point il est
important de ne pas gaspiller du temps. Gardons cela à l'esprit pour résoudre
les problèmes d'une courbe de perte. En voici une de forme classique. La perte baisse rapidement
avec nos grands pas le long du gradient, puis la courbe s'aplanit au fil du temps
avec des pas plus petits lorsqu'elle atteint une valeur minimale
sur la surface de perte. Si vous voyez une courbe de perte
de ce type, qu'en déduisez-vous ? Supposons pour le moment que l'échelle
de l'axe des pertes est grande. Qu'en déduisez-vous sur le modèle et sur la façon dont la recherche se déroule
sur la surface de perte ? Cela signifie que notre recherche bondit
dans toutes les directions, et ne progresse pas de façon constante
vers un minimum donné. Et que diriez-vous de cette courbe ? Celle-ci signifie que nous sommes
probablement toujours dans le même creux, mais qu'il nous faudra énormément
de temps pour atteindre le minimum. Dans ces deux cas toutefois, le pas d'apprentissage ne convient pas
au problème à traiter. Il est trop grand dans le premier cas,
et trop petit dans le second. Nous avons donc besoin
d'un paramètre de scaling. Dans la littérature, le terme utilisé
est "taux d'apprentissage". Avec ce paramètre dans notre code, nous avons maintenant
une descente de gradient classique. J'ai donc modifié la ligne de la boucle For
de mise à jour des paramètres. On peut envisager
d'avoir recours à la force brute pour déterminer la meilleure valeur
du taux d'apprentissage. Mais rappelez-vous que la meilleure valeur
de ce taux est souvent propre au problème. Comme il est fixé avant que
l'apprentissage ne commence, ce taux est un hyperparamètre. Pour déterminer la meilleure valeur
des hyperparamètres, il existe une méthode plus appropriée
appelée "réglage d'hyperparamètres". Nous verrons dans un prochain module
comment l'utiliser dans Cloud ML Engine. Toutefois, le taux d'apprentissage est
généralement une fraction d'une valeur nettement inférieure à 1. Retenez simplement cette formulation
de la descente de gradient, et le fait que le taux d'apprentissage
est un hyperparamètre.