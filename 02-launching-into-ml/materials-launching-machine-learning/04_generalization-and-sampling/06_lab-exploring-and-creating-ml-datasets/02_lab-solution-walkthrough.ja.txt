一般化とサンプリングを学習するモジュールの
最後のラボです かなり総合的なものです すべての手順を行うのに
時間がかかっても それは完全に想定内です ではソリューションのウォークスルーを
見ていきましょう まだ試していない人は ぜひDatalabのノートブック、
IPythonノートブックを入手してください そしてコードを実行してから このソリューションのウォークスルー動画に
戻ってきてください 引き続きご覧になる皆さんは こちらを見ていきましょう Google Cloudのタクシーの見積もりの
ノートブックを取り出しました まずやりたいのはデータの調査です 3つのステップを思い出してください データを調査して データセットを作成します 皆さん ハッシュ関数の扱いには
十分慣れたでしょう このステップでトレーニング用、
評価用、テスト用のデータセットを作ります そして最後にまだご覧になっていないのが ベンチマークの作成方法です 今後 機械学習の習得を深めていくなかで
このシンプルなベンチマークモデルを基準にして それを上回るモデルを作れるように
高度な技術を学んでいきます たとえば ディープニューラルネットワークを
TensorFlowで構築する方法などです その前にまず ゼロから順に始めていきましょう では最初にすべきことは
データサンプルの取得です BigQueryの優れた点は
一般公開データセットが多いことです フライトデータや タクシーのデータもあります ではニューヨークのタクシー料金のデータを
取得しましょう この一般公開データセット内にあります ここで見たいフィールドは何でしょう これはフィーチャーエンジニアリングですね どのデータを調べて
最終的にモデルに取り込むか考えます タクシー料金の予測の問題について考えるとき どんなデータを見るべきでしょうか？ おそらくこうでしょう タクシーに乗った時刻、
乗車地点と降車地点の正確な緯度と経度 乗客の人数 当然ですが さまざまな料金体系や 乗車人数に応じた料金の
階層構造があるでしょう 乗車距離はどれくらいか ニューヨーク橋を越えれば
通行料金がかかります 運賃に加え チップや他の経費があり 合計金額が決まります ではこれらの要因のどれが最終的に タクシーの料金を決定するのか
見ていきましょう 実際の作業に
取りかかるのはその後です 最初にやるべきことはデータの取得です Cloud Datalabのデータを取得するために
BigQueryのクエリを呼び出します これはBigQueryのサンプルから
取ったきたものです ニューヨークのタクシーのデータを
取得しました 先ほど説明したフィールドを
すべて取り出します ここではデータのごく一部を
見ていきます 最後のラボでフライトデータの
1%のサンプルを使ったのと同じです データの小さなサブセットのみを使います これが最初のクエリです 使いたいのは...そうですね 10万件のタクシー乗車レコードがありますから 1万件のタクシー乗車を抽出できるか
見てみましょう いいですね SQLクエリをパラメータ化します このパラメータ化は文字列の置換と
同じように行います クエリは rawdataクエリです
上で rawdataと指定したからです すべてのnを置換します
これでレコードを抽出できます nごとにサンプリングするわけです 対象の合計サイズは10万レコードです 最終的にこのクエリを出力して実行します これが実行されたクエリです これに対してサンプリングしています
この演算の余りは1です これでタクシー乗車が1万件に減りました サンプリングをもう一度やりたかった理由は
最初の1,000件を取得したくなかったからです ソート済みの可能性もありますし そうなるとデータにバイアスがかかります タクシーのデータで言えば 最近の乗車が最初に来るように
ソートされている可能性があります そのため 最新の3,000件のデータを
確認した場合 結果に偏りが生じる可能性があります 最近導入された変更や運賃の値上げ、
値下げがあるかもしれません データを一目見ただけではわかりません これを新近性バイアスと呼んでいます 有効なサンプリングを行うと
結果はこうなります まだ何も処理していない
データセットから返ってきたフィールドです では 実際に調べていきます 乗車人数があります 1から5などですね 乗車距離があります 面白いですね　距離が0です これが移動距離のマイル数なら 変ですね 通行料金が0 これは想定内です 運賃が$2.50で合計$2.50です わかりました 面白いデータです もう少しすばやく調査できるか
やってみましょう 一番いい方法はデータを可視化することです 機械学習ではしばしば
散布図を作成して点を調べます ここでは移動距離と運賃をプロット化しました こう思うかもしれません 「移動距離が長いほど
メーター料金が上がるだろう」 長い距離を見てみましょう ここには距離40もあります 全般的に運賃も高くなり
$100になっていますね しかしおかしな点があります データにいくつか異常がありますね 極端に短い移動が山ほどあります ほとんど0の移動もあります この直線上にあるからです これはおかしいですね
データセットから取り除く必要があります なんで移動しなかったのか
わかりません 乗ってすぐ追い出されたのでしょうか この線上の 0の点を見ましょう それからこの点を見ましょう この直線は斜めに上がっています 線のように見えますが 実は大量の点が線状に集まっているのです これはデータの性質によるものです 実は ニューヨークでは JFK空港から
定額料金でマンハッタンのどこにでも行けます この定額料金は
距離に基づいて決まります 事前にわかるので
この関係は簡単にモデル化できます ただの直線になりますね しかし JFKから来る人だけでなく ニューヨーク市内のどこに移動する人でも
予測したいです 面白いですね ではデータを前処理してきれいにする方法を
確認しましょう それからトレーニング用、評価用、テスト用に
データセットをバケット化します いきなりデータセットを分割しないで まずデータをきれいにします ガベージイン ガベージアウトですから ひどいデータを分割すれば
ひどい結果になります ひどいモデルの結果では 現実世界の動作を
モデル化することはできません 確かな経験則は「データはすべて汚い」です きれいにして適切な形にしてから
モデルに入れます モデルに必要なのは
高品質データのみです では乗車データを見ましょう 橋を渡ったデータを見ましょう 通行料が 0より大きいです それから乗車時刻として
特定の日付を見ましょう この場合は2014年5月20日です このデータの興味深い点は 経度0で乗車したり 緯度0で乗車しています これは明らかに間違っているか
汚いデータです これは除外します
有効な乗車場所ではありません 最終的につじつまの合うデータセットにして 変なレコードがないようにします ここでもう1つ気付くかもしれません 合計金額で 列のどこにも チップがいくらなのか
わかる部分がありません チップの現金の額も記録されていません モデルの目的として チップの額は自由に決められ 確認できないので
運賃には含まれていません そのため チップは予測しません そこで 運賃を
新しい合計金額として設定します この運賃は移動距離に対する料金と
通行料の合計です この例では運賃の8.5は 移動距離に対する$2.22と それに橋を渡ったので $5.33の合計です この2つを足したのが
新しい合計金額です チップは無視します さて .describeという面白い関数があります これは見ている列のデータの境界や範囲を示します 統計で非常に役立ちます では各列の 最小値と最大値を見てみましょう わかりやすい例として
乗車の緯度や経度を見ましょう 最大値が0のもの
最小値が0のものがありますね こうしたおかしな点を見つけていきます すぐ分かるものとして タクシーの運賃の最小値が
マイナス10になっています マイナスの運賃はありえません タクシーに乗って移動するお客に
お金を払う人はいませんね 乗る人がお金を払います 乗客数の最大値を確認しましょう ここでは6です ただし最大乗客数が12だったりすると
タクシー車両ではなくバスになります バスはこのデータに含まれていません このように少しずつ データセットをきれいにしましょう これが前処理という作業です 最終的に3つのバケットに
分割できるようにします そこから シンプルなベンチマークを
作成して 基準とします さてようやくデータを理解しました このプロセスは数週間もかかることがあります 慣れていない場合や
データセットの内容の専門家ではない場合 列が何百もある場合 レコードが何十億もある場合は データ内容をよく知っている専門家に
相談してください データ内に存在する関係を十分理解して 可視化し さまざまな可視化や統計関数を使ってから 機械学習の領域に進みます データ内で何が起こっているのか
根本的に理解する必要があります ここでは データの調査に
5分しか時間がかかっていませんが 現実にはデータセットの理解に数週間
数か月かかることがあります では乗車データを1つずつ見ていきましょう これはプロット化したものです
すごくいいですね 移動を確認できます
緯度と経度があります これは移動の線です これを見てください
長い線は通常 通行料金を含みます 直感的につじつまが合いますね 橋を渡るから距離が長くなるのです 橋の始点でタクシーに乗って 橋が終わるとすぐに下りる人はいないでしょう これは役立つ洞察です このすべてのデータを
クリーンアップしましょう これまで説明した情報が5つあります ニューヨーク市の経度と緯度は マイナス 74から41の
範囲内になります 乗客が0はありえません 超えてはならない人数は
議論の余地がありますが 基本的に乗客0人はありません それからチップについて説明したように 合計金額は運賃と通行料金のみになるように
再計算しました 次に 乗車と降車の場所はわかっています ただし移動距離はわかりません これは多くの人が
機械学習モデルの トレーニングデータセットを
作成する際にはまる落し穴です わからないデータというものがあります 本番でわからないものはトレーニングできません たとえば
こんなふうに言うことはできません 「移動距離は5.5マイルだった
1マイルあたり$1だから すごく単純なモデルだと
最終的にこの移動は$5.50になる」 しかし 新しいデータでは
どうなるでしょう タクシーを呼びました 料金を予測するにはモデルに
移動距離を教えなければなりません しかしまだタクシーには乗っていません まだ起こっていない未来を
知ろうとしているのです だから未来の日付は使えません 将来起こることでは
データをトレーニングできません だからこれを外します フィーチャーデータセットからも外します これはとても重要なポイントです 存在するデータのことを考えてください 本番でモデルを実行するときに存在するデータです BigQueryクエリのたくさんのWHERE節の
フィルタがここにあります 運賃の fare_amountを再計算します ここに別の列があります 別名を使って名前を変更しています この関数を作成しています この関数は
パラメータ化されたクエリが これらの特定の範囲の間で
サンプル化することを示します これが少し前に説明した
すべてのフィルターです これはモジュロ演算子で
FARM_FINGERPRINTハッシュ関数の形をしています 乗車日時である pickup_datetimeをハッシュしています ここで重要なのは 何かをハッシュした場合
それは予測に使えなくなるということです pickup_date timeに別れを告げて この列を
バケットの境界を作成するのに使います トレーニング、評価、テストです つまり ここで言っているのは 乗車日時では運賃の金額を予測できない
ということです パラメータ化できるクエリを作成しました 次の質問は トレーニングで このクエリを3回ループしたら
どうなるかということです 3つのデータセットを作る必要がありましたね トレーニング用、評価用、テスト用です トレーニングには
データの70%が必要です 0から70の間のサブサンプルです ご覧のようにsample_betweenは
先ほど作ったクエリaとbです これはこのaとbに挿入されています これは ここにある
モジュロ演算子で機能します トレーニング用には70% 評価用には70と85の間
これはデータセットの15%です テスト用には85から100で
15%のデータを使用します 実行する準備ができました 実行するクエリはこうなります 次に行うのは 保存する出力の指定です CSVファイルなど 最終的に
機械学習モデルが参照できる形にして トレーニング用、評価用、テスト用の
データにアクセスできるようにします そのためにはCSVを作成する機能が
必要です このケースでは
ローカルでトレーニングしています つまり Datalab内で
これらのCSVを保存して作成します 今後のモジュールで
Cloud Machine Learning Engineに慣れたら 他のスケーラブルな場所を使いますが 今は プロトタイピング段階なので すべてCloud Datalab内でローカルに行います ただデータの参照はBigQueryから直接行えます そしてGoogle Cloud Storageから直接ですね
Google Cloud Storageバケットです ではこれが作成中のCSVです これで運賃を削除して
CSV内で新しい運賃に更新します これが追加しているすべてのフィーチャーです これはすべて上のクエリに含まれています それから重要なループです トレーニング、評価、テストの各段階で このクエリを10万のサンプルに対して呼び出し BigQueryのクエリを実行します データフレームの結果を返し
反復して処理できます これらの結果を使い このデータフレームを「taxi-」という
接頭辞で保存します これがデータセットの名前になります taxi-trainやtaxi-validation taxi-testなどの名前で
CSV内に保存されます 何が起こっているのかここで確認できます 信じてもいいですが 検証はしてください これらのデータセットが実際に存在するのか
確認する必要があります そこで ファイルに
lsコマンドを実行します テスト用データセットは
5万8,000件のタクシー乗車 トレーニング用は40万件 評価用は10万件です これは上の分割を反映しています 70-15-15です ここで興味深いのはテスト用と
評価用のデータ件数が異っていることです これはデータの分布が原因です 正規分布していない可能性があります 固まっている多数のデータがある場合 2018年1月1日のような
特定の1日でハッシュすると 同じ結果が返されます データに十分なノイズがありません 70-15-15で分割するように指定しても
まとめてハッシュされます 元旦にタクシー乗車が多かった場合
これはすべて同じバケットに入ります 同じ日付は同じ数値にハッシュされるので
2つの場所に分割することはできません では分割を確認しましょう すべてのデータが
3つのバケットに分かれたので いよいよモデルを作成しましょう 私はダミーモデルと呼びます これがベンチマークです タクシー料金について
単純な推測をする場合 天候は考慮していません 空港から来るかどうかも考慮していません こういったより複雑なフィーチャーや直感は
もっと高度なモデルに組み込むことができます これは後でTensorFlowや フィーチャーエンジニアリングで
学びます ここでは単純なモデルを作成します これは 後で作成する高度なモデルの
RMSEや損失の指標を評価するための ベンチマークとなるモデルです では この単純なモデルを
作っていきましょう まず移動距離を予測する必要があります 単純なモデルでこれを予測します それから運賃の合計を取得して
距離で割ります それから料金を使います 1マイルあたりや1キロあたりなどです そしてすでに回答 つまり運賃がわかっている
ラベル付きトレーニングデータに基づいて データの損失の指標を計算します それからこれは線形モデルなので
RMSEを使います 浮動です 実際にやってみます いいですね 関数をいくつか定義して 緯度と経度の差
つまり乗車と降車の間の距離を取得します これら2つの間の距離を推測して
タクシーが実際に走ったマイル数を取得します この情報はトレーニングでわかっていますが 予測をしているので
この列は使えません これをもう一度予測します そしてRMSEをここにある等式で計算します それを出力して フィーチャーを解析してモデル化します ターゲットの予測を行います 予測するのは運賃です フィーチャーをリストして 最後に トレーニング、評価、テスト用の
データフレーム これらのデータセットが存在する
場所を定義します それからトレーニングを行います とても単純なモデルをトレーニングします 平均の運賃を推測するモデルです 計算する料金は金額の平均です だから$10のタクシー料金を
距離の平均で割ったものです 28行目は モデル化が実際に行われていることを
実際に確認できる唯一の場所です 私たちは15〜20分かけて
このラボを行ってきましたが 28行目が予測やモデル化を行っている
唯一の場所です つまり長い時間をかけてデータセットを作成し
クリーニングと前処理を行ったのです CSVファイルを設定して
モデルが取り込めるようにして 最後にこれを今後のモデルのパフォーマンスを
測定するベンチマークにしたのです この99%の作業は データの調査、クリーンアップ、
データセットの作成、 ベンチマークの設定で
実際のモデル化は1%です この割合は今後変化します さらにモデル化を行ったり
より洗練されたモデルの作成方法や フィーチャーエンジニアリングの方法を学ぶときにです 今回のモデルはベンチマークです これが実際に取得する1キロあたりの料金です タクシーの1キロあたりの料金が
$2.60です このRMSEを見てください トレーニングの損失の指標は7.45で
評価が9.35です テストを行ったときが最も良く
5.44でした これがベンチマークです このモデルでは タクシーの運賃は
どこに行っても1キロあたり2.61になります 道の混み具合や マンハッタンのどこに行くかや 橋の通行料金は考慮しません 橋を渡るかどうかのパラメータは
ここにはありません 時刻も考慮しません 運賃にはさまざまな要因があり 単純に 2.6ｘキロ数で予測できないのはわかりますよね こうした直感はもっと洗練されたモデルに
組み込みます 高度な考察を組み込んだ
より優れたモデルを作成すれば 5.44に勝てるはずです これが目標となるベンチマークのRMSEです 最終的なRMSEの5.44 x 実際の料金... ここで9... 違いますね すみません このデータセットでは5.44です 皆さんの結果は少し違うかもしれません じゃあ以上ですね 
ラボを終わりましょう 皆さんには専門分野のコースを継続して
受講することをおすすめします ここで終わりではありません 皆さんはデータをきれいにし
取得して調整し ベンチマークモデルを構築する方法を
学びました より洗練されたモデルとプログラムを
構築する準備ができたのです モデルからより洗練された洞察を得て
今回のRMSEを上回ることができます TensorFlowの今後のコースも
ぜひチェックしてください そして目標のRMSEを達成してください このラボは3回まで試せます ぜひ繰り返して タクシーのDatalabノートブックで
コードを編集してください ではまたお会いしましょう
お疲れさまでした