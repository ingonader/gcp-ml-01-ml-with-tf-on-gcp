1
00:00:00,000 --> 00:00:05,230
一般化とサンプリングを学習するモジュールの
最後のラボです

2
00:00:05,230 --> 00:00:07,110
かなり総合的なものです

3
00:00:07,110 --> 00:00:09,320
すべての手順を行うのに
時間がかかっても

4
00:00:09,320 --> 00:00:11,680
それは完全に想定内です

5
00:00:11,680 --> 00:00:13,805
ではソリューションのウォークスルーを
見ていきましょう

6
00:00:13,805 --> 00:00:15,255
まだ試していない人は

7
00:00:15,255 --> 00:00:19,135
ぜひDatalabのノートブック、
IPythonノートブックを入手してください

8
00:00:19,135 --> 00:00:21,425
そしてコードを実行してから

9
00:00:21,425 --> 00:00:23,890
このソリューションのウォークスルー動画に
戻ってきてください

10
00:00:23,890 --> 00:00:25,925
引き続きご覧になる皆さんは

11
00:00:25,925 --> 00:00:27,770
こちらを見ていきましょう

12
00:00:27,770 --> 00:00:33,440
Google Cloudのタクシーの見積もりの
ノートブックを取り出しました

13
00:00:33,440 --> 00:00:36,140
まずやりたいのはデータの調査です

14
00:00:36,140 --> 00:00:37,980
3つのステップを思い出してください

15
00:00:37,980 --> 00:00:39,535
データを調査して

16
00:00:39,535 --> 00:00:41,650
データセットを作成します

17
00:00:41,650 --> 00:00:44,895
皆さん ハッシュ関数の扱いには
十分慣れたでしょう

18
00:00:44,895 --> 00:00:50,490
このステップでトレーニング用、
評価用、テスト用のデータセットを作ります

19
00:00:50,490 --> 00:00:52,890
そして最後にまだご覧になっていないのが

20
00:00:52,890 --> 00:00:55,065
ベンチマークの作成方法です

21
00:00:55,065 --> 00:01:00,460
今後 機械学習の習得を深めていくなかで
このシンプルなベンチマークモデルを基準にして

22
00:01:00,460 --> 00:01:03,020
それを上回るモデルを作れるように
高度な技術を学んでいきます

23
00:01:03,020 --> 00:01:05,675
たとえば ディープニューラルネットワークを
TensorFlowで構築する方法などです

24
00:01:05,675 --> 00:01:07,030
その前にまず

25
00:01:07,030 --> 00:01:10,425
ゼロから順に始めていきましょう

26
00:01:10,425 --> 00:01:15,115
では最初にすべきことは
データサンプルの取得です

27
00:01:15,115 --> 00:01:18,805
BigQueryの優れた点は
一般公開データセットが多いことです

28
00:01:18,805 --> 00:01:20,625
フライトデータや

29
00:01:20,625 --> 00:01:23,420
タクシーのデータもあります

30
00:01:23,420 --> 00:01:28,665
ではニューヨークのタクシー料金のデータを
取得しましょう

31
00:01:28,665 --> 00:01:30,910
この一般公開データセット内にあります

32
00:01:30,910 --> 00:01:33,320
ここで見たいフィールドは何でしょう

33
00:01:33,320 --> 00:01:35,510
これはフィーチャーエンジニアリングですね

34
00:01:35,510 --> 00:01:38,650
どのデータを調べて
最終的にモデルに取り込むか考えます

35
00:01:38,650 --> 00:01:42,440
タクシー料金の予測の問題について考えるとき

36
00:01:42,440 --> 00:01:44,665
どんなデータを見るべきでしょうか？

37
00:01:44,665 --> 00:01:46,250
おそらくこうでしょう

38
00:01:46,250 --> 00:01:52,255
タクシーに乗った時刻、
乗車地点と降車地点の正確な緯度と経度

39
00:01:52,255 --> 00:01:54,280
乗客の人数

40
00:01:54,280 --> 00:01:56,730
当然ですが さまざまな料金体系や

41
00:01:56,730 --> 00:01:59,625
乗車人数に応じた料金の
階層構造があるでしょう

42
00:01:59,625 --> 00:02:01,170
乗車距離はどれくらいか

43
00:02:01,170 --> 00:02:05,530
ニューヨーク橋を越えれば
通行料金がかかります

44
00:02:05,530 --> 00:02:08,699
運賃に加え チップや他の経費があり

45
00:02:08,699 --> 00:02:10,139
合計金額が決まります

46
00:02:10,139 --> 00:02:12,840
ではこれらの要因のどれが最終的に

47
00:02:12,840 --> 00:02:16,190
タクシーの料金を決定するのか
見ていきましょう

48
00:02:16,190 --> 00:02:18,850
実際の作業に
取りかかるのはその後です

49
00:02:18,850 --> 00:02:21,175
最初にやるべきことはデータの取得です

50
00:02:21,175 --> 00:02:25,260
Cloud Datalabのデータを取得するために
BigQueryのクエリを呼び出します

51
00:02:25,260 --> 00:02:28,335
これはBigQueryのサンプルから
取ったきたものです

52
00:02:28,335 --> 00:02:31,315
ニューヨークのタクシーのデータを
取得しました

53
00:02:31,315 --> 00:02:35,940
先ほど説明したフィールドを
すべて取り出します

54
00:02:35,940 --> 00:02:40,760
ここではデータのごく一部を
見ていきます

55
00:02:40,760 --> 00:02:47,320
最後のラボでフライトデータの
1%のサンプルを使ったのと同じです

56
00:02:47,320 --> 00:02:50,400
データの小さなサブセットのみを使います

57
00:02:50,400 --> 00:02:52,045
これが最初のクエリです

58
00:02:52,045 --> 00:02:55,250
使いたいのは...そうですね

59
00:02:55,250 --> 00:03:02,395
10万件のタクシー乗車レコードがありますから

60
00:03:02,395 --> 00:03:09,030
1万件のタクシー乗車を抽出できるか
見てみましょう

61
00:03:09,030 --> 00:03:10,215
いいですね

62
00:03:10,215 --> 00:03:13,995
SQLクエリをパラメータ化します

63
00:03:13,995 --> 00:03:17,505
このパラメータ化は文字列の置換と
同じように行います

64
00:03:17,505 --> 00:03:23,710
クエリは rawdataクエリです
上で rawdataと指定したからです

65
00:03:23,710 --> 00:03:27,835
すべてのnを置換します
これでレコードを抽出できます

66
00:03:27,835 --> 00:03:30,385
nごとにサンプリングするわけです

67
00:03:30,385 --> 00:03:34,290
対象の合計サイズは10万レコードです

68
00:03:34,290 --> 00:03:36,975
最終的にこのクエリを出力して実行します

69
00:03:36,975 --> 00:03:39,195
これが実行されたクエリです

70
00:03:39,195 --> 00:03:45,965
これに対してサンプリングしています
この演算の余りは1です

71
00:03:45,965 --> 00:03:49,305
これでタクシー乗車が1万件に減りました

72
00:03:49,305 --> 00:03:54,350
サンプリングをもう一度やりたかった理由は
最初の1,000件を取得したくなかったからです

73
00:03:54,350 --> 00:03:56,120
ソート済みの可能性もありますし

74
00:03:56,120 --> 00:03:58,050
そうなるとデータにバイアスがかかります

75
00:03:58,050 --> 00:04:00,800
タクシーのデータで言えば

76
00:04:00,800 --> 00:04:04,825
最近の乗車が最初に来るように
ソートされている可能性があります

77
00:04:04,825 --> 00:04:09,550
そのため 最新の3,000件のデータを
確認した場合

78
00:04:09,550 --> 00:04:12,330
結果に偏りが生じる可能性があります

79
00:04:12,330 --> 00:04:17,765
最近導入された変更や運賃の値上げ、
値下げがあるかもしれません

80
00:04:17,765 --> 00:04:20,105
データを一目見ただけではわかりません

81
00:04:20,105 --> 00:04:22,310
これを新近性バイアスと呼んでいます

82
00:04:22,310 --> 00:04:26,390
有効なサンプリングを行うと
結果はこうなります

83
00:04:26,390 --> 00:04:31,770
まだ何も処理していない
データセットから返ってきたフィールドです

84
00:04:31,770 --> 00:04:34,070
では 実際に調べていきます

85
00:04:34,070 --> 00:04:36,080
乗車人数があります

86
00:04:36,080 --> 00:04:38,425
1から5などですね

87
00:04:38,425 --> 00:04:40,040
乗車距離があります

88
00:04:40,040 --> 00:04:44,060
面白いですね　距離が0です

89
00:04:44,060 --> 00:04:46,800
これが移動距離のマイル数なら 変ですね

90
00:04:46,800 --> 00:04:48,995
通行料金が0 これは想定内です

91
00:04:48,995 --> 00:04:52,825
運賃が$2.50で合計$2.50です

92
00:04:52,825 --> 00:04:55,300
わかりました 面白いデータです

93
00:04:55,300 --> 00:04:57,815
もう少しすばやく調査できるか
やってみましょう

94
00:04:57,815 --> 00:05:01,470
一番いい方法はデータを可視化することです

95
00:05:01,470 --> 00:05:07,365
機械学習ではしばしば
散布図を作成して点を調べます

96
00:05:07,365 --> 00:05:11,120
ここでは移動距離と運賃をプロット化しました

97
00:05:11,120 --> 00:05:12,260
こう思うかもしれません

98
00:05:12,260 --> 00:05:15,955
「移動距離が長いほど
メーター料金が上がるだろう」

99
00:05:15,955 --> 00:05:19,215
長い距離を見てみましょう

100
00:05:19,215 --> 00:05:23,115
ここには距離40もあります

101
00:05:23,115 --> 00:05:25,830
全般的に運賃も高くなり
$100になっていますね

102
00:05:25,830 --> 00:05:27,890
しかしおかしな点があります

103
00:05:27,890 --> 00:05:30,665
データにいくつか異常がありますね

104
00:05:30,665 --> 00:05:33,455
極端に短い移動が山ほどあります

105
00:05:33,455 --> 00:05:35,040
ほとんど0の移動もあります

106
00:05:35,040 --> 00:05:36,185
この直線上にあるからです

107
00:05:36,185 --> 00:05:39,210
これはおかしいですね
データセットから取り除く必要があります

108
00:05:39,210 --> 00:05:41,195
なんで移動しなかったのか
わかりません

109
00:05:41,195 --> 00:05:43,195
乗ってすぐ追い出されたのでしょうか

110
00:05:43,195 --> 00:05:47,990
この線上の 0の点を見ましょう

111
00:05:47,990 --> 00:05:51,220
それからこの点を見ましょう

112
00:05:51,220 --> 00:05:56,285
この直線は斜めに上がっています

113
00:05:56,285 --> 00:05:58,205
線のように見えますが

114
00:05:58,205 --> 00:06:00,780
実は大量の点が線状に集まっているのです

115
00:06:00,780 --> 00:06:02,605
これはデータの性質によるものです

116
00:06:02,605 --> 00:06:10,370
実は ニューヨークでは JFK空港から
定額料金でマンハッタンのどこにでも行けます

117
00:06:10,370 --> 00:06:14,725
この定額料金は
距離に基づいて決まります

118
00:06:14,725 --> 00:06:17,930
事前にわかるので
この関係は簡単にモデル化できます

119
00:06:17,930 --> 00:06:20,160
ただの直線になりますね

120
00:06:20,160 --> 00:06:23,460
しかし JFKから来る人だけでなく

121
00:06:23,460 --> 00:06:26,285
ニューヨーク市内のどこに移動する人でも
予測したいです

122
00:06:26,285 --> 00:06:29,055
面白いですね

123
00:06:29,055 --> 00:06:32,240
ではデータを前処理してきれいにする方法を
確認しましょう

124
00:06:32,240 --> 00:06:37,940
それからトレーニング用、評価用、テスト用に
データセットをバケット化します

125
00:06:37,940 --> 00:06:40,320
いきなりデータセットを分割しないで

126
00:06:40,320 --> 00:06:42,620
まずデータをきれいにします

127
00:06:42,620 --> 00:06:43,830
ガベージイン ガベージアウトですから

128
00:06:43,830 --> 00:06:45,945
ひどいデータを分割すれば
ひどい結果になります

129
00:06:45,945 --> 00:06:47,125
ひどいモデルの結果では

130
00:06:47,125 --> 00:06:50,330
現実世界の動作を
モデル化することはできません

131
00:06:50,330 --> 00:06:53,035
確かな経験則は「データはすべて汚い」です

132
00:06:53,035 --> 00:06:56,540
きれいにして適切な形にしてから
モデルに入れます

133
00:06:56,540 --> 00:07:00,150
モデルに必要なのは
高品質データのみです

134
00:07:00,150 --> 00:07:02,860
では乗車データを見ましょう

135
00:07:02,860 --> 00:07:06,860
橋を渡ったデータを見ましょう

136
00:07:06,860 --> 00:07:09,260
通行料が 0より大きいです

137
00:07:09,260 --> 00:07:11,900
それから乗車時刻として
特定の日付を見ましょう

138
00:07:11,900 --> 00:07:14,780
この場合は2014年5月20日です

139
00:07:14,780 --> 00:07:17,590
このデータの興味深い点は

140
00:07:17,590 --> 00:07:19,280
経度0で乗車したり

141
00:07:19,280 --> 00:07:21,275
緯度0で乗車しています

142
00:07:21,275 --> 00:07:25,305
これは明らかに間違っているか
汚いデータです

143
00:07:25,305 --> 00:07:29,210
これは除外します
有効な乗車場所ではありません

144
00:07:29,210 --> 00:07:32,720
最終的につじつまの合うデータセットにして

145
00:07:32,720 --> 00:07:37,075
変なレコードがないようにします

146
00:07:37,075 --> 00:07:39,870
ここでもう1つ気付くかもしれません

147
00:07:39,870 --> 00:07:42,525
合計金額で 列のどこにも

148
00:07:42,525 --> 00:07:45,705
チップがいくらなのか
わかる部分がありません

149
00:07:45,705 --> 00:07:51,930
チップの現金の額も記録されていません

150
00:07:51,930 --> 00:07:53,605
モデルの目的として

151
00:07:53,605 --> 00:07:59,445
チップの額は自由に決められ 確認できないので
運賃には含まれていません

152
00:07:59,445 --> 00:08:01,025
そのため チップは予測しません

153
00:08:01,025 --> 00:08:04,550
そこで 運賃を
新しい合計金額として設定します

154
00:08:04,550 --> 00:08:11,160
この運賃は移動距離に対する料金と
通行料の合計です

155
00:08:11,525 --> 00:08:15,780
この例では運賃の8.5は

156
00:08:15,780 --> 00:08:20,055
移動距離に対する$2.22と

157
00:08:20,055 --> 00:08:24,490
それに橋を渡ったので $5.33の合計です

158
00:08:24,490 --> 00:08:28,950
この2つを足したのが
新しい合計金額です

159
00:08:28,950 --> 00:08:30,645
チップは無視します

160
00:08:31,105 --> 00:08:35,905
さて .describeという面白い関数があります

161
00:08:35,905 --> 00:08:41,749
これは見ている列のデータの境界や範囲を示します

162
00:08:41,749 --> 00:08:44,070
統計で非常に役立ちます

163
00:08:44,070 --> 00:08:47,530
では各列の 最小値と最大値を見てみましょう

164
00:08:47,530 --> 00:08:51,600
わかりやすい例として
乗車の緯度や経度を見ましょう

165
00:08:51,600 --> 00:08:55,090
最大値が0のもの
最小値が0のものがありますね

166
00:08:55,090 --> 00:08:57,525
こうしたおかしな点を見つけていきます

167
00:08:57,525 --> 00:08:59,725
すぐ分かるものとして

168
00:08:59,725 --> 00:09:03,740
タクシーの運賃の最小値が
マイナス10になっています

169
00:09:03,740 --> 00:09:07,130
マイナスの運賃はありえません

170
00:09:07,130 --> 00:09:09,500
タクシーに乗って移動するお客に
お金を払う人はいませんね

171
00:09:09,500 --> 00:09:11,245
乗る人がお金を払います

172
00:09:11,245 --> 00:09:16,465
乗客数の最大値を確認しましょう

173
00:09:16,465 --> 00:09:18,390
ここでは6です

174
00:09:18,390 --> 00:09:23,190
ただし最大乗客数が12だったりすると
タクシー車両ではなくバスになります

175
00:09:23,190 --> 00:09:25,990
バスはこのデータに含まれていません

176
00:09:25,990 --> 00:09:28,415
このように少しずつ

177
00:09:28,415 --> 00:09:30,700
データセットをきれいにしましょう

178
00:09:30,700 --> 00:09:33,610
これが前処理という作業です

179
00:09:33,610 --> 00:09:37,400
最終的に3つのバケットに
分割できるようにします

180
00:09:37,400 --> 00:09:41,910
そこから シンプルなベンチマークを
作成して 基準とします

181
00:09:41,910 --> 00:09:45,110
さてようやくデータを理解しました

182
00:09:45,110 --> 00:09:47,300
このプロセスは数週間もかかることがあります

183
00:09:47,300 --> 00:09:51,135
慣れていない場合や
データセットの内容の専門家ではない場合

184
00:09:51,135 --> 00:09:53,955
列が何百もある場合

185
00:09:53,955 --> 00:09:56,210
レコードが何十億もある場合は

186
00:09:56,210 --> 00:09:59,475
データ内容をよく知っている専門家に
相談してください

187
00:09:59,475 --> 00:10:02,250
データ内に存在する関係を十分理解して

188
00:10:02,250 --> 00:10:03,620
可視化し

189
00:10:03,620 --> 00:10:06,785
さまざまな可視化や統計関数を使ってから

190
00:10:06,785 --> 00:10:09,080
機械学習の領域に進みます

191
00:10:09,080 --> 00:10:11,775
データ内で何が起こっているのか
根本的に理解する必要があります

192
00:10:11,775 --> 00:10:15,715
ここでは データの調査に
5分しか時間がかかっていませんが

193
00:10:15,715 --> 00:10:19,125
現実にはデータセットの理解に数週間
数か月かかることがあります

194
00:10:19,125 --> 00:10:23,310
では乗車データを1つずつ見ていきましょう

195
00:10:23,310 --> 00:10:26,180
これはプロット化したものです
すごくいいですね

196
00:10:26,180 --> 00:10:30,480
移動を確認できます
緯度と経度があります

197
00:10:30,480 --> 00:10:32,295
これは移動の線です

198
00:10:32,295 --> 00:10:37,230
これを見てください
長い線は通常 通行料金を含みます

199
00:10:37,230 --> 00:10:39,580
直感的につじつまが合いますね

200
00:10:39,580 --> 00:10:42,005
橋を渡るから距離が長くなるのです

201
00:10:42,005 --> 00:10:44,660
橋の始点でタクシーに乗って

202
00:10:44,660 --> 00:10:49,365
橋が終わるとすぐに下りる人はいないでしょう

203
00:10:49,365 --> 00:10:51,490
これは役立つ洞察です

204
00:10:51,490 --> 00:10:55,020
このすべてのデータを
クリーンアップしましょう

205
00:10:55,020 --> 00:10:57,990
これまで説明した情報が5つあります

206
00:10:57,990 --> 00:11:00,770
ニューヨーク市の経度と緯度は

207
00:11:00,770 --> 00:11:04,410
マイナス 74から41の
範囲内になります

208
00:11:04,410 --> 00:11:06,545
乗客が0はありえません

209
00:11:06,545 --> 00:11:11,000
超えてはならない人数は
議論の余地がありますが

210
00:11:11,000 --> 00:11:13,820
基本的に乗客0人はありません

211
00:11:13,820 --> 00:11:16,310
それからチップについて説明したように

212
00:11:16,310 --> 00:11:22,530
合計金額は運賃と通行料金のみになるように
再計算しました

213
00:11:22,530 --> 00:11:24,545
次に

214
00:11:24,545 --> 00:11:27,450
乗車と降車の場所はわかっています

215
00:11:27,450 --> 00:11:29,750
ただし移動距離はわかりません

216
00:11:29,750 --> 00:11:33,300
これは多くの人が
機械学習モデルの

217
00:11:33,300 --> 00:11:37,160
トレーニングデータセットを
作成する際にはまる落し穴です

218
00:11:37,160 --> 00:11:39,080
わからないデータというものがあります

219
00:11:39,080 --> 00:11:41,465
本番でわからないものはトレーニングできません

220
00:11:41,465 --> 00:11:44,170
たとえば
こんなふうに言うことはできません

221
00:11:44,170 --> 00:11:49,680
「移動距離は5.5マイルだった
1マイルあたり$1だから

222
00:11:49,680 --> 00:11:55,510
すごく単純なモデルだと
最終的にこの移動は$5.50になる」

223
00:11:55,510 --> 00:11:58,140
しかし 新しいデータでは
どうなるでしょう

224
00:11:58,140 --> 00:12:00,620
タクシーを呼びました

225
00:12:00,620 --> 00:12:04,590
料金を予測するにはモデルに
移動距離を教えなければなりません

226
00:12:04,590 --> 00:12:06,700
しかしまだタクシーには乗っていません

227
00:12:06,700 --> 00:12:08,750
まだ起こっていない未来を
知ろうとしているのです

228
00:12:08,750 --> 00:12:10,220
だから未来の日付は使えません

229
00:12:10,220 --> 00:12:12,420
将来起こることでは
データをトレーニングできません

230
00:12:12,420 --> 00:12:14,340
だからこれを外します

231
00:12:14,340 --> 00:12:16,465
フィーチャーデータセットからも外します

232
00:12:16,465 --> 00:12:17,930
これはとても重要なポイントです

233
00:12:17,930 --> 00:12:20,150
存在するデータのことを考えてください

234
00:12:20,150 --> 00:12:23,445
本番でモデルを実行するときに存在するデータです

235
00:12:23,445 --> 00:12:28,830
BigQueryクエリのたくさんのWHERE節の
フィルタがここにあります

236
00:12:28,830 --> 00:12:30,720
運賃の fare_amountを再計算します

237
00:12:30,720 --> 00:12:32,970
ここに別の列があります

238
00:12:32,970 --> 00:12:34,980
別名を使って名前を変更しています

239
00:12:34,980 --> 00:12:37,435
この関数を作成しています

240
00:12:37,435 --> 00:12:41,297
この関数は
パラメータ化されたクエリが

241
00:12:41,297 --> 00:12:44,500
これらの特定の範囲の間で
サンプル化することを示します

242
00:12:44,500 --> 00:12:47,890
これが少し前に説明した
すべてのフィルターです

243
00:12:47,890 --> 00:12:52,390
これはモジュロ演算子で
FARM_FINGERPRINTハッシュ関数の形をしています

244
00:12:52,390 --> 00:12:55,695
乗車日時である pickup_datetimeをハッシュしています

245
00:12:55,695 --> 00:12:56,880
ここで重要なのは

246
00:12:56,880 --> 00:13:00,700
何かをハッシュした場合
それは予測に使えなくなるということです

247
00:13:00,700 --> 00:13:02,815
pickup_date timeに別れを告げて

248
00:13:02,815 --> 00:13:07,780
この列を
バケットの境界を作成するのに使います

249
00:13:07,780 --> 00:13:10,520
トレーニング、評価、テストです

250
00:13:10,520 --> 00:13:12,790
つまり ここで言っているのは

251
00:13:12,790 --> 00:13:21,125
乗車日時では運賃の金額を予測できない
ということです

252
00:13:21,125 --> 00:13:24,930
パラメータ化できるクエリを作成しました

253
00:13:24,930 --> 00:13:26,520
次の質問は

254
00:13:26,520 --> 00:13:32,490
トレーニングで このクエリを3回ループしたら
どうなるかということです

255
00:13:32,490 --> 00:13:34,180
3つのデータセットを作る必要がありましたね

256
00:13:34,180 --> 00:13:36,030
トレーニング用、評価用、テスト用です

257
00:13:36,030 --> 00:13:39,745
トレーニングには
データの70%が必要です

258
00:13:39,745 --> 00:13:42,195
0から70の間のサブサンプルです

259
00:13:42,195 --> 00:13:46,750
ご覧のようにsample_betweenは
先ほど作ったクエリaとbです

260
00:13:46,750 --> 00:13:50,365
これはこのaとbに挿入されています

261
00:13:50,365 --> 00:13:56,640
これは ここにある
モジュロ演算子で機能します

262
00:13:56,640 --> 00:14:00,000
トレーニング用には70%

263
00:14:00,000 --> 00:14:07,350
評価用には70と85の間
これはデータセットの15%です

264
00:14:07,350 --> 00:14:13,595
テスト用には85から100で
15%のデータを使用します

265
00:14:13,595 --> 00:14:16,000
実行する準備ができました

266
00:14:16,000 --> 00:14:19,500
実行するクエリはこうなります

267
00:14:21,280 --> 00:14:23,240
次に行うのは

268
00:14:23,240 --> 00:14:26,340
保存する出力の指定です

269
00:14:26,340 --> 00:14:32,000
CSVファイルなど 最終的に
機械学習モデルが参照できる形にして

270
00:14:32,000 --> 00:14:35,080
トレーニング用、評価用、テスト用の
データにアクセスできるようにします

271
00:14:35,080 --> 00:14:38,570
そのためにはCSVを作成する機能が
必要です

272
00:14:38,570 --> 00:14:41,870
このケースでは
ローカルでトレーニングしています

273
00:14:41,870 --> 00:14:45,035
つまり Datalab内で
これらのCSVを保存して作成します

274
00:14:45,035 --> 00:14:48,345
今後のモジュールで
Cloud Machine Learning Engineに慣れたら

275
00:14:48,345 --> 00:14:51,030
他のスケーラブルな場所を使いますが

276
00:14:51,030 --> 00:14:54,340
今は プロトタイピング段階なので

277
00:14:54,340 --> 00:14:57,145
すべてCloud Datalab内でローカルに行います

278
00:14:57,145 --> 00:15:02,015
ただデータの参照はBigQueryから直接行えます

279
00:15:02,015 --> 00:15:07,695
そしてGoogle Cloud Storageから直接ですね
Google Cloud Storageバケットです

280
00:15:07,695 --> 00:15:10,080
ではこれが作成中のCSVです

281
00:15:10,080 --> 00:15:14,415
これで運賃を削除して
CSV内で新しい運賃に更新します

282
00:15:14,415 --> 00:15:16,650
これが追加しているすべてのフィーチャーです

283
00:15:16,650 --> 00:15:21,745
これはすべて上のクエリに含まれています

284
00:15:21,745 --> 00:15:23,745
それから重要なループです

285
00:15:23,745 --> 00:15:27,230
トレーニング、評価、テストの各段階で

286
00:15:27,230 --> 00:15:33,015
このクエリを10万のサンプルに対して呼び出し

287
00:15:33,015 --> 00:15:35,705
BigQueryのクエリを実行します

288
00:15:35,705 --> 00:15:39,770
データフレームの結果を返し
反復して処理できます

289
00:15:39,770 --> 00:15:42,225
これらの結果を使い

290
00:15:42,225 --> 00:15:48,760
このデータフレームを「taxi-」という
接頭辞で保存します

291
00:15:48,760 --> 00:15:51,060
これがデータセットの名前になります

292
00:15:51,060 --> 00:15:53,890
taxi-trainやtaxi-validation

293
00:15:53,890 --> 00:15:58,010
taxi-testなどの名前で
CSV内に保存されます

294
00:15:58,010 --> 00:16:00,910
何が起こっているのかここで確認できます

295
00:16:00,910 --> 00:16:03,340
信じてもいいですが 検証はしてください

296
00:16:03,340 --> 00:16:06,340
これらのデータセットが実際に存在するのか
確認する必要があります

297
00:16:06,340 --> 00:16:08,780
そこで ファイルに
lsコマンドを実行します

298
00:16:08,780 --> 00:16:15,550
テスト用データセットは
5万8,000件のタクシー乗車

299
00:16:15,550 --> 00:16:18,890
トレーニング用は40万件

300
00:16:18,890 --> 00:16:21,390
評価用は10万件です

301
00:16:21,390 --> 00:16:26,155
これは上の分割を反映しています

302
00:16:26,155 --> 00:16:29,420
70-15-15です

303
00:16:29,420 --> 00:16:35,600
ここで興味深いのはテスト用と
評価用のデータ件数が異っていることです

304
00:16:35,600 --> 00:16:39,000
これはデータの分布が原因です

305
00:16:39,000 --> 00:16:41,000
正規分布していない可能性があります

306
00:16:41,000 --> 00:16:43,280
固まっている多数のデータがある場合

307
00:16:43,280 --> 00:16:46,500
2018年1月1日のような
特定の1日でハッシュすると

308
00:16:46,500 --> 00:16:49,330
同じ結果が返されます

309
00:16:49,330 --> 00:16:50,945
データに十分なノイズがありません

310
00:16:50,945 --> 00:16:57,200
70-15-15で分割するように指定しても
まとめてハッシュされます

311
00:16:57,200 --> 00:17:04,755
元旦にタクシー乗車が多かった場合
これはすべて同じバケットに入ります

312
00:17:04,755 --> 00:17:13,445
同じ日付は同じ数値にハッシュされるので
2つの場所に分割することはできません

313
00:17:13,445 --> 00:17:18,650
では分割を確認しましょう

314
00:17:18,650 --> 00:17:26,305
すべてのデータが
3つのバケットに分かれたので

315
00:17:26,305 --> 00:17:30,030
いよいよモデルを作成しましょう

316
00:17:30,030 --> 00:17:31,570
私はダミーモデルと呼びます

317
00:17:31,570 --> 00:17:32,955
これがベンチマークです

318
00:17:32,955 --> 00:17:38,880
タクシー料金について
単純な推測をする場合

319
00:17:38,880 --> 00:17:41,430
天候は考慮していません

320
00:17:41,430 --> 00:17:44,595
空港から来るかどうかも考慮していません

321
00:17:44,595 --> 00:17:49,630
こういったより複雑なフィーチャーや直感は
もっと高度なモデルに組み込むことができます

322
00:17:49,630 --> 00:17:52,210
これは後でTensorFlowや

323
00:17:52,210 --> 00:17:54,035
フィーチャーエンジニアリングで
学びます

324
00:17:54,035 --> 00:17:56,600
ここでは単純なモデルを作成します

325
00:17:56,600 --> 00:18:02,530
これは 後で作成する高度なモデルの
RMSEや損失の指標を評価するための

326
00:18:02,530 --> 00:18:05,840
ベンチマークとなるモデルです

327
00:18:05,840 --> 00:18:09,410
では この単純なモデルを
作っていきましょう

328
00:18:09,410 --> 00:18:13,310
まず移動距離を予測する必要があります

329
00:18:13,310 --> 00:18:14,910
単純なモデルでこれを予測します

330
00:18:14,910 --> 00:18:19,360
それから運賃の合計を取得して
距離で割ります

331
00:18:19,360 --> 00:18:20,935
それから料金を使います

332
00:18:20,935 --> 00:18:23,350
1マイルあたりや1キロあたりなどです

333
00:18:23,350 --> 00:18:31,935
そしてすでに回答 つまり運賃がわかっている
ラベル付きトレーニングデータに基づいて

334
00:18:31,935 --> 00:18:35,740
データの損失の指標を計算します

335
00:18:35,740 --> 00:18:39,580
それからこれは線形モデルなので
RMSEを使います 浮動です

336
00:18:39,580 --> 00:18:42,670
実際にやってみます いいですね

337
00:18:42,670 --> 00:18:45,560
関数をいくつか定義して

338
00:18:45,560 --> 00:18:49,975
緯度と経度の差
つまり乗車と降車の間の距離を取得します

339
00:18:49,975 --> 00:18:58,975
これら2つの間の距離を推測して
タクシーが実際に走ったマイル数を取得します

340
00:18:58,975 --> 00:19:02,140
この情報はトレーニングでわかっていますが

341
00:19:02,140 --> 00:19:04,790
予測をしているので
この列は使えません

342
00:19:04,790 --> 00:19:06,040
これをもう一度予測します

343
00:19:06,040 --> 00:19:11,000
そしてRMSEをここにある等式で計算します

344
00:19:11,000 --> 00:19:12,960
それを出力して

345
00:19:12,960 --> 00:19:14,890
フィーチャーを解析してモデル化します

346
00:19:14,890 --> 00:19:16,950
ターゲットの予測を行います

347
00:19:16,950 --> 00:19:18,795
予測するのは運賃です

348
00:19:18,795 --> 00:19:20,615
フィーチャーをリストして

349
00:19:20,615 --> 00:19:22,130
最後に

350
00:19:22,130 --> 00:19:26,940
トレーニング、評価、テスト用の
データフレーム

351
00:19:26,940 --> 00:19:28,770
これらのデータセットが存在する
場所を定義します

352
00:19:28,770 --> 00:19:31,800
それからトレーニングを行います

353
00:19:31,800 --> 00:19:33,905
とても単純なモデルをトレーニングします

354
00:19:33,905 --> 00:19:41,300
平均の運賃を推測するモデルです

355
00:19:41,300 --> 00:19:46,050
計算する料金は金額の平均です

356
00:19:46,050 --> 00:19:50,295
だから$10のタクシー料金を
距離の平均で割ったものです

357
00:19:50,295 --> 00:19:52,740
28行目は

358
00:19:52,740 --> 00:19:57,680
モデル化が実際に行われていることを
実際に確認できる唯一の場所です

359
00:19:57,680 --> 00:20:00,650
私たちは15〜20分かけて
このラボを行ってきましたが

360
00:20:00,650 --> 00:20:04,605
28行目が予測やモデル化を行っている
唯一の場所です

361
00:20:04,605 --> 00:20:11,410
つまり長い時間をかけてデータセットを作成し
クリーニングと前処理を行ったのです

362
00:20:11,410 --> 00:20:15,905
CSVファイルを設定して
モデルが取り込めるようにして

363
00:20:15,905 --> 00:20:19,995
最後にこれを今後のモデルのパフォーマンスを
測定するベンチマークにしたのです

364
00:20:19,995 --> 00:20:23,525
この99%の作業は

365
00:20:23,525 --> 00:20:27,000
データの調査、クリーンアップ、
データセットの作成、

366
00:20:27,000 --> 00:20:30,235
ベンチマークの設定で
実際のモデル化は1%です

367
00:20:30,235 --> 00:20:32,720
この割合は今後変化します

368
00:20:32,720 --> 00:20:35,710
さらにモデル化を行ったり
より洗練されたモデルの作成方法や

369
00:20:35,710 --> 00:20:38,045
フィーチャーエンジニアリングの方法を学ぶときにです

370
00:20:38,045 --> 00:20:40,395
今回のモデルはベンチマークです

371
00:20:40,395 --> 00:20:44,730
これが実際に取得する1キロあたりの料金です

372
00:20:44,730 --> 00:20:52,230
タクシーの1キロあたりの料金が
$2.60です

373
00:20:52,230 --> 00:20:54,665
このRMSEを見てください

374
00:20:54,665 --> 00:21:02,585
トレーニングの損失の指標は7.45で
評価が9.35です

375
00:21:02,585 --> 00:21:09,740
テストを行ったときが最も良く
5.44でした

376
00:21:09,740 --> 00:21:12,920
これがベンチマークです

377
00:21:12,920 --> 00:21:21,890
このモデルでは タクシーの運賃は
どこに行っても1キロあたり2.61になります

378
00:21:21,890 --> 00:21:23,795
道の混み具合や

379
00:21:23,795 --> 00:21:26,050
マンハッタンのどこに行くかや

380
00:21:26,050 --> 00:21:27,760
橋の通行料金は考慮しません

381
00:21:27,760 --> 00:21:31,200
橋を渡るかどうかのパラメータは
ここにはありません

382
00:21:31,200 --> 00:21:33,085
時刻も考慮しません

383
00:21:33,085 --> 00:21:35,720
運賃にはさまざまな要因があり

384
00:21:35,720 --> 00:21:38,845
単純に 2.6ｘキロ数で予測できないのはわかりますよね

385
00:21:38,845 --> 00:21:41,920
こうした直感はもっと洗練されたモデルに
組み込みます

386
00:21:41,920 --> 00:21:49,060
高度な考察を組み込んだ
より優れたモデルを作成すれば

387
00:21:49,060 --> 00:21:53,880
5.44に勝てるはずです

388
00:21:53,880 --> 00:21:58,690
これが目標となるベンチマークのRMSEです

389
00:21:59,630 --> 00:22:04,780
最終的なRMSEの5.44 x 実際の料金...

390
00:22:04,780 --> 00:22:07,540
ここで9...

391
00:22:07,540 --> 00:22:09,070
違いますね

392
00:22:09,070 --> 00:22:11,520
すみません

393
00:22:11,520 --> 00:22:14,330
このデータセットでは5.44です

394
00:22:14,330 --> 00:22:17,105
皆さんの結果は少し違うかもしれません

395
00:22:17,105 --> 00:22:20,175
じゃあ以上ですね 
ラボを終わりましょう

396
00:22:20,175 --> 00:22:25,425
皆さんには専門分野のコースを継続して
受講することをおすすめします

397
00:22:25,425 --> 00:22:27,675
ここで終わりではありません

398
00:22:27,675 --> 00:22:30,635
皆さんはデータをきれいにし
取得して調整し

399
00:22:30,635 --> 00:22:33,300
ベンチマークモデルを構築する方法を
学びました

400
00:22:33,300 --> 00:22:40,590
より洗練されたモデルとプログラムを
構築する準備ができたのです

401
00:22:40,590 --> 00:22:45,015
モデルからより洗練された洞察を得て
今回のRMSEを上回ることができます

402
00:22:45,015 --> 00:22:48,860
TensorFlowの今後のコースも
ぜひチェックしてください

403
00:22:48,860 --> 00:22:52,500
そして目標のRMSEを達成してください

404
00:22:52,500 --> 00:22:53,960
このラボは3回まで試せます

405
00:22:53,960 --> 00:22:55,560
ぜひ繰り返して

406
00:22:55,560 --> 00:22:58,040
タクシーのDatalabノートブックで
コードを編集してください

407
00:22:58,040 --> 00:23:00,000
ではまたお会いしましょう
お疲れさまでした