In this lab, you'll explore the impact of different ways of creating machine learning data sets. Repeatability is important in machine learning. Imagine you started making changes in your model, like to your parameters and hyperparameters. And meanwhile, the underlying data on subsequent training runs is also changing. You'll be unable to tell whether or not your model is performing better, based on the actual performance of the models performing better, or the snapshot of data that it used for that one training run, was easier because the data is changing. By keeping the data constant as we change the model, you can tweak and tune your model, and then run it again, on the exact same experimentation data set. In this lab, you'll practice how to create, split, and hold these data sets constant. So, give it a go. Now, the solutions to all of these labs are in the code repository in GitHub. This is all open source, and you'll have access to the repository even after you finish this course. And we highly encourages you, as I like to say, "Good artists copy, great artists steal." So, feel free to use this code as a starting point for any of your future ML projects. All right. Give that lab a try and then come back for the solution walk through.