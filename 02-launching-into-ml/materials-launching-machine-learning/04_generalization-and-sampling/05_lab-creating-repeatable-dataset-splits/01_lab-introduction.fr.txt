Dans cet atelier,
vous allez découvrir l'impact de différentes façons de créer
des ensembles de données de ML. La reproductibilité est importante en ML. Imaginez que vous modifiez votre modèle, comme vos paramètres et hyperparamètres. Les données des entraînements
suivants changent aussi. Vous ne pouvez pas dire
si votre modèle est plus performant, en fonction des performances
des modèles plus performants, ou si l'instantané de données
utilisé pour cet entraînement était plus facile,
car les données changent. En utilisant les mêmes données
alors que le modèle change, vous pouvez ajuster votre modèle, puis l'exécuter à nouveau, avec le même ensemble de test. Dans cet atelier,
vous allez apprendre à créer et diviser des ensembles,
et à garantir leur constance. Essayez par vous-même. Les solutions des ateliers se trouvent
dans le dépôt du code dans GitHub. Tout est en Open Source, et vous aurez accès à ce dépôt
même après la fin du cours. Nous vous encourageons vivement,
comme j'aime à le dire, les bons artistes copient,
les grands volent. N'hésitez donc pas à utiliser ce code comme point de départ
de vos futurs projets de ML. Essayez cet atelier,
et revenez pour la solution.