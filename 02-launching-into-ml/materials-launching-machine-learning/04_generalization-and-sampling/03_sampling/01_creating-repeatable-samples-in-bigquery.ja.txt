データセットを分割することで 現実世界をシミュレーションした
データセットでモデルをテストできます そのために トレーニングには使わない
データのサブセットを分けておきます では 元のデータセットは
どこで分割したらよいでしょうか？ データセット自体が巨大だったら？ すべてのデータポイントで
トレーニングとテストが必要でしょうか？ このサンプリングのレッスンでは Google BigQueryによる
繰り返し可能なデータセットの分割方法と 避けるべき重要な落し穴を説明します そして 次のラボで実際に練習します では始めましょう データセットの分割を説明する前に 分割するデータが必要です この例では アメリカ交通統計局による
航空会社の定時運航率を使います Googleではこの一般公開データを BigQueryのすべてのユーザーに提供しています
airlineontimedata.flightsdatasetです このデータセットは
フライトの到着と出発の遅延などを 7,000万のフライトについて追跡しています このデータセットから トレーニング、評価、テスト用のデータを
サンプリングする方法を見つけましょう 統一された繰り返し可能な方法が必要です 構造化照会言語であるSQLと
SQLを実行する BigQueryは Rand関数を持っています これは 0と1の間の値を生成します データの80%を取得するのに
単純なSQLを適用できます ご覧のとおりWHERE節です これには明らかに問題があることに
気付くかもしれません この処理は繰り返し可能でしょうか あなたが使ったのと同じ80%の
トレーニング用データセットで 同僚が同じ実験をしたいとしたらどうでしょう さらにこれは 7,000万ものフライトの
データセットです 同僚の使用する5600万のフライト
つまり80%は あなたがトレーニングに使った80%のデータと
同じになるでしょうか？ もっとよい方法が必要ですね どのデータが トレーニング用、評価用、テスト用の
バケットに属しているのか確認すべきです そうすれば自分と同僚が実験を繰り返すときに 各バケットで同じデータを使うことができます さて お気づきの方もいるでしょう シンプルなランダム関数では 5つのランダムに選択された行のセットを クエリを実行するたびに取得します この方法では 残り20%のデータを特定して 評価用とテスト用のバケットに分割するのは
ほぼ不可能なほど困難です さらに データセットはソートされる場合もあり サンプルが偏る可能性があります order byを追加しても ミニバッチ勾配降下法などを行った場合に
問題が生じます 機械学習では基本的に 繰り返し可能なサンプルデータを
作成できる必要があります そのために フィールドのハッシュ関数の
最後の数桁を利用して データを分割またはバケット化します BigQueryで一般公開されている
ハッシュ関数は FARM_FINGERPRINTといいますが
普通のハッシュ関数です FARM_FINGERPRINTは
2018年12月10日のような値を 桁数の大きな文字列に変えます このハッシュ値は データセットの他のすべての
2018年12月10日で同一です さて 機械学習アルゴリズムを構築して
到着時刻の遅れを推測するとします データを日付で分割して トレーニング用データセットに
日数の約80%を取得します これは繰り返し可能です FARM_FINGERPRINTハッシュ関数が 同じ日付では常に同じ値を返すからです いつも全く同じか ほぼ同じ80%の
データを取得できます データを到着空港で分割する場合 空港の80%が
トレーニング用データセットで 残りがテスト用と評価用になります その場合 ハッシュ関数を到着空港に使います ここでクエリを見てください 評価用に新しい10%のサンプルを
取得するにはどうしたらよいでしょう？ テスト用データでは「8未満」から
「8に等しい」に変更します あるいは 残り10%の評価用、テスト用に
「8に等しい」「9に等しい」に変更します こうやってバケットを分割します フライトの遅延を予測する基準として 航空会社、時刻、天候、滑走路の数などの
空港の特徴を使用するとします どのフィールドでデータセットを
分割したらよいでしょう？ 日付？空港？航空会社名？ データを有効なセットに分割する際は
失ってもよい列を使用してください たとえば日付を分割して
到着時刻の遅れを予測しようとしています データセットは2日間のフライトだけです この場合50-50よりも
細かく分割することはできません ハッシュ関数は一方向なので
1つの値しか得られません 日付が2つしかなければ
80-20にすることはできません これらのオプションを1つずつ確認しましょう 日付に基づいて バケット化あるいはハッシュ分割したら
どうでしょう？ 問題ないですね ただ これにより クリスマスなどの休日に基づいた予測は
できなくなりました 日付に基づいてバケットを作成したので 予測の主要因は
日付と無関係なものにしなければなりません 空港名でハッシュ分割したら
どうでしょうか？ 分散されていて
ノイズのあるデータなら問題ありません ただし 空港に関する予測はできなくなります たとえば JFKの午後5時のフライトは
いつも遅れます 空港の JFKはもう使えません
それに基づいて分割したからです 航空会社名でハッシュして分割する場合は
どうでしょうか？ 航空会社は11社しかないので 十分な粒度の分割を行えるほど
分散されていません そこで80-20の代わりに 60-40などにしますが
それでも十分ではないかもしれません MLの開発を始めるとき 一番いいのはTensorFlowのコードを
小さいデータのサブセットで開発することです 製品化する際にはクラウドに
スケールアウトします MLアプリケーションを開発しているとしましょう 変更するたびにアプリケーションを
再実行する必要があります 完全なデータセットを使っていると 数時間や数日かかることがあります ペタバイトのデータを扱っていては
ソフトウェア開発はできません 小さなデータセットを使えば
コードをすばやく実行して デバックし 再実行できます そして アプリケーションがきちんと動いたら 完全なデータセットで好きなだけ
実行できます プロトタイピングに似ていますね では先ほどのフライトデータセットを
小さいサブセットに 均一にサンプリングする方法を見てみましょう バケットを作成しましたが 今度はデータを減らします フライトのデータは7,000万行です もっと小さなデータセットにしましょう 100万件のフライトにします
繰り返し可能でなければなりません フライト70件につき1件を取得し さらにその80%をトレーニング用にするには
どうすればよいでしょうか 70件中1件取得して その結果から
10件中1件を取得することはできません なぜかわかりますか？ 70で割り切れる数は
10でも割り切れるからです 2番目のモジュロ演算は ご覧のとおり役に立ちません では簡単なデモを行い
どういうことなのかお見せしましょう