1
00:00:00,580 --> 00:00:01,729
Como acaban de aprender

2
00:00:01,729 --> 00:00:04,025
dividir sus datos
les permite probar su modelo

3
00:00:04,025 --> 00:00:06,545
con el conjunto de datos
de simulación del mundo real

4
00:00:06,545 --> 00:00:09,680
mediante la exclusión
de esos subconjuntos del entrenamiento.

5
00:00:09,680 --> 00:00:13,250
Pero ¿cómo sabemos en realidad
en qué parte dividir el conjunto original?

6
00:00:13,250 --> 00:00:16,115
¿Y si el conjunto de datos es gigantesco?

7
00:00:16,115 --> 00:00:19,265
¿Necesitamos entrenar y probar
en cada uno de los puntos de datos?

8
00:00:19,265 --> 00:00:23,060
En esta lección sobre muestreo,
los guiaré en la división de los datos

9
00:00:23,060 --> 00:00:25,885
de una forma repetible
mediante Google BigQuery

10
00:00:25,885 --> 00:00:28,945
y les mostraré los obstáculos
qué deben evitar.

11
00:00:28,945 --> 00:00:31,675
Luego, lo practicarán
en el siguiente lab.

12
00:00:32,705 --> 00:00:34,035
Comencemos.

13
00:00:35,145 --> 00:00:38,200
Antes de hablar sobre la división
de un conjuntos de datos

14
00:00:38,200 --> 00:00:39,815
necesitamos uno
que podamos dividir.

15
00:00:39,815 --> 00:00:42,315
Para este ejemplo, usaremos
los datos de rendimiento

16
00:00:42,315 --> 00:00:46,730
de Airline Ontime de la Oficina
de Transporte y Estadísticas de los EE.UU.

17
00:00:46,730 --> 00:00:50,145
Google puso este conjunto de datos
público a disposición de los usuarios

18
00:00:50,145 --> 00:00:53,950
en BigQuery, como
airlineontimedata.flightsdataset.

19
00:00:53,950 --> 00:00:57,715
Este conjunto de datos
hizo el seguimiento de los retrasos

20
00:00:57,715 --> 00:01:01,320
en las llegadas y las salidas
de 70 millones de vuelos.

21
00:01:01,320 --> 00:01:05,855
Hablemos de cómo hacer el muestreo
para el entrenamiento, validación y prueba

22
00:01:05,855 --> 00:01:10,225
a partir de este conjunto de datos,
de forma eficaz, uniforme y repetible.

23
00:01:10,225 --> 00:01:13,960
SQL, es decir lenguaje estructurado
de consultas y, por lo tanto, en BigQuery

24
00:01:13,960 --> 00:01:17,215
porque ahí es donde se ejecuta SQL,
tiene la función RAND

25
00:01:17,215 --> 00:01:20,595
que generará un valor entre cero y uno.

26
00:01:20,595 --> 00:01:23,780
Pueden obtener
el 80% de sus datos con facilidad

27
00:01:23,780 --> 00:01:26,810
mediante una simple consulta WHERE de SQL,
como se muestra aquí.

28
00:01:26,810 --> 00:01:29,170
Verán algunos problemas obvios con esto.

29
00:01:29,170 --> 00:01:31,540
Piensen si este proceso sería repetible

30
00:01:31,540 --> 00:01:33,720
si un colega
quisiera repetir el experimento

31
00:01:33,720 --> 00:01:37,105
con el mismo 80% de los datos
que usaron en el entrenamiento.

32
00:01:37,105 --> 00:01:39,625
Suponiendo que el conjunto
es de 70 millones de vuelos

33
00:01:39,625 --> 00:01:42,900
¿obtendrían los mismos 56 millones
de vuelos o el 80%

34
00:01:42,900 --> 00:01:46,150
en el mismo conjunto de datos
de entrenamiento que ustedes?

35
00:01:46,150 --> 00:01:49,770
Necesitamos una mejor forma
de saber qué datos pertenecen

36
00:01:49,770 --> 00:01:53,205
a qué grupo: entrenamiento,
validación y prueba.

37
00:01:53,205 --> 00:01:57,170
Y esto nos permitirá
repetir los experimentos

38
00:01:57,170 --> 00:02:00,220
con los mismos datos de cada grupo.

39
00:02:00,490 --> 00:02:02,950
Como habrán adivinado,
una función aleatoria simple

40
00:02:02,950 --> 00:02:05,075
capturaría un nuevo conjunto de filas

41
00:02:05,075 --> 00:02:07,620
seleccionadas de forma aleatoria
como se muestra aquí

42
00:02:07,620 --> 00:02:09,340
cada vez que se ejecute la consulta.

43
00:02:09,340 --> 00:02:12,630
Esto hace que sea muy difícil,
casi imposible identificar y dividir

44
00:02:12,630 --> 00:02:16,140
el restante 20% de los datos
para los grupos de validación y prueba.

45
00:02:16,600 --> 00:02:18,945
Además,
el conjunto también se puede ordenar

46
00:02:18,945 --> 00:02:21,005
lo que puede agregar sesgo a su muestra.

47
00:02:21,005 --> 00:02:23,750
Solo agregar un ORDER BY
tiene sus propios problemas

48
00:02:23,750 --> 00:02:26,955
cuando se hace algo como
un descenso de gradientes en minilote.

49
00:02:27,975 --> 00:02:31,930
En el aprendizaje automático,
debe ser posible crear muestras

50
00:02:31,930 --> 00:02:33,445
de datos que sean repetibles.

51
00:02:34,225 --> 00:02:36,790
Una forma de hacerlo,
es usar los últimos dígitos

52
00:02:36,790 --> 00:02:39,440
de una función Hash
en el campo que están usando

53
00:02:39,440 --> 00:02:41,475
para dividir o agrupar los datos.

54
00:02:41,475 --> 00:02:44,620
Una de esas funciones Hash disponible
para el público en BigQuery

55
00:02:44,620 --> 00:02:46,735
es FARM_FINGERPRINT,
una simple función Hash.

56
00:02:46,735 --> 00:02:50,170
FARM_FINGERPRINT tomará un valor
como 10 de diciembre de 2018

57
00:02:50,170 --> 00:02:53,105
lo convertirá
en una cadena larga de dígitos.

58
00:02:53,105 --> 00:02:56,770
Este valor Hash será idéntico para todos
los valores 10 de diciembre de 2018

59
00:02:56,770 --> 00:02:58,200
en el conjunto de datos.

60
00:02:58,200 --> 00:03:00,255
Supongamos
que estamos creando un algoritmo

61
00:03:00,255 --> 00:03:02,640
de AA para predecir
los retrasos en las llegadas.

62
00:03:02,640 --> 00:03:05,030
Tendrían que dividir los datos
por fecha y obtener

63
00:03:05,030 --> 00:03:08,045
cerca del 80% de los días
en un conjunto de datos

64
00:03:08,045 --> 00:03:09,955
el conjunto de datos de entrenamiento.

65
00:03:09,955 --> 00:03:13,520
Esto es repetible,
porque la función hash FARM_FINGERPRINT

66
00:03:13,520 --> 00:03:17,995
muestra el mismo valor cada vez
que se asocia a una fecha específica.

67
00:03:17,995 --> 00:03:20,775
Pueden estar seguros de que
obtendrán el mismo 80%

68
00:03:20,775 --> 00:03:23,640
o casi el 80% de los datos cada vez.

69
00:03:23,640 --> 00:03:25,970
Si dividen los datos
por aeropuerto de llegada

70
00:03:25,970 --> 00:03:29,060
y el 80% de los aeropuertos
están en el conjunto de entrenamiento

71
00:03:29,060 --> 00:03:33,155
y los demás en los de validación y prueba,
entonces usarían la función Hash

72
00:03:33,155 --> 00:03:34,990
en el aeropuerto de llegada.

73
00:03:34,990 --> 00:03:37,900
Si observamos la consulta,
¿cómo obtendrían una nueva muestra

74
00:03:37,900 --> 00:03:40,345
del 10% para la evaluación?

75
00:03:40,855 --> 00:03:44,765
Cambiarían "< 8" a "= 8"
para los datos de la prueba

76
00:03:44,765 --> 00:03:49,430
o "= 8" o "= 9" para el otro 10%
de la evaluación o la prueba.

77
00:03:49,430 --> 00:03:51,645
Así se dividen esos grupos.

78
00:03:52,520 --> 00:03:55,045
Supongamos que quieren predecir
los retrasos de vuelos

79
00:03:55,045 --> 00:03:57,660
según la compañía aérea,
la hora del día, el clima

80
00:03:57,660 --> 00:04:00,920
y las características del aeropuerto,
como la cantidad de pistas.

81
00:04:00,920 --> 00:04:03,310
¿Según qué campos
deberíamos dividir el conjunto?

82
00:04:03,310 --> 00:04:05,740
¿Fecha? ¿Aeropuerto? ¿Compañía aérea?

83
00:04:05,740 --> 00:04:08,595
Asegúrense de dividir sus datos
en estos conjuntos válidos

84
00:04:08,595 --> 00:04:11,155
según una columna
que puedan darse el lujo de perder.

85
00:04:11,155 --> 00:04:14,120
Por ejemplo, si quieren dividir
según la fecha para predecir

86
00:04:14,120 --> 00:04:17,425
los retrasos en las llegadas
y su conjunto solo tiene vuelos de 2 días

87
00:04:17,425 --> 00:04:19,870
no podrían dividir más allá de 50-50.

88
00:04:19,870 --> 00:04:23,240
Recuerden que la función Hash
es de ida, de modo que les dará un valor.

89
00:04:23,240 --> 00:04:25,825
No podrán obtener 80-20
si solo tienen dos días.

90
00:04:25,825 --> 00:04:28,835
Veamos estas opciones una por una.

91
00:04:29,585 --> 00:04:32,935
¿Y si agrupamos o usamos Hash
y dividimos según la fecha?

92
00:04:32,935 --> 00:04:35,920
Está bien.
Pero comprendan que ya no podrán

93
00:04:35,920 --> 00:04:39,190
realizar predicciones con base
en los feriados, como Navidad

94
00:04:39,190 --> 00:04:40,830
o Acción de Gracias, por ejemplo.

95
00:04:40,830 --> 00:04:43,920
Asegúrense de que el objetivo
de su predicción no tenga que ver

96
00:04:43,920 --> 00:04:47,190
con fechas, porque los grupos
se crearon de esa manera.

97
00:04:47,190 --> 00:04:50,530
¿Qué pasa si usamos Hash y dividimos
según el nombre del aeropuerto?

98
00:04:50,530 --> 00:04:52,955
Está bien,
mientras esté distribuido y tenga ruido

99
00:04:52,955 --> 00:04:55,725
pero tengan en cuenta
que no podrán realizar predicciones

100
00:04:55,725 --> 00:04:57,595
para aeropuertos específicos.

101
00:04:57,595 --> 00:05:00,990
Por ejemplo, los vuelos de JFK
de las 5 p.m. siempre están retrasados.

102
00:05:00,990 --> 00:05:03,690
Ya no pueden usar JFK
porque dividieron según ese nombre.

103
00:05:03,690 --> 00:05:07,020
¿Y si usamos Hash y dividimos
según el nombre de la compañía aérea?

104
00:05:07,020 --> 00:05:10,500
Solo existen 11 compañías aéreas
y si quieren dividir los datos según eso

105
00:05:10,500 --> 00:05:14,935
no estarán muy bien distribuidos
como para obtener una división detallada.

106
00:05:14,935 --> 00:05:18,320
En lugar de 80-20,
es posible que obtengan 60-40

107
00:05:18,320 --> 00:05:20,860
que tal vez
no sea suficiente para ustedes.

108
00:05:21,400 --> 00:05:24,965
Cuando se comienza con el desarrollo
del AA, es mejor desarrollar el código

109
00:05:24,965 --> 00:05:27,270
de TensorFlow
en un pequeño subconjunto de datos

110
00:05:27,270 --> 00:05:30,880
y, luego, escalarlo a la nube
para la producción real.

111
00:05:31,190 --> 00:05:33,505
Supongamos
que están desarrollando una aplicación

112
00:05:33,505 --> 00:05:37,230
de AA. Cada vez que hagan un cambio
deberán volver a ejecutar la aplicación.

113
00:05:37,230 --> 00:05:40,940
Si usan el conjunto de datos completo,
esto podría llevar horas o incluso días.

114
00:05:40,940 --> 00:05:44,700
Estamos hablando de petabytes de datos
y no se puede desarrollar software así.

115
00:05:44,700 --> 00:05:48,450
Deben tener un pequeño conjunto de datos
de modo que puedan ejecutar su código

116
00:05:48,450 --> 00:05:50,715
depurarlo y, luego, ejecutarlo de nuevo.

117
00:05:50,715 --> 00:05:52,970
Una vez que la aplicación
esté funcionando bien

118
00:05:52,970 --> 00:05:55,215
podrán ejecutarla una vez
o las veces que deseen

119
00:05:55,215 --> 00:05:58,085
en el conjunto de datos completo;
es como crear un prototipo.

120
00:05:58,085 --> 00:06:00,570
A continuación, veamos
cómo podemos crear una muestra uniforme

121
00:06:00,570 --> 00:06:03,300
de un subconjunto
más pequeño de nuestro conjunto

122
00:06:03,300 --> 00:06:05,050
de datos de vuelos que usamos antes.

123
00:06:05,050 --> 00:06:08,150
Creamos los grupos,
pero ahora queremos menos datos.

124
00:06:08,820 --> 00:06:11,360
Los datos de vuelos
contienen 70 millones de filas.

125
00:06:11,360 --> 00:06:14,880
Tal vez quieran un conjunto más pequeño,
digamos un millón de vuelos

126
00:06:14,880 --> 00:06:16,910
y debe ser repetible.

127
00:06:16,910 --> 00:06:20,605
¿Cómo elegirían uno de 70 vuelos?
Y luego ¿un 80% de esos

128
00:06:20,605 --> 00:06:22,340
para el entrenamiento?

129
00:06:22,340 --> 00:06:25,550
No pueden elegir 1 de 70
y luego escoger 1 de 10

130
00:06:25,550 --> 00:06:26,825
de los resultados.

131
00:06:26,825 --> 00:06:29,160
¿Se dan cuenta por qué?

132
00:06:29,160 --> 00:06:34,260
Si eligen números divisibles por 70
también serán divisibles por 10.

133
00:06:34,260 --> 00:06:38,120
La segunda operación modulo aquí,
como ven, es inútil.

134
00:06:38,870 --> 00:06:42,290
Hagamos una demostración rápida
y les mostraré lo que esto significa.