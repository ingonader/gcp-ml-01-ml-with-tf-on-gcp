線形回帰とニューラルネットワークの 2つのMLモデルのどちらがいいか
選ぶ場合のみでなく 1つのモデルのハイパーパラメータの
微調整にも 評価用データセットを使えます ハイパーパラメータは
トレーニング前に設定しましたね この調整プロセスでは
連続してトレーニングを行い トレーニングの結果を
別の評価用データセットを使った結果と 比較して過学習をチェックします トレーニング中に評価セットを
どのように使用するか説明します 最適化で説明したように モデルのトレーニングでは
まずランダムな重みを計算し 微分を計算し 勾配降下法で損失の曲線を
降下しながら確認し 損失の指標を最小化する
これを繰り返します また 定期的に
モデルのパフォーマンスを評価します 評価ではトレーニングで
未使用のデータを使います つまり評価用データセットです トレーニングが完了したら 評価用データセットでモデルの結果を評価して ハイパーパラメータが適切なのか もう少し調整するのか確認します トレーニングと評価用データセットの
損失指標に 大きな違いがなければ ハイパーパラメータをもう少し最適化できます さて モデルの損失指標が十分最適化されて 評価用データセットでも問題がなくなりました 評価用データセットの結果が乖離し始め
かつモデルが過学習でない状態 そこが止めるタイミングです 本番用のモデルの調整ができました これに似たループを使って モデルごとにどのパラメータがいいのか
調べることもできます トレーニングの前に設定した
ハイパーパラメータと同じです たとえば 使用するネットワーク層や
ノード数を調べます ニューラルネットワークで たとえば6個のノードを
1つの設定としてトレーニングします さらに別の設定でトレーニングして 評価用データセットでどちらの設定が
優れているか確認します 最終的に 評価用データセットで
損失が少ない設定を選びます トレーニングデータセットで
損失が少ない設定ではありません この専門分野の後半では Cloud ML Engineがベイズ検索を ハイパーパラメータ空間で行う方法を
お見せします これでハイパーパラメータを
一つ一つ実験する必要がなくなります Cloud ML Engineによって さまざまな最適化戦略を使いながら
このような実験を並行して行えます トレーニングが完了したら 上司にモデルのパフォーマンスを
報告しなければなりません 成功と失敗の最終評価に
どのデータセットを使ったらよいでしょうか？ 評価用データセットでの損失や誤差のみを
報告しますか？ トレーニングでの損失や誤差と同じ場合でも？ それはできません なぜなら 評価用データセットを使って トレーニングを止める時を決めたからです つまり もう独立したデータではありません モデルが見てしまいました ではどうすればよいでしょうか？ データを3つに分割するのです トレーニング用、評価用
新たに分けたテスト用です モデルのトレーニングと評価が完了したら たった一度だけ
テスト用データセットでモデルを実行します この損失指標を上司に報告します テスト用データセットの
損失指標で このモデルを本番で使うかどうかを
決めるのです テスト用データセットで失敗したら
どうなるでしょうか 評価は成功しているのにです 同じMLモデルは再テストできません まったく新しい機械学習モデルを
再トレーニングするか 振り出しに戻って データサンプルをもっと集めて
MLモデルに新しいデータを提供します これは良いアプローチですが 小さな問題が1つあります 1 回しか使っていないテスト用データは
事実上 無駄になってしまいました これをホールドアウト法と言います すべてのデータをトレーニングで使いながら モデルのパフォーマンスの
妥当な指標を得ることはできないのでしょうか 実はできます これらの方法の妥協策として トレーニング用と評価用を分割し
それを複数回行います トレーニングしてから
評価用データセットで損失を計算します この評価用セットは 最初にトレーニングで使っていないデータから
構成されます それからデータをもう一度分割します このトレーニング用データには 最初の評価を行った時に
使ったデータも含まれることがあります それでも複数回繰り返します 最終的にこれを何回か繰り返すと 全体的に評価の損失指標が平均化されます そして評価の損失の標準偏差が得られます これでばらつきを分析し
最終的な数値を得ます これをブートストラップや
クロスバリデーションと呼びます この方法のメリットはすべてのデータを
使えることです ただし 分割データを多数作るので 何度もトレーニングする必要があります 最後に復習です データが多い場合は 完全に独立したホールドアウト法の
テスト用データセットを使います これで成功か失敗か判断できます データが多くない場合は クロスバリデーションを使います では 大きなデータセットを 分割するにはどうしたらいいでしょうか？ それが次のレッスン「サンプリング」です