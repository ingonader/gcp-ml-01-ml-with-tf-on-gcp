1
00:00:00,000 --> 00:00:03,660
Hablemos primero de la generalización,
que nos ayuda a responder

2
00:00:03,660 --> 00:00:07,559
cuándo el modelo de AA
más preciso no es la mejor opción.

3
00:00:08,739 --> 00:00:12,394
Una vez más, tenemos
el conjunto de datos de natalidad

4
00:00:12,394 --> 00:00:14,785
pero esta vez,
usaremos el peso ganado por la madre

5
00:00:14,785 --> 00:00:17,350
en el eje X
para predecir la duración del embarazo

6
00:00:17,350 --> 00:00:18,955
en el eje Y.

7
00:00:19,225 --> 00:00:22,480
¿Qué observan acerca del patrón
que ven en los datos?

8
00:00:22,480 --> 00:00:24,610
Están fuertemente correlacionados.

9
00:00:24,610 --> 00:00:27,670
Mientras más peso se gana,
más largo es el embarazo

10
00:00:27,670 --> 00:00:31,010
lo que tiene sentido intuitivamente
ya que el bebé está creciendo.

11
00:00:32,000 --> 00:00:35,125
Para modelar este comportamiento
y comprobar una correlación

12
00:00:35,125 --> 00:00:38,595
por lo general, ¿qué modelo
deberíamos invocar primero?

13
00:00:38,595 --> 00:00:40,820
Si respondieron
un "modelo de regresión lineal"

14
00:00:40,820 --> 00:00:42,520
tienen toda la razón.

15
00:00:42,520 --> 00:00:44,945
Como ya mencionamos,
para los problemas de regresión

16
00:00:44,945 --> 00:00:47,080
la métrica de pérdida
que deberán optimizar

17
00:00:47,080 --> 00:00:50,075
por lo general,
es el error cuadrático medio, MSE

18
00:00:50,075 --> 00:00:53,260
o RMSE,
el error de la raíz cuadrada de la media.

19
00:00:54,210 --> 00:00:57,580
El error cuadrático medio
nos indica lo cerca que está una línea

20
00:00:57,580 --> 00:00:59,745
de regresión del conjunto de puntos.

21
00:00:59,745 --> 00:01:02,710
Lo hace mediante el cálculo
de las distancias desde los puntos

22
00:01:02,710 --> 00:01:04,335
hasta la línea de regresión real.

23
00:01:04,335 --> 00:01:07,845
Esas distancias se llaman errores,
los que se elevan al cuadrado.

24
00:01:07,845 --> 00:01:11,105
Elevar al cuadrado es necesario
para quitar cualquier signo negativo.

25
00:01:11,105 --> 00:01:14,360
MSE también otorga mayor peso
a esas diferencias más grandes

26
00:01:14,360 --> 00:01:15,895
desde la línea.

27
00:01:15,895 --> 00:01:18,980
Si se aplica la raíz cuadrada del MSE,
se obtiene el RMSE

28
00:01:18,980 --> 00:01:22,335
que simplemente es la distancia
promedio de un punto de datos

29
00:01:22,335 --> 00:01:25,850
desde la línea ajustada
medida a lo largo de una línea vertical.

30
00:01:25,850 --> 00:01:30,070
El RMSE se interpreta directamente
con las unidades de medición en el eje Y.

31
00:01:30,070 --> 00:01:34,195
Es una mejor medida de un ajuste correcto
que un coeficiente de correlación.

32
00:01:34,585 --> 00:01:37,565
Ahora, para ambas medidas de error,
un valor más bajo señala

33
00:01:37,565 --> 00:01:40,645
un modelo de mejor rendimiento
y mientras más cerca esté el error

34
00:01:40,645 --> 00:01:42,065
de cero, será mejor.

35
00:01:43,035 --> 00:01:45,465
Aquí, usamos un modelo de regresión lineal

36
00:01:45,465 --> 00:01:48,095
que simplemente grafica
esa línea de mejor ajuste

37
00:01:48,095 --> 00:01:49,680
para minimizar el error.

38
00:01:49,850 --> 00:01:52,845
Nuestro RMSE final es 2.224.

39
00:01:53,635 --> 00:01:57,240
Y para nuestro problema,
eso está bastante bien.

40
00:01:58,390 --> 00:02:00,060
Bueno, ahora vean esto.

41
00:02:00,470 --> 00:02:02,310
¿Y si usamos un modelo más complejo?

42
00:02:02,310 --> 00:02:05,415
Un modelo más complejo
puede tener más parámetros libres.

43
00:02:05,415 --> 00:02:08,110
En este caso,
esos parámetros libres nos permiten

44
00:02:08,110 --> 00:02:11,055
capturar cada variación
en el conjunto de datos, como ven ahí.

45
00:02:11,055 --> 00:02:14,115
Aunque reducimos nuestro RMSE a cero

46
00:02:14,115 --> 00:02:16,210
el modelo
ahora es perfectamente preciso.

47
00:02:16,210 --> 00:02:17,470
¿Hemos terminado?

48
00:02:17,470 --> 00:02:20,685
¿Es el mejor modelo?
¿Podemos ponerlo en producción?

49
00:02:20,685 --> 00:02:25,450
Bueno, podrían pensar
que algo raro pasa con el segundo modelo.

50
00:02:25,450 --> 00:02:27,105
¿Cómo podemos darnos cuenta?

51
00:02:27,105 --> 00:02:30,880
En el AA, a menudo tenemos muchos datos
pero no una buena intuición.

52
00:02:30,880 --> 00:02:34,435
¿Es una red neuronal con 8 nodos
mejor que una con 12?

53
00:02:34,435 --> 00:02:36,965
Tenemos un RMSE menor
para una con 16 nodos.

54
00:02:36,965 --> 00:02:39,120
¿Deberíamos elegir esa?

55
00:02:39,120 --> 00:02:43,030
El ejemplo que ven aquí
podría ser un polinomio de grado 100

56
00:02:43,030 --> 00:02:45,190
o una red neuronal con cientos de nodos.

57
00:02:45,190 --> 00:02:48,470
Como vieron en el ejemplo de la espiral,
al final de la última clase

58
00:02:48,470 --> 00:02:50,480
sobre optimización,
un modelo más complejo

59
00:02:50,480 --> 00:02:53,270
tiene más de estos parámetros
que se pueden optimizar.

60
00:02:53,270 --> 00:02:55,875
Aunque esto puede ayudar
a ajustar datos más complejos

61
00:02:55,875 --> 00:02:58,220
como la espiral,
también puede ayudar a memorizar

62
00:02:58,220 --> 00:03:00,570
conjuntos de datos más pequeños y simples.

63
00:03:01,120 --> 00:03:04,790
¿En qué momento le decimos a un modelo
que se detenga, que está memorizando

64
00:03:04,790 --> 00:03:07,795
el conjunto de datos
y posiblemente sobreajustando?

65
00:03:08,655 --> 00:03:11,660
Una de las mejores formas de evaluar
la calidad de un modelo

66
00:03:11,660 --> 00:03:14,210
es ver su rendimiento
con un nuevo conjunto de datos

67
00:03:14,210 --> 00:03:15,955
que no ha visto antes.

68
00:03:15,955 --> 00:03:18,980
Entonces podemos determinar
si ese modelo generaliza bien

69
00:03:18,980 --> 00:03:21,000
en nuevos puntos de datos.

70
00:03:21,000 --> 00:03:24,140
Es un buen proxy para la producción
con datos del mundo real.

71
00:03:24,760 --> 00:03:28,250
Volvamos al modelo de regresión lineal
y a los modelos de redes neuronales

72
00:03:28,250 --> 00:03:30,100
para ver cómo les va.

73
00:03:30,470 --> 00:03:33,560
Nuestro modelo de regresión lineal
en estos nuevos puntos de datos

74
00:03:33,560 --> 00:03:35,175
está generalizando bastante bien.

75
00:03:35,175 --> 00:03:37,315
El RMSE es comparable
a lo que vimos antes

76
00:03:37,315 --> 00:03:40,280
y en este caso
es bueno que no haya sorpresas.

77
00:03:40,280 --> 00:03:43,055
Queremos un rendimiento coherente
de nuestros modelos

78
00:03:43,055 --> 00:03:45,500
en el entrenamiento y la validación.

79
00:03:45,830 --> 00:03:49,065
Si regresamos al segundo modelo,
vemos que no generaliza nada bien

80
00:03:49,065 --> 00:03:52,390
en el nuevo conjunto de datos
de entrenamiento y eso es muy alarmante.

81
00:03:52,390 --> 00:03:56,560
El RMSE saltó de 0 a 3.2,
lo que es un problema serio

82
00:03:56,560 --> 00:03:59,505
y quiere decir que el modelo
se sobreajustó completamente

83
00:03:59,505 --> 00:04:05,365
al conjunto de datos de entrenamiento
y que no es generalizable a nuevos datos.

84
00:04:05,785 --> 00:04:07,805
Podrían preguntarse,
¿cómo puedo asegurarme

85
00:04:07,805 --> 00:04:09,520
de que mi modelo no se sobreajuste?

86
00:04:09,520 --> 00:04:12,225
¿Cómo sé cuándo detener el entrenamiento?

87
00:04:12,225 --> 00:04:14,155
La respuesta es sorprendentemente simple.

88
00:04:14,155 --> 00:04:16,470
Dividiremos los datos.

89
00:04:16,940 --> 00:04:20,950
Mediante la división del conjunto de datos
original en grupos completamente separados

90
00:04:20,950 --> 00:04:23,560
y aislados,
pueden volver a entrenar el modelo

91
00:04:23,560 --> 00:04:27,275
en el conjunto de datos de entrenamiento
y, luego, cuando terminen de hacerlo

92
00:04:27,275 --> 00:04:30,250
comparar su rendimiento
con un conjunto de validación

93
00:04:30,250 --> 00:04:31,950
independiente y aislado.

94
00:04:31,950 --> 00:04:34,920
Los modelos que generalizaron bien
tendrán métricas de pérdida

95
00:04:34,920 --> 00:04:38,500
o valores de error similares
en el entrenamiento y la validación.

96
00:04:38,500 --> 00:04:41,160
En cuanto vean que su modelo
no tiene buen rendimiento

97
00:04:41,160 --> 00:04:43,880
con el conjunto de validación,
si las métricas de pérdida

98
00:04:43,880 --> 00:04:45,880
comienzan a aumentar
o subir por sorpresa

99
00:04:45,880 --> 00:04:47,980
es momento de parar.

100
00:04:47,980 --> 00:04:51,200
Entrenar y evaluar un modelo de AA
es un experimento para encontrar

101
00:04:51,200 --> 00:04:53,770
el modelo generalizable
y los parámetros correctos

102
00:04:53,770 --> 00:04:57,110
que se ajusten a su conjunto de datos
de entrenamiento sin memorizarlo.

103
00:04:57,110 --> 00:05:00,220
Como ven aquí,
tenemos un modelo lineal muy simple

104
00:05:00,220 --> 00:05:03,170
que no se ajusta a las relaciones
de los datos correctamente.

105
00:05:03,170 --> 00:05:05,570
Pueden ver lo malo que es visualmente.

106
00:05:05,570 --> 00:05:09,005
Hay unos cuantos puntos fuera de la forma
de la línea de tendencia.

107
00:05:09,005 --> 00:05:11,030
A eso se le llama sobregeneralización.

108
00:05:11,030 --> 00:05:14,825
En el lado opuesto del espectro,
y un poco más peligroso

109
00:05:14,825 --> 00:05:16,830
está el sobreajuste, del que ya hablamos.

110
00:05:16,830 --> 00:05:18,870
Esto se muestra en el extremo derecho.

111
00:05:18,870 --> 00:05:21,800
Aquí, aumentamos mucho
la complejidad de nuestro modelo lineal

112
00:05:21,800 --> 00:05:25,750
y lo convertimos en un polinomio
de orden n, lo que parece ayudar al modelo

113
00:05:25,750 --> 00:05:29,380
a ajustar los datos y las variaciones
que mencionamos antes.

114
00:05:29,380 --> 00:05:32,280
Aquí es donde el conjunto
de evaluación entra en la ecuación

115
00:05:32,280 --> 00:05:34,840
y tendrán que determinar
si los parámetros del modelo

116
00:05:34,840 --> 00:05:37,170
conducen al sobreajuste.
¿Es demasiado complejo?

117
00:05:37,170 --> 00:05:40,090
El sobreajuste o la memorización
del conjunto de entrenamiento

118
00:05:40,090 --> 00:05:43,270
puede ser mucho peor que un modelo
que solo se ajusta a sus datos.

119
00:05:43,270 --> 00:05:46,330
A veces no lo sabrán hasta la producción;
eso intentamos validar.

120
00:05:46,330 --> 00:05:48,690
En algún lugar
entre una sobregeneralización

121
00:05:48,690 --> 00:05:52,350
y un sobreajuste está el nivel correcto
de complejidad de un modelo.

122
00:05:52,350 --> 00:05:55,620
Veamos cómo usar el conjunto
de datos de validación para saber

123
00:05:55,620 --> 00:05:59,420
cuándo detener el entrenamiento
y prevenir el sobreajuste.