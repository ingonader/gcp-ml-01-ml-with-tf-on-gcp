まず一般化に取り組みましょう 一般化は ある問題に答えてくれます 最も正確なMLモデルが
常に最適な選択ではないという問題です 今度もおなじみの出生率の
データセットを使いましょう ただし今回は母親の体重増加をX軸にして 妊娠の経過日数をY軸で予測します どんなパターンがデータで確認できますか？ 強い相関性があるように見えます 体重が増えると経過日数も長いです 赤ちゃんが大きくなるので
直感的に納得がいきますよね これをモデル化して相関性を証明するには どのモデルを最初に使うのが
一般的でしょうか？ 線形回帰モデルと答えた人は正解です 回帰の問題で説明しましたが 最適化したい損失の指標は 通常は平均二乗誤差（MSE）か 平均二乗平方根誤差（RMSE）です 平均二乗誤差では 回帰直線と
点の近さがわかります そのために 点から実際の回帰直線までの
距離を測ります この距離を誤差といいますが
これを二乗します 二乗が必要なのは
負号を取り除くためです MSEは線からの距離が大きいものに
重み付けします MSEの平方根を取るとRMSEが求められます これはデータポイントと適合線の
垂直方向の距離の平均です RMSEはY軸の測定単位で直接解釈されます このため 相関関数よりも
適合度を測るのに適しています 両方の誤差の測定で 値が低い方がパフォーマンスがいいモデルです 誤差がゼロに近いほど優れています ここでは線形回帰モデルを使っています データに最も適合する線を引き
誤差を最小化します 最終的なRMSEは2.224です 今見ている問題に対しては
とてもいい出来でしょう しかしこれを見てください もっと複雑なモデルを使うとどうでしょうか？ モデルが複雑になると
自由パラメータが増える可能性があります この例ではこの自由パラメータによって ご覧のようにデータセットの凸凹を
すべてとらえています RMSEを減らしてゼロにすると モデルは完全に正確になりました これで完了でしょうか？ これは最適なモデルでしょうか？
本番で使えますか？ 2番目のモデルは何か怪しいと
感じるかもしれません しかし それはどうすればわかりますか？ MLではデータが大量で
そんな直感が働かないことがよくあります 8個のノードのニューラルネットワークが
12個より優れているでしょうか？ 16個のノードの方がRMSEが低いです
それを選ぶべきですか？ ご覧になっているこの例は 100次の多項式または数百のノードを持つ
ニューラルネットワークです スパイラルの例を
最適化の最終講義の終わりで見ましたが モデルが複雑になると
最適化できるパラメータが増えます モデルはスパイラルのように
さらに複雑なデータに適合できます シンプルで小さなデータセットを
記憶することもできます では モデルのトレーニング時に
データセットの記憶や過学習を防ぐには どのタイミングで止めればよいのでしょう？ モデルの品質評価の最適な方法は 未知の新しいデータセットで
パフォーマンスを確認することです 新しいデータポイントで
そのモデルが適切に一般化されているか判断できます 未知のデータセットは
現実世界の本番データの代わりになります では 線形回帰モデルと
ニューラルネットワークモデルの 出来栄えをもう一度確認しましょう 新しいデータポイントに対して線形回帰モデルは 十分に一般化されています RMSEは以前のものと似ていますが 驚きがないのはいいことです モデルのトレーニングと評価で
パフォーマンスが一貫しているのが理想です 2番目のモデルを見直してみると 新しいデータセットでは
うまく一般化されていません これは懸念です RMSEが0から3.2に大きく増えています これは大きな問題です モデルがトレーニング用データセットを
完全に過学習しています これでは新しいデータに対して
一般化できず当てになりません モデルが過学習しないように トレーニングを止めるタイミングを
知るにはどうすればよいでしょうか その答えは驚くほどシンプルです データを分割するのです 元のデータセットを分割して
まったく別のグループにします トレーニング用データセットで
モデルをトレーニングします トレーニングが完了したら 分けておいた評価用データセットでの
パフォーマンスと比較します 一般化がうまくいったモデルは 損失の指標や誤差の値が
トレーニングと評価でほぼ同じになります 評価用データセットでの
モデルのパフォーマンスが 低下してきたら たとえば 損失の指標が
上昇し始めたら そこが止めるタイミングです MLモデルのトレーニングと評価では 一般化できるモデルと
モデルのパラメータを見つけます トレーニングデータセットに適合しつつも
記憶はしていないモデルです この線形モデルはシンプルすぎて
データに適合していません どんなにひどいか
見ればわかりますね 傾向線から外れている点が
たくさんあります これを未学習と呼びます これと反対で より危険なのがすでに説明した過学習です これは右下に示されています ここでは線型モデルの複雑さを
かなり増やしました n次多項式に解釈され 先ほど見たとおり
データのすべての凸凹に適合しています ここで評価用データセットの出番です モデルのパラメータが
過学習していないか確認しましょう 複雑すぎていませんか トレーニング用データセットへの
過剰な適合は それなりに適合するモデルより
ずっと問題です 本番まで気付かないこともあります 私たちはそれを検証しました 未学習と過学習の間に
適切な複雑さのモデルが存在します では 評価用データセットの使い方を確認し トレーニングを止める時を知って
過学習を防ぐ方法を見ていきましょう