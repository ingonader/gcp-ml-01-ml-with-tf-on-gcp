1
00:00:00,590 --> 00:00:04,165
Além de ajudá-lo a escolher entre
dois modelos de ML diferentes,

2
00:00:04,165 --> 00:00:06,865
como a regressão linear
ou a rede neural,

3
00:00:06,865 --> 00:00:09,430
você também pode usar o
conjunto de dados de validação

4
00:00:09,430 --> 00:00:12,130
para ajustar os hiperparâmetros
de um único modelo.

5
00:00:12,130 --> 00:00:14,240
Lembre-se:
esses hiperparâmetros

6
00:00:14,240 --> 00:00:15,865
são definidos
antes do treinamento.

7
00:00:15,865 --> 00:00:19,780
Esse processo de ajuste é realizado
com treinamentos sucessivos

8
00:00:19,780 --> 00:00:21,627
e com a comparação 
desses treinamentos

9
00:00:21,627 --> 00:00:24,875
a um conjunto de dados 
de validação independente

10
00:00:24,875 --> 00:00:26,470
para verificar
se há sobreajuste.

11
00:00:26,470 --> 00:00:30,645
Veja como o conjunto de validação será
realmente usado durante o treinamento.

12
00:00:30,645 --> 00:00:33,225
Conforme visto durante a otimização,

13
00:00:33,225 --> 00:00:34,697
é no treinamento do modelo que

14
00:00:34,697 --> 00:00:37,720
começamos a calcular 
pesos aleatórios e derivada,

15
00:00:37,720 --> 00:00:41,145
verificar a direção abaixo da curva
de perda do gradiente descendente,

16
00:00:41,145 --> 00:00:43,420
a minimizar a métrica
de perda e repetir.

17
00:00:43,420 --> 00:00:46,420
E, periodicamente, você quer avaliar
o desempenho de um modelo

18
00:00:46,420 --> 00:00:49,295
em relação a dados que ainda não
foram vistos em treinamento,

19
00:00:49,295 --> 00:00:52,595
que é onde usamos o conjunto
de dados de validação.

20
00:00:52,595 --> 00:00:54,985
Depois de um treinamento completo,

21
00:00:54,985 --> 00:00:57,440
valide os resultados do modelo

22
00:00:57,440 --> 00:00:59,550
no conjunto de dados de validação

23
00:00:59,550 --> 00:01:02,720
e veja se os hiperparâmetros estão
ok ou se precisam de ajuste.

24
00:01:02,720 --> 00:01:04,910
E, se não houver uma
divergência significativa

25
00:01:04,910 --> 00:01:07,130
entre as métricas
de perda do treinamento

26
00:01:07,130 --> 00:01:09,400
e as do conjunto de dados de validação,

27
00:01:09,400 --> 00:01:13,060
poderemos voltar e otimizar
mais nossos hiperparâmetros.

28
00:01:14,010 --> 00:01:17,050
Quando as métricas de perda do
modelo estiverem suficientemente

29
00:01:17,050 --> 00:01:19,690
otimizadas e forem aprovadas no
conjunto de validação,

30
00:01:19,690 --> 00:01:21,405
lembre-se de começar a ver a divergência

31
00:01:21,405 --> 00:01:23,555
e confirmar que o modelo não
tem sobreajuste.

32
00:01:23,555 --> 00:01:25,750
Nesse caso, precisamos parar,

33
00:01:25,750 --> 00:01:28,750
pois nosso modelo está ajustado
e pronto para produção.

34
00:01:29,970 --> 00:01:31,835
Você pode usar
um loop semelhante a esse

35
00:01:31,835 --> 00:01:33,630
para saber
quais parâmetros

36
00:01:33,630 --> 00:01:35,385
aplicar nos seus modelos individuais

37
00:01:35,385 --> 00:01:38,560
como fizemos com os hiperparâmetros
definidos antes do treinamento.

38
00:01:38,560 --> 00:01:42,500
Por exemplo, as camadas de uma rede ou
o número de nodes a serem usados.

39
00:01:42,500 --> 00:01:44,640
Em suma, você treinará
com uma configuração,

40
00:01:44,640 --> 00:01:46,340
como seis nodes na rede neural,

41
00:01:46,340 --> 00:01:47,820
treinará com outra

42
00:01:47,820 --> 00:01:51,600
e verá qual tem o melhor desempenho
no conjunto de dados de validação.

43
00:01:51,600 --> 00:01:54,220
No fim, você escolherá uma
configuração de modelo

44
00:01:54,220 --> 00:01:56,815
que represente uma perda menor
no conjunto de validação

45
00:01:56,815 --> 00:02:00,615
e não uma perda menor
no treinamento.

46
00:02:01,525 --> 00:02:03,110
Mais adiante,

47
00:02:03,110 --> 00:02:05,740
mostraremos como 
o Cloud ML Engine pode fazer

48
00:02:05,740 --> 00:02:08,919
uma rápida pesquisa bayesiana
com um espaço de hiperparâmetro

49
00:02:08,919 --> 00:02:13,490
para que você não precise testar
um hiperparâmetro por vez.

50
00:02:13,490 --> 00:02:16,855
O Cloud ML Engine pode
ajudar neste tipo de teste

51
00:02:16,855 --> 00:02:20,615
de maneira paralela com uma
estratégia otimizada diferente.

52
00:02:22,355 --> 00:02:24,050
Depois de fazer o treinamento,

53
00:02:24,050 --> 00:02:27,165
diga ao seu chefe como
o seu modelo está funcionado.

54
00:02:27,165 --> 00:02:31,365
Qual conjunto de dados você
usará para a avaliação final?

55
00:02:31,365 --> 00:02:35,040
Você pode apenas relatar a perda ou
o erro no conjunto de dados de validação

56
00:02:35,040 --> 00:02:37,835
mesmo que ele esteja
consistente com o de treinamento?

57
00:02:37,835 --> 00:02:39,640
Na verdade, não pode.

58
00:02:39,640 --> 00:02:40,930
Por que não?

59
00:02:40,930 --> 00:02:45,060
Como você usou o conjunto de
dados de validação para decidir

60
00:02:45,060 --> 00:02:47,055
quando interromper o treinamento,

61
00:02:47,055 --> 00:02:48,980
ele não é mais independente.

62
00:02:48,980 --> 00:02:50,335
O modelo já o conhece.

63
00:02:50,335 --> 00:02:52,605
Então, o que você tem que fazer?

64
00:02:52,605 --> 00:02:55,742
Divida os dados em 3 partes:

65
00:02:55,742 --> 00:03:02,660
treinamento, validação e um novo silo
totalmente isolado chamado teste.

66
00:03:02,660 --> 00:03:05,830
Depois de treinar e validar seu modelo,

67
00:03:05,830 --> 00:03:07,030
grave-o uma vez,

68
00:03:07,030 --> 00:03:09,900
apenas uma vez com o conjunto
de dados de teste independente.

69
00:03:09,900 --> 00:03:12,350
Essa é a métrica de perda a ser
informada ao seu chefe.

70
00:03:12,350 --> 00:03:15,140
É a métrica de perda que, no
conjunto de dados de teste,

71
00:03:15,140 --> 00:03:17,665
determina se esse modelo será
usado ou não na produção.

72
00:03:17,665 --> 00:03:20,780
E o que acontece se você falhar
no conjunto de dados de teste

73
00:03:20,780 --> 00:03:22,500
mesmo se passar pela validação?

74
00:03:22,500 --> 00:03:24,950
Você não pode retestar o
mesmo modelo de ML.

75
00:03:24,950 --> 00:03:28,585
Será preciso retreinar um novo modelo
de aprendizado de máquina

76
00:03:28,585 --> 00:03:30,800
ou voltar para a prancheta e coletar mais

77
00:03:30,800 --> 00:03:35,035
amostras de dados para fornecer
novos dados ao seu modelo de ML.

78
00:03:35,035 --> 00:03:37,215
Embora essa seja uma boa abordagem,

79
00:03:37,215 --> 00:03:39,145
há um pequeno problema.

80
00:03:39,145 --> 00:03:40,650
Ninguém gosta de perder dados

81
00:03:40,650 --> 00:03:42,980
e parece que os dados
de teste foram perdidos.

82
00:03:42,980 --> 00:03:44,870
Eu os usei uma vez e descartei.

83
00:03:44,870 --> 00:03:47,590
Será que você não pode usar
todos os dados no treinamento

84
00:03:47,590 --> 00:03:50,730
e ter uma noção
do desempenho do modelo?

85
00:03:51,860 --> 00:03:53,260
Sim, você pode.

86
00:03:53,260 --> 00:03:55,330
O equilíbrio entre 
esses métodos é fazer

87
00:03:55,330 --> 00:03:59,180
uma divisão de validação
de treinamento muitas vezes.

88
00:03:59,190 --> 00:04:02,265
Treine e calcule a perda
no conjunto de dados de validação.

89
00:04:02,265 --> 00:04:04,715
Lembre-se de que
esse conjunto de validação pode ter

90
00:04:04,715 --> 00:04:07,210
pontos não usados no primeiro treinamento.

91
00:04:07,210 --> 00:04:09,060
Divida os dados de novo.

92
00:04:09,060 --> 00:04:11,350
Agora, os dados podem incluir alguns

93
00:04:11,350 --> 00:04:13,810
pontos usados na validação original,

94
00:04:13,820 --> 00:04:16,915
mas você está fazendo várias iterações.

95
00:04:16,915 --> 00:04:19,754
E depois de repetir esse
processo algumas vezes,

96
00:04:19,754 --> 00:04:23,410
você tem uma média das
métricas de perda de validação.

97
00:04:23,410 --> 00:04:26,065
Você terá o desvio padrão das
perdas de validação,

98
00:04:26,065 --> 00:04:29,480
o que ajudará a analisar o crescimento
e achar o número final.

99
00:04:29,480 --> 00:04:33,100
Esse processo é chamado de
bootstrapping ou validação cruzada.

100
00:04:33,100 --> 00:04:34,965
A vantagem é usar todos os dados,

101
00:04:34,965 --> 00:04:37,150
mas é preciso treinar muito mais vezes

102
00:04:37,150 --> 00:04:39,120
porque você
está criando mais divisões.

103
00:04:39,120 --> 00:04:42,090
No final, você precisa
ter em mente o seguinte:

104
00:04:42,095 --> 00:04:43,740
se você tem muitos dados,

105
00:04:43,740 --> 00:04:48,055
use um conjunto de dados
de teste independente,

106
00:04:48,055 --> 00:04:50,180
como uma decisão final.

107
00:04:50,180 --> 00:04:51,720
Se você não tem muitos dados,

108
00:04:51,720 --> 00:04:54,180
use a validação cruzada.

109
00:04:55,810 --> 00:04:58,140
E como você realmente divide esses

110
00:04:58,140 --> 00:05:01,390
grandes conjuntos de dados nos silos
de que tanto falamos?

111
00:05:01,390 --> 00:05:04,785
Esse é o assunto da nossa
próxima lição: amostragem.