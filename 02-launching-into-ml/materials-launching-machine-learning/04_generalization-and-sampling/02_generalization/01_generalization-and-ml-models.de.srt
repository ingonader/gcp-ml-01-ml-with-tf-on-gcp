1
00:00:00,000 --> 00:00:02,230
Fangen wir mit 
der Generalisierung an,

2
00:00:02,230 --> 00:00:05,429
um zu erfahren, 
wann das genaueste ML-Modell

3
00:00:05,429 --> 00:00:07,814
nicht unbedingt die beste Wahl ist.

4
00:00:08,844 --> 00:00:12,055
Hier finden wir das typische
Modell zur Geburtenrate wieder,

5
00:00:12,055 --> 00:00:14,310
bei dem mit der 
Gewichtszunahme der Mutter

6
00:00:14,310 --> 00:00:16,865
auf der X-Achse 
die Dauer der Schwangerschaft

7
00:00:16,865 --> 00:00:18,780
auf der Y-Achse vorausgesagt wird.

8
00:00:19,140 --> 00:00:21,620
Welches Muster erkennen Sie in den Daten?

9
00:00:21,620 --> 00:00:24,160
Es scheint eine 
starke Korrelation zu geben:

10
00:00:24,160 --> 00:00:27,510
Je größer die Gewichtszunahme,
desto länger die Schwangerschaft.

11
00:00:27,510 --> 00:00:30,395
Intuitiv ergibt das Sinn, 
da das Baby stetig wächst.

12
00:00:31,405 --> 00:00:34,245
Welches Modell 
würden Sie zuerst verwenden,

13
00:00:34,245 --> 00:00:38,180
um dieses Verhalten abzubilden 
und eine Korrelation nachzuweisen?

14
00:00:38,410 --> 00:00:40,580
Mit einem linearen Regressionsmodell –

15
00:00:40,580 --> 00:00:42,165
ganz genau.

16
00:00:42,165 --> 00:00:44,600
Wie bei Regressionsproblemen besprochen

17
00:00:44,600 --> 00:00:47,375
ist der Verlustwert,
den Sie optimieren sollten,

18
00:00:47,375 --> 00:00:50,160
in der Regel der Mean Square Error (MSE)

19
00:00:50,160 --> 00:00:52,930
oder RMSE, der Root Mean Square Error.

20
00:00:54,590 --> 00:00:59,655
Mean Square Error zeigt die Abweichung der
Regressionslinie von den einzelnen Punkten,

21
00:00:59,655 --> 00:01:03,620
indem er die Distanz zwischen
Punkten und Regressionslinie misst.

22
00:01:03,680 --> 00:01:07,535
Diese Distanzen sind die "Errors", 
die anschließend quadriert werden.

23
00:01:07,535 --> 00:01:11,085
Dieser Schritt ist notwenig, 
um negative Vorzeichen zu beseitigen.

24
00:01:11,085 --> 00:01:15,265
MSE hebt die größeren Abweichungen
von der Linie besonders hervor.

25
00:01:15,595 --> 00:01:20,720
Die Wurzel aus dem MSE ergibt den RMSE,
also die durchschnittliche Distanz eines

26
00:01:20,720 --> 00:01:25,475
Datenpunkts von der angepassten Linie,
gemessen entlang einer vertikalen Linie.

27
00:01:25,795 --> 00:01:30,110
Der RMSE wird anhand von Messeinheiten 
auf der Y-Achse interpretiert.

28
00:01:30,110 --> 00:01:33,985
Damit ist er ein besseres Maß der 
Güte als ein Korrelationskoeffizient.

29
00:01:34,565 --> 00:01:36,100
Für beide Fehlermaße gilt:

30
00:01:36,100 --> 00:01:39,350
Je kleiner der Wert, 
desto besser die Leistung des Modells

31
00:01:39,350 --> 00:01:42,390
und je näher der 
Fehler am Nullwert, desto besser.

32
00:01:43,110 --> 00:01:45,895
Hier verwenden wir ein 
lineares Regressionsmodell,

33
00:01:45,895 --> 00:01:49,465
um eine Anpassungslinie zu
ziehen und den Fehler zu minimieren.

34
00:01:49,805 --> 00:01:53,045
Der endgültige RMSE beträgt 2,224.

35
00:01:53,225 --> 00:01:56,625
Für unser Problem 
ist das schon ziemlich gut.

36
00:01:58,335 --> 00:01:59,935
Aber was passiert, wenn wir

37
00:01:59,935 --> 00:02:02,005
ein komplexeres Modell verwenden?

38
00:02:02,005 --> 00:02:05,270
Ein komplexeres Modell 
könnte mehr freie Parameter haben.

39
00:02:05,270 --> 00:02:07,945
Mit freien Parametern 
können wir jede kleine

40
00:02:07,945 --> 00:02:10,090
Abweichung im Dataset aufzeichnen.

41
00:02:10,750 --> 00:02:13,600
Wenn wir den RMSE bis auf null reduzieren,

42
00:02:13,600 --> 00:02:15,510
ist das Modell absolut präzise.

43
00:02:15,510 --> 00:02:16,725
Sind wir jetzt fertig?

44
00:02:16,725 --> 00:02:18,090
Ist dies das beste Modell?

45
00:02:18,090 --> 00:02:19,815
Kann es in die Produktion gehen?

46
00:02:20,375 --> 00:02:24,645
Sie werden vielleicht ein 
Problem beim zweiten Modell sehen.

47
00:02:25,335 --> 00:02:27,530
Aber wie können wir
sicher sein? Beim ML verwendet

48
00:02:27,530 --> 00:02:30,160
man viele Daten und wenig Intuition.

49
00:02:30,160 --> 00:02:34,385
Ist ein neuronales Netzwerk mit acht
Knoten besser als eines mit zwölf Knoten?

50
00:02:34,385 --> 00:02:38,805
Das Netzwerk mit 16 Knoten hat einen
geringeren RMSE. Ist das das richtige?

51
00:02:38,805 --> 00:02:42,120
Dieses Beispiel könnte 
ein Polynomial hundertsten Grades

52
00:02:42,120 --> 00:02:45,125
oder ein neuronales
Netzwerk mit Hunderten von Knoten sein.

53
00:02:45,125 --> 00:02:47,120
Wie beim Spiral-Beispiel am Ende des

54
00:02:47,120 --> 00:02:49,135
letzten Kurses zu Optimierung besprochen,

55
00:02:49,135 --> 00:02:52,765
hat ein komplexeres Modell mehr 
Parameter, die optimiert werden können.

56
00:02:52,765 --> 00:02:56,640
Modelle können mit komplexeren 
Daten wie einer Spirale umgehen,

57
00:02:56,640 --> 00:02:59,860
aber auch kleinere, 
einfachere Datasets speichern.

58
00:03:00,150 --> 00:03:02,990
Wann soll das Modell das Training beenden,

59
00:03:02,990 --> 00:03:07,270
weil das Dataset gespeichert
und eventuell sogar überangepasst wird?

60
00:03:08,380 --> 00:03:11,460
Die Qualität eines
Modells lässt sich gut bewerten,

61
00:03:11,460 --> 00:03:15,610
indem man prüft, ob es mit einem neuen, 
unbekannten Dataset gut funktioniert.

62
00:03:15,710 --> 00:03:20,715
So wissen wir, ob das Modell 
mit neuen Datenpunkten gut generalisiert.

63
00:03:20,905 --> 00:03:24,060
Das kann das Generieren 
von realen Daten ersetzen.

64
00:03:24,060 --> 00:03:26,950
Sehen wir uns wieder 
das lineare Regressionsmodell

65
00:03:26,950 --> 00:03:29,900
und die Modelle mit 
den neuronalen Netzwerken an.

66
00:03:30,420 --> 00:03:33,415
Das lineare Regressionsmodell 
generalisiert ziemlich gut

67
00:03:33,415 --> 00:03:35,010
mit den neuen Datenpunkten.

68
00:03:35,010 --> 00:03:37,760
Der RMSE ist so
ähnlich wie im Beispiel davor,

69
00:03:37,760 --> 00:03:39,925
was in diesem Fall sehr gut ist.

70
00:03:39,925 --> 00:03:45,290
Modelle sollten bei Training und 
Validierung konsistente Leistung erzielen.

71
00:03:45,850 --> 00:03:48,920
Wir sehen, dass das zweite 
Modell überhaupt nicht gut

72
00:03:48,920 --> 00:03:51,580
mit dem neuen 
Trainingsdesign generalisiert.

73
00:03:51,580 --> 00:03:54,770
Der RMSE ist von 0 auf 3,2 angestiegen.

74
00:03:54,770 --> 00:03:57,240
Das ist sehr 
problematisch und zeigt,

75
00:03:57,240 --> 00:04:01,160
dass sich das Modell 
an das Trainingsdataset überangepasst hat

76
00:04:01,160 --> 00:04:05,375
und mit neuen Daten nicht 
belastbar oder generalisierbar war.

77
00:04:05,805 --> 00:04:09,435
Wie kann man dafür sorgen, 
dass sich das Modell nicht überanpasst?

78
00:04:09,435 --> 00:04:11,930
Wann sollte das Training beendet werden?

79
00:04:11,930 --> 00:04:14,255
Die Antwort ist überraschend einfach:

80
00:04:14,255 --> 00:04:16,670
Die Daten müssen aufgeteilt werden.

81
00:04:16,670 --> 00:04:20,845
Indem Sie das Dataset in
separate Gruppen aufteilen,

82
00:04:20,845 --> 00:04:24,270
können Sie Ihr Modell entweder 
neu trainieren und dann mit dem

83
00:04:24,270 --> 00:04:28,190
Trainings-Dataset trainieren 
und die Leistung mit einem unabhängigen,

84
00:04:28,190 --> 00:04:31,545
im Silo gespeicherten
Validierungsdataset zu vergleichen.

85
00:04:31,715 --> 00:04:33,805
Modelle, die gut generalisieren,

86
00:04:33,805 --> 00:04:38,165
haben ähnliche Verlust- und 
Fehlerwerte beim Training und Validieren.

87
00:04:38,325 --> 00:04:39,890
Sobald Ihre Modelle mit dem

88
00:04:39,890 --> 00:04:42,405
Validierungsdataset 
schlechter funktionieren,

89
00:04:42,405 --> 00:04:45,535
z. B. wenn
die Verlustwerte langsam ansteigen,

90
00:04:45,535 --> 00:04:47,080
sollten Sie abbrechen.

91
00:04:47,390 --> 00:04:51,400
Trainieren und Auswerten von Modellen
bedeutet, das richtige generalisierbare

92
00:04:51,400 --> 00:04:53,700
Modell und zudem 
Modellparameter zu finden,

93
00:04:53,700 --> 00:04:56,745
die ohne Speicherung
an Ihr Trainingsdataset angepasst sind.

94
00:04:56,745 --> 00:04:58,770
Hier sehen Sie ein vereinfachtes

95
00:04:58,770 --> 00:05:02,850
Linearmodell, das nicht an die 
Beziehungen in den Daten angepasst ist.

96
00:05:02,850 --> 00:05:05,180
Das können Sie 
mit bloßem Auge erkennen.

97
00:05:05,180 --> 00:05:08,580
Sie sehen, dass viele 
Punkte außerhalb der Trendlinie liegen.

98
00:05:08,580 --> 00:05:10,840
Das wird als Unteranpassung bezeichnet.

99
00:05:11,250 --> 00:05:13,630
Am anderen Ende des Spektrums

100
00:05:13,630 --> 00:05:16,330
und noch gefährlicher ist Überanpassung.

101
00:05:16,330 --> 00:05:18,700
Dies wird am rechten Extrem gezeigt.

102
00:05:18,890 --> 00:05:21,550
Die Komplexität 
des Linearmodells wurde vergrößert.

103
00:05:21,550 --> 00:05:24,600
Es wird anhand eines 
Polynomials n-ten Grades interpretiert.

104
00:05:24,600 --> 00:05:28,960
Das hilft dem Modell, sich an die Daten
und kleinen Abweichungen anzupassen.

105
00:05:28,960 --> 00:05:31,645
Hier kommt 
das Evaluierungsdataset ins Spiel.

106
00:05:31,645 --> 00:05:34,805
Sie können bestimmen, 
ob die Parameter zu Überanpassung führen.

107
00:05:34,805 --> 00:05:36,075
Ist es zu komplex?

108
00:05:36,075 --> 00:05:38,980
Überanpassung oder 
gespeicherte Daten im Trainings-Dataset

109
00:05:38,980 --> 00:05:42,445
sind schlimmer als ein Modell,
das mittelmäßig an Daten angepasst ist.

110
00:05:42,445 --> 00:05:44,750
Manchmal wissen Sie 
erst bei der Produktion,

111
00:05:44,750 --> 00:05:46,145
was genau validiert wurde.

112
00:05:46,345 --> 00:05:51,690
Das richtige Maß an Modellkomplexität
liegt zwischen Unter- und Überanpassung.

113
00:05:52,060 --> 00:05:55,320
Sehen wir uns an, wie wir 
mit dem Validierungs-Dataset erkennen,

114
00:05:55,320 --> 00:05:59,250
wann wir das Training beenden sollten,
um eine Überanpassung zu verhindern.