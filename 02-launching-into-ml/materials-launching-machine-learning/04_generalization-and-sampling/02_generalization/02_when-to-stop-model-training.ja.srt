1
00:00:00,000 --> 00:00:03,415
線形回帰とニューラルネットワークの

2
00:00:03,415 --> 00:00:07,035
2つのMLモデルのどちらがいいか
選ぶ場合のみでなく

3
00:00:07,035 --> 00:00:09,850
1つのモデルのハイパーパラメータの
微調整にも

4
00:00:09,850 --> 00:00:12,160
評価用データセットを使えます

5
00:00:12,160 --> 00:00:15,750
ハイパーパラメータは
トレーニング前に設定しましたね

6
00:00:15,765 --> 00:00:19,330
この調整プロセスでは
連続してトレーニングを行い

7
00:00:19,330 --> 00:00:23,415
トレーニングの結果を
別の評価用データセットを使った結果と

8
00:00:23,415 --> 00:00:26,470
比較して過学習をチェックします

9
00:00:26,470 --> 00:00:30,945
トレーニング中に評価セットを
どのように使用するか説明します

10
00:00:30,945 --> 00:00:33,225
最適化で説明したように

11
00:00:33,225 --> 00:00:36,470
モデルのトレーニングでは
まずランダムな重みを計算し

12
00:00:36,470 --> 00:00:40,625
微分を計算し 勾配降下法で損失の曲線を
降下しながら確認し

13
00:00:40,625 --> 00:00:43,290
損失の指標を最小化する
これを繰り返します

14
00:00:43,290 --> 00:00:46,960
また 定期的に
モデルのパフォーマンスを評価します

15
00:00:46,960 --> 00:00:50,125
評価ではトレーニングで
未使用のデータを使います

16
00:00:50,125 --> 00:00:52,735
つまり評価用データセットです

17
00:00:52,735 --> 00:00:54,985
トレーニングが完了したら

18
00:00:54,985 --> 00:00:58,130
評価用データセットでモデルの結果を評価して

19
00:00:58,130 --> 00:01:00,420
ハイパーパラメータが適切なのか

20
00:01:00,420 --> 00:01:03,320
もう少し調整するのか確認します

21
00:01:03,320 --> 00:01:07,130
トレーニングと評価用データセットの
損失指標に

22
00:01:07,130 --> 00:01:09,400
大きな違いがなければ

23
00:01:09,400 --> 00:01:13,520
ハイパーパラメータをもう少し最適化できます

24
00:01:13,520 --> 00:01:16,530
さて モデルの損失指標が十分最適化されて

25
00:01:16,530 --> 00:01:19,500
評価用データセットでも問題がなくなりました

26
00:01:19,500 --> 00:01:24,221
評価用データセットの結果が乖離し始め
かつモデルが過学習でない状態

27
00:01:24,221 --> 00:01:26,940
そこが止めるタイミングです

28
00:01:26,940 --> 00:01:29,970
本番用のモデルの調整ができました

29
00:01:29,970 --> 00:01:32,210
これに似たループを使って

30
00:01:32,210 --> 00:01:35,525
モデルごとにどのパラメータがいいのか
調べることもできます

31
00:01:35,525 --> 00:01:38,860
トレーニングの前に設定した
ハイパーパラメータと同じです

32
00:01:38,860 --> 00:01:42,500
たとえば 使用するネットワーク層や
ノード数を調べます

33
00:01:42,500 --> 00:01:46,340
ニューラルネットワークで たとえば6個のノードを
1つの設定としてトレーニングします

34
00:01:46,340 --> 00:01:48,630
さらに別の設定でトレーニングして

35
00:01:48,630 --> 00:01:51,880
評価用データセットでどちらの設定が
優れているか確認します

36
00:01:51,880 --> 00:01:57,065
最終的に 評価用データセットで
損失が少ない設定を選びます

37
00:01:57,065 --> 00:02:01,255
トレーニングデータセットで
損失が少ない設定ではありません

38
00:02:01,255 --> 00:02:03,050
この専門分野の後半では

39
00:02:03,050 --> 00:02:05,740
Cloud ML Engineがベイズ検索を

40
00:02:05,740 --> 00:02:08,919
ハイパーパラメータ空間で行う方法を
お見せします

41
00:02:08,919 --> 00:02:13,490
これでハイパーパラメータを
一つ一つ実験する必要がなくなります

42
00:02:13,490 --> 00:02:16,140
Cloud ML Engineによって

43
00:02:16,140 --> 00:02:20,945
さまざまな最適化戦略を使いながら
このような実験を並行して行えます

44
00:02:20,945 --> 00:02:23,110
トレーニングが完了したら

45
00:02:23,110 --> 00:02:27,165
上司にモデルのパフォーマンスを
報告しなければなりません

46
00:02:27,165 --> 00:02:31,365
成功と失敗の最終評価に
どのデータセットを使ったらよいでしょうか？

47
00:02:31,365 --> 00:02:34,880
評価用データセットでの損失や誤差のみを
報告しますか？

48
00:02:34,880 --> 00:02:38,155
トレーニングでの損失や誤差と同じ場合でも？

49
00:02:38,155 --> 00:02:40,920
それはできません なぜなら

50
00:02:40,920 --> 00:02:43,420
評価用データセットを使って

51
00:02:43,420 --> 00:02:46,795
トレーニングを止める時を決めたからです

52
00:02:46,795 --> 00:02:49,260
つまり もう独立したデータではありません

53
00:02:49,260 --> 00:02:51,415
モデルが見てしまいました

54
00:02:51,415 --> 00:02:54,165
ではどうすればよいでしょうか？

55
00:02:54,165 --> 00:02:56,960
データを3つに分割するのです

56
00:02:56,960 --> 00:03:01,985
トレーニング用、評価用
新たに分けたテスト用です

57
00:03:01,985 --> 00:03:05,640
モデルのトレーニングと評価が完了したら

58
00:03:05,640 --> 00:03:09,910
たった一度だけ
テスト用データセットでモデルを実行します

59
00:03:09,910 --> 00:03:12,350
この損失指標を上司に報告します

60
00:03:12,350 --> 00:03:15,000
テスト用データセットの
損失指標で

61
00:03:15,000 --> 00:03:17,665
このモデルを本番で使うかどうかを
決めるのです

62
00:03:17,665 --> 00:03:20,780
テスト用データセットで失敗したら
どうなるでしょうか

63
00:03:20,780 --> 00:03:22,500
評価は成功しているのにです

64
00:03:22,500 --> 00:03:24,950
同じMLモデルは再テストできません

65
00:03:24,950 --> 00:03:29,115
まったく新しい機械学習モデルを
再トレーニングするか

66
00:03:29,115 --> 00:03:30,520
振り出しに戻って

67
00:03:30,520 --> 00:03:35,035
データサンプルをもっと集めて
MLモデルに新しいデータを提供します

68
00:03:35,035 --> 00:03:37,215
これは良いアプローチですが

69
00:03:37,215 --> 00:03:39,070
小さな問題が1つあります

70
00:03:39,070 --> 00:03:43,430
1 回しか使っていないテスト用データは
事実上 無駄になってしまいました

71
00:03:43,430 --> 00:03:46,110
これをホールドアウト法と言います

72
00:03:46,110 --> 00:03:48,740
すべてのデータをトレーニングで使いながら

73
00:03:48,740 --> 00:03:52,180
モデルのパフォーマンスの
妥当な指標を得ることはできないのでしょうか

74
00:03:52,180 --> 00:03:53,290
実はできます

75
00:03:53,290 --> 00:03:55,330
これらの方法の妥協策として

76
00:03:55,330 --> 00:03:59,185
トレーニング用と評価用を分割し
それを複数回行います

77
00:03:59,185 --> 00:04:02,825
トレーニングしてから
評価用データセットで損失を計算します

78
00:04:02,825 --> 00:04:04,340
この評価用セットは

79
00:04:04,340 --> 00:04:08,060
最初にトレーニングで使っていないデータから
構成されます

80
00:04:08,060 --> 00:04:10,210
それからデータをもう一度分割します

81
00:04:10,210 --> 00:04:12,230
このトレーニング用データには

82
00:04:12,230 --> 00:04:15,935
最初の評価を行った時に
使ったデータも含まれることがあります

83
00:04:15,935 --> 00:04:17,874
それでも複数回繰り返します

84
00:04:17,874 --> 00:04:20,180
最終的にこれを何回か繰り返すと

85
00:04:20,180 --> 00:04:23,645
全体的に評価の損失指標が平均化されます

86
00:04:23,645 --> 00:04:26,140
そして評価の損失の標準偏差が得られます

87
00:04:26,140 --> 00:04:29,510
これでばらつきを分析し
最終的な数値を得ます

88
00:04:29,510 --> 00:04:33,075
これをブートストラップや
クロスバリデーションと呼びます

89
00:04:33,075 --> 00:04:36,110
この方法のメリットはすべてのデータを
使えることです

90
00:04:36,110 --> 00:04:38,200
ただし 分割データを多数作るので

91
00:04:38,200 --> 00:04:40,520
何度もトレーニングする必要があります

92
00:04:40,520 --> 00:04:42,105
最後に復習です

93
00:04:42,105 --> 00:04:43,735
データが多い場合は

94
00:04:43,735 --> 00:04:48,070
完全に独立したホールドアウト法の
テスト用データセットを使います

95
00:04:48,070 --> 00:04:50,180
これで成功か失敗か判断できます

96
00:04:50,180 --> 00:04:51,720
データが多くない場合は

97
00:04:51,720 --> 00:04:54,700
クロスバリデーションを使います

98
00:04:54,700 --> 00:04:57,000
では 大きなデータセットを

99
00:04:57,000 --> 00:05:01,245
分割するにはどうしたらいいでしょうか？

100
00:05:01,245 --> 00:05:05,000
それが次のレッスン「サンプリング」です