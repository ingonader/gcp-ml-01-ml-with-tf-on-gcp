1
00:00:00,610 --> 00:00:02,280
Bienvenue, je m'appelle Evan Jones.

2
00:00:02,280 --> 00:00:04,710
Je crée des formations techniques
pour Google Cloud.

3
00:00:04,710 --> 00:00:06,330
Je suis passionné par le big data.

4
00:00:06,920 --> 00:00:08,595
Continuons notre découverte du ML

5
00:00:08,595 --> 00:00:10,670
avec la généralisation
et l'échantillonnage.

6
00:00:11,710 --> 00:00:14,910
Jusqu'ici, nous avons parlé
de l'entraînement de modèle

7
00:00:14,910 --> 00:00:18,473
et testé ce processus
dans TensorFlow Playground.

8
00:00:19,923 --> 00:00:23,349
Il est temps de répondre
à une question plutôt étrange.

9
00:00:23,649 --> 00:00:27,584
Quand ne doit-on pas choisir
le modèle de ML le plus juste ?

10
00:00:27,954 --> 00:00:30,669
Comme mentionné dans le dernier
module sur l'optimisation,

11
00:00:30,669 --> 00:00:33,477
ce n'est pas parce qu'un modèle
a une métrique de perte de 0

12
00:00:33,477 --> 00:00:35,479
pour un ensemble
de données d'entraînement,

13
00:00:35,479 --> 00:00:38,377
qu'il enregistrera de bons résultats
avec de nouvelles données

14
00:00:38,377 --> 00:00:39,081
du monde réel.

15
00:00:39,931 --> 00:00:43,179
Le meilleur modèle de ML
n'est pas forcément

16
00:00:43,179 --> 00:00:46,799
celui qui enregistre les meilleurs
résultats avec vos données d'entraînement,

17
00:00:46,799 --> 00:00:50,319
mais celui qui enregistre les meilleurs
résultats avec les données cachées.

18
00:00:50,319 --> 00:00:54,039
Vous devez avant tout vous intéresser
à la performance du modèle en production.

19
00:00:54,039 --> 00:00:57,039
Et cela inclut des données
que votre modèle n'a pas encore vues.

20
00:00:57,039 --> 00:01:00,320
Quelle est la performance de votre modèle
avec des données inconnues ?

21
00:01:00,320 --> 00:01:03,370
Vous devez choisir des données
qui ne sont pas montrées au modèle

22
00:01:03,370 --> 00:01:04,470
pendant l'entraînement.

23
00:01:04,470 --> 00:01:06,669
Et après l'entraînement du modèle,

24
00:01:06,669 --> 00:01:09,490
vous pouvez l'évaluer
avec ces données cachées.

25
00:01:10,370 --> 00:01:13,460
Vous apprendrez à évaluer
si votre modèle est en surapprentissage,

26
00:01:13,460 --> 00:01:16,660
et à reconnaître quand arrêter
l'entraînement d'un modèle.

27
00:01:17,370 --> 00:01:19,430
La deuxième partie
de ce module vous indique

28
00:01:19,430 --> 00:01:22,240
comment créer cet ensemble de données.

29
00:01:22,680 --> 00:01:27,500
Vous n'avez pas de données inconnues,
mais vous avez des données d'entraînement,

30
00:01:27,500 --> 00:01:31,460
que vous pouvez séparer en deux ensembles
de données d'entraînement et d'évaluation.

31
00:01:31,810 --> 00:01:35,140
Vous pouvez ensuite entraîner votre modèle
avec un ensemble de données,

32
00:01:35,140 --> 00:01:38,670
puis mesurer les performances
du modèle dans le monde réel

33
00:01:38,670 --> 00:01:41,580
par rapport à un ensemble
de données de test ou d'évaluation.

34
00:01:41,981 --> 00:01:47,171
Vous allez apprendre à créer ces ensembles
de test, d'évaluation et d'entraînement,

35
00:01:47,171 --> 00:01:49,981
et à établir
des indicateurs de performance.