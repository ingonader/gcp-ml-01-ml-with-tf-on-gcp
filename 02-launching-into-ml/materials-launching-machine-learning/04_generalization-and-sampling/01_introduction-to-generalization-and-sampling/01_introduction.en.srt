1
00:00:00,610 --> 00:00:04,890
Welcome back, I'm Evan Jones, a technical
curriculum developer for Google Cloud, and

2
00:00:04,890 --> 00:00:07,000
I love all things big data.

3
00:00:07,000 --> 00:00:10,620
Let's continue launching into ML
with generalization and sampling.

4
00:00:11,760 --> 00:00:14,785
Now so far in this course,
we've discussed ML model training and

5
00:00:14,785 --> 00:00:18,340
experimented with model training
inside of that Tensor Flow playground.

6
00:00:19,800 --> 00:00:23,690
So now it's time to answer
a rather weird question.

7
00:00:23,690 --> 00:00:27,973
When is the most accurate ML
model not the right one to pick?

8
00:00:27,973 --> 00:00:30,859
And as we hinted at in the last
model on optimization,

9
00:00:30,859 --> 00:00:35,224
simply because a model has a loss metric
of zero for your training dataset does not

10
00:00:35,224 --> 00:00:38,969
mean that it'll perform well on new
data out there in the real world.

11
00:00:40,100 --> 00:00:44,628
Now what you've got to realize is that the
best ML model is not necessarily the one

12
00:00:44,628 --> 00:00:47,690
that performs best on just
your training dataset, but

13
00:00:47,690 --> 00:00:50,438
it's the one that performs
best on unseen data.

14
00:00:50,438 --> 00:00:53,982
Your main concern should be how well
your model performs in production.

15
00:00:53,982 --> 00:00:57,010
And this implies data that
your model has yet to see.

16
00:00:57,010 --> 00:01:00,280
So how well would your model
perform on unknown data?

17
00:01:00,280 --> 00:01:03,270
Well, first you need to get some
data that’s not shown to the model

18
00:01:03,270 --> 00:01:04,540
during training.

19
00:01:04,540 --> 00:01:06,400
And after you successfully
train the model,

20
00:01:06,400 --> 00:01:10,520
you can then evaluate it
on this held-out dataset.

21
00:01:10,520 --> 00:01:14,550
You’ll learn how to assess whether or
not your model is overfitting, and

22
00:01:14,550 --> 00:01:17,350
how to gauge when to actually
stop model training.

23
00:01:17,350 --> 00:01:21,169
Now, the second part of this module is how
you can create this unknown dataset in

24
00:01:21,169 --> 00:01:22,790
the first place.

25
00:01:22,790 --> 00:01:27,060
Naturally, you don’t have unknown data,
but what you do have is a training

26
00:01:27,060 --> 00:01:31,980
dataset, that you can then split into
separate training and evaluation datasets.

27
00:01:31,980 --> 00:01:34,890
You can then experiment and
train your model with one dataset.

28
00:01:34,890 --> 00:01:37,850
And then when you're ready,
you can measure the model performance

29
00:01:37,850 --> 00:01:40,710
in the real world against an evaluation or
test dataset.

30
00:01:42,080 --> 00:01:45,960
So you learn actually how to create
these repeatable training evaluation and

31
00:01:45,960 --> 00:01:49,400
test datasets and
actually establish performance benchmarks.