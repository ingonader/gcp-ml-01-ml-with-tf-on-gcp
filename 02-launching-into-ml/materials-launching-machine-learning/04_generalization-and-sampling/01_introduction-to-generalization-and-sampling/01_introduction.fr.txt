Bienvenue, je m'appelle Evan Jones. Je crée des formations techniques
pour Google Cloud. Je suis passionné par le big data. Continuons notre découverte du ML avec la généralisation
et l'échantillonnage. Jusqu'ici, nous avons parlé
de l'entraînement de modèle et testé ce processus
dans TensorFlow Playground. Il est temps de répondre
à une question plutôt étrange. Quand ne doit-on pas choisir
le modèle de ML le plus juste ? Comme mentionné dans le dernier
module sur l'optimisation, ce n'est pas parce qu'un modèle
a une métrique de perte de 0 pour un ensemble
de données d'entraînement, qu'il enregistrera de bons résultats
avec de nouvelles données du monde réel. Le meilleur modèle de ML
n'est pas forcément celui qui enregistre les meilleurs
résultats avec vos données d'entraînement, mais celui qui enregistre les meilleurs
résultats avec les données cachées. Vous devez avant tout vous intéresser
à la performance du modèle en production. Et cela inclut des données
que votre modèle n'a pas encore vues. Quelle est la performance de votre modèle
avec des données inconnues ? Vous devez choisir des données
qui ne sont pas montrées au modèle pendant l'entraînement. Et après l'entraînement du modèle, vous pouvez l'évaluer
avec ces données cachées. Vous apprendrez à évaluer
si votre modèle est en surapprentissage, et à reconnaître quand arrêter
l'entraînement d'un modèle. La deuxième partie
de ce module vous indique comment créer cet ensemble de données. Vous n'avez pas de données inconnues,
mais vous avez des données d'entraînement, que vous pouvez séparer en deux ensembles
de données d'entraînement et d'évaluation. Vous pouvez ensuite entraîner votre modèle
avec un ensemble de données, puis mesurer les performances
du modèle dans le monde réel par rapport à un ensemble
de données de test ou d'évaluation. Vous allez apprendre à créer ces ensembles
de test, d'évaluation et d'entraînement, et à établir
des indicateurs de performance.