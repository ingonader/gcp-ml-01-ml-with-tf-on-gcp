理論を説明し
SQLのコードも少し確認しましたが BigQuery内でいくつも実行することで データセットをバケットに分割する方法の
知識を固められます ただ モジュロ演算子のコードや
SQLのWHERE節によるデータ分割を実践する前に その方法を詳しく見ていきましょう この図をご覧ください 合計7,000万件のフライトです
もっと大きなデータセットの場合もあります とにかくこの大きなデータセットを 繰り返し可能な方法で
小さくしましょう 単純なランダムのサンプリングは使えません WHERE節のフィルターを使う方法を
お見せします ここで1～2%取るとしましょう オレンジのボックスが約1%です
これを分割します この1%の50%を トレーニング用データにしましょう 残りの50%を
評価用データセットにして 評価用データセットの半分を
テスト用データセットにします これでモデルの成功または失敗を
チェックします Google BigQuery内では
どのように機能するでしょうか このコードは今後のプロジェクトで利用できます
では見てみましょう Google BigQuery内に あらかじめクエリを作成しておきました 手順を順番にお見せしましょう これがGoogle BigQueryの
インターフェースです すでにご覧になっているかもしれません まず 各フライトの行が
7,000万行あることがわかりますが ソースデータテーブルの情報を
もう少し取得します [show]オプション内で
[legacy SQL]を無効にしてください これでCommandまたはWindowsキーを押す
機能が使えるようになります SQL内の任意の場所で
テーブルをクリックすると テーブルの詳細にすばやくアクセスできます ご覧のように
ここにすべてのフィールドがあり 詳細をクリックすると フライトのレコード数を確認できます ここでデータセット内の
7,000万件のフライトを取得できます ただし1ギガバイトあります このデータセットはプレビューして
確認できます これは各フライトの日付 出発空港 他にも出発場所などの
運行に関するさまざまな情報を確認できます さて 基本的なフィールドのデータを取り出し
プレビューしましたが さらに3つを追加しました 次に 17行目のWHERE節の下で
フィルタリングを行いますが その前に このサンプルをお見せします コードをハイライト表示し
下矢印をクリックして クエリを実行します これにより この日が何なのかがわかります これをご覧ください 2008年6月30日です 以前に説明したとおり
これがFARM_FINGERPRINT関数の動作です 日付の文字列を取得して連続する数字に変えます 一方向のハッシュ関数です この数字は後でいろいろと利用できます どの場合でも2008年6月30日は
必ず同じ値になるので とても便利です このようにFARM_FINGERPRINTを使った
ハッシュが完了しました 5行目と6行目で1つ違うのは ハッシュが70で割り切れるか
700で割り切れるか確認した点です これを使う理由は 余りが0になる値で
レコードを70件毎に1件取り出すためです これにより7,000万のフライトの
1～2%をフィルターして サブデータセットに使います ご覧のように 70で割った余りを示したフィールドがあり これが0になるレコードが
70件毎に1件あります これを最初のフィルターに設定します わかりやすいように
LIMITを下に移動しますね SQLレコードのフィルタリングは
15行目からのWHERE節で行います ここにコメントがありますね 70行毎に1行取得します 先ほど下のフィールドで見たように
70で割った余りが0に等しいです 次にLIMIT 10を含めて実行します この列に表示される 70で割った余りの値が
すべて0になるはずです できました これで98%のデータを
無視することに成功しました 次に進みましょう 最初に紹介した図を思い出してください データセットの分割の図です あのオレンジのボックスに当たる
84万2,000行を取得できました これがトレーニング用データセットです ご存じのように トレーニング用、評価用、
さらにテスト用データセットを作成するため 追加でフィルタリングする必要があります 70で割った余りは濫用できないので 7で割った余りなどは使えません これはすでに0です すでに一度使っています そこで2つめのフィルタリング処理を行います ここでは700を使います
70と700の違いは データセットを分割するために
作成したいバケットのサイズで決まります さて 98%減らしたデータセットの
残り80万件のレコードを分割して 評価用、テスト用のデータセットを作成し
最初に作ったトレーニング用と分けます そのために WHERE節に別のフィルターを追加して 残りのデータセットの
50%を無視します これがどんなふうになるか
お見せしましょう 今度はこの列を使います
700で割った余りです この2番目のモジュロ演算の値は
0と700の間のどれかになります このどれかを取りましょう 0から700のセットを考えます 0と700の中間点は350です つまり 0〜350の間 と 350〜700の間に
レコードを分割します そのために「350以上」と記述します この630という数字は350より大きいので
ここに含まれているわけです ここは納得できる瞬間でもあります この日付を見てください これらはすべて2005年7月13日に
発生したフライトですが 完全に同じハッシュです ここは非常に面白い部分ですが
こういうものを扱うときの 難しい部分でもあります 講座の少し前で触れたように データセットが2日間のデータだとします たとえば2005年7月13日と
2005年7月14日なら 80-20に分割することはできません この2つのハッシュしか
ここに存在しないからです こういうわけで
ノイズの多いデータセットや 分散が十分なデータセットを用意してから
分割を行うよう勧めています ハッシュはランダム関数と異なり
常に同じ値を返すからです では 最後にこのサブセットを
さらに分割して 50%だけ含むようにします これはトレーニング用データ全体の
25%にあたりますが これをテスト用に取っておきます そのためにもう一度 中間点で処理します 今回は「525未満」と記述します 350と700の中間点は525だからです そのため 525未満のレコードを取り出すと 元のトレーニング用データセットの
25%になります ここで一番大変なのはSQL構文ではなく 心の中でこれらの境界線の
イメージを描くことです そして使用する中間点やハッシュ関数を
決めることです では最後に 10件だけのレコードを
お見せしましょう これらはすべて70で割り切れるので ここで0を確認できます そして700で割った余りを使って 最終的なテスト用データセットを作成します これはトレーニングデータの25%で
テスト用のホールドアウトとして使います これらの値は
350以上525未満です ここに420の値がありますね もう一方のデータセットに
アクセスしたい場合は？ つまり525から700の値にアクセスしたいときは ここの記号をひっくり返して
「525より大きい」にします これで トレーニング用、評価用、テスト用の
データができました ではこれらをインポートして
機械学習モデルに取り込んでみましょう これはラボでたくさん練習します また落し穴もいくつかでてきます ただ ここで学んだことが
基本的な概念です では次に進みましょう