1
00:00:00,650 --> 00:00:03,600
Analizamos este tema en teoría
y vimos un poco de código en SQL

2
00:00:03,600 --> 00:00:06,860
pero ejecutarlo en BigQuery
ayudará a solidificar sus conocimientos

3
00:00:06,860 --> 00:00:09,395
sobre cómo dividir estos conjuntos
de datos en grupos.

4
00:00:09,395 --> 00:00:11,990
Antes de hacerlo
y de que comiencen a ver mucho código

5
00:00:11,990 --> 00:00:14,105
de operaciones módulo
y dividir los conjuntos

6
00:00:14,105 --> 00:00:17,280
mediante una instrucción SQL WHERE,
hablemos sobre cómo exactamente

7
00:00:17,280 --> 00:00:18,610
dividiremos este conjunto.

8
00:00:18,610 --> 00:00:22,150
Como ven en la imagen,
tenemos 70 millones de vuelos en total.

9
00:00:22,150 --> 00:00:24,180
Podría ser un conjunto
de datos muy grande

10
00:00:24,180 --> 00:00:27,050
podría ser incluso 7,000 millones,
pero lo que debemos hacer

11
00:00:27,050 --> 00:00:29,485
es reducir un poco ese conjunto
de forma repetible.

12
00:00:29,485 --> 00:00:31,940
No podemos usar un muestreo
aleatorio simple.

13
00:00:31,940 --> 00:00:35,200
Debemos usar filtros inteligentes
de instrucciones WHERE, como verán.

14
00:00:35,200 --> 00:00:38,080
Definiremos 1% o 2%,
como ven aquí en el cuadro naranja

15
00:00:38,080 --> 00:00:42,530
y, luego, reduciremos ese 1% al 50%
para asociar el cuadro naranja

16
00:00:42,530 --> 00:00:45,405
a nuestros datos de entrenamiento.

17
00:00:45,405 --> 00:00:48,690
El 50% puede ser nuestro conjunto
de validación y el resto

18
00:00:48,690 --> 00:00:53,130
o la mitad del conjunto de validación
puede ser para el conjunto de prueba.

19
00:00:53,130 --> 00:00:55,890
Recuerden, ese conjunto
para la decisión de proceder o no.

20
00:00:55,890 --> 00:00:58,105
¿Cómo funciona eso en Google BigQuery?

21
00:00:58,105 --> 00:01:00,620
Pueden usar este código
en proyectos futuros.

22
00:01:00,620 --> 00:01:01,870
Veamos.

23
00:01:02,580 --> 00:01:05,930
En BigQuery,
tengo esta consulta ya preparada

24
00:01:05,930 --> 00:01:07,950
pero los guiaré por cada paso.

25
00:01:07,950 --> 00:01:11,260
Esta es la interfaz de BigQuery;
que posiblemente hayan visto antes.

26
00:01:11,260 --> 00:01:15,270
Lo primero que quiero hacer,
aunque dice que hay 70 millones de filas

27
00:01:15,270 --> 00:01:18,085
o vuelos individuales,
quiero obtener más información

28
00:01:18,085 --> 00:01:20,510
sobre mi tabla de fuente de datos.

29
00:01:20,510 --> 00:01:24,840
En "Show options", asegúrense
de que "Legacy SQL" esté inhabilitado.

30
00:01:25,840 --> 00:01:30,430
Eso les permite mantener
presionada la tecla Command o Windows

31
00:01:32,840 --> 00:01:34,520
y hacer clic en la tabla.

32
00:01:34,520 --> 00:01:38,110
Es una vía rápida en cualquier parte
de SQL para obtener acceso

33
00:01:38,110 --> 00:01:39,510
a los detalles de la tabla.

34
00:01:39,510 --> 00:01:42,610
Aquí pueden ver todos los campos.
Si hacen clic en "Details"

35
00:01:42,610 --> 00:01:45,815
les mostrará la cantidad
de registros que hay en el vuelo.

36
00:01:45,815 --> 00:01:48,880
Aquí se ven los 70 millones
de diferentes vuelos en este conjunto

37
00:01:48,880 --> 00:01:51,760
cerca de 8 GB
y pueden obtener una vista previa

38
00:01:51,760 --> 00:01:53,405
del conjunto, si desean.

39
00:01:53,405 --> 00:01:56,960
Aquí están las diferentes fechas
de vuelos, los aeropuertos de salida

40
00:01:56,960 --> 00:01:59,190
y muchos otros datos útiles

41
00:01:59,190 --> 00:02:01,905
que podrían esperar
de un conjunto de datos de vuelos.

42
00:02:01,905 --> 00:02:04,750
Además de esos campos genéricos
que obtenemos de estos datos

43
00:02:04,750 --> 00:02:08,770
que visualizamos aquí,
agregué tres más.

44
00:02:08,770 --> 00:02:11,960
Lo que haré antes de comenzar a filtrar

45
00:02:11,960 --> 00:02:15,380
como pueden ver en la línea 17,
con ese filtro de la instrucción WHERE

46
00:02:15,380 --> 00:02:19,220
les mostraré una muestra de esto.
Pueden ejecutar código

47
00:02:19,220 --> 00:02:22,265
en el bloque destacado
mediante la flecha hacia abajo

48
00:02:22,265 --> 00:02:23,995
y ejecutar esa consulta allí.

49
00:02:24,365 --> 00:02:31,065
Lo que esto hará es mostrarles este día.

50
00:02:31,885 --> 00:02:32,980
Veamos este.

51
00:02:32,980 --> 00:02:36,725
Es el 30 de junio de 2008
y, como mencioné antes en este ejemplo

52
00:02:36,725 --> 00:02:40,110
esto es lo que hace una función
FARM_FINGERPRINT.

53
00:02:40,110 --> 00:02:45,355
Toma esta cadena y la convierte
en una secuencia de números.

54
00:02:45,355 --> 00:02:51,320
Es una función hash de una vía,
que podemos usar como queramos

55
00:02:51,320 --> 00:02:56,400
pero, en los casos en que 30 de junio
de 2008 esté escrito de esta manera

56
00:02:56,400 --> 00:02:58,945
se aplicará el hash
con este valor específico

57
00:02:58,945 --> 00:03:02,425
lo que es muy útil
y, luego de hacer el hash, como ven aquí

58
00:03:02,425 --> 00:03:05,180
con FARM_FINGERPRINT,
lo único que hice diferente

59
00:03:05,180 --> 00:03:09,725
en las líneas 5 y 6
es que queremos ver si el hash

60
00:03:09,725 --> 00:03:15,760
es divisible exactamente por 70 o 700.

61
00:03:16,520 --> 00:03:18,250
La razón por la que usaremos eso

62
00:03:18,250 --> 00:03:23,040
es porque queremos
obtener 1 de 70 registros

63
00:03:23,040 --> 00:03:28,920
en los que el resto sea 0.
Eso formará el 1% o 2% de los 70 millones

64
00:03:29,930 --> 00:03:34,090
de vuelos con filtro amplio
en el subconjunto de datos.

65
00:03:34,090 --> 00:03:36,625
Pueden ver aquí,
tenemos este campo que se llama

66
00:03:36,625 --> 00:03:39,660
"remainder_divide_by_70",
que es igual a 0

67
00:03:39,660 --> 00:03:41,630
lo que sucede en casi 1 de 70 casos

68
00:03:41,630 --> 00:03:45,430
exactamente 1 en 70 casos
y así configuraremos el primer filtro.

69
00:03:45,430 --> 00:03:47,080
Haremos eso exactamente.

70
00:03:47,080 --> 00:03:49,405
Como ven,
moveré este límite aquí abajo

71
00:03:49,405 --> 00:03:51,145
para que puedan familiarizarse.

72
00:03:51,145 --> 00:03:54,865
Los filtros de registros en SQL
se incluyen en la instrucción WHERE

73
00:03:54,865 --> 00:03:57,995
como ven en la línea 15
y como indica el comentario

74
00:03:57,995 --> 00:04:02,175
queremos elegir 1 de 70 filas,
donde, como vieron en este campo

75
00:04:02,175 --> 00:04:05,335
"remainder_divide_by_70",
donde sea igual a cero.

76
00:04:05,335 --> 00:04:06,735
Limitaré los 10.

77
00:04:06,735 --> 00:04:10,915
Verán que cada valor
en la columna "remainder_divide_by_70"

78
00:04:10,915 --> 00:04:12,525
ahora debería ser cero.

79
00:04:12,525 --> 00:04:13,510
Ahí está.

80
00:04:14,285 --> 00:04:19,450
Descartaron, o una mejor forma
de describirlo es ignoraron, el 98%

81
00:04:19,450 --> 00:04:23,250
de los datos correctamente
y ahora lo que queremos hacer…

82
00:04:23,250 --> 00:04:27,060
Logramos, si recuerdan
en la primera imagen, esa reducción

83
00:04:27,060 --> 00:04:30,330
o esa división de los datos
que vieron en la imagen.

84
00:04:30,330 --> 00:04:37,520
Ahora tenemos cerca de 842,000 filas
en ese cuadro naranja que vieron.

85
00:04:37,520 --> 00:04:40,250
Eso es para mi conjunto de datos
de entrenamiento.

86
00:04:40,250 --> 00:04:43,245
Pero si recuerdan,
deben crear un conjunto de entrenamiento

87
00:04:43,245 --> 00:04:47,035
validación y posiblemente uno de prueba,
por lo que debemos aplicar más filtros.

88
00:04:47,035 --> 00:04:49,850
Ahora, no podemos abusar
de "remainder_divide_by_70"

89
00:04:49,850 --> 00:04:52,295
entonces, no podrían hacer
"remainder_divide_by_7".

90
00:04:52,295 --> 00:04:55,110
Porque eso ya es cero,
ya lo usaron una vez.

91
00:04:55,110 --> 00:04:58,350
Por eso tenemos la segunda
operación de filtro en el módulo

92
00:04:58,350 --> 00:05:02,500
en el que usamos los 700.
Usar 70 frente a 700

93
00:05:02,500 --> 00:05:06,860
es arbitrario
según el tamaño de sus grupos

94
00:05:06,860 --> 00:05:11,035
y el tamaño de las divisiones
de datos que quieran crear.

95
00:05:11,035 --> 00:05:14,900
Segundo, reducimos el conjunto
de datos en un 98%

96
00:05:14,900 --> 00:05:18,680
y ahora tenemos que dividir
esos 800,000 registros restantes

97
00:05:18,680 --> 00:05:22,775
en una pared
entre nuestros conjuntos de validación

98
00:05:22,775 --> 00:05:25,630
y prueba, y luego el de entrenamiento
con el que comenzamos.

99
00:05:25,630 --> 00:05:30,435
Lo que debemos hacer ahora
es agregar otro filtro

100
00:05:30,435 --> 00:05:33,020
para la instrucción WHERE

101
00:05:34,490 --> 00:05:38,200
y queremos ignorar el 50%
del conjunto de datos restante.

102
00:05:39,110 --> 00:05:41,680
Les mostraré cómo se ve eso aquí.

103
00:05:41,680 --> 00:05:45,070
Estamos usando esta columna ahora,
"remainder_divide_by_700"

104
00:05:45,740 --> 00:05:52,690
eso puede ser 
entre 0 y 700 para esa segunda operación.

105
00:05:53,210 --> 00:05:56,550
Queremos lo que esté entre…

106
00:05:57,120 --> 00:06:00,160
Si piensan en los conjuntos entre 0 y 700

107
00:06:00,160 --> 00:06:03,710
el punto medio de 0 y 700 es 350.

108
00:06:03,710 --> 00:06:10,250
Entonces, ahora tenemos registros
entre 0 y 350, y 350 y 700.

109
00:06:10,250 --> 00:06:12,840
Dividir en el medio
es exactamente la forma de obtener

110
00:06:12,840 --> 00:06:15,060
este mayor que o igual a 350.

111
00:06:15,397 --> 00:06:19,317
Como ven aquí,
esta cifra 630 es mayor.

112
00:06:19,317 --> 00:06:23,582
Por eso está incluida.
Pero es un momento de descubrimiento.

113
00:06:23,582 --> 00:06:29,535
Vean las fechas aquí,
estos son vuelos del 13 de julio de 2005

114
00:06:29,535 --> 00:06:32,365
tienen exactamente el mismo hash.

115
00:06:32,365 --> 00:06:37,195
Esto es lo interesante
y lo riesgoso de usar algo así

116
00:06:37,195 --> 00:06:40,720
es que, si agregan…
como mencionamos antes en la lección

117
00:06:40,720 --> 00:06:43,520
si tuvieran un conjunto de datos
que solo tuviera dos días

118
00:06:43,520 --> 00:06:48,020
por ejemplo, si solo tuvieran
el 13 y el 14 de julio de 2005

119
00:06:48,020 --> 00:06:52,355
no podrían hacer una división de 80-20
porque solo tendrán estos dos hash

120
00:06:52,355 --> 00:06:54,240
que están aquí.

121
00:06:55,650 --> 00:06:59,130
Por eso, dijimos que deben tener
un conjunto con ruido o bien distribuido

122
00:06:59,130 --> 00:07:02,400
antes de hacer estas divisiones
porque los hash siempre mostrarán

123
00:07:02,400 --> 00:07:05,935
el mismo valor,
a diferencia de una función aleatoria.

124
00:07:06,265 --> 00:07:11,010
Lo último que debemos hacer
es dividir aún más ese subconjunto

125
00:07:11,640 --> 00:07:16,660
para que incluya solo el 50%,
que será el 25% del total de sus datos

126
00:07:16,660 --> 00:07:19,155
de entrenamiento,
que deben reservar para la prueba.

127
00:07:19,155 --> 00:07:22,040
Y luego… de nuevo, están trabajando
con ese punto medio

128
00:07:22,040 --> 00:07:25,125
en este caso en particular,
es cualquiera que sea menor de 525

129
00:07:25,125 --> 00:07:30,100
que es el nuevo punto medio
de 350 a 700, es 525.

130
00:07:30,100 --> 00:07:33,250
Si sacamos ese pedazo de todo
lo que sea menos de 525

131
00:07:33,250 --> 00:07:36,560
tendremos el 25% del conjunto
de datos de entrenamiento original.

132
00:07:36,560 --> 00:07:39,950
Francamente, la parte más difícil
de todo esto no es la sintaxis de SQL

133
00:07:39,950 --> 00:07:43,315
sino hacer el dibujo mental
de cómo formar estos límites

134
00:07:43,315 --> 00:07:47,370
y dónde están esos puntos medios
y esas funciones hash que usarán.

135
00:07:47,370 --> 00:07:52,445
Al final, les mostraré 10 registros,
para que no tengan que esperar.

136
00:07:53,855 --> 00:07:58,205
Todos estos
deberían ser divisibles por 70

137
00:07:58,205 --> 00:08:02,530
deberían ver ceros para todos
en "remainder_divide_by_700"

138
00:08:02,530 --> 00:08:06,010
para obtener el último conjunto
de datos final para prueba.

139
00:08:06,010 --> 00:08:09,500
Este es el 25%
que queremos retener para la prueba.

140
00:08:09,500 --> 00:08:14,990
Todos los valores
deberían ser mayores que o iguales a 350

141
00:08:14,990 --> 00:08:17,710
pero menores que 525
y ven que eso se confirma aquí

142
00:08:17,710 --> 00:08:19,400
con este valor de 420.

143
00:08:19,770 --> 00:08:23,230
¿Qué pasa si queremos 
hacerlo de la manera inversa?

144
00:08:23,230 --> 00:08:28,250
Si quisieran acceder
a los valores entre 525 y 700

145
00:08:28,250 --> 00:08:33,330
simplemente invertirían el signo aquí
para que sea mayor que 525

146
00:08:33,330 --> 00:08:36,460
y luego guardarían los resultados
en tres ubicaciones diferentes

147
00:08:36,460 --> 00:08:40,275
entrenamiento, validación y prueba,
y estarían listos para importarlos

148
00:08:40,275 --> 00:08:42,230
y transferirlos a sus modelos de AA.

149
00:08:42,230 --> 00:08:44,270
Podrán practicar más esto en sus labs

150
00:08:44,270 --> 00:08:47,220
y verán algunas de las dificultades
que se les pueden presentar

151
00:08:47,220 --> 00:08:49,984
pero comprendan que estos
son aspectos básicos.

152
00:08:49,984 --> 00:08:51,994
Muy bien, continuemos.