Hi, I'm Lak, and
I lead the team that has put together the Machine Learning on
Google Cloud Platform Specialization. Welcome to the second course
in this specialization where we launch into Machine Learning. In this course, you will get foundational
machine learning knowledge, so that you understand the terminology that
we use throughout the specialization. You will also learn practical tips and pitfalls from ML practitioners here at
Google and walk away with the code and the knowledge to bootstrap your
own machine learning models. In this course, you will learn about
the different types of Machine Learning models and how the history of Machine
Learning has led to this point where deep learning models are so popular. The training of a deep learning model
usually starts with random weights. How do you initialize these weights and
how do you change those weights so that the model learns? You learn how to optimize
models using loss functions. And you learn how to evaluate those
models using performance metrics. As you learn how model training and
evaluation work, you will also learn about the common problems that can
happen when you do machine learning. And you will learn how to mitigate,
that is, how to reduce the incidence
of those kinds of problems. One of the most common problems
that can happen is a lack of what is called generalization. When you create a machine learning model
and it works well in your experiments. But then fails to perform well
in production, the failure point will often involve how you created
the machine learning data set. So you will learn why you often need
three identically distributed datasets, and how to create them
in a repeatable way. Creating a machine learning dataset is
a practical skill its something that you do not want to short change. Give yourself time to absorb the lessons. So we will start our talking about the
historical evolution of machine learning. From its use in applications
like astronomy to now where it's used widely in commercial
applications to automate many tasks to argument the way
those applications work. For example,
machine learning is used to read house numbers from street view
images to add labels in Google Maps. But while talking about the historical
evolution, we'll also describe how deep learning techniques incorporate
many of those improvements brought on by earlier machine learning methods
like decision trees and random forests. In the optimization model, we will set
up a supervised learning problem and find a solution using gradient descent. Then, we will learn about
performance metrics and how to choose between different models. Finally, we'll wrap up the module by
developing an intuitive understanding of neural networks. You will explore the impact of things
like batch size and learning rate, using a cool tool called
the transfer flow playground. Good machine learning requires
that we create datasets and models that permit generalization. So we will talk about methods of doing so in a repeatable way which
supports experimentation. The entire purpose of machine learning
is to be able to make predictions based on new data. So it's very important that we do not
overfit our models on a historical training data. So if we have a generalized model that's
trained at images of meals, for example, then it should not expect
that all meals are plated and served on ceramic plates
like that dish of spaghetti. It should also be able to recognize
the home-style South Indian dishes on the bottom as also a meal. So that's what we mean by generalization. Just looking at the photograph
has made me hungry. I'll leave you in the great
hands of my colleagues. See you around.