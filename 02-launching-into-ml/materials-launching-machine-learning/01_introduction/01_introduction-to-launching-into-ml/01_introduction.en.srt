1
00:00:00,850 --> 00:00:04,520
Hi, I'm Lak, and
I lead the team that has put together

2
00:00:04,520 --> 00:00:08,140
the Machine Learning on
Google Cloud Platform Specialization.

3
00:00:08,140 --> 00:00:11,020
Welcome to the second course
in this specialization

4
00:00:11,020 --> 00:00:13,340
where we launch into Machine Learning.

5
00:00:13,340 --> 00:00:17,590
In this course, you will get foundational
machine learning knowledge, so

6
00:00:17,590 --> 00:00:21,940
that you understand the terminology that
we use throughout the specialization.

7
00:00:21,940 --> 00:00:24,931
You will also learn practical tips and

8
00:00:24,931 --> 00:00:30,914
pitfalls from ML practitioners here at
Google and walk away with the code and

9
00:00:30,914 --> 00:00:35,886
the knowledge to bootstrap your
own machine learning models.

10
00:00:35,886 --> 00:00:40,718
In this course, you will learn about
the different types of Machine Learning

11
00:00:40,718 --> 00:00:45,550
models and how the history of Machine
Learning has led to this point where deep

12
00:00:45,550 --> 00:00:48,600
learning models are so popular.

13
00:00:48,600 --> 00:00:53,440
The training of a deep learning model
usually starts with random weights.

14
00:00:53,440 --> 00:00:57,939
How do you initialize these weights and
how do you change those weights so

15
00:00:57,939 --> 00:00:59,424
that the model learns?

16
00:00:59,424 --> 00:01:03,820
You learn how to optimize
models using loss functions.

17
00:01:03,820 --> 00:01:08,134
And you learn how to evaluate those
models using performance metrics.

18
00:01:08,134 --> 00:01:12,659
As you learn how model training and
evaluation work, you will also learn

19
00:01:12,659 --> 00:01:17,201
about the common problems that can
happen when you do machine learning.

20
00:01:17,201 --> 00:01:19,900
And you will learn how to mitigate,
that is,

21
00:01:19,900 --> 00:01:23,249
how to reduce the incidence
of those kinds of problems.

22
00:01:24,520 --> 00:01:28,095
One of the most common problems
that can happen is a lack

23
00:01:28,095 --> 00:01:30,438
of what is called generalization.

24
00:01:30,438 --> 00:01:35,650
When you create a machine learning model
and it works well in your experiments.

25
00:01:35,650 --> 00:01:40,320
But then fails to perform well
in production, the failure point

26
00:01:40,320 --> 00:01:45,173
will often involve how you created
the machine learning data set.

27
00:01:45,173 --> 00:01:50,871
So you will learn why you often need
three identically distributed datasets,

28
00:01:50,871 --> 00:01:54,940
and how to create them
in a repeatable way.

29
00:01:54,940 --> 00:01:59,740
Creating a machine learning dataset is
a practical skill its something that

30
00:01:59,740 --> 00:02:01,773
you do not want to short change.

31
00:02:01,773 --> 00:02:04,720
Give yourself time to absorb the lessons.

32
00:02:06,510 --> 00:02:10,679
So we will start our talking about the
historical evolution of machine learning.

33
00:02:10,679 --> 00:02:14,580
From its use in applications
like astronomy to now where

34
00:02:14,580 --> 00:02:18,979
it's used widely in commercial
applications to automate many

35
00:02:18,979 --> 00:02:23,190
tasks to argument the way
those applications work.

36
00:02:23,190 --> 00:02:25,971
For example,
machine learning is used to read

37
00:02:25,971 --> 00:02:30,050
house numbers from street view
images to add labels in Google Maps.

38
00:02:30,050 --> 00:02:34,797
But while talking about the historical
evolution, we'll also describe how

39
00:02:34,797 --> 00:02:39,545
deep learning techniques incorporate
many of those improvements brought on

40
00:02:39,545 --> 00:02:44,380
by earlier machine learning methods
like decision trees and random forests.

41
00:02:46,370 --> 00:02:51,267
In the optimization model, we will set
up a supervised learning problem and

42
00:02:51,267 --> 00:02:53,954
find a solution using gradient descent.

43
00:02:53,954 --> 00:02:57,051
Then, we will learn about
performance metrics and

44
00:02:57,051 --> 00:03:00,220
how to choose between different models.

45
00:03:00,220 --> 00:03:05,213
Finally, we'll wrap up the module by
developing an intuitive understanding

46
00:03:05,213 --> 00:03:06,580
of neural networks.

47
00:03:06,580 --> 00:03:12,300
You will explore the impact of things
like batch size and learning rate,

48
00:03:12,300 --> 00:03:16,726
using a cool tool called
the transfer flow playground.

49
00:03:16,726 --> 00:03:21,131
Good machine learning requires
that we create datasets and

50
00:03:21,131 --> 00:03:23,961
models that permit generalization.

51
00:03:23,961 --> 00:03:26,492
So we will talk about methods of doing so

52
00:03:26,492 --> 00:03:30,710
in a repeatable way which
supports experimentation.

53
00:03:30,710 --> 00:03:35,589
The entire purpose of machine learning
is to be able to make predictions

54
00:03:35,589 --> 00:03:36,902
based on new data.

55
00:03:36,902 --> 00:03:41,652
So it's very important that we do not
overfit our models on a historical

56
00:03:41,652 --> 00:03:43,640
training data.

57
00:03:43,640 --> 00:03:48,471
So if we have a generalized model that's
trained at images of meals, for example,

58
00:03:48,471 --> 00:03:51,576
then it should not expect
that all meals are plated and

59
00:03:51,576 --> 00:03:54,766
served on ceramic plates
like that dish of spaghetti.

60
00:03:54,766 --> 00:03:58,858
It should also be able to recognize
the home-style South Indian dishes on

61
00:03:58,858 --> 00:04:00,760
the bottom as also a meal.

62
00:04:00,760 --> 00:04:03,791
So that's what we mean by generalization.

63
00:04:03,791 --> 00:04:07,660
Just looking at the photograph
has made me hungry.

64
00:04:07,660 --> 00:04:09,968
I'll leave you in the great
hands of my colleagues.

65
00:04:09,968 --> 00:04:10,567
See you around.