1
00:00:00,000 --> 00:00:02,500
No que diz respeito ao
aprendizado a partir de dados,

2
00:00:02,500 --> 00:00:04,485
a Regressão Linear era basicamente isso.

3
00:00:04,485 --> 00:00:07,585
Até a década de 40, quando
um pesquisador chamado Frank Rosenblatt

4
00:00:07,585 --> 00:00:10,780
surge com um perceptron como
um modelo computacional de um neurônio

5
00:00:10,780 --> 00:00:14,285
no cérebro humano e mostra como ele
pode aprender funções simples.

6
00:00:16,225 --> 00:00:19,420
Tratava-se do que hoje
chamamos de Classificador Linear Binário,

7
00:00:19,420 --> 00:00:20,935
em que tentamos encontrar

8
00:00:20,935 --> 00:00:24,415
uma única linha que divide
os dados em duas classes.

9
00:00:24,415 --> 00:00:29,810
Uma camada de perceptrons seria a rede
neural feedforward mais simples possível.

10
00:00:30,380 --> 00:00:35,660
Entradas que alimentam perceptrons de uma
camada e uma soma ponderada serão feitas.

11
00:00:35,660 --> 00:00:40,075
Essa soma passaria
pela função de inativação,

12
00:00:40,075 --> 00:00:42,855
que é apenas 
uma função matemática que você aplica

13
00:00:42,855 --> 00:00:45,830
a cada elemento que
agora reside naquele neurônio.

14
00:00:45,830 --> 00:00:48,155
Mas, lembre-se de que, 
neste momento,

15
00:00:48,155 --> 00:00:50,820
isto é apenas um classificador linear.

16
00:00:50,820 --> 00:00:54,060
Portanto, a função de ativação,
que é linear neste caso,

17
00:00:54,060 --> 00:00:56,090
apenas retorna suas entradas.

18
00:00:56,090 --> 00:00:59,290
Comparar a saída dessa
função com um limite

19
00:00:59,290 --> 00:01:02,710
determinaria a qual classe
cada ponto pertence.

20
00:01:02,710 --> 00:01:07,355
Os erros seriam agregados e usados
para mudar os pesos usados na soma.

21
00:01:07,355 --> 00:01:10,890
E o processo se repetiria
até a convergência.

22
00:01:10,890 --> 00:01:13,680
Se você está tentando criar
um modelo simples de algo

23
00:01:13,680 --> 00:01:17,195
que aprende uma saída desejada
a partir de uma distribuição de entrada,

24
00:01:17,195 --> 00:01:18,825
não precisa ir longe.

25
00:01:18,825 --> 00:01:23,035
Nossos cérebros fazem isso o dia inteiro
para entender o mundo que nos cerca

26
00:01:23,035 --> 00:01:25,735
e todos os sinais que recebemos.

27
00:01:25,735 --> 00:01:28,545
Uma das principais
unidades do cérebro é o neurônio.

28
00:01:28,545 --> 00:01:30,970
As redes neurais são apenas
grupos de neurônios

29
00:01:30,970 --> 00:01:33,995
conectados em diferentes
padrões ou arquiteturas.

30
00:01:33,995 --> 00:01:37,560
Um neurônio biológico tem vários
componentes especializados em

31
00:01:37,560 --> 00:01:42,910
transmitir sinais elétricos que nos
permitem pensar, realizar ações

32
00:01:42,910 --> 00:01:46,050
e estudar o mundo fascinante do
aprendizado de máquina.

33
00:01:46,050 --> 00:01:50,280
Os sinais elétricos de outros neurônios,
como os sensoriais na retina dos olhos,

34
00:01:50,280 --> 00:01:52,700
são propagados de
neurônio em neurônio.

35
00:01:52,700 --> 00:01:55,775
O sinal de entrada é recebido
em uma das pontas do neurônio,

36
00:01:55,775 --> 00:01:57,485
que é composta de dendritos.

37
00:01:57,485 --> 00:02:02,240
Esses dendritos podem não só coletar
sinais elétricos de apenas um neurônio

38
00:02:02,240 --> 00:02:05,805
mas possivelmente de vários
que se somam em janelas

39
00:02:05,805 --> 00:02:09,107
a ponto de alterar
o potencial elétrico da célula.

40
00:02:09,107 --> 00:02:12,307
Um neurônio comum tem
um potencial elétrico em repouso

41
00:02:12,307 --> 00:02:14,450
de cerca de 70 milivolts negativos.

42
00:02:14,450 --> 00:02:17,925
À medida que os estímulos de entrada
recebidos nos dendritos aumentam,

43
00:02:17,925 --> 00:02:21,385
eles podem alcançar um limite
em torno de 55 milivolts negativos.

44
00:02:21,385 --> 00:02:24,595
Quando ocorre uma rápida
despolarização do axônio

45
00:02:24,595 --> 00:02:28,790
com várias portas de voltagem se abrindo
e permitindo um fluxo repentino de íons.

46
00:02:28,790 --> 00:02:32,665
Isso faz o neurônio disparar um potencial
de ação de corrente elétrica ao longo do

47
00:02:32,665 --> 00:02:37,820
axônio ajudado pela bainha de mielina
para melhor transmissão ao axônio.

48
00:02:37,820 --> 00:02:41,585
Aqui, os neurotransmissores
são liberados em sinapses

49
00:02:41,585 --> 00:02:46,560
que viajam pela fenda sináptica
para os dendritos de outros neurônios.

50
00:02:47,410 --> 00:02:49,650
Alguns dos neurotransmissores
são excitatórios

51
00:02:49,650 --> 00:02:51,730
e aumentam o potencial da próxima célula.

52
00:02:51,730 --> 00:02:55,195
Outros são inibitórios
e diminuem o potencial.

53
00:02:55,195 --> 00:03:00,820
O neurônio se repolariza a um potencial
menor que repouso por um tempo refratário.

54
00:03:00,820 --> 00:03:04,345
E o processo continua
no próximo neurônio até que alcança

55
00:03:04,345 --> 00:03:08,515
um neurônio motor e move a sua
mão para proteger os olhos do sol.

56
00:03:08,515 --> 00:03:13,155
E o que toda essa biologia e neurociência
têm a ver com o aprendizado de máquina?

57
00:03:13,975 --> 00:03:15,870
Parece familiar?

58
00:03:15,870 --> 00:03:18,710
Este é um perceptron de camada única.

59
00:03:18,710 --> 00:03:20,855
Assim como o neurônio,

60
00:03:20,855 --> 00:03:25,750
ele tem entradas que
multiplica por pesos e soma tudo.

61
00:03:25,750 --> 00:03:31,525
Aqui, o valor é comparado a um limite
e transformado por uma função de ativação.

62
00:03:31,525 --> 00:03:35,475
Por exemplo, se a soma
for maior ou igual a zero,

63
00:03:35,475 --> 00:03:39,210
ative ou pressione o valor de um.

64
00:03:39,210 --> 00:03:42,900
Do contrário, não ative
ou pressione um valor de zero.

65
00:03:42,900 --> 00:03:47,055
As entradas e os pesos são como os
neurotransmissores de um neurônio

66
00:03:47,055 --> 00:03:50,120
em que alguns podem
ser positivos e agregar à soma

67
00:03:50,120 --> 00:03:53,005
e outros podem ser
negativos e subtrair da soma.

68
00:03:53,005 --> 00:03:57,020
A função de etapa da unidade atua
como um limite de tudo ou nada.

69
00:03:57,020 --> 00:03:59,920
Se o limite for alcançado,
o sinal é transmitido.

70
00:03:59,920 --> 00:04:01,850
Do contrário,
nenhum sinal é transmitido.

71
00:04:02,380 --> 00:04:05,810
Por fim, há uma saída e,
como neurônios biológicos,

72
00:04:05,810 --> 00:04:07,910
isso pode realmente passar como entrada

73
00:04:07,910 --> 00:04:10,750
para outros neurônios em
um perceptron de várias camadas .

74
00:04:10,750 --> 00:04:12,710
Falaremos sobre isso em seguida.

75
00:04:12,710 --> 00:04:14,915
Isso tudo é muito legal,

76
00:04:14,915 --> 00:04:19,805
mas note que há funções
muito simples que não são aprendidas.

77
00:04:19,805 --> 00:04:22,270
Por exemplo, a função XOR.

78
00:04:22,270 --> 00:04:25,470
Marvin Minsky, um famoso
cientista da computação do MIT,

79
00:04:25,470 --> 00:04:29,970
ressaltou isso e ninguém
se interessou pela IA por 15 anos.

80
00:04:29,980 --> 00:04:32,555
Este não foi o primeiro
obstáculo das redes neurais

81
00:04:32,555 --> 00:04:34,985
que acabaram ficando
esquecidas por um tempo.

82
00:04:36,495 --> 00:04:42,375
Que componente do neurônio biológico é
análogo à entrada de um perceptron?

83
00:04:45,345 --> 00:04:48,065
A resposta correta
são os dendritos.

84
00:04:48,065 --> 00:04:50,600
Eles recebem estímulos
de outros neurônios,

85
00:04:50,600 --> 00:04:52,825
assim como em
uma rede neural artificial.

86
00:04:52,825 --> 00:04:57,725
Não é o axônio porque ele é
mais análogo à saída de um perceptron.

87
00:04:57,725 --> 00:05:01,735
Não é o núcleo porque ele
armazena o material genético celular

88
00:05:01,735 --> 00:05:03,755
e controla as atividades
das células.

89
00:05:03,755 --> 00:05:07,294
Não é a bainha de mielina porque
ela ajuda na transmissão do axônio,

90
00:05:07,294 --> 00:05:11,114
que, mais uma vez, fica na
saída do perceptron.