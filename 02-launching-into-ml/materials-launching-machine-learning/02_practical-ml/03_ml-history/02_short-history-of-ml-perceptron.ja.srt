1
00:00:00,000 --> 00:00:04,490
ここまで データから学習する
線形回帰について見てきました

2
00:00:04,490 --> 00:00:07,425
1940年代にフランク ローゼンブラットが

3
00:00:07,425 --> 00:00:10,540
人間の脳のニューロンの計算モデルとして

4
00:00:10,540 --> 00:00:12,490
パーセプトロンを考案し

5
00:00:12,490 --> 00:00:15,335
簡単な機能の学習方法を示しました

6
00:00:16,565 --> 00:00:19,430
今日ではこれをバイナリ線形分類器と呼びます

7
00:00:19,430 --> 00:00:24,155
データセットを 2つのクラスに分ける
1本の線を見つけることです

8
00:00:24,155 --> 00:00:27,015
ニューラルネットワークへのフィードとして

9
00:00:27,015 --> 00:00:30,370
単一層のパーセプトロンが最も単純です

10
00:00:30,380 --> 00:00:35,660
単一層パーセプトロンに入力が
送られて 加重合計されます

11
00:00:35,660 --> 00:00:40,195
次に この合計が いわゆる
不活性化関数を通過します

12
00:00:40,195 --> 00:00:43,745
これは そのニューロンにある
各要素に適用される

13
00:00:43,745 --> 00:00:45,830
単純な数学関数です

14
00:00:45,830 --> 00:00:48,065
ただし この時点では

15
00:00:48,065 --> 00:00:50,820
まだ線形分類器にすぎません

16
00:00:50,820 --> 00:00:53,940
この場合 活性化関数は線形で

17
00:00:53,940 --> 00:00:56,250
単に入力を返すだけです

18
00:00:56,250 --> 00:00:59,060
この出力をしきい値と比べて

19
00:00:59,060 --> 00:01:02,540
各ポイントが属するクラスを判別します

20
00:01:03,030 --> 00:01:07,385
誤差を集計し それを使って
合計の中の重みを調整します

21
00:01:07,385 --> 00:01:10,880
プロセスを収束するまで何度も繰り返します

22
00:01:10,880 --> 00:01:14,230
ある入力分布から理想的な出力を学習する

23
00:01:14,230 --> 00:01:16,755
単純なモデルを考案するとき

24
00:01:16,755 --> 00:01:21,175
遠くを探す必要はありません
私たちの脳が一日中これを行なって

25
00:01:21,175 --> 00:01:25,945
体から入ってくる周囲の世界の
シグナルを理解しているからです

26
00:01:25,945 --> 00:01:28,945
脳の基本単位の1つはニューロンです

27
00:01:28,945 --> 00:01:31,900
それをさまざまなパターンと構造で
互いに接続したのが

28
00:01:31,900 --> 00:01:34,365
ニューラルネットワークです

29
00:01:34,365 --> 00:01:38,250
生体ニューロンには
電気信号を渡す構成要素があり

30
00:01:38,250 --> 00:01:41,840
こうして あなたも私も
「考える」ことができます

31
00:01:41,840 --> 00:01:46,080
また体を動かしたり
機械学習の魅力を学んだりできます

32
00:01:46,420 --> 00:01:47,670
たとえば

33
00:01:47,670 --> 00:01:50,530
目の網膜の知覚ニューロンから出た電気信号が

34
00:01:50,530 --> 00:01:52,720
他のニューロンに伝わっていきます

35
00:01:52,720 --> 00:01:55,730
樹枝状のニューロンの一端で

36
00:01:55,730 --> 00:01:57,705
入力信号を受け取ります

37
00:01:57,705 --> 00:02:02,035
この樹枝部分では 他の1つ
または複数のニューロンから

38
00:02:02,035 --> 00:02:03,935
電気信号を集めます

39
00:02:03,935 --> 00:02:06,580
それが時間枠の中で集計され

40
00:02:06,580 --> 00:02:09,485
細胞の電位が変化します

41
00:02:09,485 --> 00:02:14,475
標準的なニューロンの休止時の電位は
約マイナス70ミリボルトです

42
00:02:14,475 --> 00:02:17,360
樹枝で受け取る入力刺激が増えると

43
00:02:17,360 --> 00:02:21,375
やがて 約マイナス55ミリボルトの
しきい値に達します

44
00:02:21,375 --> 00:02:24,595
こうして軸索の急速な減極が発生し

45
00:02:24,595 --> 00:02:28,785
大きな電圧が放たれてイオンが急に流れます

46
00:02:28,785 --> 00:02:32,850
こうしてニューロンは
電流の活動電位を 軸索に発し

47
00:02:32,850 --> 00:02:37,955
ミエリン鞘の助けで
軸索の終端にうまく伝えます

48
00:02:37,955 --> 00:02:41,540
ここで シナプスから神経伝達物質が放たれ

49
00:02:41,540 --> 00:02:43,935
シナプス間隙を伝わって

50
00:02:43,935 --> 00:02:47,090
通常は 他のニューロンの樹枝に達します

51
00:02:47,090 --> 00:02:49,570
神経伝達物質が興奮性であれば

52
00:02:49,570 --> 00:02:51,730
次の細胞の電位が高まり

53
00:02:51,730 --> 00:02:55,200
抑制的であれば電位が低くなります

54
00:02:55,200 --> 00:03:00,815
不応期では 休止時よりさらに低い電位に
ニューロンが再分極します

55
00:03:00,815 --> 00:03:03,650
さらに 次のニューロンにこのプロセスが続き

56
00:03:03,650 --> 00:03:08,775
やがて運動ニューロンに達して
目に入ってくる日光を 手で覆います

57
00:03:08,775 --> 00:03:13,885
さて この生物学や神経科学が
機械学習にどう関係するのでしょう

58
00:03:13,885 --> 00:03:15,705
どこかで見ましたね

59
00:03:15,895 --> 00:03:18,850
これは単一層パーセプトロンです

60
00:03:18,850 --> 00:03:21,030
ニューロンとよく似ています

61
00:03:21,030 --> 00:03:25,875
入力に重みを掛けてすべての入力を合計します

62
00:03:25,875 --> 00:03:28,510
その値をしきい値と比較して

63
00:03:28,510 --> 00:03:31,785
活性化関数で伝達します

64
00:03:31,925 --> 00:03:35,640
たとえば 合計がゼロ以上であれば

65
00:03:35,640 --> 00:03:39,265
活性化し 値1を押します

66
00:03:39,265 --> 00:03:43,030
そうでなければ非活性化し 値0を押します

67
00:03:43,030 --> 00:03:47,530
それぞれの入力と重みはニューロンの
神経伝達物質のように機能し

68
00:03:47,530 --> 00:03:50,165
正であれば合計に加えられ

69
00:03:50,165 --> 00:03:53,010
負であれば合計から差し引かれます

70
00:03:53,010 --> 00:03:57,015
ユニットのステップ関数は
全か無かのしきい値です

71
00:03:57,015 --> 00:03:59,850
しきい値に達したらシグナルを渡します

72
00:03:59,850 --> 00:04:02,080
達しなければ何も渡しません

73
00:04:02,460 --> 00:04:06,540
最後に 生体ニューロンのような
多層パーセプトロンでは

74
00:04:06,540 --> 00:04:10,800
出力が他のニューロンに入力として
渡されることがあります

75
00:04:10,800 --> 00:04:12,970
これについて次に説明します

76
00:04:12,970 --> 00:04:15,810
これはとても素晴らしいですが

77
00:04:15,810 --> 00:04:19,765
学習できない非常に単純な機能があります

78
00:04:19,765 --> 00:04:22,175
たとえばXOR関数です

79
00:04:22,175 --> 00:04:26,090
MITのマービン ミンスキーが
これを指摘し その後

80
00:04:26,090 --> 00:04:29,930
約15年間もAIを模索する人が現れませんでした

81
00:04:29,930 --> 00:04:33,460
ニューラルネットワークが
壁に当たって忘れ去られたのは

82
00:04:33,460 --> 00:04:35,525
これが初めてではありません

83
00:04:36,555 --> 00:04:42,345
生体ニューロンの中でパーセプトロンの
入力部分に似ているのはどこですか？

84
00:04:44,985 --> 00:04:47,805
正解は「樹枝」です

85
00:04:47,805 --> 00:04:50,405
他のニューロンから刺激を受け取ります

86
00:04:50,405 --> 00:04:52,860
人工ニューラルネットワークと同じです

87
00:04:52,860 --> 00:04:57,725
「軸索」は間違いです
パーセプトロンの出力に似ています

88
00:04:57,725 --> 00:05:01,735
「核」も間違いです
ここには細胞の遺伝物質があり

89
00:05:01,735 --> 00:05:03,875
細胞の活動を制御します

90
00:05:03,875 --> 00:05:06,105
「ミエリン鞘」も間違いです

91
00:05:06,105 --> 00:05:08,195
これは軸索の伝達を助けますから

92
00:05:08,195 --> 00:05:11,350
やはりパーセプトロンの出力部分に似ています