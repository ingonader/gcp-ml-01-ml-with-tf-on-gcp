ここまで データから学習する
線形回帰について見てきました 1940年代にフランク ローゼンブラットが 人間の脳のニューロンの計算モデルとして パーセプトロンを考案し 簡単な機能の学習方法を示しました 今日ではこれをバイナリ線形分類器と呼びます データセットを 2つのクラスに分ける
1本の線を見つけることです ニューラルネットワークへのフィードとして 単一層のパーセプトロンが最も単純です 単一層パーセプトロンに入力が
送られて 加重合計されます 次に この合計が いわゆる
不活性化関数を通過します これは そのニューロンにある
各要素に適用される 単純な数学関数です ただし この時点では まだ線形分類器にすぎません この場合 活性化関数は線形で 単に入力を返すだけです この出力をしきい値と比べて 各ポイントが属するクラスを判別します 誤差を集計し それを使って
合計の中の重みを調整します プロセスを収束するまで何度も繰り返します ある入力分布から理想的な出力を学習する 単純なモデルを考案するとき 遠くを探す必要はありません
私たちの脳が一日中これを行なって 体から入ってくる周囲の世界の
シグナルを理解しているからです 脳の基本単位の1つはニューロンです それをさまざまなパターンと構造で
互いに接続したのが ニューラルネットワークです 生体ニューロンには
電気信号を渡す構成要素があり こうして あなたも私も
「考える」ことができます また体を動かしたり
機械学習の魅力を学んだりできます たとえば 目の網膜の知覚ニューロンから出た電気信号が 他のニューロンに伝わっていきます 樹枝状のニューロンの一端で 入力信号を受け取ります この樹枝部分では 他の1つ
または複数のニューロンから 電気信号を集めます それが時間枠の中で集計され 細胞の電位が変化します 標準的なニューロンの休止時の電位は
約マイナス70ミリボルトです 樹枝で受け取る入力刺激が増えると やがて 約マイナス55ミリボルトの
しきい値に達します こうして軸索の急速な減極が発生し 大きな電圧が放たれてイオンが急に流れます こうしてニューロンは
電流の活動電位を 軸索に発し ミエリン鞘の助けで
軸索の終端にうまく伝えます ここで シナプスから神経伝達物質が放たれ シナプス間隙を伝わって 通常は 他のニューロンの樹枝に達します 神経伝達物質が興奮性であれば 次の細胞の電位が高まり 抑制的であれば電位が低くなります 不応期では 休止時よりさらに低い電位に
ニューロンが再分極します さらに 次のニューロンにこのプロセスが続き やがて運動ニューロンに達して
目に入ってくる日光を 手で覆います さて この生物学や神経科学が
機械学習にどう関係するのでしょう どこかで見ましたね これは単一層パーセプトロンです ニューロンとよく似ています 入力に重みを掛けてすべての入力を合計します その値をしきい値と比較して 活性化関数で伝達します たとえば 合計がゼロ以上であれば 活性化し 値1を押します そうでなければ非活性化し 値0を押します それぞれの入力と重みはニューロンの
神経伝達物質のように機能し 正であれば合計に加えられ 負であれば合計から差し引かれます ユニットのステップ関数は
全か無かのしきい値です しきい値に達したらシグナルを渡します 達しなければ何も渡しません 最後に 生体ニューロンのような
多層パーセプトロンでは 出力が他のニューロンに入力として
渡されることがあります これについて次に説明します これはとても素晴らしいですが 学習できない非常に単純な機能があります たとえばXOR関数です MITのマービン ミンスキーが
これを指摘し その後 約15年間もAIを模索する人が現れませんでした ニューラルネットワークが
壁に当たって忘れ去られたのは これが初めてではありません 生体ニューロンの中でパーセプトロンの
入力部分に似ているのはどこですか？ 正解は「樹枝」です 他のニューロンから刺激を受け取ります 人工ニューラルネットワークと同じです 「軸索」は間違いです
パーセプトロンの出力に似ています 「核」も間違いです
ここには細胞の遺伝物質があり 細胞の活動を制御します 「ミエリン鞘」も間違いです これは軸索の伝達を助けますから やはりパーセプトロンの出力部分に似ています