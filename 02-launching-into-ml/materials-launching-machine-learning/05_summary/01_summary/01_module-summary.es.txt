Felicitaciones por terminar
el curso de aprendizaje automático. Revisemos lo que aprendimos. Primero, vimos
que los sistemas de producción de Google se basan en años de experiencia. Repasamos la
evolución del AA en el tiempo, el desarrollo y la prominencia
de las redes neuronales profundas y por qué son la mejor opción
para una amplia gama de problemas. Por último, hablamos sobre cómo
TensorFlow y Cloud Machine Learning Engine aprovechan la experiencia
de Google con estos sistemas. Luego, buscamos el modelo
de AA óptimo en el espacio de parámetros usando el algoritmo de descenso
de gradientes para reducir las pérdidas. Ilustramos el entrenamiento de modelos usando el derivado
de las superficies de pérdida como guía a los valores mínimos. Recuerde que puede haber
más de un mínimo en superficies complejas. El descenso de gradientes es iterativo,
como vio en el bucle de entrenamiento. La idea es cambiar 
el peso de sus modelos un poco, reevaluarlos
y usarlos como guía direccional para reducir las superficies de pérdida
y cambiar los pesos progresivamente. Luego, presentamos
varias funciones de pérdidas, como RMSE para los problemas de regresión y la entropía cruzada
para la clasificación. Revisamos medidas de rendimiento, como la exactitud,
la precisión y la recuperación y analizamos ventajas y desventajas
de usarlas para informar al jefe. Luego, nos divertimos
en el área de prueba de TensorFlow. Examinamos los tamaños
de lotes pequeños, moderados y grandes y cuáles pueden generar
rendimiento poco uniforme en los modelos. Como cierre del módulo de optimización, entrenamos redes neuronales
para clasificar datos en espiral. Terminamos con un conjunto de nodos
y capas ocultas que parecía complejo. Para saber mejor si el modelo
tendría buen rendimiento en el mundo real, nos sumergimos
en el mundo de la generalización. Cuando logramos un modelo exacto
con un valor de RMSE de cero, vimos que tuvo un pésimo rendimiento
con un conjunto de datos que no conocía. Para hacer modelos generalizables
que no solo memoricen datos de prueba como le advertimos antes, dividimos el conjunto de datos original
en entrenamiento, evaluación y prueba y solo los presentamos al modelo
en momentos clave predefinidos. Luego, vimos
cómo crear subconjuntos de datos. Para ello, dividimos
y muestreamos el conjunto de datos de 70 millones de registros
de vuelos de manera repetible. Así, pudimos probar mejoras del modelo
y usar los mismos datos subyacentes en cada ejecución
de entrenamiento del modelo. Luego, en el lab sobre taxis,
descubrimos que los modelos de AA pueden generar
predicciones erradas por diversos motivos, como mala representación
de casos prácticos sobreajuste, subajuste, etcétera. Aprendimos que podemos medir la calidad del modelo
si examinamos sus predicciones. Eso fue todo. Siga practicando sus habilidades
de AA con estos labs prácticos. Lo veremos en el próximo curso.