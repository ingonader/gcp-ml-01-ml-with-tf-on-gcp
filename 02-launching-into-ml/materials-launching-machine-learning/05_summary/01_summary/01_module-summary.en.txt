Congratulations. You made it to the end of the Launching into ML course. Let's recap what we've learned so far. First up, we looked at how Google production systems are informed from years of experience. We then walked through the historical timeline of ML, and the growth and prominence of Deep Neural Networks, and why they are the best choice in a large variety of problems. Finally, we covered how TensorFlow and Cloud Machine Learning Engine build on the experience of Google creating all of these systems. Next, we searched through parameter space to find the optimal ML model, by using our gradient descent algorithm to walk down our loss surfaces. Here we Illustrated model training by taking the derivative of our loss services as our guide towards a minima. Keeping in mind, you could have more than one minima for complex services like you saw. This gradient descent process is an intuitive one as you saw on your training loop. The idea here is change the weights of your model slightly, and re-evaluate it, and use it as a directional guide walking down your loss services and changing your weights as you go. We then introduced multiple loss functions, like RMSE for regression problems, and cross entropy for classification. Then we looked at performance measures like accuracy, precision, and recall, and discussed the pros and cons for reporting to your boss with each. We then got to have some fun inside the TensorFlow playground when you looked at low, moderate, and high batch sizes, and then which of those can lead to inconsistent model performance. We concluded the optimization module by training neural networks to classify data points in a spiral. And we ended up with a seemingly complex set of nodes in hidden layers. And to better understand whether or not that model would perform well out in the real world, is where we headed into the world of generalization. Once we had the perfectly accurate model with an RMSE of zero, we saw how badly it performed against a set of new data that it had not seen before. To make our models generalize well and not simply memorize a train data set that we warned you about before, we split our original data set into training, evaluation, and testing, and show them only to the model at predefined milestones. We then discussed how to create these subsets of data by splitting and sampling our 70 million flight records data set in a repeatable fashion. This allowed us to experiment with model improvements, and keep the underlying data constant during each model training run. Then in our taxi lab, we discovered that ML models can make incorrect predictions for a variety of reasons. Poor representation of our use cases, overfitting, underfitting, what have you. We also learned that we can measure the quality remodel by examining the predictions it made. So that's it. Keep practicing your ML skills with these hands on labs if you want another go at them, and we'll see you in the next course.