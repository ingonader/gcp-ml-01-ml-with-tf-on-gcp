Parabéns! Você chegou ao fim do
curso "Launching into ML". Vamos relembrar o
que aprendeu até aqui. Primeiro, vimos como os sistemas de produção do Google acumulam
dados de anos de experiência. Depois, percorremos a linha
do tempo da história do ML e falamos sobre a importância
das redes neurais profundas e porque elas são a melhor
opção para vários problemas. Por fim, falamos sobre como o TensorFlow
e o Cloud Machine Learning Engine foram criados com base
na vasta experiência do Google. Depois, procuramos o espaço de parâmetros 
para encontrar o modelo de ML ideal usando o algoritmo de máximo declive
para analisar as superfícies de perda. Mostramos aqui o treinamento
do modelo usando a derivada dos serviços de perda como guia
para encontrar um mínimo. Lembre-se de que é possível ter
mais de um mínimo para serviços complexos. O processo de máximo declive é intuitivo,
assim como o que vimos no treinamento. A ideia é alterar um pouco os pesos, reavaliá-los e usá-los
como um guia de direção para calcular os serviços de perda
e fazer novas alterações. Depois, inserimos várias
funções de perda, como RMSD para problemas de regressão, e entropia cruzada para classificação. Em seguida, analisamos as
métricas de desempenho, como precisão e recall, e falamos sobre as vantagens
e desvantagens de cada uma. Depois, conhecemos um
pouco do TensorFlow, onde você viu tamanhos de lotes
pequenos, médios e grandes e aprendeu que todos podem gerar
modelos com desempenho inconsistente. Concluímos o modulo de otimização treinando redes neurais para
classificar pontos de dados em espiral. E, por último, vimos um conjunto complexo
de nodes em camadas ocultas. Assim, para entender se o modelo teria
um bom desempenho em um cenário real, estudamos um pouco
sobre a generalização. Como criamos um modelo
preciso com RMSE de zero, observamos que ele teve um desempenho
ruim em um novo conjunto de dados. Para que os modelos
tivessem uma boa generalização e não apenas memorizassem
o conjunto de dados treinado, dividimos o conjunto original
para treinamento, avaliação e teste e apresentamos a ele apenas
o modelo com predefinições. Depois, falamos sobre como criar
esses subconjuntos dividindo e fazendo a amostragem de 70 milhões
de dados de forma reproduzível. Isso permitiu realizar testes
com melhorias nos modelos e manter os dados subjacentes
constantes durante cada treinamento. Em seguida, descobrimos
no nosso laboratório que os modelos de ML fazem
previsões incorretas por vários motivos. Representação incorreta
dos casos de uso, sobreajuste ou subajuste. Também aprendemos
que podemos avaliar a qualidade do novo modelo
analisando as previsões dele. E é isso. Aprenda mais sobre ML
com esses laboratórios práticos. Vejo você no próximo curso.