Launching into MLコースも
終わりに近づいてきました 復習してみましょう まず Googleの本番環境システムに
蓄積された長年の経験について学びました 次に MLの歴史と ディープニューラルネットワークの進歩と普及 またそれらが
さまざまな問題に最適である理由を学び 最後に これらのシステム構築に関する
Googleの豊富な経験が TensorFlowと Cloud Machine Learning Engineに
どのように役立っているかを見てきました 次に 最適なMLモデルを見つけるために 勾配降下法アルゴリズムを使って
損失表面を確認し パラメータ空間を調べました モデルトレーニングの説明では 損失表面の導関数を使って
極小値を導き出しました 複雑なサービスでは
極小値が複数ある可能性がありましたね トレーニングループで見たように
勾配降下法は直観的なプロセスです モデルの重みを少しだけ変えて 再評価し その方向性に従って 損失表面を調べ 重み付けを変更していきます 次に いくつかの損失関数を紹介しました 回帰問題用の RMSEや 分類用の交差エントロピーなどです 次に 正解率、精度、再現率などの
パフォーマンス指標を学びました それぞれについて上司に報告することの
利点と欠点も考えました TensorFlow Playground は
面白かったですね バッチサイズの 小 中 大 を比較し モデルのパフォーマンスが
一貫しない場合があることを学びました 最適化モジュールの最後に
ニューラルネットワークのトレーニングをして データポイントを
渦巻きで分類しました 隠れ層に
複雑そうなノードセットがありましたね そして モデルが現実世界で
うまく機能するかどうか よりよく理解するために 一般化について考えました RMSEが0の完璧に正確なモデルがあっても 過去に見たことのない新しいデータセットには
うまく機能しません そのためトレーニングデータセットを
ただ記憶させるのではなく モデルが適切に一般化できるように 元のデータセットを
トレーニング、 評価、テストに分割し それらを 特定のマイルストーンでのみ
モデルに示しました 次に これらのデータのサブセットを
作る方法として 7千万件のフライト記録データセットを
反復可能な方法で分割し サンプリングしました これによりモデルの改善を試したり 各トレーニング実行中に
基礎データを一定に保ったりできました さらに タクシーのラボでは さまざまな理由で MLモデルが
間違った予測を出すことがわかりました ユースケースの表現が不十分だったり 適合しすぎ、適合不足、などの理由です また 品質を計測し モデルが出した予測を検査して
再モデル化を行いました 以上です さらに成長したい方は このハンズオン ラボで
MLスキルを学び続けてください 次のコースでお会いしましょう