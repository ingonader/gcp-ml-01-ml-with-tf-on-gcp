1
00:00:00,000 --> 00:00:03,980
Félicitations. Vous avez terminé le cours
"Mise en pratique du machine learning".

2
00:00:03,980 --> 00:00:06,230
Récapitulons
ce que nous avons appris jusqu'ici.

3
00:00:06,600 --> 00:00:09,755
D'abord, nous avons vu
que nos systèmes de production reposent

4
00:00:09,755 --> 00:00:11,300
sur des années d'expérience.

5
00:00:11,510 --> 00:00:13,755
Nous avons passé en revue
l'histoire du ML,

6
00:00:13,755 --> 00:00:16,815
et la croissance et l'importance
des réseaux de neurones profonds

7
00:00:16,815 --> 00:00:19,960
et pourquoi ils sont la meilleure solution
à de nombreux problèmes.

8
00:00:20,740 --> 00:00:24,350
Enfin, nous avons vu
comment TensorFlow et CMLE s'appuient

9
00:00:24,350 --> 00:00:27,290
sur l'expérience de Google
dans la création de ces systèmes.

10
00:00:27,740 --> 00:00:30,314
Puis, nous avons exploré
l'espace de paramètres

11
00:00:30,314 --> 00:00:32,210
pour trouver le modèle de ML optimal

12
00:00:32,210 --> 00:00:34,500
en utilisant l'algorithme
de descente de gradient

13
00:00:34,500 --> 00:00:36,420
pour observer nos services de perte.

14
00:00:36,420 --> 00:00:38,530
Nous avons illustré
l'entraînement de modèle

15
00:00:38,530 --> 00:00:40,745
en utilisant le dérivé
de nos services de perte

16
00:00:40,745 --> 00:00:42,410
comme guide
pour trouver le minimum.

17
00:00:42,410 --> 00:00:45,360
Il peut y avoir plusieurs minimums
pour les services complexes.

18
00:00:46,140 --> 00:00:50,115
Ce processus de descente de gradient
est intuitif, comme le montre le cours.

19
00:00:50,205 --> 00:00:54,305
L'idée est de modifier légèrement
les pondérations du modèle, de le réévaluer,

20
00:00:54,305 --> 00:00:57,615
et de l'utiliser comme guide
pour observer les services de perte

21
00:00:57,615 --> 00:00:59,464
et changer vos pondérations.

22
00:01:00,084 --> 00:01:02,540
Nous avons parlé
de différentes fonctions de perte,

23
00:01:02,540 --> 00:01:04,970
comme la RMSE
pour les problèmes de régression

24
00:01:04,970 --> 00:01:07,070
et l'entropie croisée
pour la classification.

25
00:01:07,260 --> 00:01:09,230
Nous avons vu des mesures de performance,

26
00:01:09,230 --> 00:01:11,330
comme la justesse,
la précision et le rappel,

27
00:01:11,330 --> 00:01:14,430
et les avantages et inconvénients
à indiquer à votre responsable.

28
00:01:15,220 --> 00:01:18,300
Nous nous sommes amusés
dans TensorFlow Playground,

29
00:01:18,300 --> 00:01:21,600
avec des tailles de lot
petites, moyennes et grandes,

30
00:01:21,600 --> 00:01:25,040
et avons trouvé lesquels pouvaient
générer des performances incohérentes.

31
00:01:25,040 --> 00:01:27,180
Nous avons conclu
le module sur l'optimisation

32
00:01:27,180 --> 00:01:28,945
en entraînant des réseaux de neurones

33
00:01:28,945 --> 00:01:30,800
pour classer les points en une spirale.

34
00:01:30,800 --> 00:01:34,700
Nous avons obtenu un ensemble complexe
de nœuds avec des couches cachées.

35
00:01:34,780 --> 00:01:38,535
Et pour mieux comprendre si ce modèle
fonctionnerait en conditions réelles,

36
00:01:38,535 --> 00:01:41,560
nous avons parlé de la généralisation.

37
00:01:42,740 --> 00:01:45,920
Après avoir trouvé un modèle juste
avec une RMSE de zéro,

38
00:01:45,920 --> 00:01:48,060
nous avons constaté
ses mauvaises performances

39
00:01:48,060 --> 00:01:50,795
avec un nouvel ensemble
de données inconnu.

40
00:01:51,175 --> 00:01:54,370
Pour que nos modèles puissent
généraliser et pas seulement mémoriser

41
00:01:54,370 --> 00:01:56,245
un ensemble de données d'entraînement,

42
00:01:56,245 --> 00:02:00,190
nous avons divisé l'ensemble d'origine
en trois ensembles distincts,

43
00:02:00,190 --> 00:02:03,225
et ne les avons montrés au modèle
qu'à des étapes prédéfinies.

44
00:02:04,695 --> 00:02:07,415
Nous avons vu comment créer
ces sous-ensembles de données

45
00:02:07,415 --> 00:02:11,080
en fractionnant et échantillonnant
nos 70 millions d'enregistrements de vol

46
00:02:11,080 --> 00:02:12,225
de façon reproductible.

47
00:02:12,645 --> 00:02:14,985
Nous avons testé l'amélioration de modèles

48
00:02:14,985 --> 00:02:18,265
et maintenu constantes les données
pendant chaque entraînement.

49
00:02:19,565 --> 00:02:20,950
Dans l'atelier sur les taxis,

50
00:02:20,950 --> 00:02:24,570
nous avons vu que les modèles de ML
peuvent faire des prédictions incorrectes

51
00:02:24,570 --> 00:02:25,760
pour différentes raisons.

52
00:02:25,760 --> 00:02:27,900
Mauvaise représentation
des cas d'utilisation,

53
00:02:27,900 --> 00:02:29,940
surapprentissage, sous-apprentissage, etc.

54
00:02:30,170 --> 00:02:32,930
Nous avons appris qu'on peut
évaluer la qualité d'un modèle

55
00:02:32,930 --> 00:02:34,320
en examinant ses prédictions.

56
00:02:34,911 --> 00:02:36,251
C'est tout pour aujourd'hui.

57
00:02:36,251 --> 00:02:39,879
Continuez à vous entraîner
en refaisant ces ateliers.

58
00:02:40,009 --> 00:02:41,739
À bientôt dans le prochain cours.