Glückwunsch! Sie haben es bis zum Ende
des Kurses "Launching into ML" geschafft! Fassen wir zusammen,
was Sie bisher gelernt haben. Zuerst haben wir uns angesehen, wie Google-Produktionssysteme über Jahre
Informationen sammeln konnten. Dann behandelten wir die
Geschichte von ML und das Wachstum und die Bedeutung von
Deep-Learning-Netzwerken und warum diese die beste Lösung
für zahlreiche Probleme sind. Abschließend haben wir behandelt, wie TensorFlow und
Cloud Machine Learning Engine auf der Erfahrung von Google bei der 
Erstellung dieser Systeme aufbauen. Wir durchsuchten den Parameterbereich,
um das ideale ML-Modell zu finden. Wir nutzten
den Gradientenabstiegsalgorithmus zur Betrachtung der Verlustdienste. Wir zeigten ein Modelltraining,
indem wir eine Ableitung unserer Verlustdienste als Orientierung
in Richtung Minima verwenden. Es könnte sein, dass es mehr als
ein Minimum für komplexe Dienste gibt. Der Gradientenabstiegsprozess ist, wie in 
der Trainingsschleife gezeigt, intuitiv. Die Idee ist, die Gewichtung Ihres
Modells zu verändern und neu zu evaluieren und als direktionale
Orientierung zur Betrachtung Ihrer Verlustdienste zu nutzen
und die Gewichtung zu ändern. Wir haben dann 
multiple Verlustfunktionen eingesetzt wie RMSE bei Regressionsproblemen und Kreuzentropie für die Klassifizierung. Wir sahen uns Leistungsmesswerte wie 
Genauigkeit, Präzision und Trefferquote an und haben die Vor- und Nachteile
für das Reporting an den Chef diskutiert. Wir haben einige interessante Einblicke in TensorFlow erhalten und uns kleinere, mittlere und große
Batch-Größen angesehen und welche davon zu einer inkonsistenten
Leistung des Modells führen können. Wir haben das Optimierungsmodul beendet,
indem wir neuronale Netzwerke trainierten, um Datenpunkte
in einer Spirale zu klassifizieren, und haben dann einen scheinbar komplexen 
Knotensatz in versteckten Ebenen erhalten. Um besser zu verstehen, ob ein Modell in der Realität
gut oder schlecht funktioniert, haben wir uns das 
Thema "Verallgemeinerung" angesehen. Als wir das exakte Modell mit einem
RMSE von null hatten, sahen wir, wie schlecht es bei einem unbekannten
neuen Satz von Daten abgeschnitten hat. Um unsere Modelle zu
verallgemeinern und nicht nur einen trainierten Datensatz zu speichern,
wovor wir zuvor gewarnt hatten, teilen wir unseren Original-Datensatz in
Training, Evaluierung und Test auf und zeigen sie dem Modell
an festgelegten Meilensteinen. Wir haben besprochen, wie wir
eine Teilmenge der Daten erstellen, indem wir unseren Datensatz
mit 70 Millionen Flugeinträgen auf wiederholbare Weise aufteilen
und Stichproben erfassen. So konnten wir mit Modellverbesserungen
experimentieren und dabei die zugrunde liegenden Daten
bei jedem Trainingslauf konstant halten. In unserem Taxi-Lab haben wir entdeckt, dass es viele Gründe für
falsche Vorhersagen von ML-Modellen gibt. Eine schlechte Darstellung
unserer Anwendungsfälle, Überanpassung, Unteranpassung usw. Wir haben auch gelernt, wie wir die 
Qualitätsanpassung messen können, indem wir uns die 
gemachten Vorhersagen ansehen. Das wars. Trainieren Sie weiterhin Ihre
ML-Fähigkeiten mit diesen praktischen Labs und wir sehen uns im nächsten Kurs!