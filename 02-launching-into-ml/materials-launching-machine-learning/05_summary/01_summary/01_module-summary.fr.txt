Félicitations. Vous avez terminé le cours
"Mise en pratique du machine learning". Récapitulons
ce que nous avons appris jusqu'ici. D'abord, nous avons vu
que nos systèmes de production reposent sur des années d'expérience. Nous avons passé en revue
l'histoire du ML, et la croissance et l'importance
des réseaux de neurones profonds et pourquoi ils sont la meilleure solution
à de nombreux problèmes. Enfin, nous avons vu
comment TensorFlow et CMLE s'appuient sur l'expérience de Google
dans la création de ces systèmes. Puis, nous avons exploré
l'espace de paramètres pour trouver le modèle de ML optimal en utilisant l'algorithme
de descente de gradient pour observer nos services de perte. Nous avons illustré
l'entraînement de modèle en utilisant le dérivé
de nos services de perte comme guide
pour trouver le minimum. Il peut y avoir plusieurs minimums
pour les services complexes. Ce processus de descente de gradient
est intuitif, comme le montre le cours. L'idée est de modifier légèrement
les pondérations du modèle, de le réévaluer, et de l'utiliser comme guide
pour observer les services de perte et changer vos pondérations. Nous avons parlé
de différentes fonctions de perte, comme la RMSE
pour les problèmes de régression et l'entropie croisée
pour la classification. Nous avons vu des mesures de performance, comme la justesse,
la précision et le rappel, et les avantages et inconvénients
à indiquer à votre responsable. Nous nous sommes amusés
dans TensorFlow Playground, avec des tailles de lot
petites, moyennes et grandes, et avons trouvé lesquels pouvaient
générer des performances incohérentes. Nous avons conclu
le module sur l'optimisation en entraînant des réseaux de neurones pour classer les points en une spirale. Nous avons obtenu un ensemble complexe
de nœuds avec des couches cachées. Et pour mieux comprendre si ce modèle
fonctionnerait en conditions réelles, nous avons parlé de la généralisation. Après avoir trouvé un modèle juste
avec une RMSE de zéro, nous avons constaté
ses mauvaises performances avec un nouvel ensemble
de données inconnu. Pour que nos modèles puissent
généraliser et pas seulement mémoriser un ensemble de données d'entraînement, nous avons divisé l'ensemble d'origine
en trois ensembles distincts, et ne les avons montrés au modèle
qu'à des étapes prédéfinies. Nous avons vu comment créer
ces sous-ensembles de données en fractionnant et échantillonnant
nos 70 millions d'enregistrements de vol de façon reproductible. Nous avons testé l'amélioration de modèles et maintenu constantes les données
pendant chaque entraînement. Dans l'atelier sur les taxis, nous avons vu que les modèles de ML
peuvent faire des prédictions incorrectes pour différentes raisons. Mauvaise représentation
des cas d'utilisation, surapprentissage, sous-apprentissage, etc. Nous avons appris qu'on peut
évaluer la qualité d'un modèle en examinant ses prédictions. C'est tout pour aujourd'hui. Continuez à vous entraîner
en refaisant ces ateliers. À bientôt dans le prochain cours.