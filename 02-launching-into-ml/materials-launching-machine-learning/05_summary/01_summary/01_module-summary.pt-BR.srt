1
00:00:00,000 --> 00:00:03,980
Parabéns! Você chegou ao fim do
curso "Launching into ML".

2
00:00:03,980 --> 00:00:06,300
Vamos relembrar o
que aprendeu até aqui.

3
00:00:06,300 --> 00:00:08,039
Primeiro, vimos como os sistemas

4
00:00:08,039 --> 00:00:11,535
de produção do Google acumulam
dados de anos de experiência.

5
00:00:11,535 --> 00:00:14,110
Depois, percorremos a linha
do tempo da história do ML

6
00:00:14,110 --> 00:00:16,785
e falamos sobre a importância
das redes neurais profundas

7
00:00:16,785 --> 00:00:20,155
e porque elas são a melhor
opção para vários problemas.

8
00:00:20,155 --> 00:00:23,940
Por fim, falamos sobre como o TensorFlow
e o Cloud Machine Learning Engine

9
00:00:23,940 --> 00:00:27,480
foram criados com base
na vasta experiência do Google.

10
00:00:27,480 --> 00:00:32,174
Depois, procuramos o espaço de parâmetros 
para encontrar o modelo de ML ideal

11
00:00:32,174 --> 00:00:36,060
usando o algoritmo de máximo declive
para analisar as superfícies de perda.

12
00:00:36,060 --> 00:00:39,000
Mostramos aqui o treinamento
do modelo usando a derivada

13
00:00:39,000 --> 00:00:41,850
dos serviços de perda como guia
para encontrar um mínimo.

14
00:00:41,850 --> 00:00:45,730
Lembre-se de que é possível ter
mais de um mínimo para serviços complexos.

15
00:00:45,730 --> 00:00:50,025
O processo de máximo declive é intuitivo,
assim como o que vimos no treinamento.

16
00:00:50,025 --> 00:00:53,200
A ideia é alterar um pouco os pesos,

17
00:00:53,200 --> 00:00:56,520
reavaliá-los e usá-los
como um guia de direção

18
00:00:56,520 --> 00:00:59,605
para calcular os serviços de perda
e fazer novas alterações.

19
00:00:59,605 --> 00:01:02,545
Depois, inserimos várias
funções de perda,

20
00:01:02,545 --> 00:01:04,834
como RMSD para problemas de regressão,

21
00:01:04,834 --> 00:01:07,070
e entropia cruzada para classificação.

22
00:01:07,070 --> 00:01:09,580
Em seguida, analisamos as
métricas de desempenho,

23
00:01:09,580 --> 00:01:11,300
como precisão e recall,

24
00:01:11,300 --> 00:01:14,640
e falamos sobre as vantagens
e desvantagens de cada uma.

25
00:01:14,640 --> 00:01:17,840
Depois, conhecemos um
pouco do TensorFlow,

26
00:01:17,840 --> 00:01:21,640
onde você viu tamanhos de lotes
pequenos, médios e grandes

27
00:01:21,660 --> 00:01:24,940
e aprendeu que todos podem gerar
modelos com desempenho inconsistente.

28
00:01:24,940 --> 00:01:26,870
Concluímos o modulo de otimização

29
00:01:26,870 --> 00:01:30,610
treinando redes neurais para
classificar pontos de dados em espiral.

30
00:01:30,610 --> 00:01:34,715
E, por último, vimos um conjunto complexo
de nodes em camadas ocultas.

31
00:01:34,715 --> 00:01:38,490
Assim, para entender se o modelo teria
um bom desempenho em um cenário real,

32
00:01:38,510 --> 00:01:42,285
estudamos um pouco
sobre a generalização.

33
00:01:42,585 --> 00:01:46,040
Como criamos um modelo
preciso com RMSE de zero,

34
00:01:46,040 --> 00:01:51,020
observamos que ele teve um desempenho
ruim em um novo conjunto de dados.

35
00:01:51,020 --> 00:01:53,480
Para que os modelos
tivessem uma boa generalização

36
00:01:53,480 --> 00:01:56,215
e não apenas memorizassem
o conjunto de dados treinado,

37
00:01:56,215 --> 00:02:00,110
dividimos o conjunto original
para treinamento, avaliação e teste

38
00:02:00,110 --> 00:02:04,265
e apresentamos a ele apenas
o modelo com predefinições.

39
00:02:04,485 --> 00:02:08,020
Depois, falamos sobre como criar
esses subconjuntos dividindo e

40
00:02:08,020 --> 00:02:12,555
fazendo a amostragem de 70 milhões
de dados de forma reproduzível.

41
00:02:12,705 --> 00:02:15,295
Isso permitiu realizar testes
com melhorias nos modelos

42
00:02:15,295 --> 00:02:19,090
e manter os dados subjacentes
constantes durante cada treinamento.

43
00:02:19,540 --> 00:02:21,675
Em seguida, descobrimos
no nosso laboratório

44
00:02:21,675 --> 00:02:25,615
que os modelos de ML fazem
previsões incorretas por vários motivos.

45
00:02:25,615 --> 00:02:27,690
Representação incorreta
dos casos de uso,

46
00:02:27,690 --> 00:02:30,220
sobreajuste ou subajuste.

47
00:02:30,330 --> 00:02:32,070
Também aprendemos
que podemos avaliar

48
00:02:32,070 --> 00:02:34,910
a qualidade do novo modelo
analisando as previsões dele.

49
00:02:35,040 --> 00:02:36,160
E é isso.

50
00:02:36,160 --> 00:02:39,710
Aprenda mais sobre ML
com esses laboratórios práticos.

51
00:02:39,710 --> 00:02:42,000
Vejo você no próximo curso.