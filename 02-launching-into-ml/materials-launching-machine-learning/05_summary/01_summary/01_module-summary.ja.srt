1
00:00:00,000 --> 00:00:04,380
Launching into MLコースも
終わりに近づいてきました

2
00:00:04,380 --> 00:00:06,300
復習してみましょう

3
00:00:06,300 --> 00:00:11,139
まず Googleの本番環境システムに
蓄積された長年の経験について学びました

4
00:00:11,139 --> 00:00:13,910
次に MLの歴史と

5
00:00:13,910 --> 00:00:17,155
ディープニューラルネットワークの進歩と普及

6
00:00:17,155 --> 00:00:20,930
またそれらが
さまざまな問題に最適である理由を学び

7
00:00:20,930 --> 00:00:24,350
最後に これらのシステム構築に関する
Googleの豊富な経験が

8
00:00:24,350 --> 00:00:27,480
TensorFlowと Cloud Machine Learning Engineに
どのように役立っているかを見てきました

9
00:00:27,480 --> 00:00:30,514
次に 最適なMLモデルを見つけるために

10
00:00:30,514 --> 00:00:33,814
勾配降下法アルゴリズムを使って
損失表面を確認し

11
00:00:33,814 --> 00:00:36,060
パラメータ空間を調べました

12
00:00:36,060 --> 00:00:38,150
モデルトレーニングの説明では

13
00:00:38,150 --> 00:00:41,850
損失表面の導関数を使って
極小値を導き出しました

14
00:00:41,850 --> 00:00:45,730
複雑なサービスでは
極小値が複数ある可能性がありましたね

15
00:00:45,730 --> 00:00:50,235
トレーニングループで見たように
勾配降下法は直観的なプロセスです

16
00:00:50,235 --> 00:00:53,380
モデルの重みを少しだけ変えて 再評価し

17
00:00:53,380 --> 00:00:56,800
その方向性に従って 損失表面を調べ

18
00:00:56,800 --> 00:00:59,605
重み付けを変更していきます

19
00:00:59,605 --> 00:01:02,545
次に いくつかの損失関数を紹介しました

20
00:01:02,545 --> 00:01:04,504
回帰問題用の RMSEや

21
00:01:04,504 --> 00:01:07,110
分類用の交差エントロピーなどです

22
00:01:07,110 --> 00:01:11,430
次に 正解率、精度、再現率などの
パフォーマンス指標を学びました

23
00:01:11,430 --> 00:01:14,800
それぞれについて上司に報告することの
利点と欠点も考えました

24
00:01:14,800 --> 00:01:18,180
TensorFlow Playground は
面白かったですね

25
00:01:18,180 --> 00:01:21,520
バッチサイズの 小 中 大 を比較し

26
00:01:21,520 --> 00:01:24,680
モデルのパフォーマンスが
一貫しない場合があることを学びました

27
00:01:24,680 --> 00:01:28,270
最適化モジュールの最後に
ニューラルネットワークのトレーニングをして

28
00:01:28,270 --> 00:01:30,690
データポイントを
渦巻きで分類しました

29
00:01:30,690 --> 00:01:34,385
隠れ層に
複雑そうなノードセットがありましたね

30
00:01:34,385 --> 00:01:37,940
そして モデルが現実世界で
うまく機能するかどうか

31
00:01:37,940 --> 00:01:39,800
よりよく理解するために

32
00:01:39,800 --> 00:01:42,025
一般化について考えました

33
00:01:42,025 --> 00:01:45,500
RMSEが0の完璧に正確なモデルがあっても

34
00:01:45,500 --> 00:01:50,035
過去に見たことのない新しいデータセットには
うまく機能しません

35
00:01:50,035 --> 00:01:53,960
そのためトレーニングデータセットを
ただ記憶させるのではなく

36
00:01:53,960 --> 00:01:56,135
モデルが適切に一般化できるように

37
00:01:56,135 --> 00:02:00,120
元のデータセットを
トレーニング、 評価、テストに分割し

38
00:02:00,120 --> 00:02:04,225
それらを 特定のマイルストーンでのみ
モデルに示しました

39
00:02:04,225 --> 00:02:07,360
次に これらのデータのサブセットを
作る方法として

40
00:02:07,360 --> 00:02:12,765
7千万件のフライト記録データセットを
反復可能な方法で分割し サンプリングしました

41
00:02:12,765 --> 00:02:15,025
これによりモデルの改善を試したり

42
00:02:15,025 --> 00:02:19,090
各トレーニング実行中に
基礎データを一定に保ったりできました

43
00:02:19,090 --> 00:02:21,295
さらに タクシーのラボでは

44
00:02:21,295 --> 00:02:25,535
さまざまな理由で MLモデルが
間違った予測を出すことがわかりました

45
00:02:25,535 --> 00:02:27,470
ユースケースの表現が不十分だったり

46
00:02:27,470 --> 00:02:29,980
適合しすぎ、適合不足、などの理由です

47
00:02:29,980 --> 00:02:31,810
また 品質を計測し

48
00:02:31,810 --> 00:02:34,850
モデルが出した予測を検査して
再モデル化を行いました

49
00:02:34,850 --> 00:02:36,020
以上です

50
00:02:36,020 --> 00:02:37,390
さらに成長したい方は

51
00:02:37,390 --> 00:02:40,490
このハンズオン ラボで
MLスキルを学び続けてください

52
00:02:40,499 --> 00:02:42,799
次のコースでお会いしましょう